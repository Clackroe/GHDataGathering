{"id": "ROOT0", "user": "acoutts", "root": "ROOT0", "reply_to": null, "timestamp": "2020-07-14T13:28:24Z", "text": "Extreme jank on iOS/Android the first time any kind of animation or transition runs (release build) - skia shader compilation ## Steps to Reproduce\r \r <!-- You must include full steps to reproduce so that we can reproduce the problem. -->\r \r 1. Install and run your app on a recent iOS device using a release build.\r \r **Expected results:** <!-- what did you want to see? -->\r Flutter apps should be just as buttery as native apps, especially on the first run when it's the customer's first time opening the app getting their first impression of it.\r \r **Actual results:** <!-- what did you see? -->\r The very first start after installing is extremely janky and laggy. The next time you start it, it will be sort of fine. After a few more starts it will be smooth.\r \r * Yes this is a release build of the app.\r \r Here are some gifs for examples on an iPhone 8 running iOS 13.5.1.\r \r ### Very first time starting the app after a fresh install\r * Notice most of the frames after the splash screen and before the screen slides up are dropped. This has the most jank (first run).\r * You can really see the jank when the loader animation stops (when that screen is disposed) and the next screen starts to slide up, but it just kind of appears with no frames in between.\r ![first-open](https://user-images.githubusercontent.com/9597207/87430036-9c93bd80-c5b2-11ea-8abb-ecd8545fe0b3.gif)\r \r ### Second time opening the app\r * The second time opening the app you can see the initial transition is _better_ but there is still some very noticeable jank as the screen slides up from the bottom.\r ![2nd-open](https://user-images.githubusercontent.com/9597207/87430055-a4536200-c5b2-11ea-9422-824dc1e9bdf7.gif)\r \r ### Third time opening the app\r * Now the third time and every time going forward it is smooth just like you'd expect.\r * But if you uninstall or update the app, then it will be janky again until the 2nd or 3rd time you open/use\r ![3rd-open](https://user-images.githubusercontent.com/9597207/87430111-b9c88c00-c5b2-11ea-8898-187186f553f5.gif)\r  it.\r \r ### Screen transitions example\r The same thing happens for screen transitions too.\r * The first time you run a new screen transition it will be laggy.\r * All future screen transitions of the same type are smooth.\r * If you use a different kind of transition somewhere in your app, that one will be laggy too the first time it runs.\r ![screens](https://user-images.githubusercontent.com/9597207/87430542-59861a00-c5b3-11ea-9b42-0fa5d93bafa5.gif)\r \r I have already tried following this doc related to SkSL caching: https://github.com/flutter/flutter/wiki/Reduce-shader-compilation-jank-using-SkSL-warm-up\r It fixed some of the first start jank issues on Android but has no effect on iOS (likely because of metal which is mentioned there). It also kind of is a bummer that if I want my app to be buttery smooth, I will always need to write integration tests (or do it manually) and save a dump of every transition / animation, and ensure to keep that skia shader capture file updated every time I change my app.\r \r To be completely honest, this is not acceptable to ship the app in its current state and I am disappointed I got this far with Flutter (7+ months) before I noticed or even heard of this kind of issue. It seems to not be Flutter's fault but Skia's, but still I think new devs should know this problem exists before they get neck deep into it. It's the kind of thing you won't notice until you have a somewhat significantly-sized app and can easily overlook at first.\r \r I really hope this can be fixed soon because it has an extremely detrimental effect on the perceived quality of your app when it's this laggy the very first time you open it, especially on brand new ios devices where native apps don't lag at all.\r \r ### Related issues\r https://github.com/flutter/flutter/issues/53607\r https://github.com/flutter/flutter/issues/60365\r https://github.com/flutter/flutter/issues/60315\r \r \r <details>\r   <summary>Logs</summary>\r \r <!--\r       Run your application with `flutter run --verbose` and attach all the\r       log output below between the lines with the backticks. If there is an\r       exception, please see if the error message includes enough information\r       to explain how to solve the issue.\r -->\r \r ```\r ```\r \r <!--\r      Run `flutter analyze` and attach any output of that command below.\r      If there are any analysis errors, try resolving them before filing this issue.\r -->\r \r ```\r ```\r \r <!-- Finally, paste the output of running `flutter doctor -v` here. -->\r \r ```\r [\u2713] Flutter (Channel dev, 1.20.0-7.1.pre, on Mac OS X 10.15.5 19F101, locale en-US)\r     \u2022 Flutter version 1.20.0-7.1.pre at /Users/andrewcoutts/Projects/flutter\r     \u2022 Framework revision 7736f3bc90 (4 days ago), 2020-07-10 16:33:05 -0700\r     \u2022 Engine revision d48085141c\r     \u2022 Dart version 2.9.0 (build 2.9.0-21.2.beta)\r \r  \r [\u2713] Android toolchain - develop for Android devices (Android SDK version 29.0.3)\r     \u2022 Android SDK at /Users/andrewcoutts/Library/Android/sdk\r     \u2022 Platform android-30, build-tools 29.0.3\r     \u2022 ANDROID_HOME = /Users/andrewcoutts/Library/Android/sdk\r     \u2022 Java binary at: /Applications/Android Studio.app/Contents/jre/jdk/Contents/Home/bin/java\r     \u2022 Java version OpenJDK Runtime Environment (build 1.8.0_242-release-1644-b3-6222593)\r     \u2022 All Android licenses accepted.\r \r [\u2713] Xcode - develop for iOS and macOS (Xcode 11.5)\r     \u2022 Xcode at /Applications/Xcode.app/Contents/Developer\r     \u2022 Xcode 11.5, Build version 11E608c\r     \u2022 CocoaPods version 1.9.3\r \r [\u2713] Chrome - develop for the web\r     \u2022 Chrome at /Applications/Google Chrome.app/Contents/MacOS/Google Chrome\r \r [\u2713] Android Studio (version 4.0)\r     \u2022 Android Studio at /Applications/Android Studio.app/Contents\r     \u2022 Flutter plugin version 45.1.1\r     \u2022 Dart plugin version 192.7761\r     \u2022 Java version OpenJDK Runtime Environment (build 1.8.0_242-release-1644-b3-6222593)\r \r [\u2713] VS Code (version 1.46.1)\r     \u2022 VS Code at /Applications/Visual Studio Code.app/Contents\r     \u2022 Flutter extension version 3.12.1\r \r [\u2713] Connected device (6 available)\r     \u2022 Android SDK built for x86 64 (mobile) \u2022 emulator-5554                            \u2022 android-x64    \u2022 Android 10 (API 29) (emulator)\r     \u2022 xFF0C 8 (mobile)                      \u2022 d7cab5675167dcdab847995b631648e5c309e1d3 \u2022 ios            \u2022 iOS 13.5.1\r     \u2022 iPhone 11 Pro Max (mobile)            \u2022 47044AC1-723C-4435-B3F7-D820DB72A023     \u2022 ios            \u2022 com.apple.CoreSimulator.SimRuntime.iOS-13-5 (simulator)\r     \u2022 macOS (desktop)                       \u2022 macos                                    \u2022 darwin-x64     \u2022 Mac OS X 10.15.5 19F101\r     \u2022 Web Server (web)                      \u2022 web-server                               \u2022 web-javascript \u2022 Flutter Tools\r     \u2022 Chrome (web)                          \u2022 chrome                                   \u2022 web-javascript \u2022 Google Chrome 83.0.4103.116\r \r \u2022 No issues found!\r ```\r \r </details>\r ", "meta": {"posReactions": "111", "negReactions": "0"}}
{"id": "COM00", "user": "acoutts", "root": "ROOT0", "reply_to": "ROOT0", "timestamp": "2020-07-14T13:30:00Z", "text": "cc @liyuqian", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM01", "user": "acoutts", "root": "ROOT0", "reply_to": "COM00", "timestamp": "2020-07-14T14:52:41Z", "text": "Some additional findings:\r\n* When I slow the global animation speed down by 50x (`timeDilation = 50`), I can see it's only the very first frame of the animation that is dropped.\r\n* After that initial jank, it is smooth for the rest of the (very slowed down) animation.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM02", "user": "acoutts", "root": "ROOT0", "reply_to": "COM01", "timestamp": "2020-07-14T15:24:12Z", "text": "Looking closer at the slowed down animations (this time `timeDilation = 25`), I think it is worse than I thought in the last comment because you can see it skip more than a few times.\r\n\r\n### First app open\r\nIt seems to skip more than once here.\r\n![ezgif-4-a92356a7cc45](https://user-images.githubusercontent.com/9597207/87444175-7119ce80-c5c4-11ea-8a9b-e68aabc26fa8.gif)\r\n\r\n### First screen transition\r\nThis one is not as bad, I just see two skips.\r\n![ezgif-4-5b7ef79dac44](https://user-images.githubusercontent.com/9597207/87444209-7b3bcd00-c5c4-11ea-855e-eaed3b25d62a.gif)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM03", "user": "bierbaumtim", "root": "ROOT0", "reply_to": "COM02", "timestamp": "2020-07-14T19:30:43Z", "text": "Experiencing same issues on both stable and beta versions, but never thought that this is an issue of flutter or Skia. \nThanks @acoutts for your research.", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM04", "user": "Ufuk94", "root": "ROOT0", "reply_to": "COM03", "timestamp": "2020-07-17T12:21:41Z", "text": "I hope this gets fixed as soon as possible. This issue completely ruins the first impression of an app. ", "meta": {"posReactions": "25", "negReactions": "0"}}
{"id": "COM05", "user": "bluemix", "root": "ROOT0", "reply_to": "COM04", "timestamp": "2020-07-17T15:16:19Z", "text": "I am hoping this issue is fixed before my initial release on iOS", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM06", "user": "liyuqian", "root": "ROOT0", "reply_to": "COM05", "timestamp": "2020-07-17T23:36:50Z", "text": "We're actively working on \"Test-based shader warmup #53609\" to solve this, but that may take some time.\r\n\r\nBefore that, you can follow https://github.com/flutter/flutter/issues/61045#issuecomment-655658088 to compile a custom Flutter engine that turns off Metal and uses OpenGL so the SkSL warm-up would solve this issue. Flutter still used OpenGL on all iOS devices a few months ago so its performance would not be too far behind. Depending on the workload, your app may prefer trading Metal's other improvements for OpenGL's vastly faster shader warm-up performance.\r\n\r\nAdmittedly, compiling the Flutter engine takes much more time than just clicking a button, turn on a flag, or running a single command. We could have made it much easier by providing an opt-out-Metal option (https://github.com/flutter/flutter/issues/61045). However, we don't know if that will bring more harm than good. That's why your feedback is valuable to us, and we'd love to hear feedback from as many app developers as possible.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM07", "user": "trighomautumnatg", "root": "ROOT0", "reply_to": "COM06", "timestamp": "2020-07-18T08:07:58Z", "text": "Our customers have complained after opening the application for the first time :(", "meta": {"posReactions": "29", "negReactions": "0"}}
{"id": "COM08", "user": "bobandrew", "root": "ROOT0", "reply_to": "COM07", "timestamp": "2020-07-23T08:17:36Z", "text": "Same issue. \r\nI spent a lot of time trying to solve this problem. But I didn't find anything, except to put a forced delay before the animation (but this fix does not completely solve the issue).\r\nHow long wait for a fix (week/month)?\r\n\r\nThanks you for the great framework.", "meta": {"posReactions": "12", "negReactions": "1"}}
{"id": "COM09", "user": "wellbranding", "root": "ROOT0", "reply_to": "COM08", "timestamp": "2020-07-24T19:00:46Z", "text": "Experiencing same issue on Android devices. For instance, the Flutter Gallery app is very laggy on the majority of medium-range Android devices like Xiaomi MI A2. The navigation part between tabs takes about 1 second and frame drop is very significant. It makes the whole application look like a web-view or built with cross-platform not native solutions, like PhoneGap :)", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM010", "user": "Ufuk94", "root": "ROOT0", "reply_to": "COM09", "timestamp": "2020-07-25T11:58:37Z", "text": "Can we change the title to include Android as well? ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM011", "user": "acoutts", "root": "ROOT0", "reply_to": "COM010", "timestamp": "2020-07-25T12:12:11Z", "text": "> Can we change the title to include Android as well?\r\n\r\nJust updated to include Android.\r\n\r\nI think the real issue here is that there is no viable fix for iOS at the moment. With android you can do the SkSL warmup routine outlined here: https://github.com/flutter/flutter/wiki/Reduce-shader-compilation-jank-using-SkSL-warm-up\r\nBut this will not do anything for iOS metal devices yet (any iOS device since the iPhone 5S).\r\n\r\nI've been trying to compile my own flutter engine with iOS metal disabled to test OpenGL but I cannot get my engine to build. If anyone can help, here is where I'm stuck now: https://github.com/flutter/flutter/issues/61045#issuecomment-660539657", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM012", "user": "Hixie", "root": "ROOT0", "reply_to": "COM011", "timestamp": "2020-07-28T23:05:17Z", "text": "@chinmaygarde is planning on writing a doc about how to address this, should be available later this week.", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM013", "user": "liyuqian", "root": "ROOT0", "reply_to": "COM012", "timestamp": "2020-08-03T23:09:00Z", "text": "For those that are having issues on Android, you can follow https://github.com/flutter/flutter/wiki/Reduce-shader-compilation-jank-using-SkSL-warm-up to solve this now.\r\n\r\nFor those that are having issues on iOS, I've updated a simpler instruction in https://github.com/flutter/flutter/issues/61045#issue-652724073 on how to try SkSL warm-up by opting out Metal. If that instruction works, please let us know what performance tradeoff you're seeing from your app.\r\n\r\nThese are the short-term solutions. Chinmay and I will give more details on the longer-term solutions later.", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM014", "user": "Hixie", "root": "ROOT0", "reply_to": "COM013", "timestamp": "2020-08-18T22:56:04Z", "text": "@chinmaygarde @liyuqian any news on the doc?", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM015", "user": "kf6gpe", "root": "ROOT0", "reply_to": "COM014", "timestamp": "2020-08-31T21:45:05Z", "text": "@acoutts Does the feedback on #61045 help the iOS case for you at all?\r\n\r\nOn the Android side, I saw that the GitHub link's been moved to the web site; I'm not sure what other action is necessary here.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM016", "user": "acoutts", "root": "ROOT0", "reply_to": "COM015", "timestamp": "2020-08-31T21:47:22Z", "text": "> @acoutts Does the feedback on #61045 help the iOS case for you at all?\r\n> \r\n> On the Android side, I saw that the GitHub link's been moved to the web site; I'm not sure what other action is necessary here.\r\n\r\nYeah, I've had metal disabled for a number of weeks now. It greatly improved our app's performance with that jank gone. We've not noticed any serious performance issues that would make us want to go back.\r\n\r\nI hope in time metal support will become better, and I hope it's easier to work around it soon. Right now flutter upgrades are quite painful as I need to recompile my engine every time I upgrade flutter versions, so I generally do it every few weeks as it takes a few hours.\r\n", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM017", "user": "liyuqian", "root": "ROOT0", "reply_to": "COM016", "timestamp": "2020-09-01T20:59:28Z", "text": "@Hixie : @chinmaygarde is a little busy recently in some other work so the doc has been delayed.\r\n\r\nBTW, this issue's title now covers both iOS and Android shader compilation jank so it looks like a duplicate of https://github.com/flutter/flutter/issues/32170", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM018", "user": "petro-i", "root": "ROOT0", "reply_to": "COM017", "timestamp": "2020-10-05T19:22:47Z", "text": "@Hixie, it doesn't look good that priority of the \"extreme jank\" issue has been decreased. There is no workaround for the issue. \r\n@liyuqian, the opting out Metal doesn't really work since Lottie and Flare animations rendering is bad in OpenGl on iPhone X/11 ([see example here](https://github.com/flutter/flutter/issues/61045#issuecomment-685898308)). Formally I can't submit PR against OpenGL iOS rendering, since it is not officially used. So, there is closed loop, for my application at least. We  cannot deliver to customer junky application and/or bad quality Lottie/Flare animations.\r\n \r\nPlease instead of changing priority to lower values, increase priority as much as possible.", "meta": {"posReactions": "22", "negReactions": "0"}}
{"id": "COM019", "user": "atrope", "root": "ROOT0", "reply_to": "COM018", "timestamp": "2020-10-05T20:39:23Z", "text": "@totalerex The priority was increased \ud83d\udc4d \r\n\r\nCheck here the Label description:\r\nhttps://github.com/flutter/flutter/labels?page=8&q=&sort=name-asc\r\n\r\nEdit: My Bad! It was indeed a downgrade.. This should bem P2 or P1.. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM020", "user": "acoutts", "root": "ROOT0", "reply_to": "COM019", "timestamp": "2020-10-05T20:42:07Z", "text": "> @totalerex The priority was increased \ud83d\udc4d\r\n> \r\n> Check here the Label description:\r\n> https://github.com/flutter/flutter/labels?page=8&q=&sort=name-asc\r\n\r\nI see it was moved from P2 to P3, so it was a downgrade.", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM021", "user": "atrope", "root": "ROOT0", "reply_to": "COM020", "timestamp": "2020-10-05T20:54:26Z", "text": "My Bad!\r\nI Saw P3 -> P2..\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM022", "user": "kf6gpe", "root": "ROOT0", "reply_to": "COM021", "timestamp": "2020-10-05T21:50:37Z", "text": "We are actively working on this, although not with the alacrity that requires it surfacing in our weekly critical issue triage, which is why it was awarded a P3 instead of a P2 --- P0-P2 bugs get reviewed for status every week; P3 issues are things we either are working on or hope to work on in short order (see https://github.com/flutter/flutter/wiki/Triage#triaging-issues for an explanation of our priority scheme).\r\n\r\nThanks for your feedback in letting us know how important this is to you.", "meta": {"posReactions": "24", "negReactions": "0"}}
{"id": "COM023", "user": "m-j-g", "root": "ROOT0", "reply_to": "COM022", "timestamp": "2020-10-15T18:57:46Z", "text": "Disappointing that this is not being considered high priority.  Can't submit to App Store with extreme jank.", "meta": {"posReactions": "15", "negReactions": "0"}}
{"id": "COM024", "user": "scaraux", "root": "ROOT0", "reply_to": "COM023", "timestamp": "2020-10-15T19:00:46Z", "text": "> Disappointing that this is not being considered high priority. Can't submit to App Store with extreme jank.\r\n\r\nDid apple say anything about your app being slow?\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM025", "user": "m-j-g", "root": "ROOT0", "reply_to": "COM024", "timestamp": "2020-10-15T19:02:43Z", "text": "> > Disappointing that this is not being considered high priority. Can't submit to App Store with extreme jank.\r\n> \r\n> Did apple say anything about your app being slow?\r\n\r\nSorry, should clarify - Not because of Apple, but because of not meeting a level of production quality", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM026", "user": "bluemix", "root": "ROOT0", "reply_to": "COM025", "timestamp": "2020-10-15T19:14:57Z", "text": "Honestly, this issue made me re-consider of cross-platform frameworks being owned by the same company (Google here) will be supported at best, and ignoring quality metrics delivery on other platforms (iOS).\nThis issue has no problem on Android, but _it is_ on iOS. I think if it was on Android, it will be solved faster.\nAnyways, Flutter is great, but please ensure issues are solved with the same priority on both Android and iOS.", "meta": {"posReactions": "16", "negReactions": "0"}}
{"id": "COM027", "user": "erf", "root": "ROOT0", "reply_to": "COM026", "timestamp": "2020-10-15T19:23:33Z", "text": "@bluemix Apple should make SwiftUI crossplatform, so at least there would be competition ;)", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM028", "user": "bluemix", "root": "ROOT0", "reply_to": "COM027", "timestamp": "2020-10-15T19:42:18Z", "text": "> @bluemix Apple should make SwiftUI crossplatform, so at least there would be competition ;)\n\nthere is a good competitor, React Native, but Flutter outperforms it in many ways", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM029", "user": "erf", "root": "ROOT0", "reply_to": "COM028", "timestamp": "2020-10-15T19:54:24Z", "text": "@bluemix i think Flutter has done it right by building everything from scratch, just need to fix these performance issues and things will be golden", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "ROOT1", "user": "adamdougal", "root": "ROOT1", "reply_to": null, "timestamp": "2018-10-17T08:48:50Z", "text": "Test summary logged using println At the moment the test summary is logged using println https://github.com/gatling/gatling/blob/11308fcf5b2048f0a28a585529d13b5c0337d85f/gatling-core/src/main/scala/io/gatling/core/stats/writer/ConsoleDataWriter.scala#L75\r \r This causes issues when shipping logs to Kibana in a logstash encoded format using the logstash-logback-encoder as println does not use that encoder. Is this done intentionally?\r \r I did originally raise this issue here https://groups.google.com/forum/#!topic/gatling/Kq-hDp3oFkk but got no response. \r \r If it's ok to change this to use a logger I'm happy to contribute.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10", "user": "slandelle", "root": "ROOT1", "reply_to": "ROOT1", "timestamp": "2018-10-17T08:58:45Z", "text": "Sorry, but all new features regarding stats (additional stats, pushing stats elsewhere) fall into the scope of [FrontLine](https://gatling.io/frontline), our Enterprise version.\r\n\r\nFor example, FrontLine provides a public API you can use to extract the stats, and a Grafana datasource.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM11", "user": "adamdougal", "root": "ROOT1", "reply_to": "COM10", "timestamp": "2018-10-17T09:17:20Z", "text": "I think this is more about logging rather then stats. At the moment we can't even turn these logs off if we don't want them. This is a problem with the open source tool.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12", "user": "slandelle", "root": "ROOT1", "reply_to": "COM11", "timestamp": "2018-10-17T09:18:43Z", "text": "> At the moment we can't even turn these logs off if we don't want them.\r\n\r\nYes you can, remove `console` from the `writers` in `gatling.conf`.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13", "user": "adamdougal", "root": "ROOT1", "reply_to": "COM12", "timestamp": "2018-10-17T09:20:29Z", "text": "Ok, that's my mistake. Though I'm still not sure why this would use a `println` rather then a logger that you can have more control over.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14", "user": "slandelle", "root": "ROOT1", "reply_to": "COM13", "timestamp": "2018-10-17T09:24:33Z", "text": "> Though I'm still not sure why this would use a println rather then a logger that you can have more control over.\r\n\r\nSo people can't mess up with the formatting and break the line length.\r\nAgain, this in not intended for extension, hence the format is not an public/stable API to be consumed.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15", "user": "adamdougal", "root": "ROOT1", "reply_to": "COM14", "timestamp": "2018-10-17T09:29:09Z", "text": "Would you be open to have a new implementation of `DataWriter` that used a logger instead?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16", "user": "slandelle", "root": "ROOT1", "reply_to": "COM15", "timestamp": "2018-10-17T09:40:37Z", "text": "No, for the very same reason: we need to make a living.\r\n\r\n> Sorry, but all new features regarding stats (additional stats, pushing stats elsewhere) fall into the scope of FrontLine, our Enterprise version.\r\n\r\nI'll sound pushy, but I think it would be fair that [billion dollars companies](https://www.statista.com/statistics/273693/bskybs-annual-revenue/) that have been using an open source software for years would consider helping the company behind the technology.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM17", "user": "adamdougal", "root": "ROOT1", "reply_to": "COM16", "timestamp": "2018-10-17T09:53:56Z", "text": "Ok, I'll concede on this. Though I think it's unrealistic to expect someone/a company to pay money for a tool that works perfectly fine for them, just to have finer grain control over their logs. We're not asking for real time live graphs or monitoring of injectors. This is something we are more then happy to do the work for to improve the tool, so it's shame we can't contribute in that way.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM18", "user": "slandelle", "root": "ROOT1", "reply_to": "COM17", "timestamp": "2018-10-17T11:11:13Z", "text": "Sorry if I sounded harsh, that wasn't my intent.\r\n\r\nWe've drawn a clear line between what goes in Gatling OSS and what goes in Gatling FrontLine:\r\nall new things related to stats/exports/integrations go into Gatling FrontLine.\r\n\r\nWe're more than happy with contributions related to core Gatling features such as HTTP and users orchestration. But we can't make any exception to the above rule.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM19", "user": "balooo", "root": "ROOT1", "reply_to": "COM18", "timestamp": "2018-10-17T14:20:36Z", "text": "@slandelle I am sorry but I don't really understand your reasoning, although I understand your concern around protecting the Enterprise value.\r\n\r\n Just to confirm, your strategy is to prefer for us to fork this project so that we can use a logger for a single line of code where you are currently using println, pushing us further away from wanting the Enterprise solution because you are classifying using a logger to output the summary as part of `stats/exports/integrations`, although that information is already being outputted in a different form?  \r\n\r\nTo be honest, this entire thread so far makes me far less inclined to introduce a dependency on the enterprise project.  I believe gatling is great as a project, I believe you should get paid to support and continue working on it full time, I also believe large companies should pay and help support opensource initiatives.   The problem is that I also believe your approach will alienate many people, or at least me and all the people I talk to about this.  It's a very simple code change, that actually makes it more consistent, as the majority of of your code base uses loggers (as any developer would expect). \r\n\r\nYou are not even arguing about not outputting that data because it's `stats/enterprise` data.  The data is there and available in the logs already!  The only difference is the primitive output mechanism.  The fact that many modern log shipping frameworks expect json/structured logs means that using println automatically makes you a less attractive product for both enterprise and non enterprise adopters.  These println statements just create noise in most modern log shipping frameworks I have worked with as they cannot be interpreted as a single event.  This is genuine feedback.\r\n\r\nI would urge you to reconsider the quick decision, because I believe this suggestion exposes no more information than you currently do, moves you towards a more standardized output like the rest of your code base, and would actually show you positively engaging in improving your entire product offering, OSS and Enterprise. \r\n\r\nThe functionality you are planning as part of Enterprise are still attractive to companies like ours, e.g. aggregation of metrics etc, grafana datasources etc.  I think you've convinced yourself that any improvements to OSS is a risk to Enterprise.  Just doesn't sit well with me.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM110", "user": "slandelle", "root": "ROOT1", "reply_to": "COM19", "timestamp": "2018-10-17T15:10:01Z", "text": "@balooo Thank you for sharing your concerns. We don\u2019t see improvements of the OSS as a risk, quite the contrary: you can have a look at all the work that\u2019s been put into upcoming Gatling 3 OSS.\r\n\r\nOur Enterprise version, Gatling FrontLine, aims to provide our users with advanced features in terms of metrics, integration and automation. This Enterprise version was designed by the feedback of our users who built their own integrations with Gatling but then struggled to stabilize them and maintain them over time.\r\n\r\nWe believe this Enterprise version is a win-win for everyone: we make you save time and money, we guarantee you stability and, at the same time, you help the open-source project continue to develop.\r\n\r\nWe would be more than happy to continue this discussion live and convince you that we are still committed to improve load testing, both for our OSS users and for our enterprise customers.\r\n\r\nAnyway, thank you for using Gatling", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM111", "user": "balooo", "root": "ROOT1", "reply_to": "COM110", "timestamp": "2018-10-17T15:56:17Z", "text": "@slandelle Thanks for the reply, but I still don't think you actually addressed the points I was trying to raise regarding this particular issue.  I still don't understand how the suggested change is against your commercial strategy.  The points I was trying to articulate are that this request:\r\n\r\n- doesn't expose any data that would previously be inaccessible / enterprise.\r\n- doesn't suggest structuring the results in a way that is easier to parse/interpret programatically\r\n- only suggests what we believe is better practice by outputting using a logger which is the standard practice\r\n- would allow for common, modern log shippers to ship your output with our creating message noise, where each println is interpreted as a new log event.\r\n\r\nI literally don't see a single reason you would be against it this request.  I've read through your comments multiple times and I still don't see a single argument you have given explaining why . \r\n\r\n> Sorry, but all new features regarding stats (additional stats, pushing stats elsewhere) fall into the scope of FrontLine, our Enterprise version.\r\n\r\nFair enough to that statement, but we're not talking about additional stats, pushing stats or anything about stats.  We're talking about not using a logger for your output which causes problems when using industry standard shipping practices that expect structured logs.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM112", "user": "slandelle", "root": "ROOT1", "reply_to": "COM111", "timestamp": "2018-10-18T08:40:25Z", "text": "I am sorry to read that my message didn't answer your questions.\r\nWe have a consistent strategy regarding our open-source solution and our Enterprise version since the R&D started in 2015. We don't plan to change it for the moment, I hope you understand. Anyway, as I said before, we would be more than pleased to discuss this with you live.\r\nClosing this thread.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT2", "user": "akopchinskiy", "root": "ROOT2", "reply_to": null, "timestamp": "2018-06-04T16:41:48Z", "text": "Change Detection is not working with asynchronous route changes ## I'm submitting a...\r Bug report\r \r ## Current behavior\r Change Detection is not working with asynchronous route change.\r After route is changed - change detection in any component linked to a route is not firing. Method `ngOnInit()` is not launched too, its lauched only after any interaction with a component (form input, etc.).\r \r ## Expected behavior\r Change Detection is working with asynchronous route change.\r \r ## Minimal reproduction of the problem with instructions\r Sample:\r https://stackblitz.com/edit/angular-tqcthi\r \r ## Environment\r Angular version: 6.0.3\r <!-- Check whether this is still an issue in the most recent Angular version -->\r \r ## Browser:\r - [*] Chrome (desktop) version LATEST\r  \r ## For Tooling issues:\r - Node version: XX  <!-- run `v8.11.1` -->\r - Platform:  Windows\r \r ## Others:\r typescript: 2.8.1\r \r ## Comments\r It's working if Observable from `this.auth.logIn()` convert to a promise, like this:\r ```typescript\r this.auth.logIn() // returns Promise\r      .then((result) => {\r                 this.router.navigateByUrl('myApp');\r             }).catch((error) => {\r                 this.router.navigateByUrl('login');\r             });\r ```\r But I don't want to use promises, I want to use the Observable! Why It's not working? >:E There is no objective reasons for that. ", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM20", "user": "vicb", "root": "ROOT2", "reply_to": "ROOT2", "timestamp": "2018-06-04T16:48:53Z", "text": "Please attach a minimal repro", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM21", "user": "akopchinskiy", "root": "ROOT2", "reply_to": "COM20", "timestamp": "2018-06-04T17:59:09Z", "text": "@vicb Done: https://stackblitz.com/edit/angular-tqcthi", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM22", "user": "splincode", "root": "ROOT2", "reply_to": "COM21", "timestamp": "2018-06-05T07:40:10Z", "text": "@akopchinskiy \r\n![image](https://user-images.githubusercontent.com/12021443/40961913-a4b87ef2-68ac-11e8-9b4f-025e33e69002.png)\r\n\r\n![image](https://user-images.githubusercontent.com/12021443/40961934-c28db294-68ac-11e8-96f0-b5f4a87ce103.png)\r\n\r\nwhy do you use a localhost? on the server this will not work\r\nchange the example", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM23", "user": "Borzilov", "root": "ROOT2", "reply_to": "COM22", "timestamp": "2018-06-05T08:34:25Z", "text": "@akopchinskiy From the attached example not obvious what kind of behavior you are expecting. If you handle an HTTP-error (for instance a request to jsonplaceholder can be used) and try to replace an observable constructor with a high-order observable (in the AuthService) you will find that ngOnInit-hook fires as usual.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM24", "user": "akopchinskiy", "root": "ROOT2", "reply_to": "COM23", "timestamp": "2018-06-05T08:36:28Z", "text": "@splincode That's absolutely does not interfere the sample. Code runs as it should. Do not distract me for this nonsense, please.\r\n\r\n@Borzilov \r\n> If you handle an HTTP-error and try to replace an observable constructor with a high-order observable (in the AuthService) you will find that ngOnInit-hook fires as usual.\r\n\r\nThat's exactly what I'm doing in the code. And `ngOnInit()` does not work.", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM25", "user": "Borzilov", "root": "ROOT2", "reply_to": "COM24", "timestamp": "2018-06-05T08:57:24Z", "text": "@akopchinskiy what exactly should happen according to your logic?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM26", "user": "akopchinskiy", "root": "ROOT2", "reply_to": "COM25", "timestamp": "2018-06-05T10:09:22Z", "text": "@Borzilov I just updated the example to make it more similar to real situation. It's working as expected, but the same code (copy-paste) does not work in my app. And I have no idea why.\r\nMaybe it's Angular Material 2 interferes with something, because I have no other libraries in my project.", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM27", "user": "splincode", "root": "ROOT2", "reply_to": "COM26", "timestamp": "2018-06-05T11:33:24Z", "text": "@vicb I think you can close the task, a person just does not understand", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM28", "user": "jasonaden", "root": "ROOT2", "reply_to": "COM27", "timestamp": "2018-06-05T22:35:23Z", "text": "This issue doesn't provide the steps to reproduce, or the exact expectation you're looking for with the example provided. It would be much easier to understand if you simplified the example somewhat (remove the extra calls inside your auth service) and explained what you're actually looking for.\r\n\r\nAlso, I'm closing and locking this issue based on the [Code of Conduct](https://github.com/angular/angular/blob/master/CODE_OF_CONDUCT.md) and the lack of respectful communication within this issue.\r\n\r\nIf the issue persists, please create a new issue with minimal reproduction, and explain exactly what to do to reproduce the issue you're having and the expected result.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT3", "user": "Alacritous", "root": "ROOT3", "reply_to": null, "timestamp": "2019-10-17T01:59:13Z", "text": "Azure Cloud Shell is readded to the profiles.json file after I remove it and restart terminal.  # Steps to reproduce\r \r Open profiles.json through the settings menu option and edit the profiles.json file. Remove the section for Azure Cloud Shell completely including the surrounding brackets and comma preceding the first curly bracket.  leaving the file valid but missing the Azure option. I have no need for it. \r \r # Expected behavior\r \r I expect to be able to remove the option that I do not have any use for. \r \r # Actual behavior\r \r When the Windows Terminal Program is run, the profile segment that was removed reappears as if by magic much to my amazement. \r If I mark the file as read-only to protect it from being reverted, Windows Terminal refuses to load. \r \r I literally watched the section in question reappear in the configuration file open in VS code after I deleted it saved the file and re-run the Terminal program. \r \r I want very much to include several invectives and expletives in this bug report. But I will refrain from doing so. \r But I want you to imagine what I would have said and you be sure and be creative. \r \r The following is the text that I remove from the configuration file that reappears when the Windows Terminal program is run. There is no error or notification. It just reappears and the option for Azure Cloud is on the menu. \r \r <----------- begin relevent text ----------->\r ,\r         {\r             \"guid\": \"{b453ae62-4e3d-5e58-b989-0a998ec441b8}\",\r             \"hidden\": false,\r             \"name\": \"Azure Cloud Shell\",\r             \"source\": \"Windows.Terminal.Azure\"\r         }\r <----------- end relevent text ----------->", "meta": {"posReactions": "8", "negReactions": "1"}}
{"id": "COM30", "user": "DHowett-MSFT", "root": "ROOT3", "reply_to": "ROOT3", "timestamp": "2019-10-17T02:14:59Z", "text": "@Alacritous thanks for _not_ including those invectives. \ud83d\ude05 \r\n\r\nWe're working on the documentation around \"dynamic profiles,\" but until that lands:\r\n\r\nThere's a fine line we're walking between dynamic and user-generated content. Most of the dynamic generators are for system-dependent things like \"what WSL distributions do you have\" and \"which versions of powershell core are installed?\". Each distribution gets its own profile, as will each powershell version.\r\n\r\nWe want to make sure they're _found_, but also that the user is clued into the fact that they can be customized. To that end, we add a \"stub\" entry to your settings file. _When we can't find it,_ we assume it's because the generator never ran or discovered new content (like: a WSL distribution was installed) rather than that the user removed it. \r\n\r\nWith just the one settings file as a single source of truth, we aren't storing a bit somewhere saying \"we already generated `{aaaa}`, don't do it again\" anywhere but the actual profiles list.\r\n\r\nBroadly speaking, you've got two options for disabling this profile (and any other dynamic/automatic profiles).\r\n\r\n1. Hide the profile, live with it being in your settings, and continue to let us know that you're not happy that it's there. Set `hidden` to `false`, and it'll stop cluttering up your profile list and key bindings.\r\n\r\n2. _Disable the whole dynamic generator_. We have three dynamic profile generators today:\r\n  * `Windows.Terminal.Azure`\r\n  * `Windows.Terminal.Wsl`\r\n  * `Windows.Terminal.PowershellCore`\r\n\r\nIf you add one of these names (or all of them!) to a new array at the top level of your settings file called `disabledProfileSources`, like this:\r\n\r\n```json\r\n{\r\n    \"defaultProfile\": \"{abcd}\",\r\n    \"disabledProfileSources\": [\r\n        \"Windows.Terminal.Azure\"\r\n    ],\r\n    // ...\r\n}\r\n```\r\n\r\nthe generator won't even run and the profile will never come back.", "meta": {"posReactions": "17", "negReactions": "0"}}
{"id": "COM31", "user": "DHowett-MSFT", "root": "ROOT3", "reply_to": "COM30", "timestamp": "2019-10-17T02:17:19Z", "text": "(The part about continuing to let us know was not meant to read like \"we're ignoring you, everybody please stop yelling\" -- it was intended to sound more like \"please express dissatisfaction; we want to make sure we're doing the right things\")", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM32", "user": "Alacritous", "root": "ROOT3", "reply_to": "COM31", "timestamp": "2019-10-17T02:26:02Z", "text": "So am I to understand that you are saying that the Terminal program scans to see what's installed each time it is run and creates the profiles for the things it finds assuming that if there isn't already a profile for it that it should just make one? \r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM33", "user": "DHowett-MSFT", "root": "ROOT3", "reply_to": "COM32", "timestamp": "2019-10-17T02:35:56Z", "text": "Indeed! It only scans for a small set of things -- WSL distributions and PowerShell Core instances. The Azure generator doesn't scan anything.\r\n\r\nFor what it's worth, this was informed by user requests in #1289, #1424, #1394, #1518, #1674, #2037, #2023, #2283, #2300, #2536 and #2804 (and the lack of autogeneration caused bugs like #1692 and #1449)\r\n\r\nWhen we have a settings UI (#1564) there'll be a more natural way to configure what terminal does/doesn't do on your behalf, and a bit more visibility into the \"scanning\" process.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM34", "user": "Alacritous", "root": "ROOT3", "reply_to": "COM33", "timestamp": "2019-10-17T03:07:12Z", "text": "You guys aren't big fans of the KISS principle, I see. \r\n\r\nI added that disabledprofilesources tag and that worked to remove the Azure Cloud option. Thanks for that. \r\n\r\nHowever, (insert ominous music here)\r\n\r\nSomething else is actually broken.  I was experimenting and just to see what would happen, I removed the PowerShell profile from the profiles.json file to see if it would come back too. And it is not there anymore and it did not come back, but the PowerShell option is still in the menu when I open the terminal program and when I click it, a tab opens with Powershell.   I have closed and reopened both the profiles.json file and Windows Terminal several times and it's not in the profiles.json file and it IS in the menu in Windows Terminal.   \r\n\r\nI then added \"Windows.Terminal.PowershellCore\" to the disabledprofilesources  mentioned previously and the PowerShell option is still in the menu. \r\n\r\nThen I renamed the profiles.json file to profiles.json.bak and reran Windows Terminal to see if it would regenerate the entire config file and it did so, creating a much sparser file than existed before with no keybinding information or color schemes. \r\n\r\nI then added the profiles I had created before to the profiles.json and set the default and added the disabledprofilesources option for Azure Cloud and now everything is as it should be. \r\n\r\nWe now return to your regularly scheduled program. \r\n\r\nadditional.  Curiouser and curiouser. I did the alt-click-settings to view the default settings file and it shows me a file that DOES include the keybindings and color schemes.  The file it generated after I deleted the profiles.json did NOT include keybindings and color schemes. \r\n\r\nWindows Terminal (Preview)\r\nVersion: 0.5.2762.0\r\n\r\n", "meta": {"posReactions": "5", "negReactions": "1"}}
{"id": "COM35", "user": "MartijnDekkers", "root": "ROOT3", "reply_to": "COM34", "timestamp": "2020-05-01T03:33:55Z", "text": "This really isn't cool, and the story about dynamic generators is really thin. You are shipping with a default config, and if a user removes a part of that config, re-adding it and not leaving any hints in the settings file how to disable your fancy \"dynamic generator\" is just a super user-hostile action. \r\n\r\nSince you ship with a default config, you can be sure that it is _found_ - because you shipped it that way. Getting rid of it was literally my first course of action on installing this software.  \r\n\r\nMy next action was googling for \"wtfbshax why is this Azure rubbish coming back\" and, after reading this thread, my next action will be to get rid of this software immediately. Microsoft once again doesn't fail to disappoint. ", "meta": {"posReactions": "2", "negReactions": "2"}}
{"id": "COM36", "user": "Alacritous", "root": "ROOT3", "reply_to": "COM35", "timestamp": "2020-05-01T03:39:16Z", "text": "I deleted this app a while ago when I discovered they were blaming Microsoft Core devs for bugs they can't be bothered to fix or work around. ", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM37", "user": "DHowett-MSFT", "root": "ROOT3", "reply_to": "COM36", "timestamp": "2020-05-01T03:47:23Z", "text": "> can't be bothered to fix or work around.\r\n\r\nI\u2019m legitimately curious which ones you\u2019re referring to. We have worked around a bunch of platform bugs that we haven\u2019t raised a fanfare about. We sit in the same buildings, and generally on the same floors, as these \u201cCore\u201d people because _we are on the core operating system team ourselves._ When they say something can\u2019t be fixed or worked around, that\u2019s the brakes and the best we can do is communicate that to our community.\r\n\r\n> Microsoft once again doesn't fail to disappoint.\r\n\r\nI appreciate you expressing your discontent here. It\u2019s the only way we can really learn how our community feels. I _don\u2019t_ appreciate you expressing it by heaping it on top of everybody I work with.\r\n\r\nThe decisions made on this project stop with me and my PM. Hi! I\u2019m a real person, happy to have a dialogue about that. \r\n\r\nEDIT- when I say \u201cstop with ...\u201d I really mean that _we\u2019re the ones responsible, at the end of the day._ Sorry about that, it sounded bad on a re-read. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM38", "user": "MartijnDekkers", "root": "ROOT3", "reply_to": "COM37", "timestamp": "2020-05-01T07:38:25Z", "text": "> I don\u2019t appreciate you expressing it by heaping it on top of everybody I work with\r\n\r\n_looks at the top of the page_ yup, still says Microsoft, as it does in your handle. You represent your organisation, and my criticism is directed at your organisation. This isn't the first time Microsoft is forcing \"good ideas\" down my throat - if it was, I'd be happy to ask you about them directly, but this is just another data-point in a long history of similarly user-hostile actions. \r\n\r\nHaving said all that, this \"feature\" is an exceptionally bad idea, that breaks all conventions of software and user interface design. Moreover, the initial impression from a user perspective is \"this is broken. I performed an action, and now this action is undone.\" There is no universe in which this is OK, and if the decisions on this project stop with you and your PM, I'd strongly recommend you both find some additional learning on this subject. \r\n\r\nFrom a software design perspective, there are many possible ways in which you could have chosen to ensure your configuation generation component works together, this one is exceptionally poor.\r\n\r\n> We want to make sure they're found, but also that the user is clued into the fact that they can be customized\r\n\r\nThe irony of this statement is significant. You are literally clueing the user in to the opposite. \"I performed a customisation, and it is undone. This doesn't appear to be customisable\"\r\n\r\nFinally, it is a very safe assumption to make that the user of this software is somewhat technical. I sincerely hope that your persona's don't include \"Rob is a greengrocer, and uses his computer to browse the web and do his accounts for his shop. Rob also plays a game from time to time. Rob als has the strong desire to download custom alpha shell/terminal software to pimp up his command prompt\". In other words, your target users can safely be assumed to be a bit more technical leaning. At the end of the day, you are expecting the user to edit a JSON file manually to modify settings.\r\n\r\nIn the context of the more technical user it would also be safe to assume that that when a piece of your default config (that ships with your package) has gone, and that this is a user action. \r\n\r\nAs I said, the motivation for this misfeature (it comes across as an ad in disguise) is flimsy at best., and doesn't give the impression that this project has the benefit of some adult supervision from time to time. ", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM39", "user": "zadjii-msft", "root": "ROOT3", "reply_to": "COM38", "timestamp": "2020-05-01T12:59:30Z", "text": "Hey, so we spent a good deal of time trying to come up with a solution to a hard set of problems. We want to cover cases like \"what happens when a dynamic profile generator doesn't always create the same list of profiles\" and \"what if a user wants to use the same settings file on two PCs with _different_ WSL distros installed\"? We wanted to make it robust, so that it would fail in the fewest possible cases. Software though is about compromises - there's not an effective way for us to dynamically generate a profile then _have the user delete that profile entirely_, and know to not delete it again. There's not a practical different between the profile not existing _because we haven't generated it_ and not existing _because the user deleted it_.\r\n\r\nYou're right that our userbase is a technical audience, which is why we expected them to be able to <!--rub two brain cells together, and-->take the four seconds it takes to read the synthesized JSON, see the `\"hidden\": false` that we stick in there, and think \"hmm, maybe that hides the profile \ud83e\udd14\".\r\n\r\nIf you'd like to read more about how we came to the conclusions on this design that we did, I'd encourage reading #1258, where we originally designed the settings model, and especially #1321, which is a changelist specifically relating to dynamic profile generation.\r\n\r\nWe're looking towards the future here, towards a scenario where users largely _aren't_ having to modify their settings files by hand, and can just use the UI for that. In that future world, all the intricacies of how dynamic profiles are implemented won't actually be exposed to the user - they'll just delete the profile in the UI, and we'll mark it as `hidden` for them.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM310", "user": "Alacritous", "root": "ROOT3", "reply_to": "COM39", "timestamp": "2020-06-30T18:21:35Z", "text": "> You're right that our userbase is a technical audience, which is why we expected them to be able to take the four seconds it takes to read the synthesized JSON, see the `\"hidden\": false` that we stick in there, and think \"hmm, maybe that hides the profile\r\n\r\nSo what you're saying is that every time I upgrade or update any software made by you and yours I have to scour the documentation and support and config files for any new \"features\" and traps you may have placed in it? \r\n\r\nHow about ASKING THE USER? Did that ever cross your mind?  \"Hey, I've detected that you've made a change in the config. I'm about to undo all your work and confuse the hell out of you, Would you like me to continue?\"\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT4", "user": "Alexhuszagh", "root": "ROOT4", "reply_to": null, "timestamp": "2017-10-17T20:09:30Z", "text": "Comprehensive, Native Windows Support Now, before you tell me this is a lot of work: I know, and am working on it (and almost done). Ideally, I would like to have my changes merged here, so I have a few questions and concerns for my current port.\r \r # Questions\r \r **Should I target a specific C++ standard?**\r \r Currently, my code depends on a few C++11 features, which can be easily removed with a few macros. This makes the code less readable, however, if C++03 support is desired, I will gladly change my implementation to conform to an older standard.\r \r **How to handle Unicode filesystem support?**\r \r Currently, LevelDB uses `char`-based (narrow) strings for for all filesystem operations, which does not translate well for Windows systems (since narrow strings use the ANSI, or OEM legacy codepages, and not UTF-8, for backwards compatibility). This means paths using international characters, or emojis, are therefore not supported with a simple port, something I consider to be an undesirable solution for a modern library. All the current forks of levelDB do not solve this fundamental issue, leading me to create my own implementation. Possible solutions include:\r \r 1. A narrow (UTF-8) API on *Nix, and a wide (UTF-16) API on Windows, using a typedef to determine the proper path type.\r 2. Converting all narrow strings from UTF-8 to UTF-16 before calling WinAPI functions.\r 3. Providing both a narrow (ANSI) and wide (UTF-16) API on Windows.\r \r The 2nd option, although the least amount of work, is the least amenable for me since the expected encoding for paths from levelDB would then conflict with the entirety of the WinAPI. The 3rd option, however, duplicates code to support both the narrow and wide WinAPI, which would increase the amount of work required to maintain levelDB. The first option is a happy median: it minimizes redundancy and is consistent with expectations about *Nix and Windows paths. I am, however, amenable to any suggestions the levelDB authors may have.\r \r **Intellectual Property**\r \r To emulate the behavior of `mmap` on Windows, I used a very lightweight library (<250 lines of code) from Steven Lee, [mman-win32](https://github.com/witwall/mman-win32). However, looking over your contributor license agreement, it seems that my port would not satisfy Google's CLA until I remove this code from my implementation. If this is the case, I could easily use the raw WinAPI functions rather than the emulated `mmap` in my Windows port. Please notify me if I should remove this code prior to submitting a pull request.\r \r # Other Changes\r \r **CMake Build System**\r \r I introduced a CMake build system, which retains most of the same logic as the existing Makefile. The existing Makefile has not been deprecated.\r \r **AppVeyor Continual Integration**\r \r To ensure builds do not break the Windows builds, I am planning to add an AppVeyor configuration, which allows continual integration on Windows using MSVC.\r \r # Summary\r \r If there is still interest for native Windows support, and the proposed changes are amenable to the levelDB authors, I would gladly submit a pull request.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM40", "user": "ghemawat", "root": "ROOT4", "reply_to": "ROOT4", "timestamp": "2017-10-17T20:29:55Z", "text": "On Tue, Oct 17, 2017 at 1:09 PM, Alexander Huszagh <notifications@github.com\n> wrote:\n\n> Now, before you tell me this is a lot of work: I know, and am working on\n> it (and almost done). Ideally, I would like to have my changes merged here,\n> so I have a few questions and concerns for my current port.\n> Questions\n>\n> *Should I target a specific C++ standard?*\n>\n> Currently, my code depends on a few C++11 features, which can be easily\n> removed with a few macros. This makes the code less readable, however, if\n> C++03 support is desired, I will gladly change my implementation to conform\n> to an older standard.\n>\n\nWe haven't made a decision w.r.t. this yet, so it will be easiest if it\ndoes not rely on on c++03 only.  Would it be a big problem to do so?\n\n\n> *How to handle Unicode filesystem support?*\n>\n> Currently, LevelDB uses char-based (narrow) strings for for all\n> filesystem operations, which does not translate well for Windows systems\n> (since narrow strings use the ANSI, or OEM legacy codepages, and not UTF-8,\n> for backwards compatibility). This means paths using international\n> characters, or emojis, are therefore not supported with a simple port,\n> something I consider to be an undesirable solution for a modern library.\n> All the current forks of levelDB do not solve this fundamental issue,\n> leading me to create my own implementation. Possible solutions include:\n>\n>    1. A narrow (UTF-8) API on *Nix, and a wide (UTF-16) API on Windows,\n>    using a typedef to determine the proper path type.\n>    2. Converting all narrow strings from UTF-8 to UTF-16 before calling\n>    WinAPI functions.\n>    3. Providing both a narrow (ANSI) and wide (UTF-16) API on Windows.\n>\n> The 2nd option, although the least amount of work, is the least amenable\n> for me since the API would then seemingly lies to users of levelDB, since\n> strings would have to be UTF-8 encoded rather than using the local code\n> page, in contrast with the entirety of the WinAPI. The 3rd option, however,\n> duplicates code to support both the narrow and wide WinAPI, which would\n> increase the amount of work required to maintain levelDB. The first option\n> is a happy median: it minimizes redundancy and is consistent with\n> expectations about *Nix and Windows paths. I am, however, amenable to any\n> suggestions the levelDB authors may have.\n>\n\nHere is what I suggest: make a separate Env implementation for Windows\n(instead of attempting to reuse env_posix.cc).  That Env implementation\n(like all other Env implementations), accepts char-based (narrow) strings,\nwhich are always utf8 encoded.  Inside this Env's implementation, it can\nconvert back and forth between the utf8 strings that the rest of leveldb\nassumes, and whatever type is appropriate for windows APIs called in the\nimplementation.\n\nIf there is significant code in env_posix.cc you find yourself needing,\nconsider refactoring that out into a separate .h/.cc (which are private to\nthe leveldb implementation) so you can share the code in your Env\nimplementation.\n\n> *Intellectual Property*\n>\n> To emulate the behavior of mmap on Windows, I used a very lightweight\n> library (<250 lines of code) from Steven Lee, mman-win32\n> <https://github.com/witwall/mman-win32>. However, looking over your\n> contributor license agreement, it seems that my port would not satisfy\n> Google's CLA until I remove this code from my implementation. If this is\n> the case, I could easily use the raw WinAPI functions rather than the\n> emulated mmap in my Windows port. Please notify me if I should remove\n> this code prior to submitting a pull request.\n>\n\nYes, this should be removed.  In general, we have been throttling back mmap\nusage anyway (it helps a bit with microbenchmarks, but causes a bunch of\nportability problems).  So I suggest a good initial start will be to just\nuse raw WinAPI functions.\n\n\n\n> Other Changes\n>\n> *CMake Build System*\n>\n> I introduced a CMake build system, which retains most of the same logic as\n> the existing Makefile. The existing Makefile has not been deprecated.\n>\n*AppVeyor Continual Integration*\n>\n> To ensure builds do not break the Windows builds, I am planning to add an\n> AppVeyor configuration, which allows continual integration on Windows using\n> MSVC.\n>\n\nThis sounds very helpful.\n\n\n> Summary\n>\n> If there is still interest for native Windows support, and the proposed\n> changes are amenable to the levelDB authors, I would gladly submit a pull\n> request.\n>\n\nThis sounds very useful to me.  I would like it if the changes were limited\nto the following:\n\n(a) A windows Env implementation as I mentioned above.\n(b) Build/portability changes.\n\nIs that feasible, or you are seeing the need to make widespread changes?\n\n\n\u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/google/leveldb/issues/519>, or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHuM0W8xE_w2Az-r6NfZqQwYWM9ZBrNVks5stQmLgaJpZM4P8vz1>\n> .\n>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM41", "user": "pwnall", "root": "ROOT4", "reply_to": "COM40", "timestamp": "2017-10-17T20:50:46Z", "text": "Work on CMake support is already underway. Please use https://github.com/pwnall/leveldb/tree/cmake as a starting point, to avoid rework. Also, please use the Travis CI and AppVeyor configurations in https://github.com/google/snappy as a starting point for yours.\r\n\r\nIn general, I recommend following the approach taken by Chromium's LevelDB integration. Chromium builds (and runs) on Windows, and does not require modifications to the rest of the LevelDB.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM42", "user": "Alexhuszagh", "root": "ROOT4", "reply_to": "COM41", "timestamp": "2017-10-17T21:04:15Z", "text": "Thank you for the feedback. This would be very feasible to do @ghemawat, especially if we use UTF-8 paths and just convert them in the Windows environment. As for CMake support, I will use that as a starting point (thank you). I will remove the `mmap` compatibility and use the raw WinAPI calls. Due to my other work, I should be able to finish this later this week.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM43", "user": "Alexhuszagh", "root": "ROOT4", "reply_to": "COM42", "timestamp": "2017-10-20T23:18:34Z", "text": "@ghemawat and @pwnall, a quick question: When I asked the C++11 features and limiting myself to C++03, did you mean limit the codebase to C++98 or C++11? I have a few situations where `std::chrono` is dramatically more convenient than other code, however, I can remove this (it's only for `NowMicros` and `SleepForMicroseconds`). Other than that, the port should not require any new features.\r\n\r\nThank you and I am effectively done with my port, other than this minor question.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM44", "user": "pwnall", "root": "ROOT4", "reply_to": "COM43", "timestamp": "2017-10-20T23:20:30Z", "text": "We've recently decided that the next release will require C++11, so it's OK to use C++11. Sorry for the code churn on your end... this decision was not taken lightly.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM45", "user": "Alexhuszagh", "root": "ROOT4", "reply_to": "COM44", "timestamp": "2017-10-21T00:16:25Z", "text": "@pwnall No worries, I understand that such fundamental choices do not lend themselves to casual decisions. Thank you for all the help.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM46", "user": "andschwa", "root": "ROOT4", "reply_to": "COM45", "timestamp": "2017-10-26T16:54:20Z", "text": "Hi @Alexhuszagh,\r\n\r\nAs a soon-to-be user of the leveldb Windows support (for Mesos), here are are my thoughts:\r\n\r\n> Should I target a specific C++ standard?\r\n\r\nFor us, C++11 is fine, we already target this.\r\n\r\n> How to handle Unicode filesystem support?\r\n\r\nThis is an annoying problem, I had to fix this for Mesos. I went with:\r\n\r\n> 2. Converting all narrow strings from UTF-8 to UTF-16 before calling WinAPI functions.\r\n\r\nIt also leads into long path issues on Windows. I took an approach similar to the one CMake took for their Windows port, a `longpath` helper to translate all paths as they reach WinAPI functions from UTF-8 to UTF-16 with `\\\\?\\` prepended if necessary. My helper is [here](https://github.com/apache/mesos/blob/master/3rdparty/stout/include/stout/internal/windows/longpath.hpp) (note that the max path is _not_ 255 despite documentation).\r\n\r\nI need to stress: native long path support is probably a must for most Windows projects nowadays. It's not terribly difficult to do, it's just _really annoying_.\r\n\r\nAlso, for your comment:\r\n\r\n> is the least amenable for me since the expected encoding for paths from levelDB would then conflict with the entirety of the WinAPI\r\n\r\nI'm not sure I entirely agree, there is no data loss going from UTF-8 to UTF-16. Both encodings are _Unicode_, it's just an implementation difference. Plus, you can do the conversion [natively in C++11](https://github.com/apache/mesos/blob/f599839bb854c7aff3d610e49f7e5465d7fe9341/3rdparty/stout/include/stout/stringify.hpp#L57). Anyway, I've not had any problems on Windows having gone this route so far.\r\n\r\nThanks for your work! I personally know the trouble it is \ud83d\ude09 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM47", "user": "andschwa", "root": "ROOT4", "reply_to": "COM46", "timestamp": "2017-10-26T17:21:23Z", "text": "Also:\r\n\r\n> I introduced a CMake build system\r\n\r\nYay, a million times, yay! We'll pull it into Mesos with `ExternalProject_Add`.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM48", "user": "Alexhuszagh", "root": "ROOT4", "reply_to": "COM47", "timestamp": "2017-10-30T22:30:06Z", "text": "Hi @pwnall and @ghemawat, I've had a few issues I cannot currently debug. I will attempt to use the Boost-based \"windows\" branch as a reference-point in short order.\r\n\r\nSpecifically, I've had 3 major issues:\r\n\r\n1. ~~`issue178_test` fails intermittently. ~10% of the time, it succeeds, without issue. 25% of the time, it produces a slightly lower number of keys than the 1.1m requires (almost always greater than 1.09m). The rest of the time, it produces the error `Assertion Failed: r->options.comparator->Compare(key, Slice(r->last_key)) > 0, file level-db\\table\\table_builder.cc, line 97`.~~\r\n\r\n2. ~~`db_test` fails intermittently (at about the same frequency) during the `random_read_counter_` section (from `env_->random_read_counter_.Reset();` to `ASSERT_LE(reads, N + 2*N/100);`~~\r\n\r\n3. ~~Most severely though, however, is the multi-threaded section seems to produce the `bad block type` error consistently, which would defeat the entire purpose of a multi-thread access.~~\r\n\r\nOtherwise, all the test cases and benchmarks work. Just a heads up for the major delay.\r\n\r\n(Items with ~~strikethrough~~ have been patched).\r\n\r\nEDIT: Everything has been patched.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM49", "user": "pwnall", "root": "ROOT4", "reply_to": "COM48", "timestamp": "2017-10-30T22:46:48Z", "text": "No worries about delays. Honestly, I'm backed up with other work for the next two of weeks, and the odds that I'll be able to look at this are very low.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM410", "user": "Alexhuszagh", "root": "ROOT4", "reply_to": "COM49", "timestamp": "2017-11-07T10:16:57Z", "text": "Everything has been patched, and I am adding extended file length support currently. @andschwa, for the extended file length support, since the `\"\\\\?\\\"` prefix effectively removes all path parsing, do you know if there's anything else I need to consider other than:\r\n\r\n1. Relative paths (which cannot use the extended file length prefix).\r\n2. `/`, `.`, or `..` in paths (somewhat tricky, see below).\r\n\r\nFor the `.` and `..` operators, manually parsing them is somewhat tricky, since directory symbolic links may be in play. The only time-tested strategy for this is to iterate over all roots, parent directories, check to see if the item is a directory symbolic link or junction, get the real path of the directory if it is a symlink or junction, and then continue from there. This is because `C:\\leveldb\\..\\leveldb-1\\README.md` does not actually point to `C:\\leveldb-1\\README.md` if `C:\\leveldb` is a symlink or junction.\r\n\r\nThis is very doable (and is relatively easy to implement), but it is fairly expensive since it requires filesystem calls. It requires a temporary vector to store each path component. Step-wise, the general approach is as follows:\r\n\r\n1. Check if the path is absolute (skip remaining steps otherwise).\r\n2. Replace all forward separators with backslashes.\r\n3. Recurse over each parent directory, from the root (drive letter, such as `C:`, or UNC root, such as `\\\\host-name\\share-name`), to the (and excluding the) file (we don't care if the file is a symlink, since relative path components cannot follow it).\r\n4. If the directory basename is `.`, ignore the directory.\r\n5. If the directory basename is `..`, remove the preceding directory component.\r\n6. Otherwise, check if the directory is a symlink by calling `CreateFile` with the `FILE_FLAG_OPEN_REPARSE_POINT` and `FILE_FLAG_BACKUP_SEMANTICS` flags. If the handle is successfully created, it's a symlink, otherwise, it is not.\r\n7. If the directory is a symlink, read the proper path using `DeviceIoControl` with the `FSCTL_GET_REPARSE_POINT` code, and reset the vector using the absolute new path.\r\n\r\nI would be amenable to implementing this (I've done this before, as may be obvious due to the detail of my explanation on how to implement such functionality), but this may add a lot of expense for a feature that application developer should have to be aware of themselves (that is, leveldb will already support an extended length path, if provided by the end-user).\r\n\r\nAnother major caveat is leveldb's filenames are short (the longest being the `MANIFEST-00000X` files, at 15 characters). Since the Windows [documentation](https://msdn.microsoft.com/en-us/library/windows/desktop/aa365247(v=vs.85).aspx) clearly states the maximum directory length must be `MAX_PATH - 12`, even with the extended length path prefix, this seems like a lot of work for an added 3 characters.\r\n\r\n@pwnall, any thoughts? Should extended file length support be added, including with the caveats mentioned above?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM411", "user": "andschwa", "root": "ROOT4", "reply_to": "COM410", "timestamp": "2017-11-08T23:27:54Z", "text": "@Alexhuszagh I don't believe you missed anything.\r\n\r\nRe: bullet 6: I'm using this logic in Mesos:\r\n\r\n```\r\n  const DWORD access_flags = resolved_path_is_directory\r\n    ? (FILE_FLAG_OPEN_REPARSE_POINT | FILE_FLAG_BACKUP_SEMANTICS)\r\n    : FILE_FLAG_OPEN_REPARSE_POINT;\r\n\r\n  const HANDLE handle = ::CreateFileW(\r\n      longpath(absolute_path).data(),\r\n      GENERIC_READ,     // Open the file for reading only.\r\n      FILE_SHARE_READ,  // Just reading this file, allow others to do the same.\r\n      nullptr,          // Ignored.\r\n      OPEN_EXISTING,    // Open existing symlink.\r\n      access_flags,     // Open symlink, not the file it points to.\r\n      nullptr);         // Ignored.\r\n```\r\n\r\nadding the `FILE_FLAG_BACKUP_SEMANTICS` flag only if its a directory. I also specifically use `OPEN_EXISTING`, though you probably got that.\r\n\r\nRe: point 7: I resolve the path using `GetFinalPathNameByHandleW` with the `FILE_NAME_NORMALIZED` flag, after using:\r\n\r\n```\r\n  const DWORD access_flags = resolved_path_is_directory\r\n    ? FILE_FLAG_BACKUP_SEMANTICS\r\n    : FILE_ATTRIBUTE_NORMAL;\r\n\r\n  const HANDLE handle = ::CreateFileW(\r\n      longpath(absolute_path).data(),\r\n      GENERIC_READ,     // Open the file for reading only.\r\n      FILE_SHARE_READ,  // Just reading this file, allow others to do the same.\r\n      nullptr,          // Ignored.\r\n      OPEN_EXISTING,    // Open existing file.\r\n      access_flags,     // Open file, not the symlink itself.\r\n      nullptr);         // Ignored.\r\n```\r\n\r\nto get a handle to the file/directory at the resolved path.\r\n\r\nRe:\r\n\r\n> but this may add a lot of expense for a feature that application developer should have to be aware of themselves (that is, leveldb will already support an extended length path, if provided by the end-user)\r\n\r\nI agree that just letting the end-user provide `\\\\?\\C:\\long\\paths` without any extra handling from `leveldb` might be just fine, so long as _all_ the Windows APIs used are the Unicode versions (and specifically listed as supporting long paths; though this is most of them).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM412", "user": "Alexhuszagh", "root": "ROOT4", "reply_to": "COM411", "timestamp": "2017-11-08T23:56:25Z", "text": "@andschwa All the Window APIs are the Unicode versions. Currently, I use `FILE_FLAG_BACKUP_SEMANTICS` for files and directories, but that is easily changed. As for `GetFinalPathNameByHandleW`, unfortunately it somewhat raises a chicken/egg problem.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM413", "user": "andschwa", "root": "ROOT4", "reply_to": "COM412", "timestamp": "2017-11-08T23:59:42Z", "text": "If `FILE_FLAG_BACKUP_SEMANTICS` is working for both, don't let me tell you it's wrong! I was using `GetFinalPathNameByHandle` specifically for resolution of symlinks; I see where it wouldn't quite work for you here.\r\n\r\n> All the Window APIs are the Unicode versions.\r\n\r\nPerfecto.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM414", "user": "jenokizm", "root": "ROOT4", "reply_to": "COM413", "timestamp": "2018-05-01T07:29:02Z", "text": "Hi, I wanted to ask how your work is going? It's been about six months since your last messages, but I do not see any result. I need to build a library under Windows and I do not know how.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM415", "user": "chrismorfos", "root": "ROOT4", "reply_to": "COM414", "timestamp": "2018-05-02T06:20:25Z", "text": "Hi how are you today ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM416", "user": "ketnoimai", "root": "ROOT4", "reply_to": "COM415", "timestamp": "2018-05-02T11:24:50Z", "text": "hi t\u00f4i b\u1eadn qu\u00e1 v\u00e0 c\u0169ng ch\u01b0a hi\u1ec3u n\u1ed9i dung c\u00f4ng vi\u1ec7c t\u00f4i ph\u1ea3i l\u00e0m l\u00e0 g\u00ec ?\nt\u00f4i bi\u1ebft r\u1ea5t \u00edt v\u1ec1 c\u00f4ng ngh\u1ec7 ! n\u1ebfu t\u00f4i c\u00f3 th\u1ec3 l\u00e0m g\u00ec \u0111\u00f3 c\u00f3 \u00edch cho b\u1ea1n th\u00ec\nb\u1ea1n h\u00e3y h\u01b0\u1edbng d\u1eabn t\u00f4i !\n\n2018-05-01 14:29 GMT+07:00 jenokizm <notifications@github.com>:\n\n> Hi, I wanted to ask how your work is going? It's been about six months\n> since your last messages, but I do not see any result. I need to build a\n> library under Windows and I do not know how.\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/google/leveldb/issues/519#issuecomment-385616180>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/Ah4_VGZLcEwyQHyJXLEB6fv3yS1ZVObzks5tuA7WgaJpZM4P8vz1>\n> .\n>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM417", "user": "Alexhuszagh", "root": "ROOT4", "reply_to": "COM416", "timestamp": "2018-05-03T16:10:31Z", "text": "@jenokizm Sorry, I got extremely busy with work and have submitted a few PRs to this extent but it still needs work. My Windows development PC just arrived after breaking in March, so I should be able to finish this soon.\r\n\r\nIf you would to use this branch, it currently works on Windows:\r\nhttps://github.com/Alexhuszagh/leveldb", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM418", "user": "pwnall", "root": "ROOT4", "reply_to": "COM417", "timestamp": "2018-05-10T00:05:40Z", "text": "I think the ball is currently in our court. I need to find time to reconcile the various Windows PRs we've received with what we think this should look like.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM419", "user": "thomasjm", "root": "ROOT4", "reply_to": "COM418", "timestamp": "2018-07-29T12:15:26Z", "text": "Hi -- no pressure, but is there any ETA for when Windows support will land? Thanks!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM420", "user": "pwnall", "root": "ROOT4", "reply_to": "COM419", "timestamp": "2018-07-30T18:53:02Z", "text": "We have no timeline for this, sorry.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM421", "user": "felipecrv", "root": "ROOT4", "reply_to": "COM420", "timestamp": "2018-12-03T17:21:51Z", "text": "@Alexhuszagh @pwnall can I take the code in the PR, rebase to fix the merge conflicts, then add commits with the suggestions from @ghemawat or that was already done by @cmumford in https://github.com/cmumford/leveldb/commit/a5888f680bea87cd14d665692cff223ea48c5f89 ?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM422", "user": "pwnall", "root": "ROOT4", "reply_to": "COM421", "timestamp": "2018-12-03T22:12:38Z", "text": "@philix Thank you very much for the offer!\r\n\r\nWe have a change for the internal codebase, which will get published after it lands. The code change is very far into the review process. At this point, I don't think there's anything that external contributors can help us with.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM423", "user": "Alexhuszagh", "root": "ROOT4", "reply_to": "COM422", "timestamp": "2018-12-03T23:06:08Z", "text": "If there's anything I can do, or anything others could do with my code to make Windows support land earlier, I'd be glad to help. In the meantime, I'm just glad Windows support seems to be approaching soon. Thanks.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM424", "user": "felipecrv", "root": "ROOT4", "reply_to": "COM423", "timestamp": "2018-12-04T07:32:06Z", "text": "@pwnall Great news. Thanks.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM425", "user": "felipecrv", "root": "ROOT4", "reply_to": "COM424", "timestamp": "2019-02-25T19:21:56Z", "text": "Hi, it's me again. I really need a Windows port to start experimenting with LevelDB.\r\n\r\nIs https://github.com/cmumford/leveldb/commit/a5888f680bea87cd14d665692cff223ea48c5f89 the best port so far?\r\n\r\nI just need to hack something together before the official port lands.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM426", "user": "pwnall", "root": "ROOT4", "reply_to": "COM425", "timestamp": "2019-02-26T01:34:41Z", "text": "At this point, I'm fairly convinced that this topic won't benefit from external input until we land the Windows port. Locking so googlers can focus their limited time on landing the code.\r\n\r\nI expect that locked conversations are frustrating to external contributors, and I'm sorry for that. I'm doing this because the subtler request above hasn't been effective.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT5", "user": "amervitz", "root": "ROOT5", "reply_to": null, "timestamp": "2017-03-13T18:20:29Z", "text": "Why does WinAppDriver.exe require developer mode? I would like to use WinAppDriver on a computer that doesn't have developer mode turned on. Is there a technical limitation or reason why it requires developer mode? It starts up just fine even when developer mode isn't turned on with the message:\r \r > Developer mode is not enabled. Enable it through Settings and restart Windows Application Driver", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM50", "user": "marc-mueller", "root": "ROOT5", "reply_to": "ROOT5", "timestamp": "2017-06-09T11:33:42Z", "text": "We have the same issue. Any reason for that? What is the requirement for that?\r\n\r\nWe simply enable developer mode before running our tests by executing the following PowerShell bevor starting up WinAppDriver.exe:\r\n```reg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\AppModelUnlock\" /t REG_DWORD /f /v \"AllowDevelopmentWithoutDevLicense\" /d \"1\"``` ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM51", "user": "rajeeshmenoth", "root": "ROOT5", "reply_to": "COM50", "timestamp": "2018-05-18T04:39:19Z", "text": "We have the same issue in WinAppDriver !! Any solution for this thread @timotiusmargo  ?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM52", "user": "khouzam", "root": "ROOT5", "reply_to": "COM51", "timestamp": "2018-05-22T22:56:11Z", "text": "Hi,\r\n\r\nWinAppDriver's requirement on DeveloperMode is based on the premise that it is a developer tool. Enabling DeveloperMode requires Administrative access to the machine, and therefore enforces that the user has the right set of permissions to control the machine.", "meta": {"posReactions": "1", "negReactions": "8"}}
{"id": "COM53", "user": "amervitz", "root": "ROOT5", "reply_to": "COM52", "timestamp": "2018-05-23T01:25:55Z", "text": "Please remove this restriction.", "meta": {"posReactions": "22", "negReactions": "0"}}
{"id": "COM54", "user": "Purus", "root": "ROOT5", "reply_to": "COM53", "timestamp": "2019-06-06T05:20:18Z", "text": "This is a blocker for using WiAppDriver in many corporates as developer mode can't be enabled for all developers.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM55", "user": "eykh", "root": "ROOT5", "reply_to": "COM54", "timestamp": "2019-07-05T11:37:02Z", "text": "So this is just an artificially created annoyance. \r\nPlease remove it!\r\n\r\n> Hi,\r\n> \r\n> WinAppDriver's requirement on DeveloperMode is based on the premise that it is a developer tool. Enabling DeveloperMode requires Administrative access to the machine, and therefore enforces that the user has the right set of permissions to control the machine.\r\n\r\n", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM56", "user": "Purus", "root": "ROOT5", "reply_to": "COM55", "timestamp": "2019-07-05T11:52:13Z", "text": "Yes. Rightly said. It's an unwanted restriction.\n\nThanks,\n\nPurusothaman Ramanujam\n\nOn Fri, 5 Jul, 2019, 5:07 PM 4alexbo, <notifications@github.com> wrote:\n\n> So this is just an artificially created annoyance.\n> Please remove it!\n>\n> Hi,\n>\n> WinAppDriver's requirement on DeveloperMode is based on the premise that\n> it is a developer tool. Enabling DeveloperMode requires Administrative\n> access to the machine, and therefore enforces that the user has the right\n> set of permissions to control the machine.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microsoft/WinAppDriver/issues/165?email_source=notifications&email_token=AAIHDZ6SFG44LLALDU6C34LP54W6RA5CNFSM4DDORD6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODZJJZBQ#issuecomment-508730502>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAIHDZ7Z7LDCXK5KJRC55PLP54W6RANCNFSM4DDORD6A>\n> .\n>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM57", "user": "ramezah", "root": "ROOT5", "reply_to": "COM56", "timestamp": "2019-07-30T10:11:01Z", "text": "Thank you @marc-mueller\r\n> We have the same issue. Any reason for that? What is the requirement for that?\r\n> \r\n> We simply enable developer mode before running our tests by executing the following PowerShell bevor starting up WinAppDriver.exe:\r\n> `reg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\AppModelUnlock\" /t REG_DWORD /f /v \"AllowDevelopmentWithoutDevLicense\" /d \"1\"`\r\n\r\nThe above command worked for me. My company policy require Avecto Priviledges. So run the Powershell as Administrator or with Avecto defendpoint and add the reg add command above and you'll see that the dev mode is switched on. \r\n\r\n![DevMode](https://user-images.githubusercontent.com/1126062/62121020-ae555580-b2ba-11e9-9f89-a246392e7f40.PNG)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM58", "user": "Taldren76", "root": "ROOT5", "reply_to": "COM57", "timestamp": "2019-11-18T15:31:02Z", "text": "This is a blocker for all automation as this is an unacceptable change in the environment in which we are performing QA. Users don't run in developer mode, so we aren't allowed to QA in it. It's as simple as that.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM59", "user": "peteferraro", "root": "ROOT5", "reply_to": "COM58", "timestamp": "2019-12-09T18:02:48Z", "text": "For what it's worth I am using WinAppDriver in a production environment to do Robotic Process Automation (RPA) Validation of application availability.  Developer Mode has been identified by our security team as a no no.  It's a show stopper.  Why FORCE developer mode?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM510", "user": "vkuppa1", "root": "ROOT5", "reply_to": "COM59", "timestamp": "2020-08-07T15:27:00Z", "text": "This is really frustrating, Our IT Team doesn't want us to Enable developer mode, this restriction is not required. It would be better if they lift off this restriction. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM511", "user": "douniwan5788", "root": "ROOT5", "reply_to": "COM510", "timestamp": "2020-12-11T05:18:23Z", "text": "This is stupid! Administrative permissions can be verified through other means, not by open a secure leak on the machine!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM512", "user": "DHowett", "root": "ROOT5", "reply_to": "COM511", "timestamp": "2020-12-11T05:20:49Z", "text": "It\u2019s a developer tool that _opens a listening port on your machine that allows anybody who connects without authentication to drive and screen scrape any application your account can access_. It\u2019s a developer tool.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT6", "user": "amorenew", "root": "ROOT6", "reply_to": null, "timestamp": "2019-12-12T19:30:24Z", "text": "Disable Origin Policy CORS in Flutter web ## Use case\r \r While calling a web service on Flutter web it will not work because of CORS Policy\r \r ## Proposal\r I saw a chrome window when I start debugging a Flutter web application\r I wonder if we could add a flag to disable the CORS policy\r like `Flutter run -d web --no-cors`\r \r `chromium-browser --disable-web-security --user-data-dir=\"[some directory here]\"\r `\r https://stackoverflow.com/questions/3102819/disable-same-origin-policy-in-chrome\r ", "meta": {"posReactions": "49", "negReactions": "0"}}
{"id": "COM60", "user": "jonahwilliams", "root": "ROOT6", "reply_to": "ROOT6", "timestamp": "2019-12-12T20:41:16Z", "text": "Disabling the CORS checks locally would lead to drastically different behavior between a debug and deployed application - you can't very well ask all users of your website to disable CORS locally. Adding this flag would be a mistake", "meta": {"posReactions": "2", "negReactions": "39"}}
{"id": "COM61", "user": "amorenew", "root": "ROOT6", "reply_to": "COM60", "timestamp": "2019-12-13T06:47:07Z", "text": "@jonahwilliams I wonder why web services work in Android debugging mode while there is no Internet permission in the Manifest file?\r\n<uses-permission android:name=\"android.permission.INTERNET\"/>\r\n\r\nFor sure the simple answer is easy debugging until adding the permission for the release version", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM62", "user": "amorenew", "root": "ROOT6", "reply_to": "COM61", "timestamp": "2019-12-13T06:51:26Z", "text": "Internet Permission for Android is the same as CORS in Chrome\r\nHere is the PR for Android Permission that makes Internet works debug mode only\r\n\r\n`This is not an \"injection\" at build time, but rather a separate manifest for debug builds\r\n`\r\nDebug mode Internet permission PR\r\n**move INTERNET permission to debug/AndroidManifest.xml**\r\nhttps://github.com/flutter/flutter/pull/22139\r\nProfile mode Internet permission PR\r\n**Add a manifest for profile builds that enables INTERNET permission**\r\nhttps://github.com/flutter/flutter/pull/26450\r\n\r\n> Adding this flag would be a mistake\r\n\r\nIt will be **optional** `-flag` only until the backend developer add whitelist for my local or in AWS config", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM63", "user": "jonahwilliams", "root": "ROOT6", "reply_to": "COM62", "timestamp": "2019-12-13T08:03:22Z", "text": "> Internet Permission for Android is the same as CORS in Chrome\r\n\r\nIt is absolutely not the same thing", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM64", "user": "krunaldarji", "root": "ROOT6", "reply_to": "COM63", "timestamp": "2019-12-15T17:15:35Z", "text": "@amreniouinnovent flutter web working locally and remotely ? I am also facing this issue with flutter web but it works fine on Mobile \r\n\r\n@jonahwilliams this is a bug in Flutter web ?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM65", "user": "amorenew", "root": "ROOT6", "reply_to": "COM64", "timestamp": "2019-12-15T18:10:46Z", "text": "@krunaldarji it is not a bug. it is security permission like when you call twitter from facebook then facebook is not allowed to call twitter.\r\nSo backend developer should allow you to call his web service from your localhost.\r\nthis security feature is for browsers only but not on mobile or postman. \r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM66", "user": "amreniouinnovent", "root": "ROOT6", "reply_to": "COM65", "timestamp": "2019-12-16T06:09:16Z", "text": "@jonahwilliams developers suggested using an extension or opening chrome with CORS disabled\r\nSo I have 2 questions:\r\n\r\n1- Why the app is not launching as a new tab in the same browser? and is there any possibility I can change the default behavior? because the chrome instance which got launched doesn't have extensions like my default chrome.\r\n\r\n2-How could I configure the app to run on Firefox instead of chrome?", "meta": {"posReactions": "8", "negReactions": "0"}}
{"id": "COM67", "user": "krunaldarji", "root": "ROOT6", "reply_to": "COM66", "timestamp": "2019-12-20T19:47:44Z", "text": "@amorenew But i hosted my website on Firebase also but still same problem any idea ? Or how to allow this api call from my localhost because i am using few microsoft sharepoint api's which i can't request Microsoft for modification.\r\n\r\nPls help.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM68", "user": "MOlechowski", "root": "ROOT6", "reply_to": "COM67", "timestamp": "2019-12-21T00:41:34Z", "text": "You can start flutter web server on random port using command flutter run -d web-server, and then go to localhost:port in your browser or you could use release app using following guide https://flutter.dev/docs/deployment/web", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM69", "user": "krunaldarji", "root": "ROOT6", "reply_to": "COM68", "timestamp": "2019-12-21T06:13:52Z", "text": "@MOlechowski Thanks for your response but its giving below error: \r\nAccess to XMLHttpRequest at 'https://login.microsoftonline.com/2a1c1526-05d412fa/oauth2/v2.0/token' from origin 'http://localhost:49948' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM610", "user": "amreniouinnovent", "root": "ROOT6", "reply_to": "COM69", "timestamp": "2019-12-22T06:56:55Z", "text": "@krunaldarji In AWS you could whitelist a specific port\r\nSo I am sure Sharepoint has the same feature\r\nBy the way, you can Add the whitelisted port for every run in the launch.json file\r\n```\r\n\"configurations\": \r\n[{\"name\": \"Flutter\",\r\n\"request\": \"launch\",\r\n\"type\": \"dart\",\r\n\"args\": [\"--web-port\",\"8080\"]\r\n}]\r\n\r\n```\r\n\r\nSharepoint CORS https://techcommunity.microsoft.com/t5/SharePoint-Developer/SharePoint-Office-365-CORS-issue-REST-API-call-to-other/m-p/777557", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM611", "user": "MohsinKhanSerpro", "root": "ROOT6", "reply_to": "COM610", "timestamp": "2020-04-28T09:09:14Z", "text": "Hi team\r\nI am facing this CORS policy issue from last 2 month, still not able to figure it out how to fix\r\n\r\n`Access to XMLHttpRequest at 'http://obuat-env.zuriwydraq.ap-south-1.elasticbeanstalk.com/api/v1/RegisterDevice' from origin 'http://35.154.115.156' has been blocked by CORS policy: Response to preflight request doesn't pass access control check: It does not have HTTP ok status.`\r\n\r\n- I have hosted my flutter web app on AWS - Apache environment\r\n\r\nplease if you any solution please help me.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM612", "user": "deakjahn", "root": "ROOT6", "reply_to": "COM611", "timestamp": "2020-05-15T16:43:54Z", "text": "The solution: create a batch file (or whatever your platform calls the shell scripts) that calls Chrome with the appropriate command line:\r\n\r\n    \"c:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\" --disable-web-security --user-data-dir=\"a-temp-location\" %*\r\n\r\n(Note the `%*` at the end, important!) Set up an environment variable named `CHROME_EXECUTABLE` to point to this file. Flutter will then use this file to start Chrome.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM613", "user": "amorenew", "root": "ROOT6", "reply_to": "COM612", "timestamp": "2020-05-15T19:52:09Z", "text": "@deakjahn \r\nHow flutter will use it? is it automatically?\r\n> Flutter will then use this file to start Chrome.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM614", "user": "deakjahn", "root": "ROOT6", "reply_to": "COM613", "timestamp": "2020-05-15T22:10:52Z", "text": "Yes. Flutter checks this env variable before it launches Chrome. If you try to start `flutter run -d chrome` on a system that doesn't have Chrome installed, Flutter will specifically ask you to either put it into the default location or to tell it where it is using `CHROME_EXECUTABLE` (this is actually how I learned of its existence :-) ).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM615", "user": "BesartLaci", "root": "ROOT6", "reply_to": "COM614", "timestamp": "2020-05-16T16:36:13Z", "text": "@deakjahn your [script solution](https://github.com/flutter/flutter/issues/46904#issuecomment-629363145) workes like a charm \ud83d\udc4d ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM616", "user": "vyvee", "root": "ROOT6", "reply_to": "COM615", "timestamp": "2020-05-20T05:36:28Z", "text": "@deakjahn Thanks! I have adapted your [script solution](https://github.com/flutter/flutter/issues/46904#issuecomment-629363145) in Linux as described below and it works perfectly!\r\n\r\nCreate a `google-chrome-unsafe.sh` with the following content:\r\n\r\n    #!/bin/sh\r\n    /usr/bin/google-chrome-stable --disable-web-security --user-data-dir=\"A-TEMP-LOCATION\" $*\r\n\r\nIt's better to create and use a dedicated folder in the home directory instead of `/tmp` for the temporary location, as Chrome will create some folders there to work properly.\r\n\r\nThen, make it executable with `chmod a+x google-chrome-unsafe.sh`\r\n\r\nThe environment variable can be set in `~/.bashrc` or `~/.bash_aliases` (if included from `.bashrc`):\r\n`export CHROME_EXECUTABLE=/path/to/google-chrome-unsafe.sh`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM617", "user": "JaiMistry", "root": "ROOT6", "reply_to": "COM616", "timestamp": "2020-05-26T05:37:55Z", "text": "@deakjahn\r\n> Yes. Flutter checks this env variable before it launches Chrome. If you try to start `flutter run -d chrome` on a system that doesn't have Chrome installed, Flutter will specifically ask you to either put it into the default location or to tell it where it is using `CHROME_EXECUTABLE` (this is actually how I learned of its existence :-) ).\r\n\r\nDo I set the `User` or `System` environment variable to `CHROME_EXECUTABLE`? I tried both and running my web application with `flutter run -d chrome` still resulted in a CORS error.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM618", "user": "deakjahn", "root": "ROOT6", "reply_to": "COM617", "timestamp": "2020-05-26T07:06:19Z", "text": "I have it in System but it shouldn't actually matter. The Flutter doctor display shows the value when it sees it, try that first.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM619", "user": "devDeejay", "root": "ROOT6", "reply_to": "COM618", "timestamp": "2020-05-29T09:53:54Z", "text": "So disabling CORS in Chrome on my development machine will fix it, but once deployed release mode in production the user's wont face any CORS issue?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM620", "user": "deakjahn", "root": "ROOT6", "reply_to": "COM619", "timestamp": "2020-05-29T15:25:16Z", "text": "They will, unless you setup your servers properly. This is something you can't skip.", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM621", "user": "jaggzh", "root": "ROOT6", "reply_to": "COM620", "timestamp": "2020-05-29T17:38:52Z", "text": "Would it help if we had \"flutter -d web-server\" accept additional headers, like:\r\n  ````--web-header \"Access-Control-Allow-Origin: my-ip-here\"````\r\nEdit: It appears more might be needed, but I'm inexperienced in this. The server currently sends out some other headers that would probably also need to be modified:\r\n```HTTP/1.1 200 OK\r\ndate: Fri, 29 May 2020 18:09:01 GMT\r\ncontent-length: 1124\r\nx-frame-options: SAMEORIGIN\r\ncontent-type: text/html\r\nx-xss-protection: 1; mode=block\r\nx-content-type-options: nosniff\r\nserver: dart:io with Shelf```\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM622", "user": "jaggzh", "root": "ROOT6", "reply_to": "COM621", "timestamp": "2020-05-29T21:51:41Z", "text": "Why is this closed anyway?  Is there some solution I'm missing?\r\nI ended up setting up a reverse proxy script to modify traffic headers (the flutter host/port are hard-coded near the top of the script).\r\n(The script is from somewhere else on the web, but I modified it for py3.x and had to make some other changes to get it working.)\r\nYou run this, it'll transparently transfer your traffic from port 9000, to 8989 where I have flutter running, removing the origin headers (and some other stuff the original script stripped), and adding in the access-control-allow-origin header.\r\nThis worked for me, although I'm getting some infinite \"font\" declaration dropped errors now.  Script below that screenshot.\r\n![image](https://user-images.githubusercontent.com/20318973/83308738-50381e00-a1bc-11ea-8a17-6eede7106b5d.png)\r\n\r\n```\r\n#!/usr/bin/env python\r\n\r\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\r\nimport argparse\r\nimport os\r\nimport random\r\nimport sys\r\nimport requests\r\n\r\nhostname = \"0.0.0.0\";\r\nhostport = \"8989\";\r\n\r\ndef merge_two_dicts(x, y):\r\n    z = x.copy()   # start with x's keys and values\r\n    z.update(y)    # modifies z with y's keys and values & returns None\r\n    return z\r\n\r\ndef set_header():\r\n    headers = {\r\n        'Meow': hostname\r\n    }\r\n    return headers\r\n\r\nclass ProxyHTTPRequestHandler(BaseHTTPRequestHandler):\r\n    protocol_version = 'HTTP/1.0'\r\n    def do_HEAD(self):\r\n        self.do_GET(body=False)\r\n\r\n    def do_GET(self, body=True):\r\n        sent = False\r\n        try:\r\n\r\n            url = 'http://{}:{}{}'.format(hostname, hostport, self.path)\r\n            req_header = self.parse_headers()\r\n\r\n            print(req_header)\r\n            print(url)\r\n            resp = requests.get(url, headers=merge_two_dicts(req_header, set_header()), verify=False)\r\n            sent = True\r\n\r\n            self.send_response(resp.status_code)\r\n            self.send_resp_headers(resp)\r\n            if body:\r\n                self.wfile.write(resp.content)\r\n            return\r\n        finally:\r\n            self.finish()\r\n            if not sent:\r\n                self.send_error(404, 'error trying to proxy')\r\n\r\n    def do_POST(self, body=True):\r\n        sent = False\r\n        try:\r\n            url = 'http://{}:{}{}'.format(hostname, hostport, self.path)\r\n            content_len = int(self.headers.getheader('content-length', 0))\r\n            post_body = self.rfile.read(content_len)\r\n            req_header = self.parse_headers()\r\n\r\n            resp = requests.post(url, data=post_body, headers=merge_two_dicts(req_header, set_header()), verify=False)\r\n            sent = True\r\n\r\n            self.send_response(resp.status_code)\r\n            self.send_resp_headers(resp)\r\n            if body:\r\n                self.wfile.write(resp.content)\r\n            return\r\n        finally:\r\n            self.finish()\r\n            if not sent:\r\n                self.send_error(404, 'error trying to proxy')\r\n\r\n    def parse_headers(self):\r\n        req_header = {}\r\n        for line in self.headers:\r\n            line_parts = [o.strip() for o in line.split(':', 1)]\r\n            if len(line_parts) == 2:\r\n                req_header[line_parts[0]] = line_parts[1]\r\n        return req_header\r\n\r\n    def send_resp_headers(self, resp):\r\n        respheaders = resp.headers\r\n        print('Response Header')\r\n        for key in respheaders:\r\n            if key not in [\r\n                           'Content-Encoding',\r\n                           'Transfer-Encoding',\r\n                           'content-encoding',\r\n                           'transfer-encoding',\r\n                           'content-length',\r\n                           'Content-Length',\r\n                           'x-frame-options',\r\n                           'x-xss-protection',\r\n                           'x-content-type-options',\r\n                           ]:\r\n                print(key, respheaders[key])\r\n                self.send_header(key, respheaders[key])\r\n                # Response Header\r\n                # date Fri, 29 May 2020 18:35:40 GMT\r\n                # x-frame-options SAMEORIGIN\r\n                # content-type text/html\r\n                # x-xss-protection 1; mode=block\r\n                # x-content-type-options nosniff\r\n                # server dart:io with Shelf\r\n        self.send_header('Access-Control-Allow-Origin', '*')\r\n        self.send_header('Content-Length', len(resp.content))\r\n        self.end_headers()\r\n\r\n\r\ndef parse_args(argv=sys.argv[1:]):\r\n    parser = argparse.ArgumentParser(description='Proxy HTTP requests')\r\n    parser.add_argument('--port', dest='port', type=int, default=9000,\r\n                        help='serve HTTP requests on specified port (default: 9000)')\r\n    args = parser.parse_args(argv)\r\n    return args\r\n\r\ndef main(argv=sys.argv[1:]):\r\n    args = parse_args(argv)\r\n    print('http server is starting on port {}...'.format(args.port))\r\n    server_address = ('0.0.0.0', args.port)\r\n    httpd = HTTPServer(server_address, ProxyHTTPRequestHandler)\r\n    print('http server is running as reverse proxy')\r\n    httpd.serve_forever()\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM623", "user": "BrendonW", "root": "ROOT6", "reply_to": "COM622", "timestamp": "2020-06-13T22:59:25Z", "text": "I really wish there was a simple solution to this. It makes developing my Flutter app that interacts with a legacy web-server very difficult. The simplest option would be to give a way of enabling other domains for the debug webserver that AndroidStudio starts, or give me away to enable source-maps in the standalone flutter webserver. \r\n\r\nI can proxy through a server, but then data errors result in incomprehensible errors because source maps never load.\r\nOR\r\nI can run directly out of Android Studio which gives me good errors, but then I can't test any network interactions. \r\n\r\nThe arguments about fooling people into having problems in production is about as valid as saying that debuggers shouldn't be supported because it is not how production works. Making development difficult WILL NOT increase Flutter Web usage.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM624", "user": "jeansebastienZ", "root": "ROOT6", "reply_to": "COM623", "timestamp": "2020-06-17T14:36:42Z", "text": "So basically no viable solution for this?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM625", "user": "deakjahn", "root": "ROOT6", "reply_to": "COM624", "timestamp": "2020-06-17T14:56:45Z", "text": "A very simply batch file and it works. https://github.com/flutter/flutter/issues/46904#issuecomment-629363145 I've been using it since my first Flutter Web day and it's still perfect. :-)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM626", "user": "jeansebastienZ", "root": "ROOT6", "reply_to": "COM625", "timestamp": "2020-06-17T18:55:20Z", "text": "Hello @deakjahn  , This batch will be used on release version ?  If i did understand well no ? Because my problem is calling some webservice  who don't accept CORS. Calling those webservices from my release version.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM627", "user": "deakjahn", "root": "ROOT6", "reply_to": "COM626", "timestamp": "2020-06-17T19:08:53Z", "text": "No, I thought you meant debugging, this is what the OP talked about. :-)\r\n\r\nIn release mode, you need correct CORS settings. I don't think Flutter can do anything about this, this is a browser security limitation. No webapp can override the security features of the browser; if it could, that would make them completely useless.\r\n\r\nSo there is actually a web service not under your control that doesn't have correct CORS settings? If it is so, how is anybody supposed to use it, quite independent from Flutter?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM628", "user": "mateusfccp", "root": "ROOT6", "reply_to": "COM627", "timestamp": "2020-06-28T20:30:29Z", "text": "> @deakjahn Thanks! I have adapted your [script solution](https://github.com/flutter/flutter/issues/46904#issuecomment-629363145) in Linux as described below and it works perfectly!\r\n> \r\n> Create a `google-chrome-unsafe.sh` with the following content:\r\n> \r\n> ```\r\n> #!/bin/sh\r\n> /usr/bin/google-chrome-stable --disable-web-security --user-data-dir=\"A-TEMP-LOCATION\" $*\r\n> ```\r\n> \r\n> It's better to create and use a dedicated folder in the home directory instead of `/tmp` for the temporary location, as Chrome will create some folders there to work properly.\r\n> \r\n> Then, make it executable with `chmod a+x google-chrome-unsafe.sh`\r\n> \r\n> The environment variable can be set in `~/.bashrc` or `~/.bash_aliases` (if included from `.bashrc`):\r\n> `export CHROME_EXECUTABLE=/path/to/google-chrome-unsafe.sh`\r\n\r\nThis solution didn't work for me on macOS.\r\n\r\nI made the following script:\r\n```sh\r\n#!/bin/sh\r\n/Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --disable-web-security --user-data-dir=\"a-temp-location\" %*\r\n```\r\n\r\nAnd set the `CHROME_EXECUTABLE` variable correctly in my `.profile`.\r\n\r\nWhen I start my Flutter Web app in debug mode it will behave exactly as it was before.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM629", "user": "deakjahn", "root": "ROOT6", "reply_to": "COM628", "timestamp": "2020-06-28T22:20:13Z", "text": "Did you leave `a-temp-location` verbatim? :-)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT7", "user": "arcanis", "root": "ROOT7", "reply_to": null, "timestamp": "2021-02-08T14:11:32Z", "text": "deps: add Yarn 1.22.5 <!--\r Before submitting a pull request, please read\r https://github.com/nodejs/node/blob/master/CONTRIBUTING.md.\r \r Commit message formatting guidelines:\r https://github.com/nodejs/node/blob/master/doc/guides/contributing/pull-requests.md#commit-message-guidelines\r \r For code changes:\r 1. Include tests for any bug fixes or new features.\r 2. Update documentation if relevant.\r 3. Ensure that `make -j4 test` (UNIX), or `vcbuild test` (Windows) passes.\r \r Developer's Certificate of Origin 1.1\r \r By making a contribution to this project, I certify that:\r \r (a) The contribution was created in whole or in part by me and I\r     have the right to submit it under the open source license\r     indicated in the file; or\r \r (b) The contribution is based upon previous work that, to the best\r     of my knowledge, is covered under an appropriate open source\r     license and I have the right under that license to submit that\r     work with modifications, whether created in whole or in part\r     by me, under the same open source license (unless I am\r     permitted to submit under a different license), as indicated\r     in the file; or\r \r (c) The contribution was provided directly to me by some other\r     person who certified (a), (b) or (c) and I have not modified\r     it.\r \r (d) I understand and agree that this project and the contribution\r     are public and that a record of the contribution (including all\r     personal information I submit with it, including my sign-off) is\r     maintained indefinitely and may be redistributed consistent with\r     this project or the open source license(s) involved.\r -->\r \r Ref https://github.com/nodejs/node/discussions/37193 (and https://github.com/nodejs/node/discussions/37193#discussioncomment-332622 in particular, cc @jasnell @mcollina)\r \r This commit adds Yarn to the Node release tarballs and installers. I tested:\r \r - Windows (`.\\vcbuild.bat msi` and ran the resulting exe)\r - MacOS (`make pkg` and ran the resulting pkg)\r - Linux (untar'd the `.tar.gz` file)\r \r In all cases, running `yarn --version` yielded the correct Yarn version (1.22.5 for infra reasons, which is for all purposes identical to 1.22.10 minus a postinstall script which has no impact whatsoever in this situation).\r \r ---\r \r * This PR changes close to nothing for existing Node.js users (this PR doesn't remove `npm` from the Node.js project, and you can still install Yarn separately from Node.js), it's meant to improve the experience of new users.\r * Reasons for integrating Yarn v1 (rather than v2) are outlined in https://github.com/nodejs/node/pull/37277#issuecomment-775586604 and more in depth in https://github.com/nodejs/node/discussions/37193#discussioncomment-341160\r * Please keep the discussion focused on Yarn v1, integration of other package managers can happen in a separate issue.", "meta": {"posReactions": "23", "negReactions": "82"}}
{"id": "COM70", "user": "bnb", "root": "ROOT7", "reply_to": "ROOT7", "timestamp": "2021-02-08T22:53:15Z", "text": "I am -1 based on the fact that Yarn v1 (a.k.a. anything other than Berry) is frozen. That does not sound like a dependency that we should be taking on imo.\r\n\r\nFrom [yarnpkg/yarn](https://github.com/yarnpkg/yarn):\r\n\r\n> The 1.x line is frozen - features and bugfixes now happen on https://github.com/yarnpkg/berry", "meta": {"posReactions": "28", "negReactions": "0"}}
{"id": "COM71", "user": "arcanis", "root": "ROOT7", "reply_to": "COM70", "timestamp": "2021-02-08T23:04:38Z", "text": "@bnb This point is discussed (and answered) [there](https://github.com/nodejs/node/discussions/37193#discussioncomment-341160). As the maintainer of both release lines I don't mind discussing it further, but I think this linked thread would be a better opportunity to discuss these topics than an implementation PR - both for ergonomic reasons and because it's already been answered.\r\n\r\nJust to be clear, I don't mind waiting for a TSC evaluation. I've only contributed to Node a couple times, and processes / ownerships are still a bit fuzzy to me. I'm happy to wait for the decision of whoever group is in charge of this kind of work. At least the implementation exists and provides a concrete picture of what the outcome would be.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM72", "user": "bnb", "root": "ROOT7", "reply_to": "COM71", "timestamp": "2021-02-08T23:37:51Z", "text": "@arcanis I appreciate the content there but it does not address my concern. The fact that Yarn v1 is frozen is a massive red flag to me as a 'new' dependency. IMO that context deserves to be held in the PR to add a dependency if it is a concern.\r\n\r\nYou assert that you expect people to stop using Yarn in favor of Berry, and have data to back that up. Further, you assert that the only changes you're planning on making are security changes - this is relatively well demonstrated by the [backlog of PRs](https://github.com/yarnpkg/yarn/pulls) that are submitted solving issues that users are having but aren't being merged or addressed, including tiny ones like [fixing broken links](https://github.com/yarnpkg/yarn/pull/8427).\r\n\r\nFrom the perspective of looking at Node.js over the next few years - rather than the short-term benefit of such a change - I frankly cannot see a reason why the Node.js project would take something on that's actively and intentionally being migrated off of as a result of the maintainers' choice in direction for it and isn't addressing problems end-users are facing outside of security issues.", "meta": {"posReactions": "27", "negReactions": "1"}}
{"id": "COM73", "user": "arcanis", "root": "ROOT7", "reply_to": "COM72", "timestamp": "2021-02-09T01:32:20Z", "text": "> I frankly cannot see a reason why the Node.js project would take something on that's actively and intentionally being migrated off of as a result of the maintainers' choice in direction for it and isn't addressing problems end-users are facing outside of security issues.\r\n\r\nThat's because you're deriving an incorrect premise, which is that Yarn 1 doesn't address problems end-users are facing. To reiterate:\r\n\r\n**Yarn 1 isn't legacy**\r\n\r\nYarn 1, as it is, is fine. It has its flaws, and some people would like more features, but, and that's critical, **its value comes from its stability**. People using Yarn 1.x right now have a project that already works. They may hit edge cases every once in a while, but the whole reason they use it is that they mostly figured out that the tradeoff was still value-positive for their current project. **Being frozen is a feature**, it's a gift that we are giving. It means that existing users won't get accidental regressions or bugs. **Yarn is about stability, and putting our users in control.** You shouldn't need to upgrade just because we release something new.\r\n\r\nYarn 2 is technologically better in many aspects. It would be easier for us to simply say that it should be the global binary at all time and that's it - similar to how npm is distributed. But different projects value different things, and in our case we care a lot about giving each user exactly the version they expect - whether it's Yarn 1, 2, 3, or 42. We care about it so much that we introduced a builtin feature for that three years ago, that we made it the default a year ago, and that we started the discussions around Corepack three months ago.\r\n\r\nOf course it means that not all users are necessarily on the latest release. That's fine! Because they already have a tool that solves their needs right now, and because we'll never break semantics by redefining existing fields or ranges - as that would negatively affect past users by forcing them to upgrade. Now, perhaps later their use case will evolve, they'll need better perfs, or to solve a particular bug, or to implement something on their own, and they'll upgrade to the latest release, which will keep receiving regular bugfixes and new features. But perhaps not, and that's fine, because they will still follow an explicitly supported use case.", "meta": {"posReactions": "5", "negReactions": "4"}}
{"id": "COM74", "user": "bnb", "root": "ROOT7", "reply_to": "COM73", "timestamp": "2021-02-11T18:16:35Z", "text": ">That's because you're deriving an incorrect premise, which is that Yarn 1 doesn't address problems end-users are facing.\r\n\r\nAt no point am I basing my assertion in that on the premise that Yarn 1 doesn't address problems end-users are facing. Bower is a good tool that solve(d/s) problems that end-users were facing. There are absolutely still people using it in production, and it still \"works\" as far as I'm aware.\r\n\r\nThat's not justification for being bundled in Node.js, imo.\r\n\r\n> Yarn 1, as it is, is fine. It has its flaws, and some people would like more features, but, and that's critical, its value comes from its stability. People using Yarn 1.x right now have a project that already works. They may hit edge cases every once in a while, but the whole reason they use it is that they mostly figured out that the tradeoff was still value-positive for their current project. Being frozen is a feature, it's a gift that we are giving. It means that existing users won't get accidental regressions or bugs. Yarn is about stability, and putting our users in control. You shouldn't need to upgrade just because we release something new.\r\n\r\nI can understand where you're coming from here, but this sounds like a pitch to me. It feels like justification of decisions without crediting the potential trade-offs or drawbacks of those decisions.\r\n\r\nThere's so much to deconstruct in this bit so rather than doing it in paragraphs, I'm going to try to summarize in bullets:\r\n\r\n* \"It has its flaws\" there are bug reports and PRs to patch them that are going unmerged. This is a very... simple and kind way to frame this.\r\n* \"People using Yarn 1.x right now have a project that already works.\" People using pnpm, bower, or jspm also have projects that work. If they're already using it and have a workflow that works for them, why do we need to include Yarn in Node.js? Why is yarn different from those other package managers?\r\n* \"They may hit edge cases every once in a while, but the whole reason they use it is that they mostly figured out that the tradeoff was still value-positive for their current project.\" Same point as above. If they're already using it and have a workflow around that, what is the reason to add it to Node.js?\r\n* \"Being frozen is a feature, it's a gift that we are giving.\" Framing a decision you've made as a \"gift\" implies that the recipient should be grateful. If they're not, that sets them up to be the villain. Frankly, I don't really think this framing has a space in this PR nor, honestly, to our users.\r\n* \"It means that existing users won't get accidental regressions or bugs. Yarn is about stability, and putting our users in control.\" How is this different than permanently pinning to a package manager version across a company? I can use the first-ever published version of Yarn and expect the same, just like I can for npm, pnpm, Bower, or jspm.\r\n* \"You shouldn't need to upgrade just because we release something new.\" Wasn't your previous assertion that you're only going to be doing security releases from now on?\r\n\r\nI am entirely familiar with the arguments around projects being \"done\" and feature complete. I think that those reasons are entirely fine within userland. Where I think we need to be more critical of that is when we're committing it into Node.js in a way that is effectively irrevocable.\r\n\r\n> that we started the discussions around Corepack three months ago.\r\n\r\nIs Corepack still progressing? If so, why are we considering this PR since Corepack would theoretically replace it?\r\n\r\n> Of course it means that not all users are necessarily on the latest release. That's fine! Because they already have a tool that solves their needs right now\r\n\r\nAgain, if they already have the tool why are we putting it in Node.js core? Doing so would _force_ them to change their existing workflows - including involuntarily upgrading users who are on an older version - which seems to be antithetical to the stated goals of Yarn.", "meta": {"posReactions": "15", "negReactions": "0"}}
{"id": "COM75", "user": "arcanis", "root": "ROOT7", "reply_to": "COM74", "timestamp": "2021-02-11T18:34:41Z", "text": "> Again, if they already have the tool why are we putting it in Node.js core? Doing so would _force_ them to change their existing workflows - including involuntarily upgrading users who are on an older version - which seems to be antithetical to the stated goals of Yarn.\r\n\r\nI don't think you understand this diff, or how Yarn is distributed. All versions of Yarn act both as a package manager and a jumper (similar, if you will, to `gulp-cli`). If it finds a `yarnPath` entry in `.yarnrc.yml`, it will use it instead of the global one. In other words, older projects will use Yarn 1 (because that's the global version used as fallback when nothing is found), or the checked-in package manager if it finds the right configuration to do so. Put simply, everyone gets what they ask for. There is no \"involuntarily upgrading users who are on an older version\". On the other hand, it does require *a* Yarn to be globally available.\r\n\r\n> I can understand where you're coming from here, but this sounds like a pitch to me. It feels like justification of decisions without crediting the potential trade-offs or drawbacks of those decisions.\r\n\r\nLet's be clear - you're telling *me* that I don't credit trade-offs or drawbacks, on a project I maintain, for a protocol that was designed a year ago, and for which noone has reported any automated breakage of any system, while still being able to migrate at the time of their choice. At this point I don't know what to tell you.\r\n\r\n> Is Corepack still progressing? If so, why are we considering this PR since Corepack would theoretically replace it?\r\n\r\n[That's answered](https://github.com/nodejs/node/discussions/37193#discussioncomment-332122).\r\n", "meta": {"posReactions": "0", "negReactions": "3"}}
{"id": "COM76", "user": "bnb", "root": "ROOT7", "reply_to": "COM75", "timestamp": "2021-02-11T19:16:01Z", "text": "> Put simply, everyone gets what they ask for.\r\n\r\nAre you 100% certain, without question, that nobody is relying on the global yarn to be a specific version rather than using `yarnPath`? If there is _anyone_ who is and they upgrade, it'll very quickly become our problem.\r\n\r\n> you're telling me that I don't credit trade-offs or drawbacks, on a project I maintain\r\n\r\nYes. In the paragraph you wrote - which is clearly what I was replying to - you only focus on the aspirational positives of Yarn v1 being frozen (outside of security updates, which you'd mentioned in a previous comment) without addressing potential trade-offs or drawbacks in a neutral way. I'm not sure how that's seemingly absurd or controversial to you.\r\n\r\n> That's answered.\r\n\r\nYou point to the Binary Management Discussion, which is somewhat about Corepack but ended up being more about version management. The [PR](https://github.com/nodejs/node/pull/35398) you opened, says this:\r\n\r\n>In short, the intent is to provide standard shims that allow users to run Yarn and pnpm commands without having to explicitly install them first, and without cluttering the Node distribution.\r\n\r\nI fail to see how this PR is not entirely antithetical to the goal of including Corepack and does not \"clutter the Node distribution\"", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM77", "user": "arcanis", "root": "ROOT7", "reply_to": "COM76", "timestamp": "2021-02-11T19:37:59Z", "text": "> Are you 100% certain, without question, that nobody is relying on the global yarn to be a specific version rather than using `yarnPath`? If there is _anyone_ who is and they upgrade, it'll very quickly become our problem.\r\n\r\nNo 2.x stable release was ever made on the npm registry. The last one which was, `2.0.0-rc.27` (out of 36), was only assigned to a `berry` tag. I'm positive no Yarn 2 user relies on a specific global version.\r\n\r\nAs for Yarn 1 users, past releases were semver-compliant, so 1.22.5 (the latest one) can installs the whole 1.x line. I would also point out that this wouldn't be any different from how npm releases work: you recently upgraded npm from 6 to 7, which is far riskier than Yarn 1.20 to 1.22 - at least semver-wise.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM78", "user": "mhdawson", "root": "ROOT7", "reply_to": "COM77", "timestamp": "2021-02-25T21:49:06Z", "text": "Discussed in the meeting today:\r\n\r\nConsensus seems to be to try to do survey to get more information to help TSC members understand the need before calling a vote. Next step is to find volunteer to drive survey as we had no volunteers in the meeting. More details in: https://github.com/nodejs/TSC/pull/973/files and you can also watch the recording https://youtu.be/7WJ1p-W56nY at around 10:00 minutes in.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM79", "user": "mmarchini", "root": "ROOT7", "reply_to": "COM78", "timestamp": "2021-02-25T22:27:22Z", "text": "@mhdawson it was also suggested that we invite @arcanis to a meeting to make a case in favor of this PR before we move to a vote.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM710", "user": "arcanis", "root": "ROOT7", "reply_to": "COM79", "timestamp": "2021-02-26T00:00:26Z", "text": "Sounds good \ud83d\udc4d\r\n\r\nOnly remark I have: as we probably all know, which package managers people use tend to be a quite polarizing topic, where both communities can sometimes display a certain lack of empathy. Years ago it was Emacs v Vim, then Tabs v Space, and nowadays Yarn v npm. I feel the need to mention this, because studies have shown that those who oppose tend to be more vocal than those who support, especially when the opposition is the status quo.\r\n\r\nGiven that the primary goal (at least for me) is to help current users, not necessarily acquire new ones, I'd be wary of the survey wording. Specifically, I'd be cautious about not making it look like a \"two parties\" question. In my opinion, the survey would benefit by proving not only that a segment of the Node community would be positively impacted by this change, but also that even those who wouldn't directly benefit from it *wouldn't be negatively impacted* either.\r\n\r\nFor instance, rather than \"would you like it? Y/N/neutral\", which could incite non-Yarn users to answer N rather than neutral, perhaps a more suitable question would be \"would it benefit your workflows? Y/N; would it impede your workflows? Y/N\" (perhaps with a \"Why?\" box on each, to get testimonies on both sides). Basically focusing on the effects rather than the feelings. My 2 cents.\r\n\r\n(One last note in the meantime, @jasnell made an informal Twitter poll pretty much about this about a year ago; while the results are incomplete with only 378 answers, it can help set expectations and perhaps give ideas about wording: https://github.com/nodejs/node/discussions/15244#discussioncomment-99336)", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM711", "user": "targos", "root": "ROOT7", "reply_to": "COM710", "timestamp": "2021-04-01T06:56:53Z", "text": "I started a test release build so we can check the result on all platforms. Will post the download link when it's ready.\r\n~https://ci-release.nodejs.org/job/iojs+release/6772/~ https://ci-release.nodejs.org/job/iojs+release/6773/", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM712", "user": "targos", "root": "ROOT7", "reply_to": "COM711", "timestamp": "2021-04-01T11:31:12Z", "text": "Here it is: https://nodejs.org/download/test/v16.0.0-test5708b0c1e5/", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM713", "user": "targos", "root": "ROOT7", "reply_to": "COM712", "timestamp": "2021-04-01T15:08:51Z", "text": "[license-builder](https://github.com/nodejs/node/blob/master/tools/license-builder.sh) should be updated to add Yarn's license to our distribution.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM714", "user": "ert78gb", "root": "ROOT7", "reply_to": "COM713", "timestamp": "2021-04-01T17:27:15Z", "text": "What will the planned future of the Yarn v1 be? Every project, which was once feature freezed, is to be sunset. There is v2 and there may be  v3, etc. The time will come when the user group is very small or 0.\nDo you have any metrics which shows the trend of the v1 usage?\n\nNode.js has a release calendar that makes changes planable.\n\nA lifetime plan for Yarn v1 is needed too, specially in the current case when it can be one of the elements of the Node.js installer.\n\nHonestly, I would like to remove it from the official docker images, too. The time will come when the question is raised:\n- keep Yarn v1 and add v2 to the docker image\n- replace Yarn v1 with v2\n\nSorry for the extra topic I just wanted to highlight this question, too.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM715", "user": "arcanis", "root": "ROOT7", "reply_to": "COM714", "timestamp": "2021-04-01T17:46:31Z", "text": "> What will the planned future of the Yarn v1 be? Every project, which was once feature freezed, is to be sunset.\r\n\r\nIt's fairly frustrating to see my words being repeatedly [ignored](https://github.com/nodejs/node/pull/37277#issuecomment-775586604). Perhaps consider that the idea may have been tossed around *a few times already* (including on this very repository, and in this very thread) and that there's a reason why the Yarn core team is doing a PR adding Yarn 1 (which acts as a jumper for both v1 and v2 users), and not Yarn 2 (which does not).\r\n\r\nIf we are to work together for the sake of our users I'd expect to see trust go both ways.", "meta": {"posReactions": "5", "negReactions": "5"}}
{"id": "COM716", "user": "jasnell", "root": "ROOT7", "reply_to": "COM715", "timestamp": "2021-04-01T18:15:38Z", "text": "@nodejs/tsc ... What do we need to do at this point to get this moving forward? I'd like to see this move forward.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM717", "user": "ert78gb", "root": "ROOT7", "reply_to": "COM716", "timestamp": "2021-04-01T18:22:09Z", "text": "Sorry, you are right I skipped the discussion.\nI read it and I found the answer to many question.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM718", "user": "mhdawson", "root": "ROOT7", "reply_to": "COM717", "timestamp": "2021-04-01T20:04:49Z", "text": "@jasnell it is waiting on a volunteer to move the survey forward that was discussed in the TSC meeting.\r\n\r\n@Trott also mentioned that he might use it to test out an RFC processes he was thinking of proposing.\r\n\r\nNot sure if there was discussion in the meeting today as I was not able to be there, but last week we agreed that if there is no progress with 2-3 weeks on either of those we'll just put it to a vote of the TSC.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM719", "user": "jamiebuilds", "root": "ROOT7", "reply_to": "COM718", "timestamp": "2021-04-01T23:11:52Z", "text": "I would really like to push for Yarn not to be included in Node. As a project it has abandoned its original intentions which made Yarn v1 appealing to the Node community. And the new direction of the Berry project has led to massive confusion and division in the community. At the same time, npm has addressed the original concerns that led to the creation of Yarn in the first place, and has shown a far more stable path forward for the community.", "meta": {"posReactions": "20", "negReactions": "3"}}
{"id": "COM720", "user": "iarna", "root": "ROOT7", "reply_to": "COM719", "timestamp": "2021-04-09T18:51:23Z", "text": "My main concern about Yarn v1 is that [bugs are now being closed](https://github.com/yarnpkg/yarn/issues/7610) as \"fixed in v2\" which is not what you do in a maintained major version. These kinds of bugs are complete show stoppers for some private registries. Shipping an unupdatable version of Yarn as an unchanging artifact in Node leaves Node permanently broken. Bugs happen, but there needs to be some process through which they can be fixed.\r\n\r\nIf this really was just a feature freeze, I would be less concerned, but as can be seen from the issue and associated PR, that's not how it's playing out on the ground.\r\n\r\nI would also add that the ecosystem needs to be able to add features to package management systems. Blessing a package manager that can't receive feature updates would reduce the ability for the Node community to adapt to changes. For instance, there's the open npm RFC to add registry dependencies -- if that lands in a way that's acceptable and adopted the major package managers still under development, it would be very uncomfortable for Node itself to be shipping with one that didn't support it.", "meta": {"posReactions": "33", "negReactions": "0"}}
{"id": "COM721", "user": "arcanis", "root": "ROOT7", "reply_to": "COM720", "timestamp": "2021-04-09T19:17:12Z", "text": "> here's the open npm RFC to add registry dependencies\r\n\r\nWhich is a very interesting example, thanks for bringing that up. The RFC you're talking about has received strong objections from both Yarn and pnpm - objections which from what transpire from the issue don't plan to be addressed. In other words, npm being the only package manager is already putting the ecosystem at risk (at least under their current handling of RFCs).\r\n\r\nAlso note that this isn't a unique occurence - in fact, it already happened a few months ago with npm 7, which tried to change how peer dependencies are semantically defined. Just like now, the RFC received early and strong pushback from both Yarn and pnpm (and other projects), but the RFC author decided to ignore them and go with it.\r\n\r\nThe lack of package managers diversity (and thus neutrality) is a problem. The role of the Node TSC is to find a solution. This PR (along with others) is a way to do that. If you have a better one go for it? I don't mind seeing competing ideas.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM722", "user": "ljharb", "root": "ROOT7", "reply_to": "COM721", "timestamp": "2021-04-09T19:24:14Z", "text": "Which peer dep RFC are you referring to? (peer deps have always been semantically required, for example; but i'm not sure if that's what you're referring to)", "meta": {"posReactions": "0", "negReactions": "3"}}
{"id": "COM723", "user": "arcanis", "root": "ROOT7", "reply_to": "COM722", "timestamp": "2021-04-09T19:26:56Z", "text": "> Which peer dep RFC are you referring to? (peer deps have always been semantically required)\r\n\r\nThis isn't the time nor place to have this debate with you once more.\r\n\r\n> since it would have greatly fragmented the package ecosystem if many package authors had gotten the wrong idea and assumed peer deps were optional by default.\r\n\r\nYou're incorrect, and I don't appreciate trying to have the last word on this argument after I told you I don't wish to debate it.", "meta": {"posReactions": "0", "negReactions": "6"}}
{"id": "COM724", "user": "ljharb", "root": "ROOT7", "reply_to": "COM723", "timestamp": "2021-04-09T19:28:34Z", "text": "Sounds like that's indeed the change you meant, then - I wasn't trying to rehash the debate, just trying to clarify what you were referring to.\r\n\r\nIn that case, I think that the ecosystem benefited hugely from having a single authority for that, since it would have greatly fragmented the package ecosystem if many package authors had gotten the wrong idea and assumed peer deps were optional by default.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM725", "user": "jasnell", "root": "ROOT7", "reply_to": "COM724", "timestamp": "2021-04-09T19:52:39Z", "text": "@ljharb:\r\n> ...having a single authority for that\r\n\r\nThat depends entirely on the point of view and on how accountable that authority is to the community. Even with the RFC process, npm's roadmap is still controlled by a singular commercial interest. Perhaps the better forum for such discussions would be the OpenJS Foundation, where a spec and reference implementation for such things could live while allowing competition on specific implementations. But... that's a separate conversation.\r\n\r\n@iarna does raise a valid point about ensuring that bugs that need to be fixed in the 1.x stream are fixed in 1.x. As I understand it, there's no intent on shipping yarn2 in core which means we cannot interpret \"fixed in 2\" as being meaningful here. @arcanis addresses that concern rather well [here](https://github.com/nodejs/node/discussions/37193#discussioncomment-341216). So long as there is a demonstrated commitment to ensuring that security and critical bug fixes are made, and that yarn1 remains functional/compatible with Node.js@latest, then I'm not sure what else can be said there that would be convincing. Specifically, no one has asserted that the yarn versions shipped in node.js would be \"unupdatable\".\r\n\r\nI would not expect Node.js to just accept that unquestioningly. I would expect Node.js to hold Yarn accountable to that promise that the issues would be addressed, and if it turns out the issues are not addressed and major bugs persist, then we would always have the option of removing yarn from the distribution.\r\n\r\n@iarna also said:\r\n> ...if that lands in a way that's acceptable and adopted the major package managers still under development, it would be very uncomfortable for Node itself to be shipping with one that didn't support it.\r\n\r\nBut that's not the case here. Node.js would not just be shipping a single package manager option that did not support the feature, it would continue shipping multiple package manager options. It would be up to users to determine what they want to use -- and whether support for that new feature is important to them or not. The users would give us the necessary feedback to determine which is the right path. That said, it would be rather unfriendly to the ecosystem as a whole for a single package manager run by a singular commercial interest to unilaterally ship a new feature that would qualify as a \"must support\" by others.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM726", "user": "mhdawson", "root": "ROOT7", "reply_to": "COM725", "timestamp": "2021-04-09T19:59:17Z", "text": "@jasnell with respect to your earlier questions, this issue is now open to work on/agree on what a vote should look like: https://github.com/nodejs/TSC/issues/1012", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM727", "user": "iarna", "root": "ROOT7", "reply_to": "COM726", "timestamp": "2021-04-09T20:37:45Z", "text": "@arcanis \r\n\r\n>Which is a very interesting example, thanks for bringing that up. The RFC you're talking about has received strong objections from both Yarn and pnpm - objections which from what transpire from the issue don't plan to be addressed. In other words, npm being the only package manager is already putting the ecosystem at risk (at least under their current handling of RFCs).\r\n\r\nWhich is exactly why I included this caveat:\r\n\r\n> if that lands in a way that's acceptable and adopted the major package managers \r\n\r\nThere were suggestions in that RFC that you expressed support for. I don't believe consensus is impossible.\r\n\r\n@jasnell \r\n\r\n> But that's not the case here. Node.js would not just be shipping a single package manager option that did not support the feature, it would continue shipping multiple package manager options. It would be up to users to determine what they want to use -- and whether support for that new feature is important to them or not. The users would give us the necessary feedback to determine which is the right path.\r\n\r\n**Are you suggesting that the Node Foundation will be taking on responsibility for updating Yarn1 in the future, if it's included? If that were the case then my concerns would be answered.** Right now the problem is, if you have to patch Yarn1 you're SOL. You have to support floating patches forever and the version users can install independently diverges from the one bundled with Node.\r\n\r\n> That said, it would be rather unfriendly to the ecosystem as a whole for a single package manager run by a singular commercial interest to unilaterally ship a new feature that would qualify as a \"must support\" by others.\r\n\r\nSurely that is true, and also not afaict relevant?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM728", "user": "jasnell", "root": "ROOT7", "reply_to": "COM727", "timestamp": "2021-04-09T20:41:33Z", "text": "> Are you suggesting that the Node Foundation will be taking on responsibility for updating Yarn1 in the future, if it's included? If that were the case then my concerns would be answered.\n\nNo, I'm saying that we would look to yarn to fix those issues and if they do not we retain the option of removing it from the distribution. It's no different than the relationship with npm today. Fixes are made upstream. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM729", "user": "iarna", "root": "ROOT7", "reply_to": "COM728", "timestamp": "2021-04-09T20:43:11Z", "text": "> No, I'm saying that we would look to yarn to fix those issues and if they do not we retain the option of removing it from the distribution. It's no different than the relationship with npm today. Fixes are made upstream.\r\n\r\nBut, and maybe I'm misunderstanding(?), they are as a matter of  policy not making fixes. It's frozen to the degree that you can't fix bugs in it. There is no plan to have more releases of Yarn 1, is there?\r\n\r\nEdited to add: If Yarn 1 were actively maintained, receiving bug fixes, I would have no complaints. But \"frozen but not legacy\" isn't enough, imo. All I want is _someone_ to be responsible for it.", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "ROOT8", "user": "archenemies", "root": "ROOT8", "reply_to": null, "timestamp": "2018-05-16T20:21:33Z", "text": "fix or document proper configuration for specifying default output order I have an HP Photosmart Plus B210a which prints pages face up. I am trying to figure out how to configure Cups to print documents so that I don't have to reverse them by hand when they come out of the printer.\r \r I found [a discussion on linuxquestions.org](https://www.linuxquestions.org/questions/ubuntu-63/can-i-set-the-cups-output-order-to-always-print-in-reverse-order-746843/) which summarizes a recommended fix:\r \r      Add the line\r      *DefaultOutputOrder: \"reverse\"\r      to the file\r      /etc/cups/ppd/PrinterName.ppd\r \r I have tried this with varying results. I printed twelve two-page documents to try to investigate what is happening. I tried printing via the `lp` command, via Evince and via Okular. I tried using a ppd file with and without the `DefaultOutputOrder` line, and I also tried specifying a default output order with `lpoptions` of \"reverse\" or \"normal\":\r \r     lpoptions -dHP_Photosmart_Plus_B210a -o outputorder=reverse\r     ...\r     lpoptions -dHP_Photosmart_Plus_B210a -o outputorder=normal\r \r The results:\r \r * `lp`: Ignores ppd line, honors lpoptions setting\r * Evince: Ignores lpoptions setting, honors ppd\r * Okular: Ignores both lpoptions and ppd\r \r As with the reporter of #1679, I would have expected the PPD which is downloaded by default for my printer to give the \"correct\" behavior by default, which is to say, not requiring me to manually reverse long documents when they come out of the printer.\r \r I also tried the solution of #1679, using\r \r     lpadmin -p printer -o outputorder-default=reverse\r     lpadmin -p printer -o outputorder-default=normal\r \r This setting was honored by Evince but not by `lp` or Okular.\r \r Okular's print dialog allows the user to change the ouput ordering, but Evince's print dialog, which appears more \"standard\" to me, says \"Page Ordering: Not available\".\r \r There was some mention of all documents going through `pstops` as a final filter. If this is true then it should be possible for Cups to give users a single point at which to configure output ordering, which works uniformly across all applications which might submit print jobs to Cups. In either case it should be documented what is the preferred way to deal with face-up printers.\r \r I humbly offer my suggestion that for \"outputorder=reverse\" to work intuitively as a per-job option, then it should interact with the per-printer option as a parity bit, e.g. reverse+reverse=normal, rather than as an \"override\" (reverse+reverse=reverse). In my experimentation it seems to be the latter, and I think this should be documented because it is somewhat different from the way that other options like \"page-ranges\" work. If I write a script to print the odd pages in order and then the even pages in reverse, I feel I should be able to get the same result (manual duplex) regardless of the printer model. In any case where the `lp` man page says:\r \r       -o outputorder=reverse\r           Prints pages in reverse order.\r \r I think it maybe should say something like:\r \r       -o outputorder=(reverse|normal)\r           Overrides printer output-order setting for this job. With\r           \"outputorder=reverse\", document will be reversed on\r           face-down printers, and correctly ordered on face-up\r           printers; and vice-versa for \"outputorder=normal\".\r \r Here is my PPD file in case it helps: [HP_Photosmart_Plus_B210a.ppd](https://github.com/apple/cups/files/2010726/HP_Photosmart_Plus_B210a.ppd.txt)\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM80", "user": "michaelrsweet", "root": "ROOT8", "reply_to": "ROOT8", "timestamp": "2018-05-17T15:41:29Z", "text": "OK, so I'm assuming from the list of applications you are using that you are using a Linux distribution of some sort. The PPD comes from the HPLIP project.\r\n\r\nUnfortunately, this isn't something we can help you with - either the cups-filters raster filter is not honoring the DefaultOutputOrder value in the PPD or the HPLIP driver isn't doing something right. Either way you need to start with your Linux distribution's bug reporter and go from there...\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM81", "user": "archenemies", "root": "ROOT8", "reply_to": "COM80", "timestamp": "2018-05-17T17:55:26Z", "text": "Michael, I can submit the bug elsewhere but do you really mean to suggest that I need to know about HPLIP and cups-filters to understand why three different tools process the options I've set (using your software) in three different ways? What about the other questions I asked? You don't think any of your documentation needs to be fixed? Can you point me to the place in the documentation where you say which of lpadmin/lpoptions/PPD solutions is expected to make the printer work correctly with all CUPS clients? Who takes responsibility when other projects don't know how to interface correctly with your software?\r\n\r\nCan you give the HP people a hint on how the HP filter would need to be modified so that it respects the `lpadmin` setting not just with Evince print jobs but also with jobs submitted by Okular and `lp`? Or how can Okular be modified so that it prints correctly on inkjets?\r\n\r\nIs there another brand of inkjet printers, which works correctly with CUPS?\r\n\r\nWhat about cups-pdf, I've noticed that when printing to the virtual PDF printer then `lp` doesn't respect the lpadmin setting, Evince doesn't respect the lpoptions setting, and Okular doesn't respect either. Is that still an HP problem? Are you ever grateful to receive bug reports about your project?\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM82", "user": "michaelrsweet", "root": "ROOT8", "reply_to": "COM81", "timestamp": "2018-05-17T18:01:15Z", "text": "@archenemies The non-CUPS software is not following the standard interfaces that CUPS provides. IOW, this is either a bug in HPLIP or cups-filters. If they follow the standard interfaces you won't have to do a damned thing to have things Just Work\u2122. We can't fix software that isn't ours...\r\n\r\nAs for pstops, no not all jobs get routed through there. Maybe 18 years ago that was the case, but not today.\r\n\r\nAs for the documentation, it is correct if the underlying driver or filters follow the standard interfaces.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM83", "user": "archenemies", "root": "ROOT8", "reply_to": "COM82", "timestamp": "2018-05-18T01:58:12Z", "text": "So cups-pdf is HP's problem too? Is there any Linux software you can name that interfaces with CUPS correctly?\r\n\r\nIt would help to have an answer to this question, relating to the configuration of face-up printers:\r\n\r\n\"Can you point me to the place in the documentation where you say which of lpadmin/lpoptions/PPD solutions is expected to make the printer work correctly with all CUPS clients?\"\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM84", "user": "michaelrsweet", "root": "ROOT8", "reply_to": "COM83", "timestamp": "2018-05-18T14:38:09Z", "text": "cups-pdf is from another developer. Both depend on cups-filters on Linux, which probably means that the problem lies with cups-filters.\r\n\r\nWe do not document printing solutions for Linux, working or otherwise. We don't write or support the software, and we don't make the distributions.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT9", "user": "Asgoret", "root": "ROOT9", "reply_to": null, "timestamp": "2019-12-19T14:16:47Z", "text": "Santa hat removal Are you happy @Christian-Schiffer? Your behaviour offence a lot of people around the world.  \r I think you must apologize to these people and @egamma must do it too.\r \r **UPD#1:** Christmas, like Hanukkah, is a great time of the year. When people give each other a little love, warmth and kindness. Trying to be better than they were during the year. So why spoil this wonderful moment of world peace with unfounded accusations, old insults and other unpleasant things? I don\u2019t understand, and you?\r \r Assign: \r https://github.com/microsoft/vscode/issues/87268\r https://github.com/microsoft/vscode/issues/87386\r ", "meta": {"posReactions": "10", "negReactions": "0"}}
{"id": "COM90", "user": "virgiliu", "root": "ROOT9", "reply_to": "ROOT9", "timestamp": "2019-12-19T14:23:54Z", "text": "Assuming he wasn't just trolling: if one gets butthurt and triggered over an emoji or icon, then the internet is not really the place where one should hang around.\r\nAssuming he was trolling: troll successful, gg\r\n\r\n\r\nPandering to icon haters seems to be high on Microsoft's list instead of handling actual bug fixes or feature requests.", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM91", "user": "appgurueu", "root": "ROOT9", "reply_to": "COM90", "timestamp": "2019-12-19T14:30:26Z", "text": "I'm also not happy that the santa hat was removed, completely ignoring the public opinion here on GH.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM92", "user": "chrisdias", "root": "ROOT9", "reply_to": "COM91", "timestamp": "2019-12-19T19:46:25Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.\r\n\r\nHappy Coding!\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT10", "user": "Avamander", "root": "ROOT10", "reply_to": null, "timestamp": "2020-07-10T13:17:17Z", "text": "IPython doesn't follow the XDG base directory specification Currently IPython uses `~/.ipython` which just clutters people's home directories and makes things like backing up configuration files much more hassle than it should be. \r \r This was last discussed more than five years ago and should be discussed again. Points made at that point in time frankly, don't really hold up. It is more consistent to follow platform specs, people learn where to look first. Secondly, for support reasons, you don't really have to ask what platform they're on, just mention the three paths in one sentence, it's actually rather easy. ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM100", "user": "adamroyjones", "root": "ROOT10", "reply_to": "ROOT10", "timestamp": "2020-07-19T11:05:02Z", "text": "For those looking for the previous discussion, it can be found [here](https://github.com/ipython/ipython/pull/4457).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM101", "user": "Carreau", "root": "ROOT10", "reply_to": "COM100", "timestamp": "2020-07-21T00:17:54Z", "text": "I believe if you move your folders in XDG compliant places it should work, though updating all the code and documentation all over the internet, plus the code to do the right thing is a lot of work; and XDG spec IIRC did not completely match or was not clear for all the types of files that could be present. \r\n\r\nThere might be packages on PyPI that may help with ~/.config /User/.../Libraries/AppData. %appdata% depending on OS, and this will also likely need to touch all the jupyter ecosystem (ipykernel, jupyter_client, traitlets, etc, so I doubt there'll be an effort from core dev to push that forward.\r\n\r\nTHough if you have issues when files _exists_ in XDG placed and not found I\"ll be happy to get fixes in. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM102", "user": "Avamander", "root": "ROOT10", "reply_to": "COM101", "timestamp": "2020-07-21T00:58:26Z", "text": "@Carreau \r\n\r\nYou're being a bit facetious. There's no need to update \"all the code and documentation all over the internet\", nobody has every done that and never will. Neither would the updating even be necessary, the official documentation should contain the location of the configuration file, that's it. The third silly thing is that you're acting like IPython doesn't have any changes that break some pieces of code or tutorials out there. All in all it makes your comment seem more like irrational stubbornness than actual concerns.\r\n\r\nNot to mention, if it's _that_ hard to change the folder, then that hardcoding seems like a massive code smell anyways and should be fixed anyways, and the choice to set the location of the folder should be up to the user.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM103", "user": "Carreau", "root": "ROOT10", "reply_to": "COM102", "timestamp": "2020-07-21T01:43:18Z", "text": "Hey, I was there for the first or changing default configuration directory, and all the issues it created; And I'm one of the person who has to deal both with public and private requests about the bits of documentation that users have tried on the internet and does not work because its inaccurate, either when it was written or because IPython changed, so yes I'm well aware of the consequences of changing. \r\n\r\nAnd so yes the official documentation is one of the last place users looks for that information, and yes sometime they look at the latest docs for 5 years old IPython version.\r\n\r\nYes `~/.ipython` is not optimal, and no it's not a code smell we removed all the complex logic because it was brittle and was super confusing, and because every time we were teaching software carpentry there was section with all the combinaisons of linux/mac/windows IPython version x.y.z\r\n\r\nSo yes I was of your opinion 10 years ago, and no to this days I still don't know the 3 path on each of the platform, even on Mac which I'm using everyday and which now hides ~/Library in the finder.\r\n\r\nYou can change the code location by setting environment variables, and I told you that if it was not working with configuration in xdg dir I would gladly accept patches for that so that you have  the choice. \r\n\r\nNow if it's to criticize the code without proper understanding of the technical and social reason of why it is the way it is, and bring XDG zealotry into the mix, I'm even less likely to make an effort.\r\n\r\nPR still accepted but discussion closed.\r\n\r\n ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT11", "user": "bk2204", "root": "ROOT11", "reply_to": null, "timestamp": "2020-02-07T16:30:17Z", "text": "proposal: path/filepath: add Resolve, replacing EvalSymlinks ### What version of Go are you using (`go version`)?\r \r <pre>\r $ go version\r go version go1.12.7 windows/amd64\r </pre>\r \r ### Does this issue reproduce with the latest release?\r \r Yes.\r \r ### What operating system and processor architecture are you using (`go env`)?\r \r Applies to all OSes\r \r ### What did you do?\r \r 1. Mounted a UNC path as a drive letter.\r 2. In CMD, switched the current working directory to that drive.\r 3. Called filepath.Abs on a relative path.\r 4. Called filepath.EvalSymlinks on the result of that function.\r \r ### What did you expect to see?\r \r The same results as calling GetFinalPathNameByHandle: a UNC path.\r \r ### What did you see instead?\r \r A path using the drive letter instead of the UNC path.\r \r ### Notes\r \r This affects any attempt to canonicalize paths using the output of Git in such a situation.  Git produces some paths as absolute and some paths as relative, and uses GetFinalPathNameByHandle for canonicalizing absolute paths.  However, Go lacks a function to canonicalize paths in a standard way, so it isn't possible to produce results equivalent to a C program and still write code that works portably across systems.\r \r Go should add a function that is explicitly defined to canonicalize paths in a way equivalent to the underlying operating system, since using filepath.Abs and filepath.EvalSymlinks doesn't work correctly on Windows.  It does work fine on Unix, but Unix paths are much simpler and easier to reason about.\r \r It was determined in #17084 that filepath.Abs and filepath.EvalSymlinks were sufficient in this case, but that doesn't appear to be true.  I expect there are other cases in which those don't work on Windows, but I am insufficiently versed in Windows paths to know what those are.\r \r This was originally reported to the Git LFS project in git-lfs/git-lfs#4012.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM110", "user": "dmitshur", "root": "ROOT11", "reply_to": "ROOT11", "timestamp": "2020-02-07T17:41:49Z", "text": "/cc @robpike @rsc per [owners](https://dev.golang.org/owners).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM111", "user": "alexbrainman", "root": "ROOT11", "reply_to": "COM110", "timestamp": "2020-02-07T22:23:38Z", "text": "> ### What did you expect to see?\r\n> The same results as calling GetFinalPathNameByHandle: a UNC path.\r\n\r\nI did not try it, but, I suspect, UNC paths wouldn't work in some situations. For example, can you pass UNC path to os.Chdir?\r\n\r\nAlex", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM112", "user": "bk2204", "root": "ROOT11", "reply_to": "COM111", "timestamp": "2020-02-07T23:07:47Z", "text": "I don't know for certain, but judging by a quick Google search, it appears to be [possible in Ruby](https://stackoverflow.com/questions/35659257/ruby-dir-chdir-not-working-in-loop-using-unc-paths), so I assume one can do that in C-based languages.\r\n\r\nI'm not a Windows developer, so I'm not a good person to ask about the capabilities of Windows.  I'm just a Unix developer trying to make general-purpose software not be terrible on Windows.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM113", "user": "alexbrainman", "root": "ROOT11", "reply_to": "COM112", "timestamp": "2020-02-08T06:16:50Z", "text": "> I don't know for certain, but judging by a quick Google search, it appears to be [possible in Ruby](https://stackoverflow.com/questions/35659257/ruby-dir-chdir-not-working-in-loop-using-unc-paths), so I assume one can do that in C-based languages.\r\n\r\nYou are correct. I was wrong. os.Chdir does work with UNC paths.\r\n\r\nAlex", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM114", "user": "bk2204", "root": "ROOT11", "reply_to": "COM113", "timestamp": "2020-06-25T16:35:06Z", "text": "It is also the case that `filepath.EvalSymlinks` fails to work when canonicalizing paths where there's a junction to a volume that lacks a drive letter (a OneDrive mount is a good example of this).  For example, if `C:\\Users\\User\\OneDrive\\Vault` is a junction pointing to a OneDrive mount and we try to call `filepath.EvalSymlinks(\"C:/Users/Users/OneDrive/Vault/home.git\")`, that will fail with `readlink C:\\Users\\User\\OneDrive\\Vault: The system cannot find the path specified.`\r\n\r\nThis also works with C-based programs.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM115", "user": "bk2204", "root": "ROOT11", "reply_to": "COM114", "timestamp": "2020-09-08T19:04:15Z", "text": "Hey,\r\n\r\nIs there any interest in fixing this?  Right now, there is no cross-platform way to canonicalize a path in Go.  We keep running up against additional cases where the existing behavior doesn't canonicalize paths properly, leading to incompatibility with other programs on the system (notably Git).  This necessarily limits the portability of using Go as a cross-platform language.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM116", "user": "networkimprov", "root": "ROOT11", "reply_to": "COM115", "timestamp": "2020-09-08T19:29:03Z", "text": "By \"function to canonicalize paths\" do you mean a variation of EvalSymlinks that works on Windows? If so, note that EvalSymlinks is not recommended: #40180 (and probably can't be fixed).\r\n\r\nGo on Windows has a variety of long-standing filesystem bugs. I suggest using x/sys/windows to call the WinAPI if that solves your problem.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM117", "user": "bk2204", "root": "ROOT11", "reply_to": "COM116", "timestamp": "2020-09-08T22:21:55Z", "text": "I mean a function, when given a path, that returns a canonicalized version of that path.  In other words, the equivalent to `realpath(3)` on Unix or `GetFinalPathNameByHandle` on Windows, and the equivalent to Rust's `std::path::canonicalize`.\r\n\r\nIt isn't helpful to me to call the Windows API because (a) I'm not a Windows programmer and have no clue how to use it, (b) it isn't cross-platform, and (c) this is a function that is generally provided by the standard library.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM118", "user": "networkimprov", "root": "ROOT11", "reply_to": "COM117", "timestamp": "2020-09-08T23:09:01Z", "text": "Go has gaps on Windows; I plug them in my code. You've seen the interest this issue evoked :-p\r\n\r\nWhat you need isn't hard. Create a file named yourpkg_windows.go, import \"golang.org/x/sys/windows\", define GetCanonicalPath() to call `CreateFile(\"yourfile\")` (to get a handle) then `GetFinalPathNameByHandle`.\r\n\r\nCreate a file yourpkg_unix.go with a `// +build` directive for your unix platforms. Define GetCanonicalPath() with the solution for unix you already know.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM119", "user": "bk2204", "root": "ROOT11", "reply_to": "COM118", "timestamp": "2020-09-09T00:44:26Z", "text": "First of all, I appreciate that you're trying to help.  However, I do feel firmly that this functionality should be in the standard library, since it is in almost every other language, and it is in POSIX.  I don't want to carry a lot of platform-specific code in a program because it's difficult to maintain and test, especially when I don't typically develop on Windows.\r\n\r\nIf Go is known to have known defects on Windows, those should be promptly fixed or clearly documented.  For many purposes, it's fine if code doesn't run or run well on Windows, but there are some cases where it does.  The documentation should clearly and prominently list any limitations with using Go on Windows so that folks can make an informed decision.  Last I checked, the `filepath` documentation didn't indicate such limitations, and hasn't for some time.\r\n\r\nNormally, when I find a bug or missing feature, I would send a patch to implement that functionality.  However, Go has a CLA, and I don't sign CLAs, so any patch I might submit wouldn't be accepted.  If that changes, I'm happy to send a patch to implement this properly if nobody gets to it before me.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM1110", "user": "ianlancetaylor", "root": "ROOT11", "reply_to": "COM119", "timestamp": "2020-09-09T00:49:18Z", "text": "On Unix systems I think the proposed function is the same as `filepath.EvalSymlinks`.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1111", "user": "bk2204", "root": "ROOT11", "reply_to": "COM1110", "timestamp": "2020-09-09T01:00:47Z", "text": "Yes, I believe that they are identical.  `filepath.EvalSymlinks` is, as far as I'm aware, equivalent to `realpath(3)` on Unix and has the semantics I'm looking for.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1112", "user": "networkimprov", "root": "ROOT11", "reply_to": "COM1111", "timestamp": "2020-09-09T12:39:24Z", "text": "This proposal should probably also deprecate EvalSymlinks, which is seriously broken on Windows, see https://github.com/golang/go/issues/40180#issuecomment-661350111", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1113", "user": "rsc", "root": "ROOT11", "reply_to": "COM1112", "timestamp": "2020-09-16T17:58:19Z", "text": "What does \"canonical\" mean, precisely?\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1114", "user": "bk2204", "root": "ROOT11", "reply_to": "COM1113", "timestamp": "2020-09-16T22:27:57Z", "text": "If there are multiple ways to refer to a filename, the canonical path is the absolute filename which uses no indirections and uses the canonical case (that is, the path component as written to the file system) if the system permits case folding.  On Unix, that's the one that contains no symlinks (and, on macOS, uses canonical case and composition).  On Windows, there are many ways to have indirection in a path: symlinks, junctions, SUBST, etc.  (I don't actually know all of the possible ways, since I almost never use Windows).  The canonical form uses none of those indirections and uses the canonical case.\r\n\r\nAnother way to say this is that assuming no hardlinks exist, a file on Unix should have exactly one canonical name whose components are either directories or non-symlink, non-directory (but possibly special) files.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1115", "user": "rsc", "root": "ROOT11", "reply_to": "COM1114", "timestamp": "2020-09-17T17:48:49Z", "text": "@networkimprov, you make assertions without being specific about them. I am confused about three of the things you've said related to this issue.\r\n\r\n- You linked to #40180 which is making a general software engineering argument along the lines of \"you should never actually replace all the symlinks, that's violating the abstractions that have been set up\". I have some sympathy for that, but if it were true, it would apply not just to EvalSymlinks but also this issue as well. If so, then we should just close this very issue (#37113) as a terrible idea.\r\n\r\n- I see that you mentioned this issue in #40966, which is about some problems with path lengths in EvalSymlinks on Windows. We've had path length problems elsewhere on Windows. Path length issues are usually pretty straightforward to fix. Why would we want to gate a fix to #40966 on a larger design discussion on this issue?\r\n\r\n- Finally, you said, with no links at all, \"This proposal should probably also deprecate EvalSymlinks, which is seriously broken on Windows.\" How is it broken? That comment would be a good place for an issue link.\r\n\r\nThanks.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1116", "user": "networkimprov", "root": "ROOT11", "reply_to": "COM1115", "timestamp": "2020-09-17T18:36:17Z", "text": "I mentioned #40180 in https://github.com/golang/go/issues/37113#issuecomment-689088220 to suggest that the issue author reconsider canonicalization of paths. I didn't link it again later, but it documents a long list of problems with EvalSymlinks on Windows (which I've now linked).\r\n\r\nRe path length bugs, other instances of those have been left alone, see #21782 & #36375. And here's a list of Windows bugs that mention \"filepath\" https://github.com/golang/go/issues?q=is%3Aopen+is%3Aissue+label%3AOS-Windows+filepath", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1117", "user": "bk2204", "root": "ROOT11", "reply_to": "COM1116", "timestamp": "2020-09-17T23:31:27Z", "text": "Canonicalization of paths is required to properly implement any sort of Git support in a project.  More generally, it's required to determine definitively if a path is under a directory, which has a wide variety of general-purpose applications outside of Git.  Whether other people think it is useful in their projects, path canonicalization is commonly used and is almost always provided by the standard library.  Canonicalizing paths is [also recommended by CMU's secure coding guidelines](https://wiki.sei.cmu.edu/confluence/display/c/FIO02-C.+Canonicalize+path+names+originating+from+tainted+sources); while those are for C, there's no reason to think Go is any different.\r\n\r\nI agree that users typically don't want to see canonicalized paths and that path canonicalization cannot be used where there's a security-sensitive race condition, but that doesn't mean it lacks applications elsewhere, just that it's unsuitable for some use cases.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1118", "user": "rsc", "root": "ROOT11", "reply_to": "COM1117", "timestamp": "2020-09-18T16:12:47Z", "text": "@networkimprov, the path length bugs are left alone only for lack of time. I don't think there's any objection to fixing them as long as it is done correctly and well.\r\n\r\n@bk2204, I'm certainly not arguing against this functionality. I'm trying to understand why EvalSymlinks shouldn't be what provides this functionality on Windows.\r\n\r\n(I do somewhat object to the name \"canonical\": if \"/home/rsc\" symlinks to some device path like \"/u123/g3tah0uojq1/rsc\", I have a hard time calling the latter the \"canonical\" one. And for what it's worth there are plenty of people who disagree with you about what \"determine definitively if a path is under a directory\" should mean. I have the bug reports to prove it. :-) But again, I'm not saying we shouldn't do this. I just think EvalSymlinks is probably the answer.)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1119", "user": "networkimprov", "root": "ROOT11", "reply_to": "COM1118", "timestamp": "2020-09-18T17:52:23Z", "text": "If you change EvalSymlinks to call `GetFinalPathNameByHandle` on Windows, it may break some apps, so I'm pretty sure Alex wouldn't agree.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1120", "user": "rsc", "root": "ROOT11", "reply_to": "COM1119", "timestamp": "2020-09-23T17:54:36Z", "text": "> If you change EvalSymlinks to call GetFinalPathNameByHandle on Windows, it may break some apps, so I'm pretty sure Alex wouldn't agree.\r\n\r\nIt would need to keep doing what it's documented to do, namely preserve relative-ness to current directory when possible. That means calling GetFinalPathNameByHandle and fixing up the result a little. But we could still build a function around GetFinalPathNameByHandle that should handle everything Windows can throw at it. \r\n\r\nDid you have a specific breakage in mind?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1121", "user": "bk2204", "root": "ROOT11", "reply_to": "COM1120", "timestamp": "2020-09-23T22:39:42Z", "text": "Are you proposing that the behavior differ from `GetFinalPathNameByHandle` (on Windows) only when the path name is relative, or when the path name is absolute as well?  The former is fine, I think, and I have no position on it; the latter would be a problem for interoperability with tools written in other languages.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1122", "user": "networkimprov", "root": "ROOT11", "reply_to": "COM1121", "timestamp": "2020-09-23T22:48:27Z", "text": "@alexbrainman what do you think of changing the implementation of `filepath.EvalSymlinks` to just call `GetFinalPathNameByHandle`?\r\n\r\ncc @ericwj", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1123", "user": "ericwj", "root": "ROOT11", "reply_to": "COM1122", "timestamp": "2020-09-24T14:17:29Z", "text": "Relative paths are not thread-safe. Full stop.\r\n\r\n`EvalSymlinks` should not be fixed but replaced. `GetFinalPathNameByHandle` *always* returns an absolute path. Paths with `\\\\?\\` syntax are always absolute.\r\n\r\n[GetFinalPathNameByHandleA function (fileapi.h) - Win32 apps | Microsoft Docs](https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-getfinalpathnamebyhandlea)\r\n\r\n> The string that is returned by this function uses the \"\\\\\\\\?\\\\\" syntax. For more information, see `CreateFile`.\r\n\r\nThe CMU guidance obviously is written without considering the arguments against `EvalSymlinks` that I wrote up - which is based on guidance from Microsoft, so I don't quite agree with your conclusion that resolving file system driver paths is a proper thing to do while canonicalizing. I have just hastily scanned that document from CMU and I don't immediately see they say you should resolve links. They just mention links could be present for awareness.\r\n\r\nI have written quite a bit of software and I have never considered writing checks like that. Usually path checks involve checking whether they are in some base path - for which `Rel` is better than `EvalSymlinks`. Sure you can ask for a properly cased path and/or fix slashes, but otherwise, why write string handling or comparisons at all? Paths usually come from somewhere. I mean from the working directory, from configuration or perhaps from user input in most cases. Usually those are already trusted without doing any checks. Or they are built from system settings, which are also trusted. That might be circumstantial evidence against your conclusion based on that article but still.\r\n\r\nAlso about the Git example still I think the application should be in control of which links get resolved. Some of the links that make up a path used by Git could still be system administrator controlled which makes it wrong to resolve them and the result dependant on system configuration. Like for my system - most Git paths ran through `EvalSymlinks` on my system will (have to) be volume GUID paths (and hence again all always absolute). But Git should never care about that or go that deep. It's wrong.\r\n\r\nEDIT: The article ignores case-sensitivity issues by using `strncmp`. That is wrong as well. Most software on Windows assumes case-insensitivity, although NTFS is case-sensitive. On Linux, FAT32 is case-insensitive.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1124", "user": "networkimprov", "root": "ROOT11", "reply_to": "COM1123", "timestamp": "2020-09-24T16:37:25Z", "text": "As it's not possible to relativize some results of `GetFinalPathNameByHandle`, that could be a cause of breakage if EvalSymlinks is reimplemented with it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1125", "user": "bk2204", "root": "ROOT11", "reply_to": "COM1124", "timestamp": "2020-09-25T00:02:57Z", "text": "> Relative paths are not thread-safe. Full stop.\r\n\r\nThat's not true on modern POSIX systems.  You can open a file descriptor to a directory and operate on a path relative to that file descriptor with the `*at` series of functions.  It may be true on Windows.\r\n\r\n> The CMU guidance obviously is written without considering the arguments against `EvalSymlinks` that I wrote up - which is based on guidance from Microsoft, so I don't quite agree with your conclusion that resolving file system driver paths is a proper thing to do while canonicalizing. I have just hastily scanned that document from CMU and I don't immediately see they say you should resolve links. They just mention links could be present for awareness.\r\n\r\nI agree with some of your points and I've stated so above.  Users usually are not interested in canonical paths.  It's also wrong to use path canonicalization in a case where the possibility of changing path resolution leads to a security problem or buggy behavior.  That's a well known problem on Unix systems and Windows is no different.\r\n\r\nIt is irrelevant to me whether the path is created with a drive letter or not, so I have no position on that argument.\r\n\r\nI agree that `EvalSymlinks`, as it exists today, is broken on Windows and does not do anything interesting or useful in most cases.  That's why I opened this issue.\r\n\r\n> I have written quite a bit of software and I have never considered writing checks like that. Usually path checks involve checking whether they are in some base path - for which `Rel` is better than `EvalSymlinks`. Sure you can ask for a properly cased path and/or fix slashes, but otherwise, why write string handling or comparisons at all? Paths usually come from somewhere. I mean from the working directory, from configuration or perhaps from user input in most cases. Usually those are already trusted without doing any checks. Or they are built from system settings, which are also trusted. That might be circumstantial evidence against your conclusion based on that article but still.\r\n\r\nThe question is not whether you think this feature is valuable.  You need not use it.  The question is whether Go ought to provide access in a portable way to cross-platform functionality that every operating system and every other major language provides and which is used in many projects for good and valuable reasons, and which, even if used imprudently, is required for compatibility with other software already existing for longer than Go has.  The fact that major organizations like CMU recommend this practice is evidence that this feature is important and valuable, even if you disagree.\r\n\r\nPath canonicalization is even more important on Windows than Unix because Windows has case-folding behavior in its file system that depends on attributes related to when the file system was created.  It is therefore impossible without the kernel's help to know the proper name of a file and whether two file names actually refer to the same item on disk, and Windows otherwise lacks the concept of device and inode numbers which are normally used to perform this check on Unix.\r\n\r\n> Also about the Git example still I think the application should be in control of which links get resolved. Some of the links that make up a path used by Git could still be system administrator controlled which makes it wrong to resolve them and the result dependant on system configuration. Like for my system - most Git paths ran through `EvalSymlinks` on my system will (have to) be volume GUID paths (and hence again all always absolute). But Git should never care about that or go that deep. It's wrong.\r\n\r\nI have seen first hand how Git broke when it did not canonicalize paths consistently, and I still have a broken repository on my system from that point.  I am a core contributor to Git and the primary driver of the SHA-256 transition.  I've developed in situations where symlinks and path resolution have important and subtle security implications.  I understand the problem space intimately and why Git has the behavior it does.  Please don't try to to tell me that Git's behavior is wrong here, because it is not.  Whether a path is created by the user, the system administrator, or any other actor does not change whether canonicalization is necessary.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1126", "user": "ericwj", "root": "ROOT11", "reply_to": "COM1125", "timestamp": "2020-09-25T14:36:20Z", "text": "> That's not true on modern POSIX systems. You can open a file descriptor to a directory and operate on a path relative to that file descriptor with the *at series of functions. It may be true on Windows.\r\n\r\nObviously that is the same on any operating system if you just use `Rel` and `Join`. But `EvalSymlinks` makes the path relative to the current working directory and it is that fact that makes it not thread-safe. You can use `Join` but again you need the current working directory as argument, which might have changed in between these two calls.\r\n\r\n> The question is not whether you think this feature is valuable. You need not use it.\r\n\r\nMy argument is not against canonicalization, but against using or fixing `EvalSymlinks` to do it. This whole comment was about using `GetFinalPathNameByHandle` to implement `EvalSymlinks`. It can't be done properly.\r\n\r\n>  Windows otherwise lacks the concept of device and inode numbers\r\n\r\nThere is the concept of object identifiers, but these are an NTFS concept. So yeah sure absolutely, the OS needs to be involved and one of the things that is wrong with `path\\filepath` is that it doesn't involve the OS enough.\r\n\r\n> Please don't try to to tell me that Git's behavior is wrong here, because it is not.\r\n\r\nI don't know what Git does, but I really think it is wrong to resolve all links - even those that are in a parent directory of the Git repo. The issue linked specifically mentions the ability to have files open while these links are being changed and to continue to open files afterwards as long as these links are not in any way, for any length of time, cached. I don't mean to criticize your intimate knowledge and experience with Git development, but the proper way to go is to know which links are part of repository configuration and which ones are system configuration and leave the latter ones forever unresolved.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1127", "user": "rsc", "root": "ROOT11", "reply_to": "COM1126", "timestamp": "2020-09-30T16:43:19Z", "text": "The two objections to using GetFinalPathNameByHandle seem to be (1) needing to return absolute paths sometimes, and (2) problems with relative paths and threads changing directories.\r\n\r\nFor (1), EvalSymlinks is _already_ defined to return an absolute path when necessary. If the result of GetFinalPathNameByHandle cannot be made relative to the current directory, then the absolute one can be returned. That's entirely within the documented behavior.\r\n\r\nFor (2), there's nothing wrong with relative paths per se provided the process is not calling os.Chdir. It is Chdir (the write operation) that is not \"thread-safe\", not the relative path evaluation (the read operations). If you have a program that uses Chdir, then yes, use absolute paths. Pass an absolute path to EvalSymlinks and you'll get one out. But if EvalSymlinks is passed a relative path, there is no added harm in returning one.\r\n\r\nIt's really looking to me like we should use GetFinalPathNameByHandle in EvalSymlinks. Are there other reasons we should not?\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1128", "user": "networkimprov", "root": "ROOT11", "reply_to": "COM1127", "timestamp": "2020-09-30T17:45:31Z", "text": "It may be in-spec to always return an absolute path. But existing apps may rely on the current behavior. It's just conjecture, but the same has torpedoed previous proposals. However I'm not personally opposed to it.\r\n\r\ncc @mattn ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1129", "user": "rsc", "root": "ROOT11", "reply_to": "COM1128", "timestamp": "2020-09-30T21:08:08Z", "text": "> It may be in-spec to always return an absolute path.\r\n\r\nThat's **not** what I'm suggesting. I wrote \"If the result of GetFinalPathNameByHandle cannot be made relative to the current directory, then the absolute one can be returned.\"\r\n\r\nI did **not** write \"The absolute one can be returned always.\"\r\n\r\nBy \"made relative\" I meant transformed to be relative to the current directory by filepath.Rel.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT12", "user": "bnb", "root": "ROOT12", "reply_to": null, "timestamp": "2021-05-06T18:48:22Z", "text": "Rename Node-API to something less confusing/misleading <!--\r Thank you for suggesting an idea to make Node.js better.\r \r Please fill in as much of the template below as you're able.\r -->\r \r **Is your feature request related to a problem? Please describe.**\r There was recently a decision to rename N-API to Node-API. I believe this is a poor decision that will result in actively harmful results for both users of the API and general Node.js users.\r \r Specifically, there are multiple problems with this naming:\r \r - Building APIs are a common use case for Node.js. This naming can lead to confusing information or misleading search results.\r - Products often refer to the way to access their services with JavaScript or Node.js as their \"JavaScript API\". If people want to use this from Node.js, there is a non-trivial chance they will look for \"Node.js API\" which will lead to confusing results.\r - Node.js itself has an API, which theoretically includes this API. Naming a part of the whole the same thing as the whole is immensely confusing from an education perspective.\r - This API is far less likely to be used than other parts of the Ndoe.js API, which leads to an exacerbation of challenge presented by the problems above.\r \r **Describe the solution you'd like**\r \r Rename Node-API to something else.\r \r **Describe alternatives you've considered**\r - Undoing Node-API rename, moving it back to N-API. \r   -  There is a reason a rename was done initially, and that reason is valid.\r - Leave it as is.\r   - This is going to be actively harmful to communication and education n the long-run.", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM120", "user": "mhdawson", "root": "ROOT12", "reply_to": "ROOT12", "timestamp": "2021-05-06T18:57:27Z", "text": "For context the rename/work is complete. The blog post which explains the changes is https://nodejs.medium.com/renaming-n-api-to-node-api-27aa8ca30ed8.\r\n\r\nThe node-api team was asked to change the name in: https://github.com/nodejs/abi-stable-node/issues/420 . Being sensitive to the concern the team took on this extra work.\r\n\r\n\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM121", "user": "Trott", "root": "ROOT12", "reply_to": "COM120", "timestamp": "2021-05-10T04:13:30Z", "text": "Repeating [what I wrote 3 months ago](https://github.com/nodejs/TSC/issues/967#issuecomment-773031602):\r\n\r\n> I support changing the name N-API to something else, but the new term does have an obvious downside. The term \"Node API\" already has a straightforward meaning. Applying it to a specific API is more vague than descriptive.\r\n> \r\n> That said, I don't know that I have better ideas. (Native Bindings API? Addon API? ABI Stability API?)\r\n\r\nI'll also add that `Node API` is somewhat contrary to our years-long efforts to have the name of the runtime spelled `Node.js` and not `Node` (or `NodeJS` or a number of other variatns). \r\n\r\nOf course, now that the name change has already happened, there are significant costs/downsides to changing the name a second time in such a short period of time. I'd still support it, though, if the name was more descriptive and not subject to misinterpretation. A better name is better for our users.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM122", "user": "jasnell", "root": "ROOT12", "reply_to": "COM121", "timestamp": "2021-05-20T22:52:51Z", "text": "I'm -1 on changing the name again and I appreciate the effort the node-api team put into making the changes. It's a good change. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM123", "user": "mhdawson", "root": "ROOT12", "reply_to": "COM122", "timestamp": "2022-06-03T15:38:29Z", "text": "This was discussed in the Node-API team meeting today and and consensus was we don't think we want/will change at this point. Some of the team members could not comment directly since it was locked.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT13", "user": "bolds07", "root": "ROOT13", "reply_to": null, "timestamp": "2020-07-24T03:02:05Z", "text": "Json support to set Firebase Remote Configs defaults <!-- DO NOT DELETE \r validate_template=false\r template_path=.github/ISSUE_TEMPLATE/fr.md\r -->\r \r ## What feature would you like to see?\r \r Would be very usefull to have a simple way to export the firebase remote config fields to a json/xml and import them into another project/default values file.\r \r Today in order to do that we must config a sample project (available here) but this project isnt able to generate de default values file.\r Would be very usefull to have a simple way to do that, i have several remote config fields and app wont work without them. so on first run user must wait a few seconds (depending on his internet) to load the remote config constants) would be very nice if i could take a snapshot of the remote config values and pack it inside the apk in order to make first run faster\r \r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM130", "user": "google-oss-bot", "root": "ROOT13", "reply_to": "ROOT13", "timestamp": "2020-07-24T03:02:06Z", "text": "I couldn't figure out how to label this issue, so I've labeled it for a human to triage. Hang tight.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM131", "user": "ashwinraghav", "root": "ROOT13", "reply_to": "COM130", "timestamp": "2020-07-27T19:22:55Z", "text": "Hi @bolds07 \r\nThanks for the suggestion. Might need some help to understand better. We have a way for you to configure [default values](https://firebase.google.com/docs/remote-config/use-config-android) for RC. I assume what you are asking for is different in that you want to snapshot the config state of a client to an exported file that can be loaded into your app's distribution apk. That right?\r\nI do see that as a goal that competes directly with keeping your clients up to date with the latest config values that you have configured on the backend. Any thoughts on how you would want the clients to trade off those goals for new installations of your application? Would you rather see the values packed into your apk or the values configured on your backend?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM132", "user": "bolds07", "root": "ROOT13", "reply_to": "COM131", "timestamp": "2020-07-27T21:03:14Z", "text": "> We have a way for you to configure default values for RC  \r\n\r\nthe way to configure default values for RC is taking a XML\r\n\r\nthe RC rest api speaks JSON, there is an obvious miscommunication problem! \r\n\r\nThere is a sample project in this repo, which teaches how to export the current RC into a json and import it into another RC project.\r\nwould be reasonable if that json could be used as default values for any project... without need of converting it to xml.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM133", "user": "ashwinraghav", "root": "ROOT13", "reply_to": "COM132", "timestamp": "2020-07-27T21:36:38Z", "text": "Default values are **not** intended to be used as a cache that sits in front of the RC service. They are defaults when no values have been configured on the service.\r\n\r\n> the way to configure default values for RC is taking a XML\r\n> the RC rest api speaks JSON, there is an obvious miscommunication problem!\r\n\r\nWe take the approach that is canonical to the platform. On Android, resources are typically XML. On iOS, it is a [plist](https://firebase.google.com/docs/remote-config/use-config-ios#set-in-app-default-parameter-values).\r\n\r\nIf I understand correctly, you are suggesting that we provide a way to configure defaults on the client using json. That seems reasonable.\r\n\r\nWorth noting that this won't solve the problem you originally raised of having to wait for the config values to be fetched after app installation.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM134", "user": "bolds07", "root": "ROOT13", "reply_to": "COM133", "timestamp": "2020-07-27T23:19:33Z", "text": "> Default values are not intended to be used as a cache that sits in front of the RC service. They are defaults when no values have been configured on the service.\r\n\r\ni really didnt understand that...\r\n\r\nfollow my thought:\r\n1- user first install app\r\n2- app tries to read a RC field during `onCreate` of first activity, the value isn't fectched yet so it will result as \"empty\".\r\n\r\nin my mind the default values will be read at this moment... am i wrong?\r\n\r\nare you saying that they arent read at this moment and only when the api knows for sure the fields doesnt exist on firebase i cant imagine a use case for it.\r\nbut if that is the case it is another suggestion to use this xml values as cache for first install apps.\r\n\r\nMy current solution is to create a loading screen for this situation. but it will fail if user tries to first open the app without internet connection (this might happen if user cleans app data)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM135", "user": "danasilver", "root": "ROOT13", "reply_to": "COM134", "timestamp": "2020-07-28T01:07:58Z", "text": "Hey @bolds07, I'm on the Remote Config team. Happy to help with how the RC SDK works with default values!\r\n\r\nWhen the SDK starts up, it loads any default values (like the ones in the XML file). When you call one of the get methods (like [`#getString(String key)`](https://firebase.google.com/docs/reference/android/com/google/firebase/remoteconfig/FirebaseRemoteConfig#getString(java.lang.String)), if a value has been fetched and activated the SDK will return that server value and otherwise return the default value for that key if one exists. Fetched values are also cached by the SDK so they'll be available (and be used over defaults) if the app has already fetched on a previous launch (and the user hasn't cleared app data).\r\n\r\nThe use case you describe where a user first opens the app without internet connection is a good case for default values since the app can use those in place of the server values.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM136", "user": "bolds07", "root": "ROOT13", "reply_to": "COM135", "timestamp": "2020-07-28T12:59:54Z", "text": "@danasilver, So I was right and @ashwinraghav comment might be misunderstood.\r\n\r\nthis turn our case back to the start point. @danasilver \r\nA - >RC SDK for android accept default values only as xml file\r\nB - >RC Rest SDK export the current RC fields only as JSON\r\n\r\nthere is an  obvious miscomunication between the systems, they should speak a common language, otherwise you are forcing ALL PROJECTS to define twice the RC values", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM137", "user": "danasilver", "root": "ROOT13", "reply_to": "COM136", "timestamp": "2020-07-28T19:35:44Z", "text": "I think @ashwinraghav explained this pretty well! We support a JSON REST API since that's a common standard for REST APIs on the web, and XML defaults on Android since that's the standard for the platform. I understand there can be frustration working between the formats.\r\n\r\nYou should only need to define RC in-app defaults once though - in the XML file. The default values saved online and available through the REST API are the server-side defaults used when no condition is met. There's more documentation on how Remote Config prioritizes parameter values in the docs here: https://firebase.google.com/docs/remote-config/parameters#parameter_value_priority", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM138", "user": "bolds07", "root": "ROOT13", "reply_to": "COM137", "timestamp": "2020-07-29T13:37:40Z", "text": "I'm sorry to tell you @danasilver but this isnt \"frustrating\" this is a super stupid architecture design...\r\nI dont understand why people working for google have such a problem admting they make mistakes...  everybody does, what makes difference is fix them or not.\r\n\r\ni cant even imagine a meeting to present the product:\r\n\"Here we have a new tool that will allow developers to set constants remotelly, helping with A/B tests and allowing the developer to change apps behavior without re-deploy.\r\n\r\nWe will provide a rest service which accepts data in the json format.\r\nAnd in case developer wants to set some default values he can use a XML/plist\"\r\n\r\nIn my company someone proposing such a frankstein architecture would be fired.\r\n\r\nYou just told me that if someone has an app in both architectures and want to use the default values THIS PERSON MUST DEFINE EVERY FIELD 3 TIMES... does it sound smart?\r\n\r\n> You should only need to define RC in-app defaults once though\r\n\r\nthis is a wrong assumption, although i agree these values shouldn't change very often, software are LIVE things: they grow, they mutate, they acquire new powers.\r\nSame way new constants are added, removed, or default values might change in a lifetime of any software.\r\nIf you were using RC on the innitial development of other firebase services, are you telling me that the default values of 3 years ago would still work for today?\r\n\r\n\r\nI hate to be rude and also hate to teach people how to do their jobs. but this architecture design of firebase RC is a clear mistake, anyone with a basic software engineer understand should be able to see that.\r\nAnd this whole text could be avoided if you guys simple had said: \r\n\"yeah that was a bad idea, i will try to put your suggestion in a next changelog or add some tool to convert json/xml then json/plist and any other technology RC lays on\"\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM139", "user": "samtstern", "root": "ROOT13", "reply_to": "COM138", "timestamp": "2020-07-29T20:32:29Z", "text": "@bolds07 I'm sorry but your tone is not acceptable, we expect everyone in the Firebase community to respect each other.  I hope you are able to work around your problem but we won't be able to help you any more on this thread.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT14", "user": "brodybits", "root": "ROOT14", "reply_to": null, "timestamp": "2018-05-30T12:35:48Z", "text": "Active owner badly needed From #4886, #6109, and other discussions I think it is clear that this project has no active owner. I am BEGGING @levithomason, @jlukic, or any other project owner to PLEASE add at least two more trusted owners or managers with the power to add more committers and maintainers so badly needed.", "meta": {"posReactions": "19", "negReactions": "0"}}
{"id": "COM140", "user": "levithomason", "root": "ROOT14", "reply_to": "ROOT14", "timestamp": "2018-06-04T03:47:51Z", "text": "@jlukic is the benevolent dictator here.  I'll let him respond, although, I think he's made his position pretty clear on it.\r\n\r\nI've suggested a few times before that an active group of folks could always come together, fork, and start making releases.  My time is overbooked working on the React port and the v2 effort, in which we'll take on our own styling.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM141", "user": "danatemple", "root": "ROOT14", "reply_to": "COM140", "timestamp": "2018-06-04T13:25:01Z", "text": "I am sure there are many who are also very satisfied users of both Semantic-UI and Semantic-UI-React, who would be happy to donate to the project where we are getting a huge amount of value for free.\r\n\r\nHowever both projects are notably lacking in \"Donate\" buttons, and the SUIR site gives the impression - possibly false - that as it is used by Amazon and Netflix, there must be plenty of sponsor $$$.\r\n\r\nMy own experience suggests that people are happy to pay - it just has to be easy, and they may need a \"nudge\".\r\n\r\nCan I suggest some Donate buttons or even a Kickstarter?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM142", "user": "y0hami", "root": "ROOT14", "reply_to": "COM141", "timestamp": "2018-06-04T14:08:57Z", "text": "@danatemple This has already been discussed here https://github.com/Semantic-Org/Semantic-UI/issues/6109", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM143", "user": "danatemple", "root": "ROOT14", "reply_to": "COM142", "timestamp": "2018-06-04T15:06:59Z", "text": "@hammy2899 yes I know. The level of donations was described there as being very low. However, this might have something to do with the fact that there are very few nudges to donate. There is a button right at the bottom of the entry webpage - but after you get to the docs, nothing (and you never go back to the main entry page, right?). There is no mention of donating on the GitHub readme, nor on the one for SUIR.\r\n\r\nSeeing as it was possible to get $1M from kickstarter for some icons (https://www.kickstarter.com/projects/232193852/font-awesome-5/), I'm just suggesting that there is maybe some untapped potential.\r\n", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM144", "user": "y0hami", "root": "ROOT14", "reply_to": "COM143", "timestamp": "2018-06-04T15:19:25Z", "text": "I agree it could be pushed more but this will still be up to Jack.\r\n\r\nWe should also think about funding platforms like https://opencollective.com", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM145", "user": "jlukic", "root": "ROOT14", "reply_to": "COM144", "timestamp": "2018-06-05T22:04:42Z", "text": "Just to be clear, my absence from frequent updates is specifically to address the need of finding a source of permanent funding for SUI.\r\n\r\nSolving UI for the web through open source and SUI is the core goal of my professional life\u2014a project I expect to continue for many more decades to come. \r\n\r\nIt is an unfortunate necessity that I must leave things on pause for the time being, but I think this approach has a much greater chance to provide permanent funding for the project and its underlying goals, beyond what might be achieved by asking for donations or crowdfunding.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM146", "user": "brodybits", "root": "ROOT14", "reply_to": "COM145", "timestamp": "2018-06-05T22:40:53Z", "text": "@jlukic, understood. The one thing we need from you and @levithomason, DESPERATELY, is hopefully less than 20 minutes of your time to give 2 actively trusted people the power to add and remove privileged maintainers within this project and ideally within this organization. They should also have the power to add more administrators like themselves if needed. (Most privileged maintainers should not have such extra administrator power.)\r\n\r\nI think this one action would be a MAJOR TECHNICAL LIFESAVER:\r\n- prevent the otherwise inevitable project fork that is under discussion here, #6413, and #6109, among other places\r\n- keep this project at the existing quality level\r\n- avoid the dead project syndrome\r\n\r\nBy \"project fork\" I mean a significant portion of the team split off, like what happened with node.js in the past. I think it would be much better to keep this project as one united team if possible.\r\n\r\n@jlukic I would like to commend you for the major efforts it must have taken on your part to get this project this far. I think we all understand 100% that you must be completely swamped with your professional work, business work for the project, and personal obligations. I remain extremely hopeful that you can help the rest of us with the one action proposed here.", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM147", "user": "douglasg14b", "root": "ROOT14", "reply_to": "COM146", "timestamp": "2018-06-06T04:57:26Z", "text": "@jlukic \r\n\r\nThe project needs lifesaving measures as it's community is dissatisfied enough to be discussing forks. I want to see this project live, and if forking it is the only way to get maintainers that then I'm behind it... You have good intentions for your project, and want to see it succeed. However, it's being smothered by inactivity and the inability of other members to step in. \r\n\r\nThe `dead project syndrome` is already rearing it's head when pull requests to fix bugs are being auto-closed due to inactivity... I see new bug reports and KNOW that I can fix it, but why bother if it's for naught and the fix gets ignored. **I love Semantic UI**, and if this project where to come back to life would happily set aside a dedicated amount of time to find and fix issues on a regular basis. I've stopped paying attention to the project over the last year, and even explored other UI libraries because it no longer seems to be moving forward.\r\n\r\nIt's at a critical point now, other passionate members are literally begging for the ability to maintain a project they love. I'm sure they want to avoid a fork, we need active maintainers that can keep this project running while you are sorting out funding. There are even members trying to maintain their own forks/versions.\r\n", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM148", "user": "ivantcholakov", "root": "ROOT14", "reply_to": "COM147", "timestamp": "2018-06-06T19:41:12Z", "text": "@jlukic At least stop the robot meanwhile.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM149", "user": "prudho", "root": "ROOT14", "reply_to": "COM148", "timestamp": "2018-06-07T08:21:23Z", "text": "@jlukic I'm sorry but I have to be this guy... The fact is that you left this repository unanswered for two plain month. Issues where opened and closed by the bot without any reponse, and nobody but you can do some critical things (merging pull requests, publishing fixes...).\r\n\r\nI can understand that you don't have time to do SUI technical stuff, and I can understand your desire to make SUI a web standard and a long goal life. But you MUST understant that without repo's activity people will not be interested in SUI anymore, and you'll try to find funds for a dead project...", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM1410", "user": "donaggio", "root": "ROOT14", "reply_to": "COM149", "timestamp": "2018-06-07T09:38:13Z", "text": "I second @prudho opinion: please @jlukic let people who already volunteered to have a more active role in this project, at least merging PR for small bug fixes, updating FA icons as mentioned on another issue and stuff like that. That will be sufficient until you manage to sort out your long term goals.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM1411", "user": "danatemple", "root": "ROOT14", "reply_to": "COM1410", "timestamp": "2018-06-07T12:14:52Z", "text": "@jlukic Jack, I trust to your judgement in this. This is the same judgement that produced the design decisions in Semantic-UI after all :)\r\n\r\nGive the guy some appreciation everyone!\r\n\r\nI have Semantic-UI-React about to be deployed and it has been excellent to work with. Just stuck with the 2.2 CSS as described here https://react.semantic-ui.com/usage", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1412", "user": "jlukic", "root": "ROOT14", "reply_to": "COM1411", "timestamp": "2018-06-08T01:57:12Z", "text": "I've disabled the bot. It won't be trolling the issues board anymore.\r\n\r\nI think the final vision of UI requires a cohesive system for theming, layouts, & ui, with simple, unified integrations for all js frameworks, and a well-defined toolkit to extend & distribute additional components, share themes and track versions between teams.  \r\n\r\nI think this is something I can produce and distribute open-source in the long-term, but will be a project much larger than SUI 2.x, and will require me pressing on for some time longer.\r\n\r\nI hope people keep that vision in mind, when considering the near-term goals like providing prompt feedback directly on GitHub discussions, quick resolution for user-contributed PRs, maintenance releases etc. It hurts me that I'm not able to keep up the same pace as I had when 2.0 was launched. I hope you guys keep that in mind, and be generous in your views", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1413", "user": "brodybits", "root": "ROOT14", "reply_to": "COM1412", "timestamp": "2018-06-08T02:24:48Z", "text": "Hey @jlukic thanks for disabling the bot. I think that will make a major difference for everyone involved.\r\n\r\nI can only imagine the stress you must be facing between a project with over 41K stars and the funding challenges.\r\n\r\nI do continue to feel pretty disappointed that the active project ownership that is so badly is still not coming in the near term. I guess we come to the inevitable second-choice alternative of forking, though some competitive fork ideas such as <https://github.com/morganbarrett/Vanilla-Semantic-UI> may prove really nice for some members of the community.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1414", "user": "donaggio", "root": "ROOT14", "reply_to": "COM1413", "timestamp": "2018-06-08T06:13:19Z", "text": "@jlukic thank you for clarifying your long-term vision for SUI, and I really really like it! But still, it doesn't seems totally incompatible with the much more short-term plan of letting other talented people maintain SUI 2.x while you work towards what it seems to be SUI 3.x / SUI-NG, don't you think?\r\n\r\nAnyway, thanks for all your hard work and dedication to this project!", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM1415", "user": "arjarn", "root": "ROOT14", "reply_to": "COM1414", "timestamp": "2018-06-08T12:43:13Z", "text": "@jlukic  : agree with prudho, donaggio (and many others) : tasks as bug fix, minors improvments, answering question about using, writing documentation are taking lot of times. It seem you've big community who love SUI and agree your mind. People are ready to help u for improving this great framework. \r\nGiving all this things to other and keeping your time for deeping development may be win-win for all :\r\n - for you, cause you can use 100% time for your (great) goal\r\n - for community cause talented people are ready to help\r\n - for users cause they'll find answers and see project is alive and active (what's more frustrating / dissuasive for dev to see dead repo ? almost if they are professional dev or Decision-makers in enterprise).\r\n\r\nI agree your mind but really sad about results...  :-|\r\n\r\nPS : sorry for my poor english, frenchies are really bad with it :-)", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1416", "user": "peterrobertz", "root": "ROOT14", "reply_to": "COM1415", "timestamp": "2018-06-11T18:59:28Z", "text": "I love you Jack, for making SUI. I just hope you dont get crazy <3", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1417", "user": "Atulin", "root": "ROOT14", "reply_to": "COM1416", "timestamp": "2018-09-02T04:05:31Z", "text": "Can we officially pronounce SemanticUI dead yet, or...\r\n![image](https://user-images.githubusercontent.com/11233299/44952087-2ed6c080-ae76-11e8-92c8-9e312ac971d9.png)\r\nIt's one thing when the repo doesn't get any new commits from the owner. It's another where the owner stops being active altogether.\r\n\r\nThere are no active maintainers (and the owner seems to be hell-bent on keeping it that way), no activity from the owner, nothing.", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM1418", "user": "dreaming-augustin", "root": "ROOT14", "reply_to": "COM1417", "timestamp": "2018-09-03T07:00:24Z", "text": "In reply to the previous comment, I'd like to say the same thing I said here: \r\nhttps://github.com/Semantic-Org/Semantic-UI/issues/6413#issuecomment-418018371 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1419", "user": "jlukic", "root": "ROOT14", "reply_to": "COM1418", "timestamp": "2018-09-10T21:27:34Z", "text": "@Atulin those are commits in master. Look at the `next` branch and twitter.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1420", "user": "davegson", "root": "ROOT14", "reply_to": "COM1419", "timestamp": "2018-09-18T13:08:29Z", "text": "@jlukic\r\n\r\n> Solving UI for the web through open source and SUI is the core goal of my professional life\u2014a project I expect to continue for many more decades to come.\r\n\r\nI do applaud that! \ud83c\udf89 I like ambitious goals. At the same time I must mention one thing: **you will not succeed on your own**.\r\n\r\nIn that regard I find it highly confusing - and disrespectful imho - that you chose to ignore all suggestions to delegate power to trusted contributors who would like to help you to maintain SUI 2.x. Which would _reduce_ your already high work load.\r\n\r\n### Solving UI for the web\r\n\r\nThis task is too great to be solved by a single person. The key here is not to solely depend on your brainpower - instead, multiply by giving others authority. I know you know this. You already talked with others about splitting up the workload, but your actions currently tell another story.\r\n\r\nIf \"Solving UI for the web\" **truly** is your goal, then I'd advise you to rethink your stance on delegation. \r\n\r\nYou already showed you have what it takes to do this! You built this awesome ship which *could* solve UI for the web. But it's gotten too big for you to micro manage every damn aspect of it. Let others help you with its navigation!\r\n\r\nPS: You will still be the captain ;)", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "ROOT15", "user": "bwateratmsft", "root": "ROOT15", "reply_to": null, "timestamp": "2020-02-13T16:51:08Z", "text": "Show a warning with Learn More link if SSH is in use without a working ssh-agent Resolves #1458 with @zifik's suggestion. Because an ssh-agent is required by the `ssh2` Node package (used by Dockerode) when using an SSH connection to a remote Docker daemon, we will show a warning with a Learn More link if SSH is in use without a working ssh-agent.\r \r The check is done by looking at the value for `SSH_AUTH_SOCK` (which on Windows can be defaulted to `\\\\.\\pipe\\openssh-ssh-agent`), and then trying to connect to that pipe to ensure it is actually working.\r \r The warning:\r ![image](https://user-images.githubusercontent.com/36966225/74459811-eccaf000-4e59-11ea-9867-4c4a08b6198c.png)\r \r The link: https://aka.ms/AA7assy", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM150", "user": "bwateratmsft", "root": "ROOT15", "reply_to": "ROOT15", "timestamp": "2020-02-18T17:02:02Z", "text": "@karolz-ms, could you look at adjusting the docs per @diablodale's feedback?\r\n\r\nWe also currently have the ability to automagically work with WSL2 when using Docker Desktop's [WSL2 backend feature](https://docs.docker.com/docker-for-windows/wsl-tech-preview/). The extension uses the `docker context` command to detect whichever context is active when the extension activates.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM151", "user": "karolz-ms", "root": "ROOT15", "reply_to": "COM150", "timestamp": "2020-02-18T17:23:46Z", "text": "@diablodale what would you like https://code.visualstudio.com/docs/containers/ssh documentation topic to say about WSL?\r\n\r\nThe whole topic is about \"connecting to remote Docker daemon\". With WSL there is no \"remote Docker daemon\" in the picture, so it should be pretty clear it does not apply to WSL. And with regards to WSL specifically we have this: https://code.visualstudio.com/docs/containers/choosing-dev-environment#_windows-subsystem-for-linux", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM152", "user": "karolz-ms", "root": "ROOT15", "reply_to": "COM151", "timestamp": "2020-02-18T19:36:33Z", "text": "@diablodale thanks. We can certainly clarify in the doc which parts do not apply to WSL (or WSL 2). \r\n\r\nFull disclosure: I haven't tried the steps listed under https://code.visualstudio.com/docs/containers/ssh#_directly-via-ssh  with WSL, but I would expect them to work, so I would like to understand why you are saying they are not supported. Are you aware of any known issues with this setup and WSL? Or maybe you tried and found the steps not working/sufficient? Thanks in advance for clarification!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM153", "user": "bwateratmsft", "root": "ROOT15", "reply_to": "COM152", "timestamp": "2020-02-18T19:39:56Z", "text": "@karolz-ms You can use [Remote - WSL](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-wsl) to attach VSCode to WSL (also, install the Docker extension within WSL; by default it runs as a UI extension). No configuration of the \"host\" (i.e. the Windows machine) is needed in that case. `bash` is automatically used as the terminal, and `dockerode` and `docker *` commands happen in the same context, so the setting `docker.host` (or env var `DOCKER_HOST`) will work for `ssh://...` values (as long as `SSH_AUTH_SOCK` is also set in WSL).\r\n\r\nWhen I tried with the Ubuntu distro, I had to call `eval $(ssh-agent -s)` and `ssh-add keyfile` from within `.bashrc` so that when the VSCode server-side process ran in WSL it would have the needed `SSH_AUTH_SOCK` environment variable, along with a running `ssh-agent` process, but I'm sure there are better ways to accomplish that. Once I did that everything worked as expected.\r\n\r\nIf you want to _not_ attach with Remote - WSL, then it is necessary to do the `ssh-agent` configuration in both Windows and WSL, because `dockerode` and `docker *` commands are not in the same context.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM154", "user": "karolz-ms", "root": "ROOT15", "reply_to": "COM153", "timestamp": "2020-02-18T19:52:38Z", "text": "@bwateratmsft thank you, that is exactly what I would expect. Based on that I would consider WSL supported.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM155", "user": "karolz-ms", "root": "ROOT15", "reply_to": "COM154", "timestamp": "2020-02-18T21:07:20Z", "text": "@diablodale thanks for clarification. I think I understand where you are coming from. The difference is in the mental model of what WSL really is. Is it *a shell*? This is how it was originally advertised (\"bash on Windows\"), but it evolved into something that nowadays most people here at Microsoft would describe it as *virtual environment for running Linux programs*. That has been made very prominent with WSL 2 and its native Linux kernel. And with this the expected, default level of integration between Win32 and WSL environment (as well as between different WSL instances) is really none. They are completely isolated.\r\n\r\nArguably complete isolation is not always the most practical choice, so WSL (and tools that leverage it) have multiple integration points with Win32 (file system mounts, socket mounts, the new Docker implementation for WSL2, VS Code Remote-WSL extension are good examples). The fundamental principle remains though that WSL environments and Win32 are isolated by default.\r\n\r\nI can see your point that for SSH connectivity (and probably other things) there is not enough integration and I agree. It is a pain to manage all the SSH identities separately for Win32 vs WSL. But this is largely an issue outside of the VS Code Docker extension control. @bwateratmsft  confirmed that  the setup described in the doc you referenced IS working with WSL, with the design of WSL as it is today. If anybody reports that it is not working, we will investigate. Hence it is supported.\r\n\r\nThank you for taking time to share your thoughts!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM156", "user": "karolz-ms", "root": "ROOT15", "reply_to": "COM155", "timestamp": "2020-02-18T23:30:19Z", "text": "Understood that we are not talking about method 1\r\n\r\nWSL is supported via Remote-WSL extension. When that extension is used, a headless instance of VS Code is installed into WSL environment. Then one can use that VS Code instance to install headless instance of Docker extension into WSL environment. That headless extension instance will see WSL environment configuration, including SSH/Docker configuration, and will drive the Docker extension UI running on Win32 side. All the data comes from the WSL environment and all the Docker commands are executed in that environment. The only caveat that Brandon describes is that ssh-agent configuration does not survive WSL environment restart, so it needs to be re-created via `.bashrc` file. This probably needs to be added to the doc. Everything else in https://code.visualstudio.com/docs/containers/ssh#_directly-via-ssh doc applies to WSL via Remote-WSL unchanged. \r\n\r\nWhat is not supported is running VS Code and Docker extension entirely on Win32 side, without Remote-WSL extension. At least not without extra manual work of keeping Win32 and WSL configuration in sync. This goes back to the point they are isolated environments.\r\n\r\nHope this clarifies things but please let me know if I missed something. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM157", "user": "bwateratmsft", "root": "ROOT15", "reply_to": "COM156", "timestamp": "2020-02-19T17:57:08Z", "text": "I agree that those are gaps in the documentation, but I'm not convinced that we _should_ document them. There's probably an infinite number of ways and combinations of ways to make remote connectivity work, but I think that our docs should stick to the beaten path(s), so to speak:\r\n\r\nA - Want to talk to remote Docker via HTTP? Use the appropriate `DOCKER_*` env vars or `docker.*` settings.\r\n\r\nB - Want to talk to remote Docker via SSH? Use Remote - SSH with Docker extension installed inside (preferred), or use the SSH features the Docker extension has (`DOCKER_HOST` / `docker.host` and `SSH_AUTH_SOCK`).\r\n\r\nC - Want to talk to remote Docker in WSL? Use Remote - WSL with Docker extension installed inside (preferred), or stand up SSH within WSL and use the SSH features the Docker extension has.\r\n\r\nD - Want to talk to remote Docker in WSL2? Use Remote - WSL with Docker extension installed inside (preferred), or the Docker WSL2 backend feature (preferred, but somewhat less so) (no extension config needed), or stand up SSH within WSL2 and use the SSH features the Docker extension has.\r\n\r\nMethod 3 (Remote - WSL + SSH) is a combination of options C and B, IMO better solved with just option B alone, so I'd prefer to not document it. The variant of method 2 (WSL as shell + SSH) is essentially option B but since it uses WSL as a shell, requires additional config work due to the disparate environments.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT16", "user": "Byloth", "root": "ROOT16", "reply_to": null, "timestamp": "2019-06-21T08:10:57Z", "text": "Terminal shows an empty window and then crashes Hi!  \r I'm trying to run this new Windows Terminal.\r \r After some difficulties and a few attempts I was able to build and deploy the project locally.  \r *\u00abGreat! Finally!\u00bb* I said to myself, just before clicking on the `Windows Terminal (Dev Build)` in the Start menu...\r \r This was the result: an empty window.\r > ![image](https://user-images.githubusercontent.com/14953974/59504305-f5ba8a80-8ea2-11e9-929f-4a56104b77b9.png)\r \r After a few seconds, it simply disappeared and then...  \r Well... Nothing more!\r \r ---\r \r Here are some useful (hopefully) information about my current system:\r >  Windows 10 1903 Build 18362.175\r >  x64 architecture\r >  `Developer mode` enabled\r >  Repo version built: v0.2.1715.0 (66cb7c4b58b0e41ffaeb952ef27f1a8c67e90db8)\r >  Build with Visual Studio 2019\r >  Built and deployed for x64 architecture\r \r ---\r \r Some time ago, I commented already here (https://github.com/microsoft/terminal/issues/489#issuecomment-502067642) explaining the same issue...  \r But, nobody could help me.\r \r Maybe opening a Issue I will be luckier...\r >  Sorry for the \"duplicate\"... \ud83d\ude14", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM160", "user": "DHowett-MSFT", "root": "ROOT16", "reply_to": "ROOT16", "timestamp": "2019-06-21T17:29:48Z", "text": "From another comment on the same issue,\r\n> if you are seeing a blank screen, make sure you are targeting the right architecture. you cannot run windows terminal x86 on an x64 machine.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM161", "user": "DHowett-MSFT", "root": "ROOT16", "reply_to": "COM160", "timestamp": "2019-06-21T17:30:15Z", "text": "Admittedly, I could have read \"built and deployed for x64 architecture\" and figured that out.\r\nCan you share the build log?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM162", "user": "yodurr", "root": "ROOT16", "reply_to": "COM161", "timestamp": "2019-06-22T02:28:55Z", "text": "I think the Terminal was so impressed with your desktop image it didn't want to render on top of it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM163", "user": "ShadowEO", "root": "ROOT16", "reply_to": "COM162", "timestamp": "2019-06-22T05:32:43Z", "text": "FWIW, I'm receiving the same behavior on my x86 tablet after installing the *MS Store* version. Previous copies compiled by me worked, so I'm left scratching my head as to why this is occurring now. I hadn't yet tested on my x64 laptop however, so I am unsure if it's the same there..\r\n\r\nUpdate: After looking at event viewer, I'm receiving an appcrash. I have pulled the events into an evtx if needed.\r\n```\r\nFaulting application name: WindowsTerminal.exe, version: 1.0.1906.20005, time stamp: 0x5d0c1506\r\nFaulting module name: Windows.UI.Xaml.dll, version: 10.0.18922.1000, time stamp: 0xf1c7f3c3\r\nException code: 0xc0000005\r\nFault offset: 0x007d208e\r\nFaulting process id: 0x2238\r\nFaulting application start time: 0x01d528c0b2bc30da\r\nFaulting application path: C:\\Program Files\\WindowsApps\\Microsoft.WindowsTerminal_0.2.1715.0_x86__8wekyb3d8bbwe\\WindowsTerminal.exe\r\nFaulting module path: C:\\Windows\\System32\\Windows.UI.Xaml.dll\r\nReport Id: 61ba7cc9-da7a-4bfb-8a43-b375251ebb66\r\nFaulting package full name: Microsoft.WindowsTerminal_0.2.1715.0_x86__8wekyb3d8bbwe\r\nFaulting package-relative application ID: App\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM164", "user": "magiblot", "root": "ROOT16", "reply_to": "COM163", "timestamp": "2019-06-22T22:39:21Z", "text": "I just installed from MS Store and experience the same issue. 64-bit OS here.\r\n```\r\nNombre de la aplicaci\u00f3n con errores: WindowsTerminal.exe, versi\u00f3n: 1.0.1906.20005, marca de tiempo: 0x5d0c1459\r\nNombre del m\u00f3dulo con errores: TerminalApp.dll, versi\u00f3n: 1.0.1906.20005, marca de tiempo: 0x5d0c140d\r\nC\u00f3digo de excepci\u00f3n: 0xc0000005\r\nDesplazamiento de errores: 0x000000000003a539\r\nIdentificador del proceso con errores: 0x1d48\r\nHora de inicio de la aplicaci\u00f3n con errores: 0x01d52949ad9a3604\r\nRuta de acceso de la aplicaci\u00f3n con errores: C:\\Program Files\\WindowsApps\\Microsoft.WindowsTerminal_0.2.1715.0_x64__8wekyb3d8bbwe\\WindowsTerminal.exe\r\nRuta de acceso del m\u00f3dulo con errores: C:\\Program Files\\WindowsApps\\Microsoft.WindowsTerminal_0.2.1715.0_x64__8wekyb3d8bbwe\\TerminalApp.dll\r\nIdentificador del informe: a7d6acc0-650b-40e3-a36b-2280d62e8ea9\r\nNombre completo del paquete con errores: Microsoft.WindowsTerminal_0.2.1715.0_x64__8wekyb3d8bbwe\r\nIdentificador de aplicaci\u00f3n relativa del paquete con errores: App\r\n```\r\nI wonder if it can be ran from the command line and see if it prints any error messages.\r\nEDIT: No, it doesn't. (`wt.exe`)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM165", "user": "ShadowEO", "root": "ROOT16", "reply_to": "COM164", "timestamp": "2019-06-23T07:19:38Z", "text": "So I attempted to build it on my own, and I am receiving the same behavior on my latest build. I did happen to try the x64 version on my laptop and it worked fine, but x86 is still not working. Sadly my x86 tablet doesn't have enough storage to be able to install VS onto it and VS won't let me set up a remote debugging profile for x86 (says Debug|x86 is missing from the project manifest when I even attempt to open the properties) so at the moment, my attempts to get to the bottom of why have stalled...\r\n\r\nI may need to set up a x86 VM just to debug with :/ assuming the behavior persists there as well.\r\n\r\nNow I'm just trying to grab myself an older copy of my build, just so I can at least use the new Terminal, even if it isn't as up to date..", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM166", "user": "tanayagar", "root": "ROOT16", "reply_to": "COM165", "timestamp": "2019-06-23T11:52:50Z", "text": "I'm facing the same issue, don't think that there is any compatibility issues here\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM167", "user": "Byloth", "root": "ROOT16", "reply_to": "COM166", "timestamp": "2019-06-23T15:47:14Z", "text": "Ok...  \r\nI think I found out why this is happening... \ud83e\udd14\r\n\r\nA couple of minutes ago I tried to run again the Terminal on my PC to log any errors to attach here...  \r\nWell... It runs (and it's **great**)! \ud83e\udd29\r\n\r\n> \u00abSo? Why now runs? What's the difference?\u00bb\r\n\r\n---\r\n\r\nToday I was using my notebook on my legs (without any devices connected).  \r\nUsually, I use my notebook connected to this [Universal Dock](https://www.dell.com/en-us/shop/dell-universal-dock-d6000/apd/452-bcyt/pc-accessories).\r\n\r\nThese kind of devices ([DisplayLink](https://www.displaylink.com/) docks) are seen by the OS as external video cards without extended support for hardware acceleration...  \r\nIn facts, you can't run video games or 3D graphics in general even if your GPU is the best one you can buy!\r\n\r\n---\r\n\r\nSo, I think, if the video card you're trying to render the Terminal on isn't compatible with hardware acceleration (or something like that) it, simply, crashes badly.\r\n\r\nIt could be also your case @ShadowEO, @magiblot and @tanayagar?  \r\nMaybe something like:\r\n\r\n- Cheap hardware?\r\n- Integrated video cards?\r\n- Virtual machines?\r\n- *... and so on?*", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM168", "user": "gfbearsfan", "root": "ROOT16", "reply_to": "COM167", "timestamp": "2019-06-23T16:48:18Z", "text": "I have similar issue.  After installing the Terminal, selecting the top pane dropdown, then <Settings> (while the Widows Powershell is auto-selected),  the terminal loads Visual Studio blank page & crashes.  \r\nI also have my (Lenovo W541) notebook on a docking station and am using Win 10 Pro x64b, Nightly, vers 1903, OS Build 18922.1000", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM169", "user": "magiblot", "root": "ROOT16", "reply_to": "COM168", "timestamp": "2019-06-23T17:34:08Z", "text": "@Byloth \r\n> So, I think, if the video card you're trying to render the Terminal on isn't compatible with hardware acceleration (or something like that) it, simply, crashes badly.\r\n> \r\n> It could be also your case @ShadowEO, @magiblot and @tanayagar?\r\n> Maybe something like:\r\n> \r\n>     * Cheap hardware?\r\n> \r\n>     * Integrated video cards?\r\n> \r\n>     * Virtual machines?\r\n> \r\n>     * _... and so on?_\r\n\r\nYes, I do have an Intel GPU (HD Graphics 520) but drivers and harware acceleration are in order. I don't use a docking station or VM, altough I do have this laptop connected to an external display through VGA/DP. But unplugging it changed nothing.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1610", "user": "ShadowEO", "root": "ROOT16", "reply_to": "COM169", "timestamp": "2019-06-23T20:03:19Z", "text": "That's a novel idea, but previous builds worked fine, for instance, I can reinstall one of my older dev builds and it opens and runs fine.\r\n\r\nYes, I am on cheap hardware for this device, it's a TMAX TM101W635L. Using an Intel HD Graphics (I am unsure of the exact model atm, as I am away from the machine.)\r\n\r\nVirtual Machines work fine on the device, but they aren't in active use (on 2 GBs of non-expandable RAM, you can see why).\r\n\r\nMy tests are all done on device itself, so no docking stations, no external hardware at all.\r\n\r\nI'm planning on setting up a 32-bit VS2019 VM on my main laptop tonight to see if the issue occurs there, and if so, to debug it as well.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1611", "user": "andreili", "root": "ROOT16", "reply_to": "COM1610", "timestamp": "2019-06-23T20:11:45Z", "text": "> * Cheap hardware?\r\n> * Integrated video cards?\r\n> * Virtual machines?\r\n> * _... and so on?_\r\n\r\ni5-9600K, RTX-2070, 32Gb RAM, Host OS - blank window and crash.\r\nInto debug, crash here:\r\n\r\n> >\tWindowsTerminal.exe!winrt::get_activation_factory<winrt::Windows::Foundation::IActivationFactory>(const winrt::param::hstring & name)Line 5222\tC++\r\nWindowsTerminal.exe!winrt::impl::factory_cache_entry<winrt::TerminalApp::App,winrt::Windows::Foundation::IActivationFactory>::call<<lambda_7763f00f6aca3060375b844bec98aa5c> &>(winrt::TerminalApp::App::<lambda_7763f00f6aca3060375b844bec98aa5c> & callback)Line 5420\tC++\r\nWindowsTerminal.exe!winrt::impl::call_factory<winrt::TerminalApp::App,winrt::Windows::Foundation::IActivationFactory,<lambda_7763f00f6aca3060375b844bec98aa5c> >(winrt::TerminalApp::App::<lambda_7763f00f6aca3060375b844bec98aa5c> && callback)Line 5501\tC++\r\n \tWindowsTerminal.exe!winrt::TerminalApp::App::App()Line 952\tC++\r\n \tWindowsTerminal.exe!AppHost::AppHost()Line 30\tC++\r\n \tWindowsTerminal.exe!wWinMain(HINSTANCE__ * __formal, HINSTANCE__ * __formal, wchar_t * __formal, int __formal)Line 35\tC++\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1612", "user": "corganfuzz", "root": "ROOT16", "reply_to": "COM1611", "timestamp": "2019-06-23T21:34:36Z", "text": "crashing here , I also have a displaylink device 4k, hooked up to a mini displayport  port. and getting this error:\r\n\r\n```powershell\r\nFaulting application name: WindowsTerminal.exe, version: 1.0.1906.20005, time stamp: 0x5d0c1459\r\nFaulting module name: unknown, version: 0.0.0.0, time stamp: 0x00000000\r\nException code: 0xc0000005\r\nFault offset: 0x0000000000000000\r\nFaulting process id: 0x2ee4\r\nFaulting application start time: 0x01d52a090c39d27d\r\nFaulting application path: C:\\Program Files\\WindowsApps\\Microsoft.WindowsTerminal_0.2.1715.0_x64__8wekyb3d8bbwe\\WindowsTerminal.exe\r\nFaulting module path: unknown\r\nReport Id: 51227091-efa4-43dc-bc7a-61696a519a8f\r\nFaulting package full name: Microsoft.WindowsTerminal_0.2.1715.0_x64__8wekyb3d8bbwe\r\nFaulting package-relative application ID: App\r\n```\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1613", "user": "tanayagar", "root": "ROOT16", "reply_to": "COM1612", "timestamp": "2019-06-24T05:07:16Z", "text": "> @Byloth\r\n> \r\n> > So, I think, if the video card you're trying to render the Terminal on isn't compatible with hardware acceleration (or something like that) it, simply, crashes badly.\r\n> > It could be also your case @ShadowEO, @magiblot and @tanayagar?\r\n> > Maybe something like:\r\n> > ```\r\n> > * Cheap hardware?\r\n> > \r\n> > * Integrated video cards?\r\n> > \r\n> > * Virtual machines?\r\n> > \r\n> > * _... and so on?_\r\n> > ```\r\n> \r\n> Yes, I do have an Intel GPU (HD Graphics 520) but drivers and harware acceleration are in order. I don't use a docking station or VM, altough I do have this laptop connected to an external display through VGA/DP. But unplugging it changed nothing.\r\n\r\nI have an integrated Intel card ( Intel HD graphics 620). As for cheap hardware and vms, my answer would be no. Any way to fix?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1614", "user": "vRITHNER", "root": "ROOT16", "reply_to": "COM1613", "timestamp": "2019-06-24T06:10:08Z", "text": "Hi, I have the same issue and my graphic card is a NVIDIA GeForce GTX 1060 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1615", "user": "MrR0bert", "root": "ROOT16", "reply_to": "COM1614", "timestamp": "2019-06-25T08:42:48Z", "text": "In my case, I was able to fix it by forcing the app to use the Intel HD Graphics 630 graphics card instead of the GTX 1050 card in the NVIDIA control panel.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1616", "user": "vRITHNER", "root": "ROOT16", "reply_to": "COM1615", "timestamp": "2019-06-25T08:50:29Z", "text": "Thanks for the tip. May I ask you how you did that ?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1617", "user": "Byloth", "root": "ROOT16", "reply_to": "COM1616", "timestamp": "2019-06-25T09:21:18Z", "text": "> In my case, I was able to fix it by forcing the app to use the Intel HD Graphics 630 graphics card instead of the GTX 1050 card in the NVIDIA control panel.\r\n\r\nMmmh... Strange! \ud83e\udd14  \r\nI tried it too but, actually, it continues to run on the integrated video card (even if I choose the dedicated video card).\r\n\r\nBut, yeah... Probably, I did something wrong! \ud83d\ude05\r\n\r\n![image](https://user-images.githubusercontent.com/14953974/60086068-b90c5000-973a-11e9-8368-ce621e97fe10.png)\r\n\r\n> I dragged the Terminal around the screen\r\n\r\n\r\n---\r\n\r\nI also tried on another computer equipped with an NVidia GTX 970 and it worked well.\r\n\r\nI did some other tests and, for some reason, when I run the Terminal on the external monitor connected through the docking station in crashes (as I said before)...  \r\nBut, if I run it on the internal monitor (works fine, of course) and then I drag the window onto the external monitor, it continues to run without any problems. \ud83d\ude35\r\n\r\n---\r\n\r\nHere is my event log (I hope it can be useful):\r\n\r\n```\r\nNome dell'applicazione che ha generato l'errore: WindowsTerminal.exe, versione: 1.0.1906.20005, timestamp: 0x5d0c1459\r\nNome del modulo che ha generato l'errore: ucrtbase.dll, versione: 10.0.18362.1, timestamp: 0x5cbddb81\r\nCodice eccezione: 0xc0000409\r\nOffset errore 0x000000000006d3be\r\nID processo che ha generato l'errore: 0x4208\r\nOra di avvio dell'applicazione che ha generato l'errore: 0x01d52b2e6735c3fe\r\nPercorso dell'applicazione che ha generato l'errore: C:\\Program Files\\WindowsApps\\Microsoft.WindowsTerminal_0.2.1715.0_x64__8wekyb3d8bbwe\\WindowsTerminal.exe\r\nPercorso del modulo che ha generato l'errore: C:\\WINDOWS\\System32\\ucrtbase.dll\r\nID segnalazione: e5cd7755-bd3d-487c-a658-fbce95b3f982\r\nNome completo pacchetto che ha generato l'errore: Microsoft.WindowsTerminal_0.2.1715.0_x64__8wekyb3d8bbwe\r\nID applicazione relativo al pacchetto che ha generato l'errore: App\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1618", "user": "MrR0bert", "root": "ROOT16", "reply_to": "COM1617", "timestamp": "2019-06-25T09:35:47Z", "text": "> \r\n> \r\n> Thanks for the tip. May I ask you how you did that ?\r\n\r\nI opened the NVIDIA Control Panel, under Manage 3D Settings select the Program Settings tab. At step one, the Windows Terminal is listed as \"microsoft.windowsterminal_[id]\". At step two I selected the integrated graphics (sorry for the poor drawing skills :)):\r\n\r\n![afbeelding](https://user-images.githubusercontent.com/20636874/60087344-215c3100-973d-11e9-8ac2-a563ed9819a2.png)", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1619", "user": "8thHalfHour", "root": "ROOT16", "reply_to": "COM1618", "timestamp": "2019-06-25T19:33:02Z", "text": "I have an NVIDIA GeForce GTX 1080 Ti card here with onboard Intel UHD 630, though somehow, suddenly, today the app is working again. I have no idea why or how.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1620", "user": "miniksa", "root": "ROOT16", "reply_to": "COM1619", "timestamp": "2019-06-25T21:00:33Z", "text": "From anyone in this thread, I need a crash dump. I tried searching every Report ID you all posted, and none of them are coming through.\r\n\r\nI suspect that the issues related to not being able to use hardware rendering might be solved with #1263.\r\n\r\nThere's probably also some robustness to be added to the DX renderer so it sets itself up correctly. If any of you are building from source, it would be nice to have you check if conhost.exe built from the same sources crashes when the key at `HKCU\\Console` `UseDx` `REG_DWORD` `0x1` is set (create it if it isn't there.) That will confirm if a crash is isolated to the DX renderer or Terminal startup specific.\r\n\r\nI also have the theory that you are all experiencing like 4 different issues here, so we might have to split them up if I try to fix one and it isn't fixed for all of you.\r\n\r\nLastly, we don't readily have access to this type of hardware around here. I'll see what we can do, but if I can get some close assistance, that's the best.\r\n\r\n ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1621", "user": "ShadowEO", "root": "ROOT16", "reply_to": "COM1620", "timestamp": "2019-06-25T21:44:01Z", "text": "@miniksa Certainly! How can I go about getting a crash dump of it from the affected machine?\r\n\r\nI also went to my development station (x64) and attempted the `UseDx` change you requested. I can confirm that conhost fails to start with `UseDx` set to `0x1` on a machine where the same source build does work properly. Toggling `UseDx` back off results in a working console again.\r\n\r\nInterestingly, I did this test on the affected tablet (once again with same sources), and conhost works in both scenarios on it, I get a command prompt as normal.. however Cascadia still fails.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1622", "user": "cpbotha", "root": "ROOT16", "reply_to": "COM1621", "timestamp": "2019-06-28T08:13:00Z", "text": "I tried out eight of the Azure Pipelines `master` builds from here: https://dev.azure.com/ms/Terminal/_build?definitionId=136&_a=summary to try and determine where things started breaking.\r\n\r\nIn reverse chronological sequence, i.e. newest build last:\r\n\r\n- #1374 update link to public preview: WORKS\r\n- #1512 fix punct readme: WORKS\r\n- #1452 about dialog contents selectable: WORKS\r\n- #1314 set default startup proj: WINDOW STAYS BLANK\r\n- #1263 fallback swren: WINDOW STAYS BLANK\r\n- #1093 connect clipboard func to keybindings: WINDOW STAYS BLANK\r\n- #929 Apply a GDI region to the top level Island window to allow dragging with a single Island: BLANK THEN CRASH\r\n- #1436 altgr: BLANK THEN CRASH\r\n\r\nIn other words, between the subsequent merges of #1452 and #1314 (both on 2019-06-24) terminal went from working to blank window at startup (but no crash), and then between the subsequent merges of #1093 and #929 (both on 2019-06-25), terminal went from blank window no crash to blank window and then crash.\r\n\r\n(How #1314, which seems to be only a re-ordering in the OpenConsole solution file, can break terminal like this is surprising. However, uninstalling-reinstalling the builds here only confirms the working / non-working status.)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1623", "user": "cpbotha", "root": "ROOT16", "reply_to": "COM1622", "timestamp": "2019-06-28T08:45:21Z", "text": "@miniksa here is a crash dump of the #1436 PR Azure Pipelines build crashing.\r\n\r\n[WindowsTerminal.exe.12900.zip](https://github.com/microsoft/terminal/files/3338327/WindowsTerminal.exe.12900.zip)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1624", "user": "DHowett-MSFT", "root": "ROOT16", "reply_to": "COM1623", "timestamp": "2019-06-28T17:34:52Z", "text": "Thanks for doing a rough bisect for us!\r\n\r\nThis doesn't look safe _at all_.\r\n\r\n```\r\n.  0  Id: 3264.2748 Suspend: 0 Teb: 0000001b`495e5000 Unfrozen\r\n # Child-SP          RetAddr           Call Site\r\n00 0000001b`496fe530 00007ffd`df6acaff ucrtbase!abort+0x4e\r\n01 0000001b`496fe560 00007ff6`2e9a952b ucrtbase!terminate+0x1f\r\n02 0000001b`496fe590 00000000`00002000 WindowsTerminal!__scrt_unhandled_exception_filter+0x37 [d:\\agent\\_work\\2\\s\\src\\vctools\\crt\\vcstartup\\src\\utility\\utility_desktop.cpp @ 91] \r\n03 0000001b`496fe598 00000020`00001000 0x2000\r\n04 0000001b`496fe5a0 00000000`01000000 0x00000020`00001000\r\n05 0000001b`496fe5a8 00000000`00000000 0x1000000  \r\n```\r\n\r\nI'm really glad our build pipelines hold on to symbols. :smile:", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1625", "user": "miniksa", "root": "ROOT16", "reply_to": "COM1624", "timestamp": "2019-06-28T18:46:18Z", "text": "> @miniksa Michael Niksa FTE Certainly! How can I go about getting a crash dump of it from the affected machine?\r\n> \r\n> I also went to my development station (x64) and attempted the `UseDx` change you requested. I can confirm that conhost fails to start with `UseDx` set to `0x1` on a machine where the same source build does work properly. Toggling `UseDx` back off results in a working console again.\r\n> \r\n> Interestingly, I did this test on the affected tablet (once again with same sources), and conhost works in both scenarios on it, I get a command prompt as normal.. however Cascadia still fails.\r\n\r\nYou can technically right click a process in the Details page of Task Manager and create a dump and attach it somewhere online, but be warned, it may contain personally identifiable information as it dumps the entire memory space.\r\n\r\nYou can also try using the Feedback Hub and choosing the Windows Terminal app and submitting that way.\r\n\r\nOr if it crashes, you can try getting the Windows Error Reporting information from the event viewer and give me all of that so I can try to look up the IDs with the WER service.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1626", "user": "ShadowEO", "root": "ROOT16", "reply_to": "COM1625", "timestamp": "2019-06-28T20:56:29Z", "text": "> it may contain personally identifiable information\r\n\r\nThat's fine, the tablet it's on gets very light usage. The only real identifiable information on the device may be my real name (which is fine) or the user profile directory, which only contains part of my Github username.\r\n\r\nHere is a OneDrive shared folder containing the evtx file (with both Windows Error Reporting event and Application Crash event) and for extra measure, a process dump for you! https://1drv.ms/u/s!AqACoL07fxpWoOIwO6InGCb8fvsZJg?e=ot9XoI\r\n\r\nLet me know if you can't get that, and I'll upload it somewhere else, that process dump was larger than I expected for something taking only 5MB of RAM at that time lol.\r\n\r\n(TIL I can easily create process dumps, that's a cool feature!)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1627", "user": "Byloth", "root": "ROOT16", "reply_to": "COM1626", "timestamp": "2019-07-01T08:04:56Z", "text": "> [...] if it crashes, you can try getting the Windows Error Reporting information from the event viewer and give me all of that so I can try to look up the IDs with the WER service.\r\n\r\n---\r\n\r\nHere's a ZIP with some files extracted directly from the Event Viewer...  \r\nI hope this is what you're looking for, @miniksa... \ud83d\ude05\r\n\r\n> [\ud83d\udce6 Windows Terminal crash.zip](https://github.com/microsoft/terminal/files/3344460/Windows.Terminal.crash.zip)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1628", "user": "ShadowEO", "root": "ROOT16", "reply_to": "COM1627", "timestamp": "2019-07-04T00:04:57Z", "text": "Saw the store version was updated recently. Let the affected PC update and am still experiencing the issue.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1629", "user": "metathinker", "root": "ROOT16", "reply_to": "COM1628", "timestamp": "2019-07-04T00:05:28Z", "text": "As it happens, I also have the problem of recent versions of Windows Terminal crashing on startup with an empty window - and I too have an interesting crash dump! I also got a Time Travel Debugging trace in case that proves useful.\r\n\r\nLink - sorry, it's Microsoft-internal-only because of my concerns re my private information:\r\nhttps://aka.ms/AA5ix7s", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT17", "user": "c3ph3us", "root": "ROOT17", "reply_to": null, "timestamp": "2018-07-09T15:29:20Z", "text": "storage OOM not proper handled by gradle  when we have storage OOM gradle doesn't sygnalize that, instead proper info we have a bullshit :)\r \r `$ gradle clean`\r \r >FAILURE: Build failed with an exception.\r >\r >* What went wrong:\r >Unable to start the daemon process.\r >This problem might be caused by incorrect configuration of the daemon.\r >For example, an unrecognized jvm option is used.\r >Please refer to the user guide chapter on the daemon at >https://docs.gradle.org/4.7/userguide/gradle_daemon.html\r >Please read the following process output to find out more:`\r >-----------------------\r >* Try:\r >Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log >output. Run with --scan to get full insights.\r \r Unable to start the daemon process... **when explicity run with false flag in props file**\r \r the next try maybe gradle didn't read the prop file proper .. **so explicity set no deamon arg**\r \r `$ gradle --info --no-daemon clean`\r \r >Initialized native services in: /opt/gradle/ceph3us/native\r To honour the JVM settings for this build a new JVM will be forked. Please consider using the daemon: https://docs.gradle.org/4.7/userguide/gradle_daemon.html.\r Starting process 'Gradle build daemon'. Working directory: /opt/gradle/ceph3us/daemon/4.7 Command: /opt/jdk1.8/bin/java -XX:+AggressiveOpts -XX:+UseG1GC -Xmn512m -XX:MaxMetaspaceSize=1g -XX:SurvivorRatio=40 -XX:+UseCompressedOops -XX:+UseCompressedClassPointers -XX:-OmitStackTraceInFastThrow -XX:SoftRefLRUPolicyMSPerMB=100 -XX:-HeapDumpOnOutOfMemoryError -Xms512m -Xmx3g -Dfile.encoding=UTF-8 -Duser.country=PL -Duser.language=pl -Duser.variant -cp /opt/gradle/lib/gradle-launcher-4.7.jar org.gradle.launcher.daemon.bootstrap.GradleDaemon 4.7\r Successfully started process 'Gradle build daemon'\r An attempt to start the daemon took 1.005 secs.\r \r FAILURE: Build failed with an exception.\r \r >* What went wrong:\r Unable to start the daemon process.\r This problem might be caused by incorrect configuration of the daemon.\r For example, an unrecognized jvm option is used.\r Please refer to the user guide chapter on the daemon at https://docs.gradle.org/4.7/userguide/gradle_daemon.html\r Please read the following process output to find out more:\r -----------------------\r \r \r >* Try:\r Run with --stacktrace option to get the stack trace. Run with --debug option to get more log output. Run with --scan to get full insights.\r \r >* Get more help at https://help.gradle.org\r \r still some daemon shit WTF ??? one more try brings same results of bulshit doeasnt reveal the TRUE CAUSE for BUILD FAILED \r \r '$ gradle --debug --no-daemon clean'\r \r >{ unrelated sensitive data cut}\r >16:50:14.639 [DEBUG] [org.gradle.process.internal.DefaultExecHandle] Changing state to: STARTING\r 16:50:14.640 [DEBUG] [org.gradle.process.internal.DefaultExecHandle] Waiting until process started: Gradle build daemon.\r 16:50:14.655 [DEBUG] [org.gradle.process.internal.DefaultExecHandle] Changing state to: STARTED\r 16:50:14.656 [INFO] [org.gradle.process.internal.DefaultExecHandle] Successfully started process 'Gradle build daemon'\r 16:50:14.656 [DEBUG] [org.gradle.launcher.daemon.client.DefaultDaemonStarter] Gradle daemon process is starting. Waiting for the daemon to detach...\r 16:50:14.657 [DEBUG] [org.gradle.process.internal.ExecHandleRunner] waiting until streams are handled...\r 16:50:14.659 [DEBUG] [org.gradle.launcher.daemon.bootstrap.DaemonOutputConsumer] Starting consuming the daemon process output.\r 16:50:15.611 [DEBUG] [org.gradle.process.internal.DefaultExecHandle] Changing state to: DETACHED\r 16:50:15.611 [DEBUG] [org.gradle.process.internal.DefaultExecHandle] Process 'Gradle build daemon' finished with exit value 0 (state: DETACHED)\r 16:50:15.611 [DEBUG] [org.gradle.launcher.daemon.client.DefaultDaemonStarter] Gradle daemon process is now detached.\r 16:50:15.613 [INFO] [org.gradle.launcher.daemon.client.DefaultDaemonStarter] An attempt to start the daemon took 0.982 secs.\r 16:50:15.620 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] \r 16:50:15.620 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] FAILURE: Build failed with an exception.\r 16:50:15.620 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] \r 16:50:15.620 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * What went wrong:\r 16:50:15.620 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Unable to start the daemon process.\r 16:50:15.620 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] This problem might be caused by incorrect configuration of the daemon.\r 16:50:15.620 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] For example, an unrecognized jvm option is used.\r 16:50:15.620 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Please refer to the user guide chapter on the daemon at https://docs.gradle.org/4.7/userguide/gradle_daemon.html\r 16:50:15.620 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Please read the following process output to find out more:\r 16:50:15.620 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] -----------------------\r 16:50:15.620 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] \r 16:50:15.620 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] \r 16:50:15.620 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Try:\r 16:50:15.620 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Run with --stacktrace option to get the stack trace.  Run with --scan to get full insights.\r 16:50:15.621 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] \r 16:50:15.621 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Get more help at https://help.gradle.org\r \r **pleaes add OOM storage watcher during task execution that will throw some sort of StorageOOM exception**\r \r **distracts from the fact that there was no memory left at the start of the gradle .. which should be signalized apriori any taskl start / evaluate**\r \r tneet to consider the SPACE \r -- WHERE PROJECT IS EXECUTED (build output)   \r -- WHEN GRADLE WRITES  (cache, etc) \r \r **those places should be checked during start gradle (LOW MEM WARNING) and monitored as mentioned above**\r \r \r i have wasted 5 min befor i did to know the real cause.. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM170", "user": "oehme", "root": "ROOT17", "reply_to": "ROOT17", "timestamp": "2018-07-09T20:30:35Z", "text": "Closing due to abusive language. Please read our code of conduct and open an issue using appropriate language.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM171", "user": "c3ph3us", "root": "ROOT17", "reply_to": "COM170", "timestamp": "2018-07-18T14:23:11Z", "text": "@oehme  you are funny :) you can learn a bit about semantics, grammar and the meanings of words - essentialy about language and usage :) \r\ncan you tell me who was here offended ?\r\n\r\n**maybe better was to use here a euphemisms so that the dumb people didn't think they were being offended when in fact nobody was...**  if you fell so then it is your right to feel as you want to :) \r\n\r\nunderstanding is key to everything.. so **try to understand it does not hurt!**\r\n\r\n\r\ncipa, kutas, jebnij, pierdolenie \r\n\r\nbest \r\nceph3us", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM172", "user": "oehme", "root": "ROOT17", "reply_to": "COM171", "timestamp": "2018-07-18T14:38:23Z", "text": "If this is your way of communicating, please stay away from our community.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT18", "user": "cbazza", "root": "ROOT18", "reply_to": null, "timestamp": "2017-08-14T16:16:38Z", "text": "Consider JSX-like syntax inside dart code It would be great if aside from the current way of building widgets you could add JSX like capabilities. I mean add tiny syntactic sugar to enable XML like constructs inside dart code. It just makes code so much easier to read/develop/debug/maintain and also easier for powerful GUI builders to integrate with editable code.\r \r Looking for something like DSX:\r https://spark-heroku-dsx.herokuapp.com/index.html\r \r Carlos.\r \r ---\r \r The current issue with DSX is about proper integration with Flutter tools as to provide a great developer experience with debugger, auto-complete, etc. working on .dsx files.\r \r Telling users that they can use DSX but can't use debugger or enjoy auto-complete is a non starter for me. If anybody wants to help, what I need is to figure out a way to add full preprocessing support (with source map) to Dart Tools and VS Code Dart plug in. Once the tools support that DSX or any other transpiling language (any language that is a superset of Dart but compiles everything down to Dart) would just work.\r \r If you can and would like to help, let me know.\r ", "meta": {"posReactions": "100", "negReactions": "59"}}
{"id": "COM180", "user": "sethladd", "root": "ROOT18", "reply_to": "ROOT18", "timestamp": "2017-08-14T16:30:25Z", "text": "cc @lukechurch ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM181", "user": "Hixie", "root": "ROOT18", "reply_to": "COM180", "timestamp": "2017-08-15T20:43:01Z", "text": "@cbazza Can you elaborate on why you want this? Maybe show an example of what it would look like compared to today?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM182", "user": "cbazza", "root": "ROOT18", "reply_to": "COM181", "timestamp": "2017-08-15T21:25:06Z", "text": "Ok, so the \"Basic widgets\" example on 'https://flutter.io/widgets-intro/#basic-widgets' would look like the following:\r\n```dart\r\nimport 'package:flutter/material.dart';\r\n\r\nclass MyAppBar extends StatelessWidget {\r\n  MyAppBar({this.title});\r\n\r\n  // Fields in a Widget subclass are always marked \"final\".\r\n\r\n  final Widget title;\r\n\r\n  @override\r\n  Widget build(BuildContext context) {\r\n    let style = {\r\n        height: 56.0, // in logical pixels\r\n        padding: const EdgeInsets.symmetric(horizontal: 8.0),\r\n        decoration: <BoxDecoration color={Colors.blue[500]}/>,\r\n    };\r\n  \r\n    return <Container style={style}>\r\n      <Row>\r\n        <IconButton\r\n            icon={<Icon name={Icons.menu}/>}\r\n            tooltip='Navigation menu'\r\n            onPressed={null}\r\n        />\r\n        <Expanded>\r\n           {title}\r\n\t</Expanded>  \r\n        <IconButton\r\n            icon={<Icon name={Icons.search}/>}\r\n            tooltip='Search'\r\n            onPressed={null}\r\n        />\r\n      </Row>\r\n    </Container>;\r\n  }\r\n}\r\n\r\nclass MyScaffold extends StatelessWidget {\r\n  @override\r\n  Widget build(BuildContext context) {\r\n    // Material is a conceptual piece of paper on which the UI appears.\r\n    return <Material>\r\n      <Column>\r\n          <MyAppBar\r\n             title={<Text \r\n               text='Example title'\r\n               style={Theme.of(context).primaryTextTheme.title},\r\n             />}\r\n          />\r\n          <Expanded>\r\n            <Center>\r\n              <Text text='Hello, world!'/>\r\n            </Center>\r\n          </Expanded>\r\n      </Column>\r\n    </Material>;\r\n  }\r\n}\r\n\r\nvoid main() {\r\n  runApp(<MaterialApp\r\n    title='My app'\r\n    home={<MyScaffold/>}\r\n  />);\r\n}\r\n```\r\n", "meta": {"posReactions": "47", "negReactions": "45"}}
{"id": "COM183", "user": "Hixie", "root": "ROOT18", "reply_to": "COM182", "timestamp": "2017-08-15T21:35:48Z", "text": "How about this syntax?:\r\n\r\n```dart\r\nimport 'package:flutter/material.dart';\r\n\r\nclass MyAppBar extends StatelessWidget {\r\n  MyAppBar({this.title});\r\n\r\n  // Fields in a Widget subclass are always marked \"final\".\r\n\r\n  final Widget title;\r\n\r\n  @override\r\n  Widget build(BuildContext context) {\r\n    return Container(\r\n      height: 56.0, // in logical pixels\r\n      padding: EdgeInsets.symmetric(horizontal: 8.0),\r\n      decoration: BoxDecoration(color: Colors.blue[500]),\r\n      child: Row(\r\n        children: <Widget>[\r\n          IconButton(\r\n            icon: Icon(Icons.menu),\r\n            tooltip: 'Navigation menu',\r\n            onPressed: null,\r\n          ),\r\n          Expanded(\r\n            child: title,\r\n          ),\r\n          IconButton(\r\n            icon: Icon(Icons.search),\r\n            tooltip: 'Search',\r\n            onPressed: null,\r\n          ),\r\n        ],\r\n      ),\r\n    );\r\n  }\r\n}\r\n\r\nclass MyScaffold extends StatelessWidget {\r\n  @override\r\n  Widget build(BuildContext context) {\r\n    // Material is a conceptual piece of paper on which the UI appears.\r\n    return Material(\r\n      child: Column(\r\n        children: <Widget>[\r\n          MyAppBar(\r\n            title: Text(\r\n              'Example title',\r\n              style: Theme.of(context).primaryTextTheme.title,\r\n            ),\r\n          ),\r\n          Expanded(\r\n            child: Center(\r\n              child: Text('Hello, world!'),\r\n            ),\r\n          ),\r\n        ],\r\n      ),\r\n    );\r\n  }\r\n}\r\n\r\nvoid main() {\r\n  runApp(MaterialApp(\r\n    title: 'My app',\r\n    home: MyScaffold(),\r\n  ));\r\n}\r\n```", "meta": {"posReactions": "42", "negReactions": "31"}}
{"id": "COM184", "user": "cbazza", "root": "ROOT18", "reply_to": "COM183", "timestamp": "2017-08-15T21:44:30Z", "text": "Huumm, a little improvement but not so good... \r\nHere are the things that gets accomplished by using XML:\r\n(1) No more 'child' & 'children' stuff\r\n(2) easy for 3rd party tools to manipulate (parse, analyse and regenerate)\r\n(3) notice that the switching between markup and programming is easily detected. I mean inside XML you have '{}' to delimit code and in code you have '<Capital' to delimit markup. \r\nAlso separate all the 'style' things from the main structure.\r\nI know this is basically fully endorsing React's way but you are half way there anyways ;)\r\n", "meta": {"posReactions": "24", "negReactions": "10"}}
{"id": "COM185", "user": "sethladd", "root": "ROOT18", "reply_to": "COM184", "timestamp": "2017-08-15T21:48:30Z", "text": "cc @kasperl", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM186", "user": "Hixie", "root": "ROOT18", "reply_to": "COM185", "timestamp": "2017-08-15T21:49:41Z", "text": "> (1) No more 'child' & 'children' stuff\r\n\r\nI don't really understand why that's desireable. \"child\" and \"children\" aren't special. Consider ListTile for example. How would you do that one? Why are \"icon\" in IconButton, or \"home\" in MaterialApp, something you want to give a name for, but not \"child\" in Expanded? All three are just arbitrary arguments that happen to take Widget objects. There's nothing magical about \"child\" vs \"home\".\r\n\r\n\r\n> (2) easy for 3rd party tools to manipulate (parse, analyse and regenerate)\r\n\r\nYou can parse, analyze, and regenerate Dart code. But I agree we should make that easier. Hopefully in the coming years the Dart team will provide better APIs for this.\r\n\r\n\r\n> (3) notice that the switching between markup and programming is easily detected.\r\n\r\nWhy is that desireable? I mean, why would any of this count as \"programming\"? It's all just expressions.\r\n\r\n\r\n> I mean inside XML you have '{}' to delimit code and in code you have '<Capital' to delimit markup. \r\n\r\nI don't really understand the distinction.\r\n\r\n\r\n> Also separate all the 'style' things from the main structure.\r\n\r\nYou can do this today in Flutter if you really want to, just put the style in a variable like you did in the XML case.", "meta": {"posReactions": "11", "negReactions": "12"}}
{"id": "COM187", "user": "cbazza", "root": "ROOT18", "reply_to": "COM186", "timestamp": "2017-08-15T22:02:18Z", "text": "> I don't really understand why that's desireable. \"child\" and \"children\" aren't special. Consider ListTile for example. How would you do that one? Why are \"icon\" in IconButton, or \"home\" in MaterialApp, something you want to give a name for, but not \"child\" in Expanded? All three are just arbitrary arguments that happen to take Widget objects. There's nothing magical about \"child\" vs \"home\".\r\n\r\nLess boilerplate, you don't need to say it because it is inherited in the structure.\r\n\r\n> Why is that desireable? I mean, why would any of this count as \"programming\"? It's all just expressions.\r\n\r\nIt's related to (2) because it makes life of toolmakers, specially GUI builders, much easier since they don't need to fully parse Dart; but it also makes reading the code easier. \r\n\r\n> I don't really understand the distinction.\r\n\r\nThe format of XML is very simple so when you see '{}' you know it is calculating an expression in dart. Same for the opposite, when reading dart code and you see '<Capital' (a less-than followed by a word that is capitalized. example \\<Row>) you know that an object hierarchy is being created from XML markup.\r\n\r\n", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM188", "user": "cbazza", "root": "ROOT18", "reply_to": "COM187", "timestamp": "2017-08-15T22:07:57Z", "text": "Also in the final XML processor I would avoid passing objects to attributes of parents and instead create child tags as below:\r\n```dart\r\nthis...\r\n          <MyAppBar>\r\n             <Title style={Theme.of(context).primaryTextTheme.title}>  \r\n                 Example title\r\n             </Title>\r\n          </MyAppBar>\r\n\r\ninstead of this...\r\n          <MyAppBar\r\n             title={<Text \r\n               text='Example title'\r\n               style={Theme.of(context).primaryTextTheme.title},\r\n             />}\r\n          />\r\n``` ", "meta": {"posReactions": "15", "negReactions": "6"}}
{"id": "COM189", "user": "Hixie", "root": "ROOT18", "reply_to": "COM188", "timestamp": "2017-08-15T22:23:28Z", "text": "> Less boilerplate, you don't need to say it because it is inherited in the structure.\r\n\r\nBut why only for some of the properties? And how do you handle cases where there's two child slots, like ListItem? XML-ish syntax just doesn't seem to handle this very well.\r\n\r\nAlso I'm not really sure it's less boilerplate.\r\n\r\nCompare:\r\n```xml\r\n   <Container style={style}>\r\n      <Row>\r\n        <IconButton\r\n            icon={<Icon name={Icons.menu}/>}\r\n            tooltip='Navigation menu'\r\n            onPressed={null}\r\n        />\r\n        <Expanded> {title} </Expanded>  \r\n      </Row>\r\n    </Container>\r\n```\r\n\r\n```dart\r\n   Container(style: style,\r\n      child: Row(\r\n        children: [\r\n          IconButton(\r\n            icon: Icon(Icons.menu),\r\n            tooltip: 'Navigation menu',\r\n            onPressed: null,\r\n          ),\r\n          Expanded(child: title),\r\n        ],\r\n      ),\r\n    )\r\n```\r\n\r\nIt's not at all clear to me that the XML-ish syntax is cleaner or less boilerplatey. There's lots more punctuation, and some duplication of content (e.g. in the close tags). And you had to add some names, so sure, you lose \"child\", but you gain \"name\" on Icon.\r\n\r\nAlso with XML how do you make it clear that Row can take zero, one, or more than one child, while Center has to have exactly one child? What would happen if someone did this?:\r\n\r\n```xml\r\n   <Center> <Test/> <Test/> </Center>\r\n```\r\n\r\n> It's related to (2) because it makes life of toolmakers, specially GUI builders, much easier since they don't need to fully parse Dart;\r\n\r\nThey wouldn't need to fully parse Dart if we had a Dart parsing API either, though, right? I mean, you'd parse what you want to parse and leave the rest. Also I'm not sure it's actually easier to parse, since it's not actually XML; see below.\r\n\r\n> but it also makes reading the code easier. \r\n\r\nI'm not at all convinced that the XMLy version here is easier to read. Once you've read a few build functions, you quickly get used to the nested constructor syntax.\r\n\r\n> The format of XML is very simple so when you see '{}' you know it is calculating an expression in dart.\r\n\r\nIt's not actually XML, though, right? It's some variant of XML. Are there well-defined parsing rules for it? For example, is this valid?\r\n\r\n```xml\r\n  <Test name={describe(\"}\")}>\r\n```\r\n\r\nHow does it know that the first \"}\" isn't the end of the attribute expression, without parsing Dart?\r\n\r\n> Same for the opposite, when reading dart code and you see '<Capital' (a less-than followed by a word that is capitalized. example \\<Row>) you know that an object hierarchy is being created from XML markup.\r\n\r\nYou know this today when you see the `new` keyword too, right? Or indeed in the new-less markup proposal above when you see any capitalised word. Is this really a benefit of XML, or are you more familiar with XML than Dart?\r\n\r\n> Also in the final XML processor I would avoid passing objects to attributes of parents and instead create child tags as below:\r\n\r\nI really don't understand what you're proposing here. It's not well-formed XML at all as far as I can tell. Can you elaborate on exactly what the syntax you are proposing is and how it works? For example, the \"Text\" constructor seems to have disappeared; how does the processor know that <Title> creates a Text widget?\r\n\r\n\r\nSorry if I sound defensive or aggressive. :-) This is a topic that's come up several times but I've never had someone willing to actually argue the case before so I'm finding this conversation very useful in teaching me what the reasoning behind the request is. Please don't take my argumentative tone as dismissive, I'm very interested in your input here.", "meta": {"posReactions": "24", "negReactions": "7"}}
{"id": "COM1810", "user": "cbazza", "root": "ROOT18", "reply_to": "COM189", "timestamp": "2017-08-16T17:34:19Z", "text": "Look, you are mixing everything I say and this conversation is going nowhere. In legal terms you are \"Badgering the witness\".\r\n\r\nIf you are really interested in learning why JSX is hot, just google for \"react tutorial\" and notice that for the past 2 years all articles on React use JSX. The original way of creating component hierarchies in React (which is equivalent to the current way in Flutter) is never mentioned again because JSX became the preferred method (best practice).\r\n\r\nhttps://facebook.github.io/react/tutorial/tutorial.html\r\nhttps://facebook.github.io/react-native/docs/flatlist.html\r\n\r\nAnother interesting thing is that Typescript has adopted JSX also:\r\nhttps://www.typescriptlang.org/docs/handbook/jsx.html\r\n\r\nYou failed to grasp that XML parsing (with some extra code to skip '{}' properly) is orders of magnitude simpler than fully parsing a programming language like Dart. That is a fact. You are assuming that tool builders will use Dart on their development, not the case, Intellij most likely is using Kotlin and Java on their IDEs that supports Dart (they are a special case because they specialize in language parsing; everybody else will struggle to fully parse Dart from another language).\r\n\r\nWhat I like about putting XML inside another language is that it provides a cognitive separation between the two because XML is very distinct from programming languages. Just scrolling through the source file you can easily see what is code and what is declarative markup. Can't accomplish that with dart code pretending to be markup. \r\n\r\nStop nit-picking things that are not fully specified. All your doubts have answered for it just learn more about how that was handled in JSX. I just don't have the time for this here.\r\n", "meta": {"posReactions": "29", "negReactions": "12"}}
{"id": "COM1811", "user": "Hixie", "root": "ROOT18", "reply_to": "COM1810", "timestamp": "2017-08-16T19:10:29Z", "text": "My apologies if I sound defensive or aggressive. This is a topic that's come up several times but I'd never had someone willing to actually argue the case before so I was finding this conversation very useful in teaching me what the reasoning behind the request was. Please don't take my argumentative tone as dismissive, I'm very interested in your input here.\r\n\r\nPlease don't feel you have to reply. I'm commenting here so that there is transparency regarding the issues that we would have to resolve before we're able to make a decision or design one way or the other. This is basically just a Socratic dialogue. Your participation is welcome but certainly you should not feel that it is your responsibility to defend your proposal.\r\n\r\n----\r\n\r\nI've no doubt that JSX is \"hot\". In React, the non-JSX syntax is a lot worse than the alternative syntax proposed in this issue (the one that looks like our current code but without the \"new\" and \"const\" keywords). What I'm trying to understand is whether the same reasons that JSX is \"hot\" in React apply to Flutter.\r\n\r\nRegarding TypeScript doing JSX, In 2012 I was involved in efforts to specify [E4H](http://www.hixie.ch/specs/e4h/strawman), and even before that there was [E4X](https://en.wikipedia.org/wiki/ECMAScript_for_XML). Both efforts died. So it's important to me that we understand what exactly it is people like about JSX vs other syntaxes.\r\n\r\nParsing XML isn't easy, parsing sort-of-XML-but-with-curly-braces-somehow is not easy either. Parsing sort-of-XML-but-with-curly-braces-somehow-that-is-embedded-in-another-language is even less easy. However, how easy that is to implement probably isn't a big deal because it's going to be implemented once or twice and then the library that does it will be reused. (I've been heavily involved in writing the specs for parsing HTML and been involved in similar work for XML, and I've implemented a parser for Dart, so I have a pretty good idea of how difficult parsing markup languages vs programming languages actually is.)\r\n\r\n> What I like about putting XML inside another language is that it provides a cognitive separation between the two because XML is very distinct from programming languages. Just scrolling through the source file you can easily see what is code and what is declarative markup. Can't accomplish that with dart code pretending to be markup.\r\n\r\nBut why is it beneficial to be able to do that?\r\n\r\nIt's pretty obvious when scrolling through Flutter apps where the build functions are (they're the giant nested expressions). What is it about \"declarative markup\" that is important to separate from \"code\"?\r\n\r\n> Stop nit-picking things that are not fully specified. All your doubts have answered for it just learn more about how that was handled in JSX. I just don't have the time for this here.\r\n\r\nAs far as I can tell, JSX doesn't handle the things I was asking about. For example, React doesn't have the concept of child slots. The closest thing I could find is something they do by switching back to JS then back to JSX inside that, so you'd need to be able to parse both the programming language and the markup language.", "meta": {"posReactions": "14", "negReactions": "0"}}
{"id": "COM1812", "user": "cbazza", "root": "ROOT18", "reply_to": "COM1811", "timestamp": "2017-08-17T14:34:08Z", "text": "> What I'm trying to understand is whether the same reasons that JSX is \"hot\" in React apply to Flutter.\r\n\r\nYes, the exact same thing applies here. The current way looks good to you because that's the only option you have. Give people a second option and the same will happen. \r\n\r\nWhether E4X died or not is irrelevant because nothing lives forever. I have used ActionScript with E4X a lot and thought that Adobe did an excellent job there. In a way Flutter is just a newer version of Adobe Flash with Flex apps.\r\n\r\n> (I've been heavily involved in writing the specs for parsing HTML and been involved in similar work for XML, and I've implemented a parser for Dart, so I have a pretty good idea of how difficult parsing markup languages vs programming languages actually is.)\r\n\r\nGreat so you know that parsing a markup language is trivial compared to parsing an imperative programming language.\r\n\r\n> But why is it beneficial to be able to do that?\r\n\r\nCode readability and simplicity which in turn drives a whole bunch of other benefits.\r\n\r\n> It's pretty obvious when scrolling through Flutter apps where the build functions are (they're the giant nested expressions). What is it about \"declarative markup\" that is important to separate from \"code\"?\r\n\r\nOn your giant nested expressions can you easily see structure? can this structure be easily manipulated by other tools like GUI builders interchangebly ? I mean like Adobe Flex Builder use to do, drag and drop widgets around, wire them on UI and then switch to code view and just edit anything you want and then switch back to gui mode and continue to manipulate the widgets. You can't do that easily when the programmer goes inside your \"giant nested expressions\" and writes any valid dart code that doesn't follow the structure that the GUI editor is expecting. With a fixed XML structure that is not a problem.\r\n\r\n> As far as I can tell, JSX doesn't handle the things I was asking about. For example, React doesn't have the concept of child slots\r\n\r\nIt handles it just fine, you just don't know how to do it. So going forward just put the example in question here and I will provide you with what I think the JSX version should be.\r\n \r\n```dart\r\n  new ListTile(\r\n    title: new Text('CineArts at the Empire',\r\n        style: new TextStyle(fontWeight: FontWeight.w500, fontSize: 20.0)),\r\n    subtitle: new Text('85 W Portal Ave'),\r\n    leading: new Icon(\r\n      Icons.theaters,\r\n      color: Colors.blue[500],\r\n    ),\r\n  ),\r\n```\r\n```dart\r\n  <ListTile>\r\n    <title> \r\n      <Text style={{fontWeight: FontWeight.w500, fontSize: 20.0}}>\r\n         CineArts at the Empire\r\n      </Text>\r\n    </title>\r\n    <subtitle>\r\n      <Text>85 W Portal Ave</Text>\r\n    </subtitle>\r\n    <leading>\r\n      <Icon data={Icons.theaters} color={Colors.blue[500]}/>\r\n    </leading>\r\n  </ListTile>,\r\n```\r\n\r\nIt looks longer than the dart version but I could had placed everything in the same number of lines. Thing is an IDE/Editor can provide '+' & '-' to expand and collapse these XML nodes anyways.\r\n\r\nMake Flutter look familiar to React developers and you have a chance of attracting a bunch of new users to Flutter.\r\n\r\n", "meta": {"posReactions": "17", "negReactions": "12"}}
{"id": "COM1813", "user": "Hixie", "root": "ROOT18", "reply_to": "COM1812", "timestamp": "2017-08-17T17:49:09Z", "text": "> Whether E4X died or not is irrelevant because nothing lives forever.\r\n\r\nWhether it died isn't the issue, it's why it died. Did it die because it didn't provide a solution that people wanted? Did it die because of implementation issues? Did it die because of patent issues? Was it too early? Too late? I think it's important to learn lessons from past experiences. Why did E4X and E4H fail where JSX has succeeded?\r\n\r\nWhat I find interesting is that people who are new to Flutter often ask for two things: a markup language, and animated GIFs. Then three months in, they are still asking for animated GIFs, but not for a markup language. It could be that this is because the markup language isn't actually needed once you're used to writing build methods in Dart. It could be that they still want a markup language but have worked around the omission and so don't think to ask anymore. It's worth figuring out which because otherwise we risk spending effort on something that is the wrong choice (in either direction).\r\n\r\n> On your giant nested expressions can you easily see structure?\r\n\r\nYes, at least as easily as with XML. Personally, I find XML to be very verbose and it obfuscates the structure. But I think this is more about what you're used to.\r\n\r\n(We're also experimenting with IDEs that put in [virtual \"closing tag\" comments](https://github.com/Dart-Code/Dart-Code/issues/383#issuecomment-321985929) for you so you can see the structure without having to actually write it.)\r\n\r\n> Great so you know that parsing a markup language is trivial compared to parsing an imperative programming language.\r\n\r\nMy experience is that declarative vs imperative is not the distinction that matters when it comes to determining how easy a language is to parse. (For example, HTML is \"declarative\" but it may be among the most complicated languages to parse that I've ever dealt with.)\r\n\r\n> Code readability and simplicity which in turn drives a whole bunch of other benefits.\r\n\r\nIf this is the main benefit then this is something we can test. We could take a mixture of engineers who are used to writing HTML, React, iOS code, Android code, Flutter, command-line apps, and so on, and present them each with various syntaxes, and ask them to describe what they think the resulting UI would look like. We can then measure which syntax gets the best results. @InMatrix is this something we could look at after the animation work wraps up, maybe?\r\n\r\n> can this structure be easily manipulated by other tools like GUI builders interchangebly ?\r\n\r\nYes, in principle at least. It should be relatively straight-forward to mechanically convert Dart expressions to XML or JSON or whatever other structured language one might use. It's just a matter of converting the syntax, the actual information is the same. Personally I wouldn't convert it to a different syntax if I was making a GUI editor, I would just parse it into a data structure in memory straight from Dart.\r\n\r\n> You can't do that easily when the programmer goes inside your \"giant nested expressions\" and writes any valid dart code that doesn't follow the structure that the GUI editor is expecting. With a fixed XML structure that is not a problem.\r\n\r\nThe thing is, you can put exactly the same \"any valid dart code\" in the XML structure as in the Dart expression. They are literally mechanically interchangeable. So I don't really see how using XML helps with this particularly. For example how would you turn this into XML?:\r\n\r\n```dart\r\nnew ListView.builder(\r\n  padding: new EdgeInsets.all(8.0),\r\n  itemExtent: 20.0,\r\n  itemBuilder: (BuildContext context, int index) {\r\n    return new Text('entry $index');\r\n  },\r\n)\r\n```\r\n\r\n> It handles it just fine, you just don't know how to do it.\r\n\r\nI meant specifically JSX. I agree that your proposed syntax would be a perfectly valid way to approach the problem.", "meta": {"posReactions": "10", "negReactions": "0"}}
{"id": "COM1814", "user": "HansMuller", "root": "ROOT18", "reply_to": "COM1813", "timestamp": "2017-08-17T19:03:15Z", "text": "I worked on Adobe's Flex SDK, which combined XML markup and ActionScript, for the last couple years that the product existed at Adobe.  I understand the appeal of markup for defining UIs however I can also remember some drawbacks:\r\n\r\n- Flex application visuals could be defined in terms of markup and code. As I remember it, code tended to dominate in large real-world apps.  Readability isn't necessarily a benefit for apps defined as a complex hybrids of markup and code.\r\n- The \"Flex Builder\" IDE had to support apps that were defined by  markup and code. This made the IDE difficult to build and maintain. Developers tended to view it as an ActionScript tool.\r\n- Evolving and maintaining the XML \"compiler\" was a significant burden that kept a team of engineers busy full-time.  Keeping the compiler and toolkit in lockstep slowed down the evolution of the overall sdk.\r\n\r\nIt's been years and I can no longer recall all the details. However my overall impression is that defining UIs with a combination of markup and code is a mixed bag at best.", "meta": {"posReactions": "10", "negReactions": "0"}}
{"id": "COM1815", "user": "cbazza", "root": "ROOT18", "reply_to": "COM1814", "timestamp": "2017-08-17T21:51:01Z", "text": "> Whether it died isn't the issue, it's why it died. Did it die because it didn't provide a solution that people wanted? Did it die because of implementation issues? Did it die because of patent issues? Was it too early? Too late? I think it's important to learn lessons from past experiences. Why did E4X and E4H fail where JSX has succeeded?\r\n\r\nIt died because E4X was only implemented in ActionScript which was only used inside Adobe Flash/Flex and Adobe killed the project. Instead Adobe changed direction towards open standards where there is no single source provider with possibility of lock-in and ecosystem implosion.\r\n\r\n> What I find interesting is that people who are new to Flutter often ask for two things: a markup language, and animated GIFs. Then three months in, they are still asking for animated GIFs, but not for a markup language. It could be that this is because the markup language isn't actually needed once you're used to writing build methods in Dart. It could be that they still want a markup language but have worked around the omission and so don't think to ask anymore. It's worth figuring out which because otherwise we risk spending effort on something that is the wrong choice (in either direction).\r\n\r\nWell, if I asked you for 2 things and you didn't do either in 3 months and there is an alternative to the first thing, I would also only ask you for what is totally impossible to do given your responsiveness and previous delivery performance.\r\n\r\n> (We're also experimenting with IDEs that put in virtual \"closing tag\" comments for you so you can see the structure without having to actually write it.)\r\n\r\nKind of funny but it's like putting the XML closing tag that you mentioned before was too verbose.\r\n\r\n> If this is the main benefit then this is something we can test. We could take a mixture of engineers who are used to writing HTML, React, iOS code, Android code, Flutter, command-line apps, and so on, and present them each with various syntaxes, and ask them to describe what they think the resulting UI would look like. We can then measure which syntax gets the best results. @InMatrix is this something we could look at after the animation work wraps up, maybe?\r\n\r\nSure you can do that go ahead, I am sure you will find out that \"Once you do React(with JSX) you simply don't go back\". Survey experienced React developers and ask them if they think JSX is bad and it should never had been done. Show your way and ask them if they want to replace JSX with what you have. Before you do that, close the doors and lock up the place because these developers are just going to grab their stuff and sprint for the closest exit.\r\n\r\n> The thing is, you can put exactly the same \"any valid dart code\" in the XML structure as in the Dart expression.\r\n\r\nSure, but for the GUI builders that's just a block of bytes that doesn't need to be touched and can be easily skipped. Making it design/code interchangeability practically possible instead of in principle.\r\n\r\n```dart\r\nnew ListView.builder(\r\n  padding: new EdgeInsets.all(8.0),\r\n  itemExtent: 20.0,\r\n  itemBuilder: (BuildContext context, int index) {\r\n    return new Text('entry $index');\r\n  },\r\n)\r\n``` \r\n\r\n```dart\r\nlet style = {\r\n  padding: new EdgeInsets.all(8.0),\r\n  itemExtent: 20.0\r\n};\r\n\r\n<ListView.builder style={style}>\r\n  {(context, index) => <Text> entry {index} </Text>}\r\n</ListView.builder>\r\n```\r\n", "meta": {"posReactions": "7", "negReactions": "5"}}
{"id": "COM1816", "user": "cbazza", "root": "ROOT18", "reply_to": "COM1815", "timestamp": "2017-08-17T21:54:38Z", "text": "I used Adobe Flex Builder extensibly...\r\n\r\n> Developers tended to view it as an ActionScript tool.\r\n\r\nYes, but I often switched from design view to code view and vice-versa.\r\nStarting a screen I would go to design view and use drag/drop to layout widgets and generate first static screen. Then I would add in code and some static data to fill in screen so I could show people something running that looked like production ready stuff. Productivity was incredible. As development progressed, I connected the front end to the back end and the amount of ActionScript code grew and yes it dominated the code overall but even at close to release time, I often used the design view to tweak the UI without having to dig into code. \r\n\r\n> However my overall impression is that defining UIs with a combination of markup and code is a mixed bag at best.\r\n\r\nNot in today's world. Imperative languages have evolved in the philosophy of Python and are great for development. Declarative techniques with embedded markup (XML) became mainstream with the advent of React; and JSON became the preferred text based data format.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1817", "user": "Hixie", "root": "ROOT18", "reply_to": "COM1816", "timestamp": "2017-08-17T22:45:35Z", "text": "> E4X was only implemented in ActionScript\r\n\r\nE4X was an ECMA standard. Mozilla shipped it for a while, but then removed it (a very unusual move for a browser vendor). Other browser vendors never wanted to implement it. (They've implemented other new ECMA features, though.) With E4H, the browser vendors were never interested in implementing it (though again, they've implemented plenty of other things I've helped invent).\r\n\r\n> Well, if I asked you for 2 things and you didn't do either in 3 months and there is an alternative to the first thing, I would also only ask you for what is totally impossible to do given your responsiveness and previous delivery performance.\r\n\r\nThat's one possible theory. People tend to ask for many other things besides, though, and many of the things they ask for get implemented, and there are workarounds for animated GIFs too, so I'm not sure this fully explains the situation.\r\n\r\n> Kind of funny but it's like putting the XML closing tag that you mentioned before was too verbose.\r\n\r\nIndeed. This is an optional IDE feature, and one that you don't have to write into the code, which makes a big difference to whether the verbosity is an issue, though.\r\n\r\n\r\n> ...`ListView`...\r\n\r\nHow would a GUI editor handle this markup? I don't really understand how to visualise the UI for this.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1818", "user": "branflake2267", "root": "ROOT18", "reply_to": "COM1817", "timestamp": "2017-08-17T23:47:46Z", "text": "This may be a counter argument to this request, and/or maybe some insight's to keep in mind if you want markup. I have strong feelings that adding markup creating some challenges with GWT I'd hate to see another API go through. \r\n\r\nI've seen a couple other frameworks go through this transition regarding with UI building. Markup like this works great for tooling, in so far it's heavenly for the IDE developers. It's easier to separate the responsibilities of who does what. Although I think it can be done better. \r\n\r\nGWT started out this way, building UI's with Java. Then came along UiBinder, where you could build the UI in xml markup, with a specification. Then the tooling, Eclipse Plugin, was able to generate UI's in xml markup. Android is doing it too, no need to belabor the point. So what I saw happen, markup works great for UI IDE developers. But really, markup is a huge huge investment in time and added complexity tooling to transition it to real program. And the tooling is always last to come. So in the mean time, while all that manifests into reality, there are two worlds. Two interesting ways of doing everything. One in the default language and one in markup. So I support GWT today. When I write documentation, I have to write it twice, once for Java and once for UiBinder XML Markup. So the real question, if you want to go down the markup road, I think the question should be asked, is the added complexity worth the journey! \r\n\r\nJSX I think aims to solve other issues where you want to blend together what your doing with HTML and javascript. It really doesn't feel like the added complexity of markup specification suits the needs of writing UI with markup. Especially when you don't really have a document markup language as the target. At least not for the everyday user. \r\n\r\nOn a positive note. I like to work on tooling. So I can see a markup language being quite useful. It's much easier to write and modify AST when your using markup.\r\n\r\nBut then again, if you have enough minds on the job, it doesn't really matter what you do. At the end of the day, if the developer can write his application faster with your api, your going to get traction. But at what cost to the engineering team. \r\n\r\nI think the real question is, how can the UI be built faster. I think tooling could write the dart, skip any middle man markup. And my aim isn't really to say it's not worth it, but really count the cost's on all the fronts if the road is taken!\r\n\r\n\r\n", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM1819", "user": "cbazza", "root": "ROOT18", "reply_to": "COM1818", "timestamp": "2017-08-18T17:12:38Z", "text": "> E4X was an ECMA standard. Mozilla shipped it for a while, but then removed it (a very unusual move for a browser vendor). Other browser vendors never wanted to implement it.\r\n\r\nI would say only Adobe fully championed E4X and had a good following with developers. Browser vendors do add and remove stuff from their browsers all the time; didn't Google remove MathML support?\r\n\r\n> That's one possible theory. People tend to ask for many other things besides, though, and many of the things they ask for get implemented, and there are workarounds for animated GIFs too, so I'm not sure this fully explains the situation.\r\n\r\n**Here is the thing about React and JSX. Initially I completely dismissed it**, I was in love with Angular and doing massive work with Ember. I tried desperately to convince the team to go with Angular but that didn't go anywhere as others had their eyes on Aurelia. Someone pointed me to React, I read the docs and evaluated and simply said that there was nothing in there that Angular or others couldn't do it. Then last year I worked on a new project and had the chance to try something new so I gave React a try and **you really don't fully appreaciate what React brings to the table until you develop with it for awhile, then it becomes night and day against all other frameworks. It's a mixture of simplicity and expressiveness brought together by JSX.** \r\n\r\n> How would a GUI editor handle this markup? I don't really understand how to visualise the UI for this.\r\n\r\n```dart\r\nlet style = {\r\n  padding: new EdgeInsets.all(8.0),\r\n  itemExtent: 20.0\r\n};\r\n\r\n<ListView.builder style={style}>\r\n  {(context, index) => <Text> entry {index} </Text>}\r\n</ListView.builder>\r\n```\r\n\r\nI would represent the \\<List.builder> as a rectangle and if its child/children where other widgets I would put rectangles for that inside it.\r\nSince the child in this case is a function, you can simply put a rectangle saying 'uneditable/code' to tell users that this widget is created from code or in this case easily deduce that the function is a shallow wrapper to the <Text> widget and simply present that; I mean a rectangle that says that the function is a shallow function wrapper and inside it the List item widget rectangle (\\<Text> in this case).\r\n", "meta": {"posReactions": "6", "negReactions": "7"}}
{"id": "COM1820", "user": "cbazza", "root": "ROOT18", "reply_to": "COM1819", "timestamp": "2017-08-18T17:15:26Z", "text": "> But really, markup is a huge huge investment in time and added complexity tooling to transition it to real program.\r\n\r\nAll I am asking is to add these simple extensions on the Dart compiler so that if developers want to they can write using this XML structure. The old way would continue to work and the amount of work involved to do this is not huge at all. You can actually see how many lines of code it takes the babel.js compiler to do JSX and I am talking hundreds and not thousands of lines (I just checked it).\r\n\r\n> And the tooling is always last to come. So in the mean time, while all that manifests into reality, there's two worlds. Two interesting ways of doing everything. One in the default language and one in markup\r\n\r\nSure but React has been like this and that is not an issue at all.\r\n\r\n> When I write documentation, I have to write it twice, once for Java and once for UiBinder XML Markup.\r\n\r\nNot in React because markup lives inside code.\r\n\r\n> is the added complexity worth the journey!\r\n\r\nAbsolutely, it's like the argument of whether you should train your developers with the latest techniques and risk them leaving your company. The bigger risk is keeping them around untrained. So you must adopt the latest techniques out there or risk being left behind.\r\n\r\nReact is leading the journey with the latest techniques to develop UI/UX. It has tremendous traction with developers. Your greatest risk is not meeting the React bar.\r\n\r\n> JSX I think aims to solve other issues where you want to blend together what your doing with HTML and javascript\r\n\r\nJSX is not just for HTML, React Native generates Views (like Flutter Widgets) from the XML markup.\r\n\r\n> I think the real question is, how can the UI be built faster.\r\n\r\nMore like how UI/UX can be built better. Better meaning: faster, higher quality (code and UI/UX), smooth designer-developer interaction, etc.\r\n\r\nBy the way, really nice job done on the developer tools; 'flutter doctor' was awesome !!!\r\nI am now cooking with gas and can be dangerously creative ;)\r\n\r\n", "meta": {"posReactions": "5", "negReactions": "5"}}
{"id": "COM1821", "user": "InMatrix", "root": "ROOT18", "reply_to": "COM1820", "timestamp": "2017-08-21T18:00:39Z", "text": "I just wanted to respond to the readability question raised here, though I understand readability is only one of the many factors we need to consider. \r\n\r\n>> Code readability and simplicity which in turn drives a whole bunch of other benefits.\r\n\r\n> If this is the main benefit then this is something we can test. We could take a mixture of engineers who are used to writing HTML, React, iOS code, Android code, Flutter, command-line apps, and so on, and present them each with various syntaxes, and ask them to describe what they think the resulting UI would look like. We can then measure which syntax gets the best results. @InMatrix is this something we could look at after the animation work wraps up, maybe?\r\n\r\nThere are certainly ways to empirically study code readability, and we can have a more serious discussion when it's time for Q4 planning. To make such a study useful, we need to define what kinds of reading tasks are important to developers in the context of Flutter programming. In addition to reading a whole build method and picture what the resulting UI might be, readability also affects smaller tasks such as identifying the build method in a dart file, matching braces, reading inline comments, etc. \r\n\r\nTo support some of those more narrowly-scoped tasks, we can experiment with UI enhancements in the editor first, which is usually cheaper than introducing and maintaining a markup language. The closing label feature in VS code is one of such UI enhancements, and we should understand how well it solves the brace matching problem it sets out to address. There are plenty of other options in this space we haven't tried yet. For example, a different font or background color might be used to display the build method to help the developer mentally separate it from the rest of their code.\r\n\r\nAnother thing that strikes me as important is how we can encourage people to not write giant build method and take advantage of the composition nature of the framework. If the build method is taller than the height of your screen, it's going to be hard to read regardless it's Dart or XML. ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1822", "user": "cbazza", "root": "ROOT18", "reply_to": "COM1821", "timestamp": "2017-08-21T19:36:17Z", "text": "> Another thing that strikes me as important is how we can encourage people to not write giant build method and take advantage of the composition nature of the framework. If the build method is taller than the height of your screen, it's going to be hard to read regardless it's Dart or XML.\r\n\r\nIt's not just the build method. It's all other methods that the build method calls to build the widget tree. Very common in React to use smaller methods to build sub-tree pieces and then call those into the larger tree. \r\n\r\nAlso in WebStorm with JSX, each XML node has +/- that can be used to expand/collapse node and children to make reading structures larger than the height of the screen easier.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1823", "user": "Hixie", "root": "ROOT18", "reply_to": "COM1822", "timestamp": "2017-08-21T20:55:52Z", "text": "One thing we've found in Flutter is that big build methods are not great for performance, and we try to encourage people to break down their build methods into smaller reusable widgets. In particular, in Flutter having a build method that's built out of the results of other methods is somewhat of an antipattern that we'd rather discourage rather than make easier. (This is somewhat of a recent realisation so a lot of our examples and widgets don't do this well yet.)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1824", "user": "cbazza", "root": "ROOT18", "reply_to": "COM1823", "timestamp": "2017-08-21T21:59:47Z", "text": "> we try to encourage people to break down their build methods into smaller reusable widgets.\r\n\r\nDoes it really become a reusable widget or simply a wrapper/composite widget? I mean to be reusable you should have at least 2 usage instances. \r\n\r\nThe AppBar on https://flutter.io/catalog/samples/basic-app-bar/ is so unique that you can't really call it an reusable component; it's a wrapper/composite component and in these cases why not just use a local method to build that part of the UI? I guess if it did more things it would make sense to place it in a wrapper/composite component.\r\n\r\n> One thing we've found in Flutter is that big build methods are not great for performance\r\n\r\nSince you mentioned performance, having the animation loop drive the build method will cause performance problems for smooth animation. You don't want your build method called 60 times a second or more, specially considering that the build method is user code (for example, it could have a super long loop that takes forever and it would cause animations to skip). Being a Flutter beginner perhaps I got that wrong.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1825", "user": "Hixie", "root": "ROOT18", "reply_to": "COM1824", "timestamp": "2017-08-21T22:05:47Z", "text": "> The AppBar on https://flutter.io/catalog/samples/basic-app-bar/ is so unique that you can't really call it an reusable component\r\n\r\nIt's also relatively small, so that's ok.\r\n\r\nRegarding performance, this is somewhat off-topic for this issue so please file a new issue if you want to discuss it (or e-mail flutter-dev or post on stack overflow, whatever you prefer).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1826", "user": "nsuper", "root": "ROOT18", "reply_to": "COM1825", "timestamp": "2017-11-20T13:44:02Z", "text": "https://github.com/Kotlin/anko/wiki/Anko-Layouts", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1827", "user": "birkir", "root": "ROOT18", "reply_to": "COM1826", "timestamp": "2017-12-11T08:42:16Z", "text": "It's crazy to see this issue getting buried. In my opinion it's going to be a make or break for Flutter to implement JSX-like syntax for composing widgets.\r\n\r\nI simply don't understand the target audience, many ios and android devs are moving to react native, it would seem to be the perfect opportunity to harvest market share.\r\n\r\nI encourage people involved to give react native a spin and see what we are talking about.", "meta": {"posReactions": "14", "negReactions": "6"}}
{"id": "COM1828", "user": "zoechi", "root": "ROOT18", "reply_to": "COM1827", "timestamp": "2017-12-11T09:59:54Z", "text": "I don't miss JSX a bit in Flutter. This would only bloat the framework and tools for a few small gains here and there.", "meta": {"posReactions": "18", "negReactions": "5"}}
{"id": "COM1829", "user": "cbazza", "root": "ROOT18", "reply_to": "COM1828", "timestamp": "2017-12-11T15:16:34Z", "text": "@birkir I am 100% with you on this issue. Lack of JSX, which is a perfect fit for Flutter, makes Flutter look old and rusty, feels like 1990s technology. Actually it seems like everyone, in one way or another, is adopting JSX; the latest one being the popular Vue.js framework.\r\n ", "meta": {"posReactions": "10", "negReactions": "9"}}
{"id": "ROOT19", "user": "ceet2016", "root": "ROOT19", "reply_to": null, "timestamp": "2019-10-28T07:55:20Z", "text": "\u4f60\u597d\uff0c\u4f60\u7684\u8bed\u8a00\u7248\u672c\u4e0a\u8fdd\u53cd\u4e86\u4e2d\u56fd\u6cd5\u5f8b ![up-796da3ff8acde0e73f27b9035ab0b3b0](https://user-images.githubusercontent.com/29434060/67661067-37078e80-f99b-11e9-9929-19064b5ab7dd.png)\r \r \u4f60\u597d\u3002\u4f60\u7684\u6587\u6863\u4e0a\u5bf9\u4e8e\u56fd\u5bb6\u7684\u6807\u6ce8\u8fdd\u53cd\u4e86\u4e2d\u56fd\u6cd5\u5f8b\uff0c\u53f0\u6e7e\u662f\u4e2d\u56fd\u7684\u4e00\u90e8\u5206\uff0c\u662f\u4e2d\u56fd\u7684\u4e00\u4e2a\u7701\uff01\u4e0d\u5e94\u8be5\u88ab\u5355\u72ec\u5217\u51fa\u6765\uff0c\u5e0c\u671b\u4fee\u6539\uff01", "meta": {"posReactions": "5", "negReactions": "16"}}
{"id": "COM190", "user": "GammaGames", "root": "ROOT19", "reply_to": "ROOT19", "timestamp": "2019-10-28T14:19:46Z", "text": "Translated:\r\n\r\n### Hello, your language version violates Chinese law.\r\n\r\n> Hello there. The marking of the country on your document violates Chinese law. Taiwan is a part of China and a province of China! Should not be listed separately, I hope to modify", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM191", "user": "peterrobertz", "root": "ROOT19", "reply_to": "COM190", "timestamp": "2019-10-30T10:04:10Z", "text": "Uhhh China ......\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM192", "user": "fudanglp", "root": "ROOT19", "reply_to": "COM191", "timestamp": "2019-10-31T10:03:57Z", "text": "\u6ca1\u5fc5\u8981\u8fd9\u6837\uff0c\u60f3\u8ba9\u53f0\u6e7e\u56de\u5f52\u8fd9\u6837\u505a\u662f\u9002\u5f97\u5176\u53cd", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM193", "user": "joseph1125", "root": "ROOT19", "reply_to": "COM192", "timestamp": "2019-11-07T04:12:39Z", "text": "> Uhhh China ......\r\n\r\nWelcome to the world of Chinazi, my friend.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM194", "user": "helloroy", "root": "ROOT19", "reply_to": "COM193", "timestamp": "2019-11-11T02:07:04Z", "text": "China law not world law, if you are using this framework at China, feel free to address it by yourself.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM195", "user": "y0hami", "root": "ROOT19", "reply_to": "COM194", "timestamp": "2019-11-12T09:26:47Z", "text": "Just want to jump in here because it seems to be getting slightly heated.\r\n\r\nThis docs page has nothing to do with countries or territories it's just to show all the **_flags_** provided by SUI and because Taiwan and China use different flags there is 2 entries in this list.", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM196", "user": "Gary50613", "root": "ROOT19", "reply_to": "COM195", "timestamp": "2019-11-30T07:37:31Z", "text": "\u984d...\u53f0\u7063\u5c31\u53f0\u7063\u641e\u4ec0\u9ebc", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM197", "user": "windowsed1225", "root": "ROOT19", "reply_to": "COM196", "timestamp": "2019-11-30T07:43:24Z", "text": "ur mum this is other language and tw and hk is using same lanuage we dont want to fking Simplified chinese L", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT20", "user": "cemo", "root": "ROOT20", "reply_to": null, "timestamp": "2018-02-07T13:46:46Z", "text": "FR: Firebase Analytics Server Side My Environment: \r \r   * Operating System version: Any\r   * Firebase SDK version: Any\r   * Library version: Latest\r   * Firebase Product: analytics\r \r Please provide Firebase analytics Api for server side. We would like to give a decision right now and being limited on client side is unfortunately not acceptable. \r ", "meta": {"posReactions": "87", "negReactions": "0"}}
{"id": "COM200", "user": "hiranya911", "root": "ROOT20", "reply_to": "ROOT20", "timestamp": "2018-02-07T17:47:31Z", "text": "What features would you like to see in a server-side analytics API? Client SDKs primarily support logging analytics events. I don't think there's a use case to support that server-side.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM201", "user": "cemo", "root": "ROOT20", "reply_to": "COM200", "timestamp": "2018-02-07T18:17:08Z", "text": "I would like to use firebase analytics as a marketing automation tool. My primary purpose is forwarding all events in our system to firebase and using its audience feature. \r\n\r\nI want to do this in server side because it has major advantages. \r\n\r\n1. Instead of implementing firebase in multiple client, I can implement in a single server and maintain it. \r\n2. Accuracy of data in client sides are usually problematic. \r\n\r\nI believe that it has great potential in server side as well. ", "meta": {"posReactions": "43", "negReactions": "0"}}
{"id": "COM202", "user": "avishalom", "root": "ROOT20", "reply_to": "COM201", "timestamp": "2018-02-14T22:36:32Z", "text": "Just to clarify, \r\nA user does something which you log on your server, you are looking for a way for the server to log the event *as the user* (would you be passing user specific event attributes? (e.g. user-agent)). \r\nis that it? ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM203", "user": "cemo", "root": "ROOT20", "reply_to": "COM202", "timestamp": "2018-02-15T09:42:16Z", "text": "@avishalom the scenario you are describing is exactly valid. You can consider our server as an agent. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM204", "user": "esprehn", "root": "ROOT20", "reply_to": "COM203", "timestamp": "2018-02-16T03:42:11Z", "text": "We have the same problem in cloud functions. The cloud function reacts to the client doing something and needs to log an event to analytics on behalf of that user. We don't want to give the client access to the data necessary to log such an event though.\r\n\r\nIt's the same use cases and motivate:\r\nhttps://developers.google.com/analytics/devguides/collection/protocol/v1/", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM205", "user": "adam-hurwitz", "root": "ROOT20", "reply_to": "COM204", "timestamp": "2018-05-24T18:23:28Z", "text": "This appears to be exactly what we need to send data from Firebase to BigQuery using Cloud Functions: [From Firestore to BigQuery with Firebase Functions](https://blog.questionable.services/article/from-firestore-to-bigquery-firebase-functions/).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM206", "user": "rromanchuk", "root": "ROOT20", "reply_to": "COM205", "timestamp": "2018-08-04T09:20:15Z", "text": "@avishalom  I'm not able to track revenue because it's not bound to any user action on the client, it's actually an event by the negation of an action. It's not bound by a specific schedule either (it's not subscription model). The only way i could sort of maybe kind of do this is with silent push notifications that trigger a Firebase event, but this error prone. The only thing i can think of is using user properties to track accumulating revenue which will at least provide some context. ", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM207", "user": "nightrise", "root": "ROOT20", "reply_to": "COM206", "timestamp": "2018-08-09T17:40:06Z", "text": "Any updates on this feature, or documentation on doing it ourselves (via REST API for example)? I'm rather surprised this isn't a use-case covered by the core library. In server-authoritative applications, there are many use-cases where analytics events are emitted by the server, and not available to the client. In order to have a complete data-set we need to be able to emit analytics events server-to-server. ", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM208", "user": "namanyayg", "root": "ROOT20", "reply_to": "COM207", "timestamp": "2018-08-14T19:51:46Z", "text": "Is there any solution here? Is there some way to use BigQuery perhaps?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM209", "user": "dabramovici", "root": "ROOT20", "reply_to": "COM208", "timestamp": "2018-08-15T13:21:58Z", "text": "Also interested in this. Any updates?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2010", "user": "cemo", "root": "ROOT20", "reply_to": "COM209", "timestamp": "2018-08-15T13:46:43Z", "text": "Please upvote issue as well", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2011", "user": "namanyayg", "root": "ROOT20", "reply_to": "COM2010", "timestamp": "2018-08-15T13:49:57Z", "text": "For what it's worth, I don't see this happening anytime soon. Google simply doesn't support server side analytics, firebase analytics is exclusively for apps.\r\n\r\nRight now I've imported my data into bigquery and am working on adding server side integration with my bigquery table. With this, I should be able to use bq to query data and later use datastudio to display it. I found this video helpful: https://www.youtube.com/watch?v=Ki_F6VCOtXU", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2012", "user": "andvalsol", "root": "ROOT20", "reply_to": "COM2011", "timestamp": "2018-11-17T12:52:10Z", "text": "Is still there an option to add Firebase Analytics on the server side?", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM2013", "user": "samdozor", "root": "ROOT20", "reply_to": "COM2012", "timestamp": "2018-12-20T20:29:50Z", "text": "I'll add in that a SaaS analytics product that doesn't support a server-to-server flow today is extremely rare. Google's own \"measurement protocol\" for Google Analytics is widely adopted. And of course players like Adobe, Amplitude and Mixpanel support it. The value and use-cases for server-side APIs are well enumerated over hundreds of other tools. \r\n\r\nThat being said - opening up a server-to-server flow is more complicated than just documenting an API - since you have to support all of the \"interesting\" things folks will use it for. *Supporting* server data means that customers will try to send in web data, and offline data, and OTT data, etc. How do you accurately link up client-side and server-side identity? \r\n\r\nBy way of a guess - perhaps Google is in the process of combining GA and Firebase Analytics (frankly the branding is already getting conflated - they're calling it \"Google Analytics for Firebase\" as of this writing...), in which case it makes sense to hold off on releasing a true server-to-server flow. More conspiratorially, maybe they're deliberately limiting the use-cases for Firebase such that it's basically unusable for the enterprise businesses, who absolutely need a server-to-server flow, but who already are paying for GA 360.\r\n\r\nOnly time will tell! Either they'll come up with a solution or, in my opinion, Firebase will be relegated as a 2nd-tier analytics offering.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM2014", "user": "ToddKerpelman", "root": "ROOT20", "reply_to": "COM2013", "timestamp": "2018-12-21T18:49:45Z", "text": "Hey, folks. I'll just chime in to say this is a feature request the Analytics team has certainly heard from customers, and it's something they're looking into, but as usual I can't share any specific plans or roadmap or anything.\r\n\r\nRight now, probably your best option would be to import your analytics data from Google Analytics for Firebase into BigQuery and then combine that with any other data you might be generating server-side, kinda like what @namanyayg mentioned.", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM2015", "user": "cemo", "root": "ROOT20", "reply_to": "COM2014", "timestamp": "2018-12-22T18:55:17Z", "text": "@ToddKerpelman This is great. I think that this API is already implemented for mobile devices. In order to send events by mobile devices there must be an API for this purpose. I feel that the API needs to be officially documented and publicly available for server side. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2016", "user": "stari4ek", "root": "ROOT20", "reply_to": "COM2015", "timestamp": "2019-01-30T21:36:45Z", "text": "This is the only solution to implement subscription tracking since there is no automatic subscription tracking provided by firebase", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2017", "user": "lauri3new", "root": "ROOT20", "reply_to": "COM2016", "timestamp": "2019-02-25T14:11:41Z", "text": "Is there any update on this or a link to a custom solution? \r\nIdeally I want to be able to update user properties in firebase analytics from server side, so I can filter by them later when using other firebase services e.g. FCM", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2018", "user": "n-sviridenko", "root": "ROOT20", "reply_to": "COM2017", "timestamp": "2019-04-29T06:50:56Z", "text": "We also need this.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM2019", "user": "Energy0124", "root": "ROOT20", "reply_to": "COM2018", "timestamp": "2019-05-07T15:37:15Z", "text": "There is an important use case for games with IAP as any client-side information is going to be unreliable. Having the event logged in server-side make it a bit more reliable. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2020", "user": "n-sviridenko", "root": "ROOT20", "reply_to": "COM2019", "timestamp": "2019-05-12T08:18:54Z", "text": "Many things happen server-side (e.g. events happening when the user is offline). Without such a simple feature, it's impossible to target the right users. This fact forces us think towards other solutions on the market :( ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM2021", "user": "copilots-app", "root": "ROOT20", "reply_to": "COM2020", "timestamp": "2019-05-15T08:27:26Z", "text": "This is crucial for our solution as well. Please consider a fix ;-)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2022", "user": "puf", "root": "ROOT20", "reply_to": "COM2021", "timestamp": "2019-07-07T13:15:59Z", "text": "It is now possible to [add an Analytics label to messages](https://firebase.google.com/docs/cloud-messaging/understand-delivery#adding_analytics_labels_to_messages). Does that mean this FR can now be implemented?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2023", "user": "cemo", "root": "ROOT20", "reply_to": "COM2022", "timestamp": "2019-09-26T13:03:49Z", "text": "@ToddKerpelman, Is there any update on this? ", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM2024", "user": "voxelbusters", "root": "ROOT20", "reply_to": "COM2023", "timestamp": "2019-10-02T13:44:49Z", "text": "> It is now possible to [add an Analytics label to messages](https://firebase.google.com/docs/cloud-messaging/understand-delivery#adding_analytics_labels_to_messages). Does that mean this FR can now be implemented?\r\n\r\nLooks like it has some limitations. Do you recommend for general logging from Firebase functions?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2025", "user": "mmilowski", "root": "ROOT20", "reply_to": "COM2024", "timestamp": "2019-10-09T18:59:54Z", "text": "@ToddKerpelman  I consulting Firebase analytics with the clients and its common problem :/ I was thinking about solution and maybe create few standard events (or it will be a new type of standard events) which can have permission to connect with server-side. Two cases that I have in my mind are 1. mobile app with subscription model \r\n2. mobile app like a uber where clients don't\u00a0need to have an open app after they finished\u00a0their trip. \r\nI'm not programmer but marketer so sry if my thoughts are totally wrong ;)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2026", "user": "stari4ek", "root": "ROOT20", "reply_to": "COM2025", "timestamp": "2019-10-10T06:17:45Z", "text": "Looks like there're server-side reporting already which is used to report app_store_* events.\r\nThey are not exported to BigQuery and do not have any standard properties (user_id, device, ...) comparing to any other events. Here is my SO question about it: https://stackoverflow.com/questions/58300435/app-store-subscription-events-are-not-exported-to-bigquery", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM2027", "user": "Legoless", "root": "ROOT20", "reply_to": "COM2026", "timestamp": "2019-10-25T13:43:50Z", "text": "Oh, you gotta be joking. There's in-app subscription events happening, which is related directly to client app, but can only be reliably detected on server side. Such as users being charged on monthly basis, trial periods, introductional periods, etc. So there is no way (apart from using a billion other tools) to directly send these events to Firebase? All analytics tools support this...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2028", "user": "baakind", "root": "ROOT20", "reply_to": "COM2027", "timestamp": "2019-11-06T12:55:27Z", "text": "We also need this.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM2029", "user": "kopfnick", "root": "ROOT20", "reply_to": "COM2028", "timestamp": "2019-11-22T13:01:26Z", "text": "I am a little surprised that this also was not ported over from old analytics - absolutely need this for server side event logging out of things happening in the database into user lifecycles...\r\nFor us especially it would also be crucial in order to get some events as conversions into ads...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT21", "user": "chinmaygarde", "root": "ROOT21", "reply_to": null, "timestamp": "2021-01-25T10:40:48Z", "text": "[Prototype] [Do NOT Merge] Binary Metal Archive Prototype for iOS/Mac. This patch wires up Metal Binary Archives for Mac and iOS. Metal Binary Archives\r are used to cache pipeline state objects generated at runtime on the device and\r serialize them to disk when rendering is paused. In this prototype, the binary\r archives are serialized to disk when the application moves into the background.\r On the next launch of the application, the serialized representation of the\r archives is used for the creation of new pipeline state objects.\r \r Per the [details in the linked issue][1], I do not recommend we land this patch.\r This PR is just meant to be a record of the prototyping work done to evaluate\r Metal Binary Archives for Flutter.\r \r [1]: https://github.com/flutter/flutter/issues/60267#issuecomment-762786388\r \r ## Observations\r \r Once patched in, the following observations can be made while running a Flutter application.\r \r * After first launch, the application caches directory should contain a `.metallib` file with the following format. `flutter_engine_<engine_version>_<skia_version>_<index>.metallib`. This was done so any changes to the Flutter engine or the Skia version would not run the risk of using invalid cached contents. The file ([example](https://github.com/flutter/engine/files/5865817/flutter_engine_08daa2c8962687253fbcbd812d08d70c34c86721_069e484cc3b9518f115312c065a6f9c843b0839a_0.metallib.zip)) seems to be a Mach-O binary. This is consistent with Apple's recommendation that the `lipo` tool be used to combine archives harvested from devices of different GPU families.\r * This file will get updated every time the application is backgrounded and will get reused when the application is launched.\r * To prevent any issues with threading (I could find no mention in the docs about the thread safety aspects of any of the APIs) only raster thread operations will using this archive.\r * One open question not answered in my linked comment was how much these archives would help for jank during subsequent application launches (as seeding the archive for first launch is a no-go). I tried to find determine this by making sure the cache was seeded and launching the application again. My hope was to see a reduction in the `GrMtlPipelineStateBuilder::finalize` trace in Observatory. This [did not materialize (trace is from a warmed up archive)](https://github.com/flutter/engine/files/5865862/warmed_cached_pipeline_state_extra_skia_traces.json.zip). This seems to be because the primary cause of jank in pipeline state setup is the construction of the Metal shader library (SKSL -> MSL -> MTLLibrary (AIR?)) and not the pipeline state object construction. An annotated version of one of the traces is as follows:\r ![Screen Shot 2021-01-25 at 2 24 51 AM](https://user-images.githubusercontent.com/44085/105694897-5058fc80-5eb6-11eb-8440-5b6f973abe0a.png)", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM210", "user": "flutter-dashboard[bot]", "root": "ROOT21", "reply_to": "ROOT21", "timestamp": "2021-01-25T10:40:51Z", "text": "It looks like this pull request may not have tests. Please make sure to add tests before merging. If you need an exemption to this rule, contact Hixie on the #hackers channel in [Chat](https://github.com/flutter/flutter/wiki/Chat).\n\n__Reviewers__: Read the [Tree Hygiene page](https://github.com/flutter/flutter/wiki/Tree-hygiene#how-to-review-code) and make sure this patch meets those guidelines before LGTMing.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM211", "user": "escamoteur", "root": "ROOT21", "reply_to": "COM210", "timestamp": "2021-01-26T10:30:41Z", "text": "Just curious, why isn't it possible to cache or even distribute the MSL version of the shaders instead of doing the translation fom SKLS to Msl at runtime? Or even precompile Msl?\r\nDid you have a look how https://github.com/kakashidinho/metalangle solves this?", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM212", "user": "huvi8161", "root": "ROOT21", "reply_to": "COM211", "timestamp": "2021-01-28T15:29:01Z", "text": "One more question regarding your statement @chinmaygarde, \"This seems to be because the primary cause of jank in pipeline state setup is the construction of the Metal shader library (SKSL -> MSL -> MTLLibrary (AIR?)) and not the pipeline state object construction.\", could we do something to speed up creation of Metal shader library?", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM213", "user": "dnfield", "root": "ROOT21", "reply_to": "COM212", "timestamp": "2021-02-03T17:54:00Z", "text": "@chinmaygarde - what if we could get skia to use https://developer.apple.com/documentation/metal/mtldevice/1433391-newlibrarywithdata?language=occ instead? It seems like that should be faster...", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM214", "user": "escamoteur", "root": "ROOT21", "reply_to": "COM213", "timestamp": "2021-02-03T22:22:58Z", "text": "> @chinmaygarde - what if we could get skia to use https://developer.apple.com/documentation/metal/mtldevice/1433391-newlibrarywithdata?language=occ instead? It seems like that should be faster...\r\n\r\nThat's what I meant above", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM215", "user": "KrillioSokolov", "root": "ROOT21", "reply_to": "COM214", "timestamp": "2021-02-09T17:25:04Z", "text": "Unprofessional for Flutter team to have this issue for more than 1 year.\r\nIt is just shows up the whole Google company style - quantity over quality. \r\nCan't wait cross-platform solution from Apple. It will be just different, as always later than Google, but just perfectly usable.\r\n\r\nPLEASE PROVIDE SOLUTION to whole community ASAP or just put Flutter here https://killedbygoogle.com. ", "meta": {"posReactions": "5", "negReactions": "3"}}
{"id": "COM216", "user": "escamoteur", "root": "ROOT21", "reply_to": "COM215", "timestamp": "2021-02-09T17:54:47Z", "text": "@KrillioSokolov may I remind you of the code of conduct of this repository which strongly encourages a kind behaviour?\r\nThis isn't an issue that is so easy to fix. Always keep in mind that this is a full framework you get for free.\r\nAnd this issue would be way easier if Apple hadn't decided not to join all other Vendors in Vulkan but to develop Metal.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM217", "user": "KrillioSokolov", "root": "ROOT21", "reply_to": "COM216", "timestamp": "2021-02-09T18:28:11Z", "text": "@escamoteur, I am really sorry if I break any rules. I'm struggling about passive reaction of Flutter team. \r\n\r\nYes, you are right it's for free, except developers fee, right? We are paying commission in the Play Store, paying account fees and Google provides tools for making applications which will gain more money for Google. It's simple consumption chain. \r\n\r\nFor sure, me and many others developers feel deceived about this situation, because Flutter team PROMISED 60 fps animation! We all invest years of our lives in usage this technology, we spent our tech-reputation to push ours companies to take a risk and invest resources to achieve this technology. And what we have got from Flutter team? \r\n\r\nIndifference for the whole year! They decide to expand to the web and desktop, instead of contributing theirs main features and take care of community. That's why I tell, that \"quantity over quality\"\r\n\r\nAnd you are really think that is the Apple's problem? If you decide to create cross-platform system you had better to being ready for changes from each contributed platforms, a specially from a such moody company as Apple. \r\n", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM218", "user": "aliakhtar", "root": "ROOT21", "reply_to": "COM217", "timestamp": "2021-02-09T19:40:21Z", "text": "I'm grateful to the Flutter developers for their work on Flutter, and for making it available for free.\r\n\r\nA few points.\r\n\r\n- On the Flutter site, this issue is still not clearly shown. I spent a week of full time effort learning Flutter, only to find out about this issue hidden in the shader optimization article. I feel misled because everything I first saw on homepage etc, promised 60 FPS and native performance. I think its bordering on unethical to not make this problem clearly known to new developers.\r\n\r\n- This issue should be a higher priority than anything else, instead it still seems like its a P3 or lower. No one is even assigned to this issue yet?\r\n\r\n- There should be an ETA / timeline for a resolution.\r\n\r\nIt looks like there's a solution available - running animations in the background to warm up the shader. We just need something around that to be made official.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM219", "user": "omchiii", "root": "ROOT21", "reply_to": "COM218", "timestamp": "2021-02-09T19:41:32Z", "text": "Flutter team itself said that they considered the option to go with OpenGL and Metal, but they didn\u2019t. They decided to go with Metal only. What I don\u2019t understand is how did they not see this issue when they were testing? I don\u2019t believe switching over to Metal was a 3 minute decision.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2110", "user": "omchiii", "root": "ROOT21", "reply_to": "COM219", "timestamp": "2021-02-09T19:48:41Z", "text": "> I'm grateful to all the Flutter developers for their work on Flutter, and for making it available for free.\r\n> \r\n> A few points.\r\n> \r\n> * On the Flutter site, this issue is still not clearly shown. I spent a week of full time effort learning Flutter, only to find out about this issue hidden in the shader optimization article. I feel misled because everything I first saw on homepage etc, promised 60 FPS and native performance. I think its bordering on unethical to not make this problem clearly known to new developers.\r\n> * This issue should be a higher priority than anything else, instead it still seems like its a P3 or lower. No one is even assigned to this issue yet?\r\n> * There should be an ETA / timeline for a resolution.\r\n> \r\n> It looks like there's a solution available - running animations in the background to warm up the shader. We just need something around that to be made official.\r\n\r\nTo be honest. Flutter being free in this case makes it only worse. I wish it was paid so we would not get the \u201cit\u2019s free, whatever you get be happy\u201d response. At least we would not get a 100 line code commit after 1 year on such a huge issue.", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM2111", "user": "huvi8161", "root": "ROOT21", "reply_to": "COM2110", "timestamp": "2021-02-11T08:10:02Z", "text": "@chinmaygarde do you have any comments on the idea to cache and distribute MSL? Also is this an issue where you will track further progress on this issue? Do you have some kind of document or could you create one in which you would describe the setup to tray to debug this so maybe somebody also could get involved and maybe we could get more ideas? And the final question is are you the only person that is working on this?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2112", "user": "dnfield", "root": "ROOT21", "reply_to": "COM2111", "timestamp": "2021-02-11T17:13:06Z", "text": "Chinmay and I talked about this a bit offline.\r\n\r\nCaching the MSL has a few challenges:\r\n\r\n- Apple doesn't seem to provide a good way to fetch the binary archives from the device/application for caching.\r\n- It still has many disadvantages, such as not necessarily knowing when you'd need to do this, whether your cached shaders are still valid or not, whether you're missing an important one, etc.\r\n\r\nWe're trying to come up with a more comprehensive solution for this - one that would clearly let developers know when their scene might be complex enough to result in lengthy shader compilation, and what options they have to mitigate that.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM2113", "user": "escamoteur", "root": "ROOT21", "reply_to": "COM2112", "timestamp": "2021-02-11T17:32:58Z", "text": "@dnfield from my understanding the shaders we are talking of don't get there source dynamically or are they? So you wouldn't even need to cache them you could directly bundle the precompiled metal shaders. In contrary to OpenGL you always know that the metal API will be there.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2114", "user": "KrillioSokolov", "root": "ROOT21", "reply_to": "COM2113", "timestamp": "2021-02-11T17:44:40Z", "text": "Anyone else has opinion that cashing is just a crutch? Looks like, it is just attempt to run away from the problem and try to hide it. \r\n\r\nGuys from Flutter team, you spend tone of time to learn algorithms, data structure, low level programming for get work in Google and for now is it actually that type of solution you wanna provide being hired by the one of the best company in the world? Crutch? \r\n\r\nAll application on flutter just lagging, even Google applications, everyone understand that cashing would probably decrease lagging, but not remove them all. When you solve this issue(instead of provide workaround) Flutter will be best SaaS decision in the world, even for iOS users! \r\n\r\n Believe in you guys.", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM2115", "user": "escamoteur", "root": "ROOT21", "reply_to": "COM2114", "timestamp": "2021-02-11T17:48:56Z", "text": "> \r\n> \r\n> Anyone else has opinion that cashing is just a crutch? Looks like, it is just attempt to run away from the problem and try to hide it.\r\n> \r\n> Guys from Flutter team, you spend tone of time to learn algorithms, data structure, low level programming for working in Google and for now is it actually that type of solution you wanna provide in one of the hugest company in the world? Crutch? All application on flutter just lagging, even Google applications, everyone understand that cashing would probably decrease lagging, but not remove them all.\r\n\r\nI recommend diving a bit deeper in the world of shaders an crossplatform GPU programming before making such a statement. Shaders have to be compiled before you can use them the first time. There is no way around it. So caching the compiled shaders is the usual way you do this.  My guess is that iOS native Apps use shaders that are already loaded by the operating system.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2116", "user": "KrillioSokolov", "root": "ROOT21", "reply_to": "COM2115", "timestamp": "2021-02-11T17:55:34Z", "text": "@escamoteur, hm...  Will increasing a duration of showing Launch Screen give enough time to launch engine and load shaders to use it? \r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2117", "user": "escamoteur", "root": "ROOT21", "reply_to": "COM2116", "timestamp": "2021-02-11T17:59:32Z", "text": "@KrillioSokolov from my understanding Flutter only creates the shaders when it needs them the first time, which makes sense because why create shaders for widgets you never use.\r\nMy guess is if you create the widgets where you encounter the jank already behind your Startup screen, that could help, but I' not sure if shaders will be created if the widgets are hidden.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2118", "user": "acoutts", "root": "ROOT21", "reply_to": "COM2117", "timestamp": "2021-02-11T18:00:47Z", "text": "> @escamoteur, hm... Will increasing a duration of showing Launch Screen give enough time to launch engine and load shaders to use it?\r\n\r\nThe problem with this approach is you can't do it with a screen transition. I tried this even putting a hidden navigator behind the current screen with a stack and pushing/popping 3-5 times behind a loading screen, and it had no impact on the perceived jank after that.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2119", "user": "dnfield", "root": "ROOT21", "reply_to": "COM2118", "timestamp": "2021-02-11T18:02:42Z", "text": "I think we're starting to get a bit off topic here.\r\n\r\nVery briefly, the need for shader compilation has to do with Flutter allowing you to dynamically create lots of different pixel configurations on the GPU. In theory, one could try to write a lot of that logic itself as a shader program, compile that \"uber shader\" once, and then never suffer from shader compilation jank during application run. In practice, that's extremely difficult to do correctly and may not even be possible to do performantly - shaders want to be small, well defined programs typically, and supporting everything that Flutter can do with such a program (on all the GPUs we have to support) is a very large problem space. Caching smaller programs can help, but it is not an ideal solution since different GPU/OS/driver versions can cause cache misses. This could be a problem even on iOS, where different phone/iPad models and iOS versions are in use. There are other design possibilities being considered as well.\r\n\r\nAs I said, we're working to come up with an overall better solution for this, but it's not an easy problem to deal with. This is considered an important issue by the team. We welcome contributions here as well, whether it's a patch or design proposals/feedback.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM2120", "user": "escamoteur", "root": "ROOT21", "reply_to": "COM2119", "timestamp": "2021-02-11T18:02:58Z", "text": "> \r\n> \r\n> > @escamoteur, hm... Will increasing a duration of showing Launch Screen give enough time to launch engine and load shaders to use it?\r\n> \r\n> The problem with this approach is you can't do it with a screen transition. I tried this even putting a hidden navigator behind the current screen with a stack and pushing/popping 3-5 times behind a loading screen, and it had no impact on the perceived jank after that.\r\n\r\nYeah, I was already fearing the the engine is too \"smart\" not to create any shader unless it really has to use it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2121", "user": "dnfield", "root": "ROOT21", "reply_to": "COM2120", "timestamp": "2021-02-11T18:07:56Z", "text": "@acoutts - I wonder if you'd have better luck with that solution by actually rasterizing frames from that animation to a pixel buffer. Putting it somewhere invisible may get optimized away.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2122", "user": "acoutts", "root": "ROOT21", "reply_to": "COM2121", "timestamp": "2021-02-11T18:08:47Z", "text": "> @acoutts - I wonder if you'd have better luck with that solution by actually rasterizing frames from that animation to a pixel buffer. Putting it somewhere invisible may get optimized away.\r\n\r\nI'd love to give it a shot. Have any docs I can read up on for how to do this kind of thing?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2123", "user": "dnfield", "root": "ROOT21", "reply_to": "COM2122", "timestamp": "2021-02-11T18:09:08Z", "text": "I'll also mention: sometimes the solution is just to do something less expensive. See for example https://github.com/flutter/flutter/pull/75670 - we found that using `drawRect` calls instead of a `LinearGradient` saves significant amount of time on initial rendering time.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2124", "user": "dnfield", "root": "ROOT21", "reply_to": "COM2123", "timestamp": "2021-02-11T21:34:03Z", "text": "@acoutts - not really. I'd try to just experiment with rendering the widget into a repaint boundary and using https://api.flutter.dev/flutter/rendering/RenderRepaintBoundary/toImage.html to render it into a small image as part of a warmup routine, or https://api.flutter.dev/flutter/rendering/OffsetLayer/toImage.html if that makes more sense.\r\n\r\nYou might also try just directly using the `SceneBuilder` API and using `Scene.toImage` depending on how you approach it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2125", "user": "huvi8161", "root": "ROOT21", "reply_to": "COM2124", "timestamp": "2021-02-11T21:53:49Z", "text": "@dnfield If I understand you well we should try to convert our page ui(scene) into an image and than try to paint it inside Flutter default warmup routine (https://api.flutter.dev/flutter/painting/DefaultShaderWarmUp-class.html) am I correct in this assumption? Also for us the main issue is the the cupertino route page transition we have other animations but nothing is as important as the first few page transitions and they have issue with shader compilation, page transition shader is directly related with the content of this page, we should try to get the images of pages that user is going to see first and put them in warmup routine? Can you just confirm or deny my assumptions?  ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2126", "user": "dnfield", "root": "ROOT21", "reply_to": "COM2125", "timestamp": "2021-02-11T21:55:00Z", "text": "You don't want to save the image - you want to get Skia to create the shader(s) needed to create the image.\r\n\r\nI'm not necessarily recommending this approach, but I think it's one that might be worth experimenting with and see what we can get out of it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2127", "user": "dnfield", "root": "ROOT21", "reply_to": "COM2126", "timestamp": "2021-02-11T21:55:38Z", "text": "IOW, you want to try to capture relevant frame(s) from your actual widgets/transitions, and rasterize them so that the needed shader(s) get compiled up front.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2128", "user": "huvi8161", "root": "ROOT21", "reply_to": "COM2127", "timestamp": "2021-02-11T22:00:52Z", "text": "Does it make sense to put that widget in a stack below the content of login page, this way it is not going to be visible to the user, but is Fluttter going to send that widget to GPU to create shader since it is not visible(it is in stack below some other content)?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2129", "user": "dnfield", "root": "ROOT21", "reply_to": "COM2128", "timestamp": "2021-02-11T22:02:02Z", "text": "I think you'd probably want to do this during a splash screen or at least during some other idle time in the app. Exactly when is hard to say. We'd want to see that such a method is workable too though  first :)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT22", "user": "chrisrlong", "root": "ROOT22", "reply_to": null, "timestamp": "2016-12-01T12:06:29Z", "text": "depends_on cannot be used in a module Hi there,\r \r \r ### Terraform Version\r 0.8.0 rc1+\r \r ### Affected Resource(s)\r module\r \r \r ### Terraform Configuration Files\r ```hcl\r module \"legacy_site\" {\r   source = \"../../../../../modules/site\"\r   name = \"foo-site\"\r   health_check_target = \"TCP:443\"\r   azs = \"${var.azs}\"\r   instance_count = \"${var.instance_count}\"\r   vpc = \"apps\"\r   region = \"${var.region}\"\r   environment = \"${var.environment}\"\r   run_list = \"hs_site_foo\"\r \r   #rds_complete = \"${module.rds.db_instance_id}\"\r   #elasticache_cache_complete = \"${module.elasticache_cache.elasticache_id}\"\r   #elasticache_sessions_complete = \"${module.elasticache_sessions.elasticache_id}\"\r \r   depends_on = [\r   \"module.rds\",\r   \"module.elasticache_sessions\"\r   ]\r \r }\r ```\r \r ### Debug Output\r Error loading Terraform: module root: module legacy_site: depends_on is not a valid parameter\r module root: module legacy_site: depends_on is not a valid parameter\r \r ### Expected Behavior\r I am trying to use the new depends_on instead of the above outputs, so I create and provision my app once I know database and caches are built.\r \r ### Actual Behavior\r Nothing as terraform errors out as above.\r \r ### Steps to Reproduce\r \r 1. `terraform apply`\r \r ### References\r depends_on can reference modules. This allows a resource or output to depend on everything within a module. (#10076)\r ", "meta": {"posReactions": "339", "negReactions": "0"}}
{"id": "COM220", "user": "stack72", "root": "ROOT22", "reply_to": "ROOT22", "timestamp": "2016-12-01T12:10:37Z", "text": "Hi @chrisrlong \r\n\r\nThis is very strange - we introduced depends_on for modules in 0.8.0-beta2\r\n\r\ncan you run terraform version and post the output here for me?\r\n\r\nPaul", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM221", "user": "chrisrlong", "root": "ROOT22", "reply_to": "COM220", "timestamp": "2016-12-01T13:24:05Z", "text": "Hi @stack72,\r\n\r\nI have complied master from version b15b8bd (Terraform v0.8.0-dev (b15b8bd99aae33c5b68cbecf5aef375c0798147c+CHANGES)), which should include beta2 features. (I did this to get 10337  and 10338 fixes)\r\n\r\nIt seems it would work if you set a resource to depend on a module, but you cannot set a module to depend_on another module......\r\n\r\nThanks for the great tool btw ;)\r\n\r\nChris\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM222", "user": "stack72", "root": "ROOT22", "reply_to": "COM221", "timestamp": "2016-12-01T13:35:08Z", "text": "Hi @chrisrlong \r\n\r\nthanks for getting back to me - you are indeed correct - modules cannot (currently) depend_on other modules but can depend on a resource only\r\n\r\nWill change the tag on this from bug to enhancement :)\r\n\r\nKeep an eye out for it soon \u2122\ufe0f \r\n\r\nThanks\r\n\r\nPaul", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM223", "user": "mitchellh", "root": "ROOT22", "reply_to": "COM222", "timestamp": "2016-12-01T13:42:28Z", "text": "Retagging as enhancement, since this isn't broken functionality, its functionality that doesn't exist yet. :) ", "meta": {"posReactions": "19", "negReactions": "0"}}
{"id": "COM224", "user": "sheerun", "root": "ROOT22", "reply_to": "COM223", "timestamp": "2017-01-03T13:49:22Z", "text": "My use case: the slave virtual machine depends on master virtual machine to exist", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM225", "user": "shantanugadgil", "root": "ROOT22", "reply_to": "COM224", "timestamp": "2017-01-07T22:10:25Z", "text": "I am seeing the same error:\r\n`module root: module example: depends_on is not a valid parameter`\r\n\r\nMy Terraform version is:\r\nTerraform v0.8.2\r\n\r\nMy use case is that I want a module to depend on a resource.", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM226", "user": "arehmandev", "root": "ROOT22", "reply_to": "COM225", "timestamp": "2017-01-09T01:54:54Z", "text": "Error loading Terraform: module root: module etcdbastion: depends_on is not a valid parameter.\r\n^ Seeing it here too", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM227", "user": "cemo", "root": "ROOT22", "reply_to": "COM226", "timestamp": "2017-01-10T21:22:10Z", "text": "@mitchellh I believe this one can solve unnested modules problem too. There were some issues regarding this #10883 before. This solution would be intuitive and address these issues. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM228", "user": "vladimir-kozyrev", "root": "ROOT22", "reply_to": "COM227", "timestamp": "2017-02-14T14:47:28Z", "text": "Waiting for this feature to be added :+1: ", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM229", "user": "prog893", "root": "ROOT22", "reply_to": "COM228", "timestamp": "2017-02-23T08:35:01Z", "text": "+1", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2210", "user": "avatar4d", "root": "ROOT22", "reply_to": "COM229", "timestamp": "2017-02-23T19:14:21Z", "text": "+1", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2211", "user": "panmanphil", "root": "ROOT22", "reply_to": "COM2210", "timestamp": "2017-02-23T19:16:41Z", "text": "+1 This would really help modularizing our code\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2212", "user": "shoelessrob", "root": "ROOT22", "reply_to": "COM2211", "timestamp": "2017-02-23T19:35:21Z", "text": "+1", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2213", "user": "mschenck", "root": "ROOT22", "reply_to": "COM2212", "timestamp": "2017-02-23T19:40:47Z", "text": "+1", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2214", "user": "cpanayides", "root": "ROOT22", "reply_to": "COM2213", "timestamp": "2017-02-24T20:23:34Z", "text": "+1", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2215", "user": "derBroBro", "root": "ROOT22", "reply_to": "COM2214", "timestamp": "2017-02-25T11:33:35Z", "text": "+1", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM2216", "user": "waffleshop", "root": "ROOT22", "reply_to": "COM2215", "timestamp": "2017-02-28T16:48:52Z", "text": "+1", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM2217", "user": "laiph", "root": "ROOT22", "reply_to": "COM2216", "timestamp": "2017-03-02T18:25:03Z", "text": "+1", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM2218", "user": "mqasim1983", "root": "ROOT22", "reply_to": "COM2217", "timestamp": "2017-03-07T16:55:41Z", "text": "+1", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2219", "user": "seyeda", "root": "ROOT22", "reply_to": "COM2218", "timestamp": "2017-03-07T22:14:42Z", "text": "+1", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2220", "user": "AirbornePorcine", "root": "ROOT22", "reply_to": "COM2219", "timestamp": "2017-03-10T17:28:36Z", "text": "Anyone have a good workaround for this in the meantime?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2221", "user": "jacobwgillespie", "root": "ROOT22", "reply_to": "COM2220", "timestamp": "2017-03-10T17:35:55Z", "text": "My pseudo workaround is to add a list variable inside the module:\r\n\r\n```hcl\r\nvariable \"depends_on\" { default = [], type = \"list\" }\r\n```\r\n\r\nThen when using the module, pass it a computed value from the resource I want it to depend on:\r\n\r\n```hcl\r\nmodule \"something\" {\r\n  depends_on = [\"${aws_instance.instance.private_ip}\"]\r\n}\r\n```\r\n\r\n", "meta": {"posReactions": "13", "negReactions": "9"}}
{"id": "COM2222", "user": "AirbornePorcine", "root": "ROOT22", "reply_to": "COM2221", "timestamp": "2017-03-10T18:17:30Z", "text": "Thanks, that doesn't entirely fit what I think this issue is talking about though - making a module able to depend on another one. I don't have any resources that the module should depend on - it should depend on another module being created.\r\n\r\nI've tried doing stuff like this:\r\nmodule 1:\r\n```\r\noutput \"wait_for_cluster\" { value = \"ref to a resource that gets created last by this module\" }\r\n```\r\n\r\nmodule 2:\r\n```\r\nvariable \"wait_for_cluster\" {}\r\n```\r\n\r\nMain terraform template:\r\n```\r\nmodule \"1\" {\r\n\r\n}\r\n\r\nmodule \"2\" {\r\n wait_for_cluster = \"${module.1.wait_for_cluster}\"\r\n}\r\n```\r\n\r\nBut this doesn't do anything - my module two is still created at basically the same time as module 1.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2223", "user": "b-dean", "root": "ROOT22", "reply_to": "COM2222", "timestamp": "2017-03-10T18:45:43Z", "text": "@AirbornePorcine In your second module you need to actually use the wait_for_cluster variable somewhere that establishes a dependency. Such as in a template or a trigger on a `null_resource`, etc.\r\n\r\nSee https://github.com/hashicorp/terraform/issues/1178#issuecomment-207369534 from @kristjanelias\r\n\r\nThe only change I'd make to his workaround is to maybe make the dummy dependency resource use a trigger so it changes when the instance changes.\r\n\r\n```hcl\r\nresource \"null_resource\" \"dummy_dependency\" {\r\n  triggers {\r\n    dependency_id = \"${aws_instance.instance.id}\"\r\n  }\r\n}\r\n```", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM2224", "user": "AirbornePorcine", "root": "ROOT22", "reply_to": "COM2223", "timestamp": "2017-03-10T20:59:08Z", "text": "Ah, that makes sense! Should have known that Terraform would optimize away my variable if I didn't use it. :) I tried out your suggestion with the trigger and that didn't do it, but setting the depends_id on a tag on some resource in module 2 seems to have done it. Hacky but oh well I guess.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2225", "user": "eedwardsdisco", "root": "ROOT22", "reply_to": "COM2224", "timestamp": "2017-03-16T05:00:59Z", "text": "@stack72 \r\n\r\nOn 0.9.0\r\n\r\nStill getting \"depends_on is not a valid parameter\" when used within a module definition. I see a lot of +1s asking to be able to depend on another module itself, but the feature that's supposed to work (depend on a module's resource), is broken.\r\n\r\nThis is biting me HARD because of the big warning at the top of the [ecs service page](https://www.terraform.io/docs/providers/aws/r/ecs_service.html) which describes needing to use depends_on to prevent a race condition. Due to this bug, **you cannot prevent it**.", "meta": {"posReactions": "29", "negReactions": "0"}}
{"id": "COM2226", "user": "sbatchu0108", "root": "ROOT22", "reply_to": "COM2225", "timestamp": "2017-03-27T20:11:51Z", "text": "+1\r\n", "meta": {"posReactions": "0", "negReactions": "3"}}
{"id": "COM2227", "user": "awebneck", "root": "ROOT22", "reply_to": "COM2226", "timestamp": "2017-03-29T13:58:04Z", "text": "+1", "meta": {"posReactions": "0", "negReactions": "5"}}
{"id": "COM2228", "user": "artrunde", "root": "ROOT22", "reply_to": "COM2227", "timestamp": "2017-04-02T18:24:46Z", "text": "+1", "meta": {"posReactions": "0", "negReactions": "5"}}
{"id": "COM2229", "user": "Wenzil", "root": "ROOT22", "reply_to": "COM2228", "timestamp": "2017-04-19T16:59:37Z", "text": "+1", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT23", "user": "christhomas", "root": "ROOT23", "reply_to": null, "timestamp": "2019-04-20T12:58:13Z", "text": "encrypt is decrypting wrong I'm trying to use encrypted variables and I've followed the encrypted vars page on travis-ci.com as well as various blogs and I always seem to get the wrong export values.\r \r I tried to do the following (I'm already logged in):\r ```\r travis encrypt DOCKERHUB_USERNAME=\"xxxxxx\"\r ```\r \r It gave me a piece of text like:\r \r ```\r secure: \"<really long string>\"\r ```\r \r So I copied it into the .travis-ci.yml like this:\r \r ```\r env:\r   global:\r     - secure: \"<really long string>\"\r ```\r \r then in the build log I see something like this:\r ```\r Setting environment variables from .travis.yml\r $ export ppfBdhkSGyo0sky15G4PwHch7PCI=[secure]\r ```\r \r I've also just now found a blog which gave the idea that I should wrap the entire X=Y into a single quoted string, like this:\r ```\r travis encrypt 'DOCKERHUB_USERNAME=\"xxxx\"'\r ```\r \r But that also doesn't work. So how is this supposed to work? What exactly am I doing wrong here?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM230", "user": "close-issue-app[bot]", "root": "ROOT23", "reply_to": "ROOT23", "timestamp": "2019-04-20T12:58:14Z", "text": "Please post on https://travis-ci.community instead. Thank you!", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM231", "user": "christhomas", "root": "ROOT23", "reply_to": "COM230", "timestamp": "2019-04-20T13:16:29Z", "text": "Why would I post this on the community site? I'm experiencing this problem on the travis-ci.com website??", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM232", "user": "cotsog", "root": "ROOT23", "reply_to": "COM231", "timestamp": "2019-04-20T18:16:00Z", "text": "@christhomas The community site is where we are moving conversations about problems happening on travis-ci.com or travis-ci.org. Thanks in advance for posting your questions over there.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT24", "user": "ChuckJonas", "root": "ROOT24", "reply_to": null, "timestamp": "2016-11-08T15:24:00Z", "text": "API Access to \"Open Editors\" I have a use case where I would like to be able to get a list of all the open editors (basically exactly what is shown here).  \r \r <img width=\"222\" alt=\"loginstructions_ts_-_vs-apex-debug\" src=\"https://cloud.githubusercontent.com/assets/5217568/20104763/68b379fa-a58c-11e6-8f48-185e5ae47060.png\">\r \r I understand that Editors are disposed but I just need a list of filenames.\r \r Something like: `workspace.openDocuments:Array<TextDocument>` or even just `workspace.openFiles:Array<string>`.\r \r Long term, it might be nice to have API access to operate on this list (EG: sort open editors pane by last opened, name, etc).\r \r \r ", "meta": {"posReactions": "316", "negReactions": "0"}}
{"id": "COM240", "user": "ChuckJonas", "root": "ROOT24", "reply_to": "ROOT24", "timestamp": "2016-12-09T19:42:03Z", "text": "Also, just wanted to add that this is blocking our vscode Salesforce IDE extension ([mavensmate](https://marketplace.visualstudio.com/items?itemName=DavidHelmer.mavensmate)) from reaching feature parity with Sublime and Atom (and thus increasing the risk of it being abandoned by users).  \r\n\r\nBackground:  Salesforce requires that classes be compiled on their servers.  In order to refactor multiple classes, you must send a single compilation request with all classes.  Because compilation is slow, you typically only want to compile a subset of your project (IE only files related to a refactor).  \r\n\r\nThe way existing salesforce IDE's handle this, is by allowing users to compile all open tabs.  ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM241", "user": "eamodio", "root": "ROOT24", "reply_to": "COM240", "timestamp": "2017-02-28T15:36:54Z", "text": "@ChuckJonas I don't know if this is still blocking you, but I've used a [hack here](https://github.com/eamodio/vscode-restore-editors/blob/master/src/documentManager.ts#L57) that might work for your depending on your use-case. You can see it in action in the [Restore Editors](https://marketplace.visualstudio.com/items?itemName=eamodio.restore-editors) extension.", "meta": {"posReactions": "11", "negReactions": "0"}}
{"id": "COM242", "user": "ChuckJonas", "root": "ROOT24", "reply_to": "COM241", "timestamp": "2017-02-28T22:11:30Z", "text": "@eamodio ahhh very nice! Never would have thought to use the `workbench.action.nextEditor` cmd to loop through all the editors.\r\n\r\nStill seems like sort of a ridiculous hack for something that should obviously be accessible in the API.", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM243", "user": "eamodio", "root": "ROOT24", "reply_to": "COM242", "timestamp": "2017-02-28T22:43:18Z", "text": "@ChuckJonas totally agree, but it was the best I could figure out with the tools available ;)", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM244", "user": "jrieken", "root": "ROOT24", "reply_to": "COM243", "timestamp": "2017-03-24T11:00:47Z", "text": "fyi @dbaeumer ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM245", "user": "lukebatchelor", "root": "ROOT24", "reply_to": "COM244", "timestamp": "2017-04-28T09:58:05Z", "text": "Cheers @eamodio, using your work around for something I'm working on too! \r\n\r\nAlso noticed I had to copy the way you wait in between executing commands because sometimes the activeEditor wont be set yet? Is that a separate issue worth reporting do you think?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM246", "user": "eamodio", "root": "ROOT24", "reply_to": "COM245", "timestamp": "2017-04-28T16:58:48Z", "text": "@lukebatchelor getting an active editor of `undefined` is to be expected at this point. It gets set to `undefined` if there are really no editors, but also if the focus switches to a non-editor window", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM247", "user": "lukebatchelor", "root": "ROOT24", "reply_to": "COM246", "timestamp": "2017-04-28T22:46:31Z", "text": "@eamodio, Im not getting undefined in these cases, but sometimes the same editor. \r\n\r\nI assumed that was why have the 500ms pauses in your code?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM248", "user": "eamodio", "root": "ROOT24", "reply_to": "COM247", "timestamp": "2017-04-29T05:08:51Z", "text": "@lukebatchelor sort of -- the timeout is because while the `workbench.action.nextEditor` will move to the next tab, if you have 2 non-text editors next to each other, the active editor becomes `undefined` when it switches to the first (and the active editor changed event will fire), but now when it switches to the next, it will still be `undefined`, but no event will fire, because it went from `undefined` to `undefined` -- so the timeout is a safety net for the event not firing", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM249", "user": "lukebatchelor", "root": "ROOT24", "reply_to": "COM248", "timestamp": "2017-04-29T06:52:09Z", "text": "Oh okay. Thats different to what i was getting. \r\n\r\nI'll try again but i was executing closeActiveEditor then logging the active editors document uri and would sometimes be the same still, until i added the pause. Same with nexrEditor. \r\n\r\nWeird.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2410", "user": "loligans", "root": "ROOT24", "reply_to": "COM249", "timestamp": "2017-05-19T22:47:24Z", "text": "This would be really nice to have! \r\n\r\nI am working on an extension that takes **encrypted** files and **decrypts** them. The problem is I need the **encrypted file path** so that I can decrypt the file.\r\n\r\nvscode doesn't let you access the file uri of a binary file because the active editor is undefined.\r\n\r\nAlternatively it would be cool to allow the user to choose what encoding to display binary files. I would think the default would be UTF-8.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM2411", "user": "jrieken", "root": "ROOT24", "reply_to": "COM2410", "timestamp": "2017-05-28T09:29:58Z", "text": "#11247 is about making the tab-model not only readable but also writeable, e.g. open a background-tab which we must consider when implementing this", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2412", "user": "eamodio", "root": "ROOT24", "reply_to": "COM2411", "timestamp": "2017-09-08T19:10:04Z", "text": "FYI there is some further conversion about this here: https://github.com/Microsoft/vscode/issues/26568#issuecomment-322384117\r\n\r\n@jrieken any thoughts on that? It doesn't address the need of an API for a lot of other use-cases, but it could provide a nice shortcut for a (decent?) set of scenarios.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2413", "user": "Gruntfuggly", "root": "ROOT24", "reply_to": "COM2412", "timestamp": "2018-03-23T15:12:20Z", "text": "Is there any progress or plan for this functionality? It feels really odd that there is still no way for an extension to be able to simply get a list of the currently opened files (even if they are not loaded).", "meta": {"posReactions": "16", "negReactions": "0"}}
{"id": "COM2414", "user": "DanTup", "root": "ROOT24", "reply_to": "COM2413", "timestamp": "2018-04-03T13:45:12Z", "text": "I'm hitting this too. I need to provide my language service with a list of \"priority files\" and I was sending what I believed to be:\r\n\r\n1. Visible documents\r\n2. Other open (non-visible) documents\r\n\r\nHowever I've discovered that my means for getting open (non-visible) documents (workspace.textDocuments) is flawed and contains documents that had their editors closed, but the documents are still \"open\" according to Code.\r\n\r\nThis means I'm unable to write tests to ensure that my priority files are working correctly, as I have no way of telling which files a user actually has open (but not visible).", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM2415", "user": "jpoon", "root": "ROOT24", "reply_to": "COM2414", "timestamp": "2018-06-27T12:16:43Z", "text": "We need this for VSCodeVim as well. Our use case is explained here: https://github.com/Microsoft/vscode/issues/51001#issuecomment-397177893", "meta": {"posReactions": "30", "negReactions": "0"}}
{"id": "COM2416", "user": "c10b10", "root": "ROOT24", "reply_to": "COM2415", "timestamp": "2018-07-06T10:28:19Z", "text": "Is this planned any time soon? The vim issue is pretty annoying.", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM2417", "user": "kylesalter", "root": "ROOT24", "reply_to": "COM2416", "timestamp": "2018-08-23T20:07:16Z", "text": "@c10b10 Hopefully thumbs up attract more attention to this issue. For non-vim users, we cannot effectively edit the same file opened in two different editor groups (e.g. split one file vertically and view/edit different parts in each pane)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2418", "user": "Divni", "root": "ROOT24", "reply_to": "COM2417", "timestamp": "2018-09-21T22:57:08Z", "text": "+many. The API feels needlessly restrictive. What's the downside for MS to make this available for extension developers? I can't think of one.\r\n\r\nMuch as I like vscode the API could really use some love. Not to sound unappreciative, but the quality of extensions has so much potential if only the API would open up a bit more.", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM2419", "user": "Samox", "root": "ROOT24", "reply_to": "COM2418", "timestamp": "2018-10-24T21:42:29Z", "text": "+1 ! Needed for a personal extension that keeps me from opening too many files :0", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2420", "user": "Gruntfuggly", "root": "ROOT24", "reply_to": "COM2419", "timestamp": "2018-11-24T16:51:09Z", "text": "@jrieken  Is there any update on this? The tab model issue (that I was pinning my hopes on) has been closed...\r\n\r\nThis issue has been open for over 2 years?\r\n", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM2421", "user": "KamasamaK", "root": "ROOT24", "reply_to": "COM2420", "timestamp": "2018-11-24T18:03:11Z", "text": "As the [fifth highest voted open issue for the API](https://github.com/Microsoft/vscode/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3Aapi), I hope to see this in the VS Code Roadmap 2019 as the final release of 2018 wraps up in the few weeks.", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM2422", "user": "Yzrsah", "root": "ROOT24", "reply_to": "COM2421", "timestamp": "2018-12-04T09:05:30Z", "text": "I've encountered a bunch of extensions that are broken or work poorly due to this specific issue.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM2423", "user": "lukebatchelor", "root": "ROOT24", "reply_to": "COM2422", "timestamp": "2018-12-04T10:33:32Z", "text": "Haha. Funny you linked that, my comments above were for when I was making that add-on :P\r\n\r\nYou'll be pleased to know that \"close all saved\" is actually built into VSCode now (thanks to @soneymathew)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2424", "user": "mabenson00", "root": "ROOT24", "reply_to": "COM2423", "timestamp": "2019-03-05T22:06:11Z", "text": "it'd be cool to be able to switch between tabs in your workspace on a branch switch.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2425", "user": "PiotrKarczmarz", "root": "ROOT24", "reply_to": "COM2424", "timestamp": "2019-03-06T09:04:21Z", "text": "> \r\n> \r\n> it'd be cool to be able to switch between tabs in your workspace on a branch switch.\r\n\r\nThis workflow any many others will be supported in the extension that I'm building for VS and VS Code - [http://contextkeeper.io](http://contextkeeper.io/?ref=DC8)\r\n\r\nI want to cover all aspects of \"dev context\" that is created when working at specific PR/task/feature/bug. There is often a need to switch to something else and there is no easy way to turn back and restore lost context. Moreover there will be a way to save and share your contexts with entire team because they will be saved as diffable files (aka mental snapshots). Ready to commit in git. Stay tuned!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2426", "user": "noppa", "root": "ROOT24", "reply_to": "COM2425", "timestamp": "2019-03-06T13:00:32Z", "text": "@PiotrKarczmarz \r\n> extension that I'm building for VS and **VS Code**\r\n\r\nBut how? How do you get the open editors when there's no API for it (hence this issue)?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2427", "user": "PiotrKarczmarz", "root": "ROOT24", "reply_to": "COM2426", "timestamp": "2019-03-07T10:24:01Z", "text": "> \r\n> \r\n> @PiotrKarczmarz\r\n> \r\n> > extension that I'm building for VS and **VS Code**\r\n> \r\n> But how? How do you get the open editors when there's no API for it (hence this issue)?\r\n\r\n@noppa good question. When there is no official API it will be harder to implement but I believe possible. In the second comment @eamodio mentioned hack that his Restore Editors is using. When you will dig long enough sometimes you find a way.\r\n\r\nVisual Studio also doesn't have any explicit API for its internal engine that restores last opened windows and tabs. It has .suo file when it stores them but it's like black box. You could save or restore certain windows state but you have no control how it will be done at window/tab level. Because VS's last opened files engine has many flaws I wrote independent engine that ContextKeeper is using to position VS's windows and restore tabs. It works very well and allows a whole range of possibilities like opening the same mental snapshot when you switch from your desktop box to laptop without manual windows repositioning - it's detects current resolutions of connected monitors and prepare appropriate layout where all windows fit nicely to new environment. The ContextKeeper's engine allows to save mental snapshots to human-friendly diffable files so you could not only switch between different contexts easily but also track what was changed in them via git. Sharing contexts with a team opens another range of possibilities.\r\n\r\nNothing above would be possible when I would give up and tried to use broken and limited \".suo\" API. It took a lot of time but I found a way and created \"alternative\" API.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2428", "user": "Gruntfuggly", "root": "ROOT24", "reply_to": "COM2427", "timestamp": "2019-03-07T11:07:50Z", "text": "For vscode, it sounds like you'll end up hacking the application code rather than building an extension then, which is a shame. On your website it says you have a commit ready for git - I assume that's for Visual Studio and not vscode?\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2429", "user": "PiotrKarczmarz", "root": "ROOT24", "reply_to": "COM2428", "timestamp": "2019-03-07T13:38:36Z", "text": "> \r\n> \r\n> For vscode, it ounds like you'll end up hacking the application code rather than building an extension then, which is a shame. On your website it says you have a commit ready for git - I assume that's for Visual Studio and not vscode?\r\n\r\n@Gruntfuggly ContextKeeper will be pure extension for both VS Code and VS. I know that are limitations. Some of them discussed in this thread but also others like no support for floating windows in VS Code  #10121 which were always supported in VS. Workaround will be to use grid layout #14909 when you will try to open context from VS in VS Code to simulate the same windows and tabs layout (yes, opening the same context in both VS and VS Code will be possible!). I want to deliver similar experience for both VS and VS Code but knowing the limitations. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT25", "user": "CitrusWire", "root": "ROOT25", "reply_to": null, "timestamp": "2021-01-04T22:57:31Z", "text": "Inconsistent type styling in Godot editor **Godot version:**\r 3.2.3\r \r \r **Issue description:**\r The types: `int`, `bool`, and `float` are all styled as keywords rather than types in the editor:\r \r ![image](https://user-images.githubusercontent.com/72134064/103586104-4a39b680-4edc-11eb-9584-626a581d42f0.png)\r \r This introduces confusion to new users.\r \r I'd also suggest int, bool, and float should be capitalised to be consistent with the rest of the types. One of the reasons that PHP has such a poor reputation in many circles is because of its lack of consistency. For example its naming of `substr` or `str_replace` and countless other string functions.\r \r Edit: `enum` type too?", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM250", "user": "YuriSizov", "root": "ROOT25", "reply_to": "ROOT25", "timestamp": "2021-01-04T23:39:15Z", "text": "> I'd also suggest int, bool, and float should be capitalised to be consistent with the rest of the types. One of the reasons that PHP has such a poor reputation in many circles is because of its lack of consistency.\r\n\r\nThis has nothing to do with consistency and not the same as PHP's problems. Primitive types are not capitalized in most C-like languages, while classes can be capitalized as per individual style guide. If anything, `Array` and especially `String` being capitalized is inconsistent. But I guess this is borrowed from the engines C++ core.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM251", "user": "akien-mga", "root": "ROOT25", "reply_to": "COM250", "timestamp": "2021-01-05T07:14:48Z", "text": "int, float and bool are plain old data types (*Edit:* primitive types is more correct, POD types is a wider and potentially more confusing concept). Array and String are templates, which are not trivial. So it makes sense for templated types to be capitalized like other non trivial types (e.g. Object).", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM252", "user": "CitrusWire", "root": "ROOT25", "reply_to": "COM251", "timestamp": "2021-01-05T11:40:04Z", "text": "I would ask you both: from the end user's perspective do they care whether something is a primitive type or a class type? That seems like an academic difference that's only pertinent to the engine devs, not to the vast majority of game developers.\r\n\r\nIn python behind the scenes everything is a Class, but to the users they see types, classes, even functions. The built-in types are all consistently lower-case (str, dict, tuple...) with the exception of `None` which is also a special value (as `True / False`).\r\n\r\nIt's hard to understate the value of consistency for a developer.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM253", "user": "akien-mga", "root": "ROOT25", "reply_to": "COM252", "timestamp": "2021-01-05T11:47:50Z", "text": "It's not a matter of engine devs, it's very common in most programming languages that primitive types are identified as such with their case, as they typically have properties which different from non-primitive types (passing by value vs reference, copy/clone, etc.).\r\n\r\nFor example, C# uses `PascalCase` for classes but its primitive types `bool`, `float`, `int` are lowercase.\r\n\r\nAnother example: Rust primitive data types are lowercase: https://learning-rust.github.io/docs/a8.primitive_data_types.html\r\nBut it's non-primitive data types (e.g. structs, enums) are PascalCase.\r\nIn Godot, types like Vector3 or Color are not primitive data types (they're collections of primitive data types, here `float`) and in a language like Rust, they'd typically be represented by structs (in C++ they're classes).\r\n\r\nThere's no *in*consistency here, this is on purpose, and this has not been a problem in the past 6 years for Godot users, whether experienced or beginners.", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM254", "user": "YuriSizov", "root": "ROOT25", "reply_to": "COM253", "timestamp": "2021-01-05T12:05:01Z", "text": "I second Akien about capitalization, but I want to remind everyone that the first part of this issue is about syntax highlight \ud83d\ude42 \r\n\r\nSo to address that... Of the top of my head I cannot remember if any other language in any other editor highlighted primitive types the same as keywords or not, but this can probably be arranged anyway on our end. We can make a color for primitives a separate setting and let users decide if they want it to be the same as keywords, as classes, or have a unique color all together.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM255", "user": "CitrusWire", "root": "ROOT25", "reply_to": "COM254", "timestamp": "2021-01-05T13:48:02Z", "text": "@akien-mga - I see your C#/Rust examples, but isn't Godot meant to be Python like?\r\n\r\n> as they typically have properties which different from non-primitive types (passing by value vs reference, copy/clone, etc.).\r\n\r\nIs this distinction a thing in Godot? As far as I can see the Class types are a mixture of Reference (i.e. Array) and Value (i.e. PoolStringArray).\r\n\r\nAs a end-user why do I care about whether something is primitive or classed? I can't see much of any difference, and if there is a different I'd suggest it should be explicitly documented in the docs rather than hoping the dev intuits it from capitalisation.\r\n\r\n> Of the top of my head I cannot remember if any other language in any other editor highlighted primitive types the same as keywords or not\r\n\r\nPyCharm groups all built-ins which includes types (`str`) and functions(`len()`); they're distinct from keywords.\r\nI prefer Godot's way in that regard in that types get their own style.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM256", "user": "dalexeev", "root": "ROOT25", "reply_to": "COM255", "timestamp": "2021-01-05T16:41:42Z", "text": "> I'd also suggest int, bool, and float should be capitalised to be consistent with the rest of the types.\r\n\r\nI've already [suggested](https://github.com/godotengine/godot/issues/16863#issuecomment-684058966). Also, it would solve the first problem **automatically**.\r\n\r\n> There's no _in_consistency here\r\n\r\nNo, there **is** inconsistency with the following naming conventions:\r\n\r\n```gdscript\r\nvar name: Name\r\nfunc name(name: Name) -> Name\r\nname is Name\r\nname as Name\r\n```\r\n\r\nAll types _except_ these three have a capitalized name. Any _exception_ is inconsistency. The only question is whether there are any advantages to having the exception.\r\n\r\n> this has not been a problem in the past 6 years for Godot users, whether experienced or beginners\r\n\r\nThis is only because this inconsistency affects only appearance, but not behavior. Just like the fact that these types are highlighted in a different color than the rest.\r\n\r\n> We can make a color for primitives a separate setting and let users decide if they want it to be the same as keywords, as classes, or have a unique color all together.\r\n\r\nSorry, but in my opinion this is useless. All types should be highlighted with the same color. Otherwise it will be too colorful: primitive types - in one color, built-in types - in another, classes - in a third, custom classes - in the fourth, 2D types - in the fifth, 3D types - in the sixth, etc.\r\n\r\n> I would ask you both: from the end user's perspective do they care whether something is a primitive type or a class type?\r\n\r\nAbsolutely agree. What does knowing whether the type is primitive or not? What is the difference between a primitive type and a non-primitive type? I could understand if types passed by value were written with a small letter, and types passed by reference with a capital letter. Or built-in types with small, and classes with capital. The only reason these three types are written with small letters is tradition, habit, and blind copying of C/C ++.\r\n\r\n> it's very common in most programming languages\r\n\r\nYes, you are right, it is, although it is absolutely pointless.\r\n\r\nBut in some languages (Kotlin, Haxe, Ada, etc) all types (even \"primitive\" ones) start with a capital letter, and this warms my perfectionist soul.\r\n\r\nBut since it does not affect behavior, this is not a change I would fight for. It's just a little annoying that people think in such fictitious categories as \u201cprimitive\u201d types. In comparison, the illogical and counter-intuitive behavior of the division operator creates much bigger problems, but people don't want to notice them and react extremely negatively due to the strength of their habits.\r\n", "meta": {"posReactions": "1", "negReactions": "1"}}
{"id": "COM257", "user": "dalexeev", "root": "ROOT25", "reply_to": "COM256", "timestamp": "2021-01-05T16:59:32Z", "text": "> primitive types are identified as such with their case, as they typically have properties which different from non-primitive types (passing by value vs reference, copy/clone, etc\r\n\r\nIn this regard, in GDScript `bool`/`int`/`float` behave exactly like `String`, `Vector2`, `Packed*Array` and most other types, i.e. passed by value. Only `Array`, `Dictionary` and `Object` are passed by reference.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM258", "user": "YuriSizov", "root": "ROOT25", "reply_to": "COM257", "timestamp": "2021-01-05T17:02:23Z", "text": "> Also, it would solve the first problem automatically.\r\n\r\nNo, it wouldn't. The way GDScript tokenizer works in terms of syntax highlight has nothing to do with the capitalization.\r\n\r\n> Sorry, but in my opinion this is useless. All types should be highlighted with the same color. Otherwise it will be too colorful: primitive types - in one color, built-in types - in another, classes - in a third, custom classes - in the fourth, 2D types - in the fifth, 3D types - in the sixth, etc.\r\n\r\nThis is not what was suggested. I only propose we solve the problem presented here with a separate option for primitive types. By default, it would be the same color as keywords, as it is now, but whoever would like to highlight them differently, be it matching the color of classes or another color, would be able to do so. In the end, it will be as colorful as each individual user wants, which is fitting, as this issue is about individual user's preferences.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM259", "user": "akien-mga", "root": "ROOT25", "reply_to": "COM258", "timestamp": "2021-01-05T17:14:16Z", "text": "Again, there's two things in this issue:\r\n\r\n- The original report that primitive types are wrongly colored. That's a bug and I'm not even sure why it warrants discussion, they should be colored like any other type. PR welcome, that's likely easy to fix.\r\n\r\n- Renaming primitive types to `Int`, `Bool`, `Float` -> https://github.com/godotengine/godot-proposals\r\nI'm not interested in discussing this further here for the sake of perfectionism.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM2510", "user": "dalexeev", "root": "ROOT25", "reply_to": "COM259", "timestamp": "2021-01-05T17:53:10Z", "text": "> No, it wouldn't. The way GDScript tokenizer works in terms of syntax highlight has nothing to do with the capitalization.\r\n\r\nAs far as I know, the problem is not in the tokenizer, but in the mechanism for highlighting the code of the `TextEdit` class. It's just that `int` is highlighted like a built-in python-like function (like `len` and `str`) and this overrides the type highlighting. If we split it into `int` (function) and `Int` (type), then the problem will be solved automatically.\r\n\r\nThere are no `bool()`, `int()`, `float()` functions on the @GDScript documentation page (although they are highlighted as built-in functions), in fact they are built-in type constructors like `String()` and `Vector2()`. It's funny that there is no difference between `str()` and `String()`, apparently `str()` was created to make GDScript look more like Python.\r\n\r\nThis is just a note, actually the problem is broader, for example `load` is always highlighted in red, even in `func load()` and `self.load`.\r\n\r\n> This is not what was suggested. I only propose we solve the problem presented here with a separate option for primitive types.\r\n\r\nDoes the user have a real need for this? Why do we need to provide the user with the ability to highlight \"primitive\" types with a different color than non-primitive ones? Maybe we need to add an option to change the color for each type? I mean, primitive types aren't that different from non-primitive types that they deserve a separate color.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2511", "user": "dalexeev", "root": "ROOT25", "reply_to": "COM2510", "timestamp": "2021-01-05T18:15:13Z", "text": "@akien-mga I respect your efforts to maintain order in discussions, but the two issues are related. I tried to count the differences between primitive types and non-primitive types and counted two differences:\r\n\r\n1. Primitive types are highlighted in a different color (recognized as a bug).\r\n2. Primitive types are written with a lowercase letter (a tradition of many C-like languages).\r\n\r\nI did not find any more differences (maybe someone will find it). Please note that both differences concern only appearance (color and case).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2512", "user": "name-here", "root": "ROOT25", "reply_to": "COM2511", "timestamp": "2021-01-05T23:43:52Z", "text": "Primitive data types have a few properties different from other data types:\r\n- They don't act like objects, and so don't have functions (things like `Vector2.normalized()`)\r\n- Faster to move around and perform operations on\r\n\r\nAlso, I was just messing around in GDScript, and it seems anything inheriting from `Object` (`Reference`, `Node`, etc.) isn't reserved, allowing you to do things like `var Control : int = 10`, which prevents you from accessing `Control` until your variable goes out of scope (can't do `Control.new()`, for example).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2513", "user": "dalexeev", "root": "ROOT25", "reply_to": "COM2512", "timestamp": "2021-01-06T00:30:52Z", "text": "@name-here These are not significant differences, just implementation details. In JavaScript, for example, you can do `1.2345.toFixed(2)`. GDScript is a high-level language, so the low-level details of C++ are not important here enough to emphasize these three types. Knowing about their primitiveness in C++ does nothing for a GDScript developer.\r\n\r\nOnce again, this is not a thing that I would fight for. I refer to it as \"It would be nice.\" I just wanted to show that \"primitive\" types are a strange tradition. But I face the objection that there are some real reasons to classify primitive types into a separate category. It surprises me.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2514", "user": "name-here", "root": "ROOT25", "reply_to": "COM2513", "timestamp": "2021-01-06T04:47:19Z", "text": "It GDScript really all that high-level?  It basically just interfaces with Godot's built-in C++ classes (a limited subset, at that), with python-like syntax and a few handy shortcuts like iterating over arrays more easily.  And since GDScript does not exist outside of Godot\u2014and never will\u2014implementation details are important, since _GDScript __is__ its implementation, nothing more_.  There is nothing outside of the implementation that dictates what GDScript is supposed to be, or how it is supposed to work (the docs are only meant to describe what it is).  This is a major difference between GDScript and \"mainstream\" languages.\r\n\r\nGDScript has a lot of ties to the C++ of the engine it interacts with\u2014those \"implementation details\" being some of them.  If Godot used semicolons and braces instead of line breaks, colons and indents, would you feel the same way about this?\r\n\r\nThe real problem, though, is that any potential benefits of a change do not outweigh the obvious costs. True, there's no reason GDScript _has_ to use \"`int`\" instead of \"`Int`\", but changing it will break every current Godot coder's code and intuition with no real benefit.  One reason it may have ended up this way is that it mirrors the names of those things in C++ (what the engine devs are seeing all day), where all the types added by the engine are PascalCase, and primitive types are all lowercase.  Since the C++ functions GDScript interacts with all use the C++ built-in `bool`, `int` and `float` types, and Godot's own `Vector2`, `Variant`, `Array`, etc. types, the current situation makes GDScript code nicely mirror the same code in C++.  This isn't very useful to those who only use GDScript, but is nice for anyone also using other languages with Godot.  So I'll have to disagree with your that \"it would be nice\" to change it.\r\n\r\nIn general, I'd say the engine's syntax highlighting (and, relatedly, which things in GDScript are reserved words) is a little strange in `3.x` (why are built-in functions like `print` and `floor` reserved?), but I just did some testing, and it seems `master` doesn't really have globally reserved words (probably because of the parser rewrite).  It does, however, still have weird highlighting if for some inexplicable reason you do `var Node` or `var int` (`Node` is highlighted green and `int` red when they should be white like other variable names).", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM2515", "user": "dalexeev", "root": "ROOT25", "reply_to": "COM2514", "timestamp": "2021-01-06T10:37:38Z", "text": "GDScript is a high-level language because there are no pointers or other low-level memory manipulations. In terms of design and syntax, GDScript is a mixture of Python, JavaScript, and C++. But some things taken from C++ don't fit well with the fact that GDScript is a language whose goal is to be simple for beginners. I disagree with the opinion that GDScript should look familiar to C++ developers.\r\n\r\nThis change is highly optional and insignificant, as most people don't care. But even if it were accepted, the old code would be easy to fix automatically, unlike some of the other recent GDScript changes.\r\n\r\nTo summarize: in GDScript, primitive types are written in lowercase **only** because they are written this way in C++. There is no other reason.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM2516", "user": "CitrusWire", "root": "ROOT25", "reply_to": "COM2515", "timestamp": "2021-01-06T11:02:36Z", "text": "@akien-mga - I disagree that there are two things here. There's two flavours of the same thing. Put simply:\r\n\r\nAre primitives a special type of Type?\r\nYes = Then different styling and capitalisation could make sense\r\nNo = Then they should be styled and capitalised the same way as other types\r\n\r\nThis is not a \"perfectionism\" thing. This is a consistency thing. It's in the same vein of why Godot has a [contributors style guide](https://docs.godotengine.org/en/stable/community/contributing/code_style_guidelines.html): Because anything that reduces the cognitive load on a developer is a good thing and consistency does that.\r\n\r\nNow personally I don't see how primitives are special to GDScript users, but @dalexeev has done a better job covering that than I did.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2517", "user": "akien-mga", "root": "ROOT25", "reply_to": "COM2516", "timestamp": "2021-01-06T13:08:49Z", "text": "> Are primitives a special type of Type?\r\nYes = Then different styling and capitalisation could make sense\r\nNo = Then they should be styled and capitalised the same way as other types\r\n\r\nFor the last time: YES, they are a \"special type of type\".\r\n\r\nI'm tired of this bikeshedding. I tried to advocate for keeping this issue focused on the actual bug that can be fixed (syntax highlighting), but you keep bringing it back to advocating for breaking compatibility in the language design as if this was the same level of implication.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT26", "user": "cjcenizal", "root": "ROOT26", "reply_to": null, "timestamp": "2019-03-27T16:49:32Z", "text": "[eslint-plugin-react-hooks] \"Rules of hooks\" considers any function beginning with \"use\" to be a React Hook **Do you want to request a *feature* or report a *bug*?**\r \r This seems like a bug.\r \r **What is the current behavior?**\r \r 1. Follow the steps for adding the linting rules outlined on the [Rules of Hooks page](https://reactjs.org/docs/hooks-rules.html).\r 2. Create a plain JS function with a name that begins with `use`, e.g. `useFoo`. Call this function from within another plain JS function, e.g. `testFoo`.\r     ```js\r     function useFoo() {\r     }\r \r     function testFoo() {\r       useFoo();\r     }\r     ```\r 3. The linter will complain:\r      ```\r      React Hook \"useFoo\" is called in function \"testFoo\" which is neither a React function component or a custom React Hook function  react-hooks/rules-of-hooks\r      ```\r \r **What is the expected behavior?**\r \r Ideally, the rule would ignore functions that begin with `use` but are not React Hooks.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM260", "user": "infodusha", "root": "ROOT26", "reply_to": "ROOT26", "timestamp": "2019-03-27T17:37:26Z", "text": "In fact, how do you know your _useAnything_ is not a hook?\r\nIt can have nither _useEffect_ nor _useState_ and still be valid hook", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM261", "user": "cjcenizal", "root": "ROOT26", "reply_to": "COM260", "timestamp": "2019-03-27T17:49:19Z", "text": "Sorry, I'm new to hooks so I just now saw this in the [Build your own Hooks docs](https://reactjs.org/docs/hooks-custom.html#using-a-custom-hook):\r\n\r\n> **Do I have to name my custom Hooks starting with \u201cuse\u201d?** Please do. This convention is very important. Without it, we wouldn\u2019t be able to automatically check for violations of rules of Hooks because we couldn\u2019t tell if a certain function contains calls to Hooks inside of it.\r\n\r\nI suppose the other side of this coin is that you're prohibited from naming any non-Hook function with a name that begins with \"use\" (or disable the eslint rule for that function). If that's the case and there's no way around this then feel free to close this. \ud83d\ude04 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM262", "user": "gaearon", "root": "ROOT26", "reply_to": "COM261", "timestamp": "2019-03-28T01:54:46Z", "text": "Yeah it's intentional. We needed to pick a convention, and `use` was the least crowded out of descriptive short suffixes based on the JS codebases we've seen in open source and at FB. \r\n\r\nThere's always bound to be some false positives. But at that point `use` convention is already so ingrained that people would likely *expect* it to be a Hook. So it's worth disallowing it anyway to avoid extra confusion.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM263", "user": "cjcenizal", "root": "ROOT26", "reply_to": "COM262", "timestamp": "2019-03-28T02:50:51Z", "text": "Thanks @gaearon! Keep up the great work.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM264", "user": "micha149", "root": "ROOT26", "reply_to": "COM263", "timestamp": "2019-04-25T10:27:44Z", "text": "@gaearon whats up with other functions beginning with `use`? For example ramdas `useWith`\u2026  Maybe the rule should check if any of the _problematic_ functions like `useState`, `useEffect` etc. is used inside my hook, otherwise the checks can be handled differently.\r\n\r\nOtherwise something like a whitelist of functions which are not hooks might be useful as a configuration parameter. ", "meta": {"posReactions": "8", "negReactions": "0"}}
{"id": "COM265", "user": "rpearce", "root": "ROOT26", "reply_to": "COM264", "timestamp": "2019-11-13T18:09:06Z", "text": "@micha149 what are you doing to get around the issue with `useWith` from ramda? Telling eslint to ignore the line or rule for the file, entirely?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM266", "user": "micha149", "root": "ROOT26", "reply_to": "COM265", "timestamp": "2019-11-22T11:07:50Z", "text": "Hey @rpearce. Sorry for the delay, but I'm on vacation.\r\n\r\nTo be honest: I currently didn't use the entire eslint rule at the moment. But if I used it, I'd ignore the exact rule per line. For example:\r\n\r\n``` javascript\r\n// eslint-disable-next-line react-hooks/rules-of-hooks\r\nconst get = useWith(path, [split('.')]);\r\n```\r\n\r\nor\r\n\r\n```javascript\r\nconst aIncludesB = useWith( // eslint-disable-line react-hooks/rules-of-hooks\r\n    includes,\r\n    [\r\n        prop('b'),\r\n        prop('a'),\r\n    ],\r\n);\r\n```\r\n\r\nBut any automatism or at least a whitelist would be my preferred way\u2026", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM267", "user": "rpearce", "root": "ROOT26", "reply_to": "COM266", "timestamp": "2019-11-22T14:42:12Z", "text": "@micha149 Thank you for the response! We did the same, but we also limited the rules of hooks in our eslint config to only our component folders like this:\r\n```js\r\n  overrides: [\r\n    {\r\n      files: ['path/to/folder1/**/*.js', 'path/to/folder2/**/*.js'],\r\n      rules: {\r\n        'react-hooks/rules-of-hooks': 'error',\r\n      },\r\n    },\r\n  ],\r\n  rules: {\r\n    // ...\r\n    'react-hooks/rules-of-hooks': 0, // see overrides for enabled info\r\n  }\r\n```", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM268", "user": "jtiscione", "root": "ROOT26", "reply_to": "COM267", "timestamp": "2020-07-17T17:20:39Z", "text": "This is absolutely unacceptable behavior. This rule is simply assuming it owns the entire namespace of all functions beginning with \"use\", and starts screaming about unrelated functions in the rest of the project that have nothing to do with React.\r\n\r\nThis is much more atrocious than carelessly declaring variables in the global namespace! Whoever came up with this idea clearly doesn't understand why ESLint was created in the first place. There are plenty of domains where you would like to give a function a name beginning with \"use\". Not all of us are React developers and we shouldn't have to change code in unrelated parts of the application.\r\n\r\nWe're having a real problem with this because ESLint ignores the .eslintrc.json file (due to some other bug in ESLint), and it breaks the build.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM269", "user": "cjcenizal", "root": "ROOT26", "reply_to": "COM268", "timestamp": "2020-07-17T18:00:06Z", "text": "@jtiscione I understand you're upset and this rule is causing problems for you. At the same time, remember you're using open-source software. You're not paying for it and the maintainers of this tool don't owe you anything. You'll get farther along if you give yourself time to cool down before posting a complaint about OSS.\r\n\r\nWhen you do post a complaint, you'll maximize your chances of getting what you want by avoiding incendiary language like \"absolutely unacceptable\", \"screaming\", \"atrocious\", \"carelessly\", and \"doesn't understand\". I've found that it helps to clearly describe the problem I'm encountering and propose some solutions or ask questions to understand the problem space better.\r\n\r\nHow you communicate establishes your own reputation, for better or worse!", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM2610", "user": "gaearon", "root": "ROOT26", "reply_to": "COM269", "timestamp": "2020-07-17T19:08:26Z", "text": "@jtiscione \r\n\r\n>Not all of us are React developers and we shouldn't have to change code in unrelated parts of the application.\r\n\r\nI empathize with your frustration, but the solution to it is to not run React-related rules on non-React-related parts of your codebase.\r\n\r\n>We're having a real problem with this because ESLint ignores the .eslintrc.json file (due to some other bug in ESLint), and it breaks the build.\r\n\r\nThis seems like something you'd need to find a solution for.\r\n\r\nI'm going to lock this thread because this heated atmosphere is not constructive.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT27", "user": "cpatte7372", "root": "ROOT27", "reply_to": null, "timestamp": "2018-05-06T18:23:50Z", "text": "[WARNING]: Unable to parse /etc/ansible/hosts as an inventory source Hello Community,\r \r I'm very new to ansible.\r \r I'm currently running Ansible from Azure Cloud Shell.\r \r I have added a machine to the Hosts file. However, whenever I attempt to ping or connect to the machine I get the following errors:\r \r [WARNING]: Unable to parse /etc/ansible/hosts as an inventory source\r \r  [WARNING]: No inventory was parsed, only implicit localhost is available\r \r  [WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'\r \r Can someone let me know how to fix this problem please.\r \r Thanks\r \r Carlotn", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM270", "user": "ansibot", "root": "ROOT27", "reply_to": "ROOT27", "timestamp": "2018-05-06T18:31:32Z", "text": "@cpatte7372 Greetings! Thanks for taking the time to open this issue. In order for the community to handle your issue effectively, we need a bit more information. \n\nHere are the items we could not find in your description:\n- ansible version\n- component name\n\nPlease set the description of this issue with this template:\nhttps://raw.githubusercontent.com/ansible/ansible/devel/.github/ISSUE_TEMPLATE.md\n\n[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)\n<!--- boilerplate: issue_missing_data --->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM271", "user": "cpatte7372", "root": "ROOT27", "reply_to": "COM270", "timestamp": "2018-05-06T19:13:43Z", "text": "@ansibot , thanks for reaching out. \r\n\r\nSee below:\r\n\r\ncarlton@Azure:~$ ansible --version\r\nansible 2.4.3.0\r\n  config file = /home/carlton/ansible.cfg\r\n  configured module search path = [u'/home/carlton/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\r\n  ansible python module location = /opt/ansible/local/lib/python2.7/site-packages/ansible\r\n  executable location = /opt/ansible/bin/ansible\r\n  python version = 2.7.12 (default, Dec  4 2017, 14:50:18) [GCC 5.4.0 20160609]\r\n\r\nI'm not sure what you mean by 'Component Name'\r\n\r\nJust so you know, I'm open thread on stackoverflow, which I thought might fix the issue see \r\n\r\nhttps://stackoverflow.com/questions/50202849/sudo-privileges-required-in-azure-cloud-shell-to-mkdir\r\n\r\nHowever, this was just a work around to fix the underlying issue as described in this thread.\r\n\r\nThanks again, I hope you can help me fix this.\r\n\r\nCheers", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM272", "user": "yokee99", "root": "ROOT27", "reply_to": "COM271", "timestamp": "2018-05-07T07:09:06Z", "text": "I have the same problem  and  I install it by brew on Mac ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM273", "user": "cpatte7372", "root": "ROOT27", "reply_to": "COM272", "timestamp": "2018-05-07T07:15:45Z", "text": "@yokee99 , thanks for reaching out. I use a PC. Do you know the equivalent  to 'brew' in PC?\r\n\r\nCheers", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM274", "user": "bcoca", "root": "ROOT27", "reply_to": "COM273", "timestamp": "2018-05-07T14:44:04Z", "text": "List Information\r\n================\r\n\r\nHi!\r\n\r\nThanks very much for your interest in Ansible.  It sincerely means a lot to us. \r\n\r\nThis appears to be a user question, and we'd like to direct these kinds of things to either the mailing list or the IRC channel.\r\n\r\n   * IRC: #ansible on irc.freenode.net   \r\n   * mailing list: https://groups.google.com/forum/#!forum/ansible-project\r\n\r\nIf you can stop by there, we'd appreciate it.  This allows us to keep the issue tracker for bugs, pull requests, RFEs and the like.\r\n\r\nThank you once again and we look forward to seeing you on the list or IRC.  Thanks!", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM275", "user": "varshadhamal", "root": "ROOT27", "reply_to": "COM274", "timestamp": "2018-06-18T06:18:56Z", "text": "I have installed through Cygwin on windows 10. \r\n\r\nHaving same issue\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM276", "user": "rm-rf-etc", "root": "ROOT27", "reply_to": "COM275", "timestamp": "2018-06-21T19:29:27Z", "text": "@bcoca, while I fully understand your reasoning, this is detrimental to people learning how to use Ansible. Google groups are literally terrible. For example, there are 0 results for \"Unable to parse /etc/ansible/hosts as an inventory source\" when searching this in the group. However, Google finds multiple hits, and among the top ranking hits are these issue threads. Github issue tracker has a far superior interface because it's easy for winning solutions to be marked with reaction emojis. When a winning solution is found, the more people that it works for, the more emojis that solution will collect. This saves people a lot of time and reading, because I can skim an issue thread for the reaction emojis, I don't need to struggle to comprehend every commenter's broken english description of something that's probably not even relevant. Please reconsider.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT28", "user": "creotiv", "root": "ROOT28", "reply_to": null, "timestamp": "2019-05-07T09:48:30Z", "text": "No built application for download WTF guys, you can't make built version of app? so to use it i need to download huge amounts of not needed data and applications? That not how the Linux works.\r ", "meta": {"posReactions": "11", "negReactions": "27"}}
{"id": "COM280", "user": "lol768", "root": "ROOT28", "reply_to": "ROOT28", "timestamp": "2019-05-07T09:57:22Z", "text": "Mentioned in https://github.com/microsoft/Terminal/issues/428 a bit already", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM281", "user": "creotiv", "root": "ROOT28", "reply_to": "COM280", "timestamp": "2019-05-07T10:05:30Z", "text": "Im not the one)", "meta": {"posReactions": "1", "negReactions": "3"}}
{"id": "COM282", "user": "DavidDeSloovere", "root": "ROOT28", "reply_to": "COM281", "timestamp": "2019-05-07T10:18:46Z", "text": "Have patience, if there is no release, then Terminal hasn't been released yet for preview. \r\nAlso, doesn't hurt to be polite.", "meta": {"posReactions": "20", "negReactions": "0"}}
{"id": "COM283", "user": "creotiv", "root": "ROOT28", "reply_to": "COM282", "timestamp": "2019-05-07T10:32:30Z", "text": "@DavidDeSloovere if it not released yet, then where i got the link to this repo?\r\nIm very polite as it possible with MS brand.\r\n\r\nAnd also polite mean to make installation for users, and not throwing in their faces some code and say \"do whatever you want with it\". And really i don't see a problem to build executable installation, it's a task for few hours max for one dev.", "meta": {"posReactions": "1", "negReactions": "16"}}
{"id": "COM284", "user": "LauraWebdev", "root": "ROOT28", "reply_to": "COM283", "timestamp": "2019-05-07T10:41:04Z", "text": "@creotiv you are looking at the source code of the new terminal. There is no official build available yet so you either build it yourself or wait until the first builds come in. It's really not that hard to understand...", "meta": {"posReactions": "8", "negReactions": "1"}}
{"id": "COM285", "user": "ZgblKylin", "root": "ROOT28", "reply_to": "COM284", "timestamp": "2019-05-07T10:46:37Z", "text": "The generated ```.appx``` file does not contain any certificates, it couldn't be installed by double-click or powershell. The only way I found is select \"Deploy Solution\" in vs2017 IDE.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM286", "user": "creotiv", "root": "ROOT28", "reply_to": "COM285", "timestamp": "2019-05-07T10:48:09Z", "text": "@AndreasWebdev so why there is no installer? is it so hard to make?", "meta": {"posReactions": "0", "negReactions": "10"}}
{"id": "COM287", "user": "cjim8889", "root": "ROOT28", "reply_to": "COM286", "timestamp": "2019-05-07T11:06:17Z", "text": "Why don't you develop your own terminal instead of asking like you are the CEO of Microsoft?", "meta": {"posReactions": "4", "negReactions": "2"}}
{"id": "COM288", "user": "creotiv", "root": "ROOT28", "reply_to": "COM287", "timestamp": "2019-05-07T11:16:19Z", "text": "@cjim8889 why i should?", "meta": {"posReactions": "0", "negReactions": "7"}}
{"id": "COM289", "user": "wayheming", "root": "ROOT28", "reply_to": "COM288", "timestamp": "2019-05-07T11:16:59Z", "text": "@creotiv why should they?", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM2810", "user": "creotiv", "root": "ROOT28", "reply_to": "COM289", "timestamp": "2019-05-07T11:21:15Z", "text": "@wayheming because they published it and advertise it", "meta": {"posReactions": "0", "negReactions": "7"}}
{"id": "COM2811", "user": "wayheming", "root": "ROOT28", "reply_to": "COM2810", "timestamp": "2019-05-07T11:21:59Z", "text": "@creotiv So what? they told you that there is no release yet", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM2812", "user": "creotiv", "root": "ROOT28", "reply_to": "COM2811", "timestamp": "2019-05-07T11:23:44Z", "text": "@wayheming then maybe should think about that before start advertise it? or spent 1-2h and make installation. It's installation and not human like AI system", "meta": {"posReactions": "0", "negReactions": "5"}}
{"id": "COM2813", "user": "wayheming", "root": "ROOT28", "reply_to": "COM2812", "timestamp": "2019-05-07T11:25:45Z", "text": "@creotiv you can always not use analog from the Internet if you don't have enough knowledge to install this terminal", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM2814", "user": "scottbilas", "root": "ROOT28", "reply_to": "COM2813", "timestamp": "2019-05-07T11:30:46Z", "text": "The sense of entitlement is strong with this one", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM2815", "user": "creotiv", "root": "ROOT28", "reply_to": "COM2814", "timestamp": "2019-05-07T11:32:05Z", "text": "@wayheming strange to hear this in MS repo which is \"new era UX\"))\r\n\r\n ", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM2816", "user": "wayheming", "root": "ROOT28", "reply_to": "COM2815", "timestamp": "2019-05-07T11:33:02Z", "text": "@creotiv good luck with learning terminal installation", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2817", "user": "GreenMan36", "root": "ROOT28", "reply_to": "COM2816", "timestamp": "2019-05-07T11:52:35Z", "text": "@creotive\r\n\r\nDear creorive,\r\n\r\nI would like to leave you some words, I do mean to end the discussion and not advance it.\r\n\r\nThere will be a Windows store entry for early adopters sometime this summer. And the release date is set for this Winter.\r\n\r\nThey advertised this for developers to thinker and contribute, not for anyone to just press a build file or use an installer.\r\n\r\nBy enabling the current barrier you ensure that the people who are using it have the skills to do so the right way. And therefore are able to contribute correctly.\r\n\r\nIf there was a simple build file or installer, I, an everyday Joe, will thinker with it and I may screw things up on my computer or make excessive issues on this GitHub. (I would say, one like this.)\r\n\r\nSo i am convinced that this is the perfect way to tease this product. Mind you that this is a release but not a Launch of the product. This is like an alpha, not representative of the final product and thus not finished.\r\n\r\nWould you complain the same way if Valve gave away the source for HL3 but wont give you an installer? No, you should be happy with what you got.\r\n\r\nIf you are un-able to build this yourself or find it too much of a hassle, this product is probably not made for you. (Sorry)\r\n\r\nBut I doubt that since I could get this to work and I dont know what i am doing.\r\n\r\nI hope this gives you a different perspective on the discussion.\r\n\r\n-Jasper\r\n\r\nPS: if you really want to have an easy way to install this, fork it, fix it, make a pull request and contribute.\r\n\r\nPPS: Some people shouldn't act like a ass just because they think different. @wayheming @scottbilas @cjim8889", "meta": {"posReactions": "11", "negReactions": "0"}}
{"id": "COM2818", "user": "wayheming", "root": "ROOT28", "reply_to": "COM2817", "timestamp": "2019-05-07T11:57:08Z", "text": "@10jasper10 \r\nI agree that @creotiv should not act like an ass", "meta": {"posReactions": "1", "negReactions": "1"}}
{"id": "COM2819", "user": "GreenMan36", "root": "ROOT28", "reply_to": "COM2818", "timestamp": "2019-05-07T12:00:39Z", "text": "@wayheming\r\nI didn't mean that but whatever floats your boat man. \ud83d\ude43", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM2820", "user": "wayheming", "root": "ROOT28", "reply_to": "COM2819", "timestamp": "2019-05-07T12:02:51Z", "text": "@10jasper10 \ud83d\udc1f\ud83c\udf0a\ud83d\udc74", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2821", "user": "glen-84", "root": "ROOT28", "reply_to": "COM2820", "timestamp": "2019-05-07T12:57:51Z", "text": "Duplicate of #468.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2822", "user": "warpdesign", "root": "ROOT28", "reply_to": "COM2821", "timestamp": "2019-05-07T13:08:31Z", "text": "> Have patience, if there is no release, then Terminal hasn't been released yet for preview.\r\n> Also, doesn't hurt to be polite.\r\n\r\nThen why inviting people to `try it out`?\r\n\r\n![image](https://user-images.githubusercontent.com/199648/57301696-e98c2200-70d9-11e9-99ad-b3f13ad79956.png)\r\n", "meta": {"posReactions": "2", "negReactions": "2"}}
{"id": "COM2823", "user": "wayheming", "root": "ROOT28", "reply_to": "COM2822", "timestamp": "2019-05-07T13:36:26Z", "text": "@warpdesign Twitter account is called Windows Developer and implies that the person will be able to cope with the installation from GitHub", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2824", "user": "notmike101", "root": "ROOT28", "reply_to": "COM2823", "timestamp": "2019-05-07T13:37:30Z", "text": "> Then why inviting people to `try it out`?\r\n\r\nYou're referencing that picture of a tweet, right?  The tweet posted by Windows **Developer**?  The Twitter account primarily followed by developers?  The one that says \"Microsoft Developer is your resource for development tips, tricks, research, case studies...Everything you need to develop apps that users love.\"?   The tweet I'm assuming is targeted towards developers, not standard users?\r\n\r\nYou're talking about that one, right? \r\n\r\nEven then, my only real question to you is this:\r\nhttps://github.com/warpdesign/js-x86\r\n\r\nWhere's your binaries?  Just because it's \"early and incomplete\" (just like this code on this repo is) shouldn't be an excuse. ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM2825", "user": "wayheming", "root": "ROOT28", "reply_to": "COM2824", "timestamp": "2019-05-07T13:38:58Z", "text": "@notmike101 exactly!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2826", "user": "PLQin", "root": "ROOT28", "reply_to": "COM2825", "timestamp": "2019-05-07T13:44:08Z", "text": "Expect an executable installer because I won't compile , \r\nemmm ;\r\n\r\nremind me when you're ready   \ud83d\udc4d ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2827", "user": "wayheming", "root": "ROOT28", "reply_to": "COM2826", "timestamp": "2019-05-07T13:49:33Z", "text": "@PLQin \r\nInitial builds of WSL 2 will be available through the Windows insider program by the end of June 2019.\r\nhttps://devblogs.microsoft.com/commandline/announcing-wsl-2/", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2828", "user": "creotiv", "root": "ROOT28", "reply_to": "COM2827", "timestamp": "2019-05-07T14:04:28Z", "text": "3 month to make an installer for an app)) that's nice)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2829", "user": "creotiv", "root": "ROOT28", "reply_to": "COM2828", "timestamp": "2019-05-07T14:08:40Z", "text": "> > Then why inviting people to `try it out`?\r\n> \r\n> You're referencing that picture of a tweet, right? The tweet posted by Windows **Developer**? The Twitter account primarily followed by developers? The one that says \"Microsoft Developer is your resource for development tips, tricks, research, case studies...Everything you need to develop apps that users love.\"? The tweet I'm assuming is targeted towards developers, not standard users?\r\n> \r\n> You're talking about that one, right?\r\n> \r\n> Even then, my only real question to you is this:\r\n> https://github.com/warpdesign/js-x86\r\n> \r\n> Where's your binaries? Just because it's \"early and incomplete\" (just like this code on this repo is) shouldn't be an excuse.\r\n\r\nBecause its not a system app))) so it strange to have executable on it)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT29", "user": "crquan", "root": "ROOT29", "reply_to": null, "timestamp": "2015-11-23T05:42:59Z", "text": "atom as an editor is too big compare to sublime 3 is 7.2MB  ``` console mint@gnome3-on-mac:~$ (cd Downloads/; ls -lh atom* sublime* ) -rw-r--r-- 1 mint users  68M Nov 19 13:45 atom-amd64.deb -rw-r--r-- 1 mint users 7.2M Mar 26  2015 sublime_text_3_build_3083_x64.tar.bz2 ```  install size: atom is 208M vs. sublime3 is 17M  ``` console $ (cd Downloads/; dpkg-deb --fsys-tarfile atom-amd64.deb ) |tar -xvv ./usr/share/atom/ drwxr-xr-x root/root         0 2015-11-19 13:44 ./usr/share/atom/ -rw-r--r-- root/root    410849 2015-11-19 13:44 ./usr/share/atom/natives_blob.bin -rw-r--r-- root/root    587068 2015-11-19 13:44 ./usr/share/atom/snapshot_blob.bin -rw-r--r-- root/root  10206624 2015-11-19 13:44 ./usr/share/atom/icudtl.dat -rw-r--r-- root/root      1055 2015-11-19 13:44 ./usr/share/atom/LICENSE -rw-r--r-- root/root    520152 2015-11-19 13:44 ./usr/share/atom/libgcrypt.so.11 -rwxr-xr-x root/root  59086736 2015-11-19 13:44 ./usr/share/atom/atom -rw-r--r-- root/root         7 2015-11-19 13:44 ./usr/share/atom/version [...] mint@gnome3-on-mac:~$ \\du -xsh ./usr/share/atom/ 208M    ./usr/share/atom/ mint@gnome3-on-mac:~$ \\du -xsh ./opt/sublime_text_3/ 17M ./opt/sublime_text_3/ ```  run like:  ``` console mint@gnome3-on-mac:~$ ./usr/share/atom/atom App load time: 299ms ```  I'm trying to understand why it's so large: it seems a nodejs project / embedding a nodejs v0.10.40 binaries, and suffering the same nodejs project's recursive node_modules problem,  ``` console mint@gnome3-on-mac:~$ \\du -xa ./usr/share/atom |sort -n [...] 3748    ./usr/share/atom/resources/app/apm/node_modules/npm/node_modules/request 4244    ./usr/share/atom/resources/app.asar.unpacked/node_modules 4284    ./usr/share/atom/resources/app/apm/node_modules/first-mate 4884    ./usr/share/atom/resources/app.asar.unpacked 5864    ./usr/share/atom/chromedriver/chromedriver 5872    ./usr/share/atom/chromedriver 8540    ./usr/share/atom/content_shell.pak 9968    ./usr/share/atom/icudtl.dat 10784   ./usr/share/atom/resources/app/apm/node_modules/npm/node_modules 11184   ./usr/share/atom/resources/app/apm/bin/node 11196   ./usr/share/atom/resources/app/apm/bin 11796   ./usr/share/atom/resources/app/apm/node_modules/npm 16384   ./usr/share/atom/libnode.so 21744   ./usr/share/atom/resources/app/apm/node_modules 33516   ./usr/share/atom/resources/app/apm 33524   ./usr/share/atom/resources/app 57704   ./usr/share/atom/atom 73464   ./usr/share/atom/resources/app.asar 112480  ./usr/share/atom/resources 212484  ./usr/share/atom mint@gnome3-on-mac:~$ ls -lh ./usr/share/atom/resources/app.asar -rw-r--r-- 1 mint users 72M Nov 19 13:44 ./usr/share/atom/resources/app.asar mint@gnome3-on-mac:~$ \\du -xsh ./usr/share/atom/resources/app.asar [...] 72M ./usr/share/atom/resources/app.asar 33M ./usr/share/atom/resources/app/apm 22M ./usr/share/atom/resources/app/apm/node_modules 16M ./usr/share/atom/libnode.so 12M ./usr/share/atom/resources/app/apm/node_modules/npm 11M ./usr/share/atom/resources/app/apm/bin/node 11M ./usr/share/atom/resources/app/apm/node_modules/npm/node_modules mint@gnome3-on-mac:~$ ./usr/share/atom/resources/app/apm/bin/node -v v0.10.40 mint@gnome3-on-mac:~$ find ./usr/share/atom -name node_modules |wc -l 90 mint@gnome3-on-mac:~$ find ./usr/share/atom -name node_modules -exec ls -1 {} \\; |wc -l 277 mint@gnome3-on-mac:~$ find ./usr/share/atom -name node_modules -exec ls -1 {} \\; |sort -u |wc -l 223 ```  The largest ones are app.asar (72M), apm (33M), and node binaries (16M+11M), and there are 90 node_modules directories totally, from 277 to unique 223 package names means a lot of potential duplicate code,  The app.asar (72M) resource file seems to be a large plain text file with 16 bytes binary header, is that a webpack or something I don't understand, look like a plain text javascript file, why it needs to be 72MB large? why not try some xz or gzip compressed resource?  ``` console mint@gnome3-on-mac:~$ file ./usr/share/atom/resources/app.asar ./usr/share/atom/resources/app.asar: data mint@gnome3-on-mac:~$ hexdump -C ./usr/share/atom/resources/app.asar |& head -n40 00000000  04 00 00 00 b0 08 0b 00  ac 08 0b 00 a5 08 0b 00  |................| 00000010  7b 22 66 69 6c 65 73 22  3a 7b 22 64 6f 74 2d 61  |{\"files\":{\"dot-a| 00000020  74 6f 6d 22 3a 7b 22 66  69 6c 65 73 22 3a 7b 22  |tom\":{\"files\":{\"| 00000030  2e 67 69 74 69 67 6e 6f  72 65 22 3a 7b 22 73 69  |.gitignore\":{\"si| 00000040  7a 65 22 3a 34 31 2c 22  6f 66 66 73 65 74 22 3a  |ze\":41,\"offset\":| 00000050  22 30 22 7d 2c 22 69 6e  69 74 2e 63 6f 66 66 65  |\"0\"},\"init.coffe| 00000060  65 22 3a 7b 22 73 69 7a  65 22 3a 33 38 36 2c 22  |e\":{\"size\":386,\"| 00000070  6f 66 66 73 65 74 22 3a  22 34 31 22 7d 2c 22 6b  |offset\":\"41\"},\"k| 00000080  65 79 6d 61 70 2e 63 73  6f 6e 22 3a 7b 22 73 69  |eymap.cson\":{\"si| 00000090  7a 65 22 3a 31 30 30 34  2c 22 6f 66 66 73 65 74  |ze\":1004,\"offset| 000000a0  22 3a 22 34 32 37 22 7d  2c 22 70 61 63 6b 61 67  |\":\"427\"},\"packag| 000000b0  65 73 22 3a 7b 22 66 69  6c 65 73 22 3a 7b 22 52  |es\":{\"files\":{\"R| 000000c0  45 41 44 4d 45 2e 6d 64  22 3a 7b 22 73 69 7a 65  |EADME.md\":{\"size| [...] mint@gnome3-on-mac:~$ tail -c +17 ./usr/share/atom/resources/app.asar | less {\"files\":{\"dot-atom\":{\"files\":{\".gitignore\":{\"size\":41,\"offset\":\"0\"},\"init.coffee\":{\"size\":386,\"offset\":\"41\"},\"keymap.cson\":{\"size\":1004,\"offset\":\"427\"},\"packages\":{\"files\":{\"README.md\":{\"size\":60,\"offset\":\"1431\"}}},\"snippets.cson\":{\"size\":698,\"offset\":\"1491\"},\"styles.less\":{\"size\":762,\"offset\":\"2189\"}}},\"exports\":{\"files\":{\"atom.js\":{\"size\":1642,\"offset\":\"2951\"}}},\"less-compile-cache\":{\"files\":{\"008ee39f25f61883969b7638fa1eee8c89057781\":{\"files\":{\"content\":{\"files\":{\"03fe3eda02e330109d9471f0f9bb8033fc5284ea\":{\"files\":{\"package-card.json\":{\"size\":7316,\"offset\":\"4593\"},\"package-readme.json\":{\"size\":2464,\"offset\":\"11909\"},\"settings-view.json\":{\"size\":17570,\"offset\":\"14373\"},\"variables.json\":{\"size\":286,\"offset\":\"31943\"}}},\"0ca72fa78b0f02602636d1eea2ee52e59c89b9ba\":{\"files\":{\"find-and-replace.json\":{\"size\":7516,\"offset\":\"32229\"}}},\"10da4fc591498d7e0cc359330a4c634853928cc9\":{\"files\":{\"incompatible-packages.json\":{\"size\":1442,\"offset\":\"39745\"}}},\"235ea17d31c14d2abdb70d798d0a0a2c444344c9\":{\"files\":{\"encoding-selector.json\":{\"size\":725,\"offset\":\"41187\"}}},\"38c4d79a3870966993e7817b7331827c4ff9d8f7\":{\"files\":{\"index.json\":{\"size\":5280,\"offset\":\"41912\"}}},\"3cf8cf26996687e169a7146b88246c1b913a6656\":{\"files\":{\"tree-view.json\":{\"size\":1951,\"offset\":\"47192\"}}}, [...] ```  Could you atom developers try to reduce the size ? is there any one making effort on any node dedupe solution? if can't compare with sublime, anyway keep install size below 100M or even smaller would be much appreciated; thanks ", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM290", "user": "lee-dohm", "root": "ROOT29", "reply_to": "ROOT29", "timestamp": "2015-11-24T16:40:22Z", "text": "Atom has been reduced in size significantly in the past (#6313, #6407, #6395, #6447, atom/notifications#54, among others). As a matter of fact, the `app.asar` that you mention compressing _is_ a compressed file. (See the [atom/asar repository](https://github.com/atom/asar) for more information on the file format.)\n\nIf you have examples of duplicate code or specific suggestions of methods for shrinking the size of Atom, please open Issues or Pull Requests with that information. Unfortunately, I fear that simply \"make it smaller\" is not specific enough to be actionable.\n", "meta": {"posReactions": "2", "negReactions": "7"}}
{"id": "COM291", "user": "crquan", "root": "ROOT29", "reply_to": "COM290", "timestamp": "2015-11-24T18:16:05Z", "text": "I'm not a node developer don't even know how to hack this project.\nOnly providing my general feedback here, 208MB is beyond the size of an editor should be,\n\nthe `app.asar` is not compressed anyway, if you open it with a hex editor, you will see 90%+ of this 72MB file is plain text, which means further compressable, here I apply a simple xz compress get a 13MB file, but I don't know how to change the main binary to load resource from the compressed file\n\n```\n-rw-r--r-- 1 mint users  72M Nov 19 13:44 app.asar\n-rw-r--r-- 1 mint users  13M Nov 19 13:44 app.asar.xz\n```\n", "meta": {"posReactions": "7", "negReactions": "1"}}
{"id": "COM292", "user": "anaisbetts", "root": "ROOT29", "reply_to": "COM291", "timestamp": "2015-11-24T18:26:25Z", "text": "There are a number of things that Atom could do to reduce install size, but tbh, does it _really_ matter? Engineering work costs time, and optimizing disk space isn't really worth that time given that you can buy [a 16GB USB Thumb drive on Amazon](http://www.amazon.com/PNY-Attach%C3%A9-16GB-Flash-Drive/dp/B003SGQQQU/ref=sr_1_4?ie=UTF8&qid=1448389544&sr=8-4&keywords=16GB+Thumb+drive) for less than a cup of coffee (in San Francisco :P). That's 78 copies of Atom, for $5. \n", "meta": {"posReactions": "1", "negReactions": "15"}}
{"id": "COM293", "user": "Zireael07", "root": "ROOT29", "reply_to": "COM292", "timestamp": "2015-11-24T18:49:16Z", "text": "I think the original user's concern is not about disk space but download bandwidth. Disk space is indeed cheap. Bandwidth isn't so, especially if you live somewhere where you can't switch ISPs.\n", "meta": {"posReactions": "10", "negReactions": "0"}}
{"id": "COM294", "user": "crquan", "root": "ROOT29", "reply_to": "COM293", "timestamp": "2015-11-29T23:11:24Z", "text": "> can buy a 16GB USB Thumb drive\n\nthat's not a good excuse for doing nothing, not everybody like you github employees (I heard most atom developers are ?) has a macbook for each, and there are many ones still using old computers, ...\n", "meta": {"posReactions": "1", "negReactions": "2"}}
{"id": "COM295", "user": "lee-dohm", "root": "ROOT29", "reply_to": "COM294", "timestamp": "2015-11-30T02:31:15Z", "text": "> you github employees\n\nThis is challenging the person, not the idea, and is generally considered poor form in online discussions.\n\nYou still haven't addressed my concern with this Issue, @crquan, namely that there isn't a method of determining if Atom is \"beyond the size of an editor should be\". You only state that 208MB is too much. A bug is nearly worthless if it cannot ever be fixed. And without a clearly defined goal, this bug cannot be fixed.\n\nIs 207MB too big? Is 200MB? Is 10MB? Please give an example of what size is \"small enough\" and what size \"too big\" and, most importantly, why.\n", "meta": {"posReactions": "4", "negReactions": "1"}}
{"id": "COM296", "user": "thedaniel", "root": "ROOT29", "reply_to": "COM295", "timestamp": "2015-11-30T13:40:35Z", "text": "In any case, as long as Atom uses electron, it's going to be an order of magnitude larger on disk than the example you provided (sublime 3 at 7 megs) because of libchromiumcontent, etc. We're generally working on reducing the file size of the editor where we can, but I am going to close this issue in favor of more specific issues - you could, for example, have a conversation about the pros and cons of asar actually doing compression rather than concatenation on the electron repository, or file an issue about problems with dependency deduping in atom. \n\nStill, Atom is likely going to be in the 100 meg order of magnitude, not 10 , for the forseeable future.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM297", "user": "qcq", "root": "ROOT29", "reply_to": "COM296", "timestamp": "2016-01-24T07:58:55Z", "text": "I really agree with @crquan , The package is too big, However the Atom is open source, May be This is a only advantage vs sublime, If so, How can atom accepted by common people. We all know sublime can use free for a long time which you can think. @lee-dohm as a common user, We already find the \"bug\" lies, not us to fix it. Not all common people go through all the code which Atom has. This is just suggestion or mind which everyone can see it.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM298", "user": "texelate", "root": "ROOT29", "reply_to": "COM297", "timestamp": "2016-08-16T06:07:38Z", "text": "I'll add my comment, albeit late. I am using Atom on Xubuntu running alongside Chrome OS. I only have a 16 GB SSD to play with and once you factor in the Chrome OS, Xubuntu and the necessary software that comes with them, there isn't much room left. I currently only have 2.5 GB left so Atom is taking up 10% of that.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM299", "user": "qcq", "root": "ROOT29", "reply_to": "COM298", "timestamp": "2016-09-01T00:14:58Z", "text": "@thedaniel, **I do not think** it is a good idea to close this, even have a plan to reduce the size of atom, why not keep this open as a place where can remind us we have a really important thing to do. not just a idea. \n@paulcbetts, I want to speak directly, the words \"very cheap to buy a USB\" seems really ridiculous. if that is right, why not make atom more bigger, to 2G. or what else...... what is the meaning of one software which exist? especially loved by people. that is ..... everyone knows it. maybe you will tell me, Atom is a open source, you just work for it as volunteer. That make no sense, why you make efforts to a open source, because you love it. when you love it, why not keep it the best. \n@lee-dohm, Then about the purpose, 200M, 100M? @crquan already gives us a good example ###sublime###. your words looks so ridiculous too, I have to say. no offence. Thanks.\n\nanyway, Thanks all the efforts to ATOM. Thanks all you here. Thanks.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2910", "user": "fenec", "root": "ROOT29", "reply_to": "COM299", "timestamp": "2017-07-14T21:47:27Z", "text": "Just installed it on my Mac. Gosh, it's 530 Mb...\r\n", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM2911", "user": "qcq", "root": "ROOT29", "reply_to": "COM2910", "timestamp": "2017-07-15T06:28:48Z", "text": "<img width=\"261\" alt=\"screen shot 2017-07-15 at 14 28 03\" src=\"https://user-images.githubusercontent.com/8703631/28237099-e48059da-6969-11e7-970f-a36ad08dc1bf.png\">\r\n<img width=\"264\" alt=\"screen shot 2017-07-15 at 14 28 33\" src=\"https://user-images.githubusercontent.com/8703631/28237100-e4cf5db4-6969-11e7-8d7a-5be740fa4982.png\">\r\n", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM2912", "user": "brndd", "root": "ROOT29", "reply_to": "COM2911", "timestamp": "2017-08-23T10:45:12Z", "text": "Atom was taking up 1.5GiB (*one and a half gibibytes*) in my %APPDATA% folder on Windows 10. Because this goes on my OS SSD where space is very limited, I ended up uninstalling it. This is just ridicilous for a bloody text editor, but then again it's JavaScript.", "meta": {"posReactions": "3", "negReactions": "1"}}
{"id": "COM2913", "user": "johnlanz", "root": "ROOT29", "reply_to": "COM2912", "timestamp": "2017-09-16T03:44:08Z", "text": "Hey guys, Atom is taking 7GB on my SSD for 1 year of using it. Maybe its a problem after all?\r\n![atom7gb](https://user-images.githubusercontent.com/601899/30508887-4c4d6f6c-9ad4-11e7-9a2f-8c3d33c950e5.png)\r\n", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM2914", "user": "mathieu-jobin", "root": "ROOT29", "reply_to": "COM2913", "timestamp": "2017-09-16T04:56:15Z", "text": "Adding to this, Atom was taking 5.5GB on my SSD as well, most of it in local appdata. Windows 10.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2915", "user": "ShalokShalom", "root": "ROOT29", "reply_to": "COM2914", "timestamp": "2017-09-21T13:37:05Z", "text": "Just saying: VSCode is < 100 mb download size, ~ 200 mb memory print and also build up on Electron.", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM2916", "user": "50Wliu", "root": "ROOT29", "reply_to": "COM2915", "timestamp": "2017-09-21T19:42:13Z", "text": "There is a known issue on Windows where the auto-updater may fail to remove old versions of Atom.  It is safe to delete all the older versions.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2917", "user": "CallmeNezha", "root": "ROOT29", "reply_to": "COM2916", "timestamp": "2018-02-10T13:09:10Z", "text": "I used to use atom a lot, and now it pushed me to vscode side, because obviously this HUGE beast become a problem~", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM2918", "user": "MichaelMacha", "root": "ROOT29", "reply_to": "COM2917", "timestamp": "2018-07-01T21:04:17Z", "text": "I understand that Node.js style code must be transmitted as text, and 1.0 GB sounds reasonable for a piece of software with the versatility of Atom. Admittedly, I am also not a Node.js developer; I  haven't used it in about a year and a half. However, I'm installing software on Mint 19 right now, and it's had to download an entire gigabyte.\r\n\r\nPart of why I picked up Atom was because it was so much quicker and more lightweight than something like Visual Studio. Is there anyway you could perhaps take a machine-compiled portion of that code, and put it together as a binary on the host, then distribute it selectively? Something like binary, dev, and src packages? Because it is losing its original grace, and if this keeps up, I may have to switch.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM2919", "user": "vitobotta", "root": "ROOT29", "reply_to": "COM2918", "timestamp": "2018-11-05T10:22:41Z", "text": "I was searching about Atom's size and found this thread. I downloaded it from atom.io for my Mac and the app is a whopping 865MB!!! So is this normal? I was searching because I was afraid the download could have been compromised on the website or something like that... \r\n\r\nHow can a text editor take more than 800 MB of disk space?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT30", "user": "csotiriou", "root": "ROOT30", "reply_to": null, "timestamp": "2018-06-16T16:26:42Z", "text": "Proposal: Consider using  bgfx as a rendering backend? I started using Godot lately, and I find it ingenious. I am using a Mac, and while I don't intend to release something Mac-only in the end, it is the best development platform for me, as well as many others.\r \r Following the news regarding the deprecation of OpenGL for Apple platforms I saw this issue on GitHub, https://github.com/godotengine/godot/issues/19368 and I personally feel that the issues raised by the Godot team are all valid. It also seems that the team has already planned Vulkan support, and Mac / iOS will be supported using MoltenVK.\r \r However, before this happens, I would like to throw another option to the table, which is using bgfx as a rendering backend. https://github.com/bkaradzic/bgfx\r \r BGFX has DirectX, OpenGL, and Metal support out of the box and will soon add Vulkan support (https://github.com/bkaradzic/bgfx/issues/274). MoltenVK for Mac also seems like a viable option, but it has some limitations atm (https://github.com/KhronosGroup/MoltenVK/blob/master/Docs/MoltenVK_Runtime_UserGuide.md#limitations) which I have to admit I don't know how much they affect Godot (if at all).\r \r Since BGFX's API allows supporting multiple rendering backends without changing its core API, perhaps using this instead of investing time only in Vulkan will be better for Godot in the long run?\r \r I totally respect Godot team's decisions regarding Vulkan, and I trust that if Godot chooses this path it will work as good as now - if not better. I just threw the BGFX idea in order to have some feedback on whether BGFX was something that was already considered - and what is the team's opinion on choosing BGFX instead of investing time only on Vulkan support (also having to trust that MoltenVK will always work as advertised).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM300", "user": "fire", "root": "ROOT30", "reply_to": "ROOT30", "timestamp": "2018-06-16T17:35:30Z", "text": "See the reason why SDL was not accepted at. https://github.com/godotengine/godot/pull/16470", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM301", "user": "csotiriou", "root": "ROOT30", "reply_to": "COM300", "timestamp": "2018-06-16T17:47:28Z", "text": "Can you please elaborate on how the SDL issue is relevant?\r\n\r\nSDL was considered as an abstraction layer on user input systems and getting rendering contexts ready to use.\r\n\r\nBgfx, however, allows full and API-agnostic rendering. \r\n\r\nDo you mean that maintenance of an additional abstraction layer in Godot would be painful?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM302", "user": "fire", "root": "ROOT30", "reply_to": "COM301", "timestamp": "2018-06-16T18:07:05Z", "text": "See: https://github.com/godotengine/godot/pull/16470#issuecomment-364070439\r\n\r\nSummary of points:\r\n\r\n\\<Reduz> Imagine a situation where we use SDL2 and drop the existing backends. What happens every time we need a platform specific feature not available on SDL2? (Something it happens often) . We have the following scenarios:\r\n\r\n\\<Reduz> Added to that, the problem is that we may need to add something that SDL does not support and, while for us it's something specific with a simple use, while adding this function to SDL may involve creating a large API with all the functions that are needed for abstraction.\r\n\r\n\\<Reduz> I'm sorry, no matter how I try to think of ways we could use SDL, it's always more disadvantages than advantages.. \r\n\r\nNow replace SDL with BGFX. \r\n\r\nThere are two parts of abstraction. A) low level abstraction B) construction of the rendering pipeline for mobile (gles2) vs pc (vulkan)\r\n\r\nUsing bfgx only helps for A), B) needs to rebuilt.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM303", "user": "ghost", "root": "ROOT30", "reply_to": "COM302", "timestamp": "2018-06-17T11:17:46Z", "text": "possible dumb question incoming:\r\nbut, when vulkan rendering stuff gets complete, it would negate this issue right?\r\n\r\ni imagine time spent on vulkan will far supersede bgfx, or other rendering systems", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM304", "user": "csotiriou", "root": "ROOT30", "reply_to": "COM303", "timestamp": "2018-06-17T14:19:52Z", "text": "@girng correct.\r\n\r\n@fire the way I understand your comments, it's an issue of third party support (what if Godot needs something that bgfx does not offer in the future), and having full control over the implemented features.\r\n\r\nI get it, but I also hope that Vulkan works as advertised as well.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM305", "user": "reduz", "root": "ROOT30", "reply_to": "COM304", "timestamp": "2018-06-19T15:52:19Z", "text": "This option was discussed and discarded in the past (as you can imagine), but since this was not discussed in an issue, I will take the time to explain why BGFX is not an option.\r\n\r\n1) There are two main platforms that need to be supported. Modern Desktop PC (OpenGL ES 3, and later Vulkan) and mobile including medium and low end (OpenGL ES 2). These APIs are not programmed the same way, so a \"wrapper\" to simplify the work is impossible. GLES3/Vulkan uses UBOs, VAOs, TBOs. shaders with integers and plenty of features. GLES2 is very basic and supports none of that, so different approaches need to be used to write a back end. Modern hardware also uses certain rendering techniques (HDR/clustered/single pass shading), while low end uses other techniques (LDR/multipass). As such, being a fact that pretty much no code is shared between backends, BGFX does not save the work of having to write two backends for different hardware.\r\n\r\n2) Having an extra layer of complexity in the middle makes things more complex, and makes debugging more difficult. Contributors would need to learn BGFX to write rendering code instead of a more standard API like Vulkan or OpenGL, out of which there is plenty of documentation and examples. If you want to use tools for debugging Vulkan or OpenGL, they will be confusing with BGFX as a backend too. As net worth, BGFX as a middle layer is a negative point here, not a positive one.\r\n\r\n3) Khronos has the [Vulkan Portability Initiative](https://www.khronos.org/vulkan/portability-initiative), where they aim to run it over Metal, DirectX, etc. This is pretty much the same as BGFX, thus decreasing even further the value of  BGFX.\r\n\r\n4) Using Vulkan allows us to take advantage of extensions and new features on bleeding edge hardware much faster than using BGFX.\r\n\r\n5) Our contributors are part of the Khronos Advisory Board, so by using Vulkan we can give valuable feedback of our experience to hardware manufacturers, making sure they hear us when woring on future versions of the specification.\r\n\r\nHope it's clearer now! There is more than plenty of reasons to not use BGFX.\r\n\r\n", "meta": {"posReactions": "12", "negReactions": "5"}}
{"id": "COM306", "user": "csotiriou", "root": "ROOT30", "reply_to": "COM305", "timestamp": "2018-06-21T18:49:38Z", "text": "@reduz this was exactly the kind of answer I was aiming for, thanks.", "meta": {"posReactions": "2", "negReactions": "1"}}
{"id": "COM307", "user": "bkaradzic", "root": "ROOT30", "reply_to": "COM306", "timestamp": "2018-09-01T17:34:24Z", "text": "@reduz Please refrain from talking negatively about bgfx when you justifying your strategic decision about Godot, since there is really no animosity between two projects. Both are open source, have their own place, and not even competitors...\r\n\r\nWhatever your strategic decision for Godot is, it's totally legit. I'm here only to defend bgfx from false statements.\r\n\r\n> There are two main platforms that need to be supported. Modern Desktop PC (OpenGL ES 3, and later Vulkan) and mobile including medium and low end (OpenGL ES 2). These APIs are not programmed the same way, so a \"wrapper\" to simplify the work is impossible. GLES3/Vulkan uses UBOs, VAOs, TBOs. shaders with integers and plenty of features. GLES2 is very basic and supports none of that, so different approaches need to be used to write a back end.\r\n\r\nExample of this actually exist in bgfx code base. Since bgfx is declarative API not imperative, you can actually write code that works optimally on two completely different APIs.\r\n\r\n> Modern hardware also uses certain rendering techniques (HDR/clustered/single pass shading),  while low end uses other techniques (LDR/multipass). As such, being a fact that pretty much no code is shared between backends, BGFX does not save the work of having to write two backends for different hardware.\r\n\r\nYou're talking here about two different rendering pipelines, not two different renderers. Yes with bgfx too you have to implement two different pipelines to support your low-end hardware and high-end hardware. The difference is, when you use bgfx that both pipelines are avilable on all renderers. Which means that you can enable your low-end pipeline for desktop users who have old HW/OS/etc. and you can enable your high-end pipeline for mobile users who have beefy phone/table.\r\n\r\n>  If you want to use tools for debugging Vulkan or OpenGL, they will be confusing with BGFX as a backend too. As net worth, BGFX as a middle layer is a negative point here, not a positive one.\r\n\r\nThis is actually nonsensical statement. When you debug rendering issues in bgfx with for example RenderDoc, PIX, or GPA, you see underlying API and they are not getting confused with bgfx.\r\n\r\n> Khronos has the Vulkan Portability Initiative, where they aim to run it over Metal, DirectX, etc. This is pretty much the same as BGFX, thus decreasing even further the value of BGFX.\r\n\r\nNot really, since bgfx is not low-level renderer.\r\n\r\n> Using Vulkan allows us to take advantage of extensions and new features on bleeding edge hardware much faster than using BGFX.\r\n\r\nIf you just want to use single renderer in bgfx, and you don't care about cross-platform and feature parity between renders it's as fast to add features to single renderer with bgfx too.\r\n", "meta": {"posReactions": "15", "negReactions": "0"}}
{"id": "COM308", "user": "reduz", "root": "ROOT30", "reply_to": "COM307", "timestamp": "2018-09-01T20:30:34Z", "text": "@bkaradzic I never said anything negative about BGFX itself, only in the context of Godot.\r\n\r\nThe point of the discussion was mainly that, given two render pipelines need to be written anyway, using BGFX is not an advantage or solution regarding to that. You answers completely missed it.\r\n\r\nFor the other answers, I was not questioning whether BGFX was high or low level, or whether it can be debugged, or anything else. The point was simply that _it is_ added complexity (which is undeniable) for an use case that is redundant and provides no advantages **_in the context of Godot_**. As this added complexity does not solve our problems, there is no justification to going for it.\r\n\r\nApologies, but I think you are being overly defensive when the whole argument was about Godot, not BGFX.\r\n", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM309", "user": "bkaradzic", "root": "ROOT30", "reply_to": "COM308", "timestamp": "2018-09-02T00:43:57Z", "text": "> The point was simply that it is added complexity (which is undeniable) for an use case that is redundant and provides no advantages in the context of Godot. As this added complexity does not solve our problems, there is no justification to going for it.\r\n\r\nThis is what I'm talking about. You're saying that bgfx would add complexity into your code base, but it's actually quite oposite, by using bgfx it removes complexity from usual code base. Once someone replaces their own renderer with bgfx, they usually have redundant code on higher level, they don't have to do state tracking anymore since bgfx deals with that, they don't have to do multiple passes over scene because bgfx allows you to submit out of order and orders draw calls for you, etc. But bgfx is complex on it's own.\r\n\r\nIn the past you made statements that you want to control whole stack, and you don't want to introduce risk by adding 3rd party open source software. I find this is more honest response, since there is nothing that I can add or remove from bgfx that would make you reconsider your strategy about renderer. So no need to justify your decision about renderer by saying bgfx does or doesn't do X, Y, Z, if your decision was unrelated to bgfx as you stated before.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3010", "user": "reduz", "root": "ROOT30", "reply_to": "COM309", "timestamp": "2018-09-02T01:39:18Z", "text": "@bkaradzic It definitely _is_ complexity. You seem to be assuming that just because of adding BGFX support, everything will be fine and no one will ever have to learn how the underlying APIs work. \r\n\r\nThis is, unfortunately not the case and how things work in real life. This may work for APIs or libraries where you truly no longer need to care how internal implementations of things work as long as they do what they have to. Bullet is a good example of this.\r\n\r\nHowever, in my experience, if we were to use BGFX, contributors would still need to also know the underlying APIs as well (OpenGL or Vulkan). How else are they supposed to fine tune performance, or understand why something fails when it does? \r\n\r\nIf this was a simple game, or a tool or something like that I am sure BGFX would be fine, but thinking BGFX will fit like a glove for us and just work is very naive. We have a lot more responsibility than you do at providing something that works for our users. We need to extract the best out of the resources and performance from the underlying hardware, since we are already a middle layer ourselves.\r\n\r\nSo, as I already made it pretty clear that there is no advantage to it, due to us needing two rendering pipelines, and that contributors will still need to understand the underlying rendering APIs. I hope you understand that to me it's just extra unnecessary complexity that is best kept away of Godot.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3011", "user": "akien-mga", "root": "ROOT30", "reply_to": "COM3010", "timestamp": "2018-09-02T08:15:17Z", "text": "@bkaradzic I understand that you are defensive about the project you maintain, but please re-read [@reduz's arguments](https://github.com/godotengine/godot/issues/19602#issuecomment-398449702) and you'll see that there is no critic made of BGFX itself.\r\n\r\nReplace \"BGFX\" by \"a rendering middle layer\" and you'll get what @reduz meant, if it was not clear enough. @reduz doesn't even have experience using BGFX, so he can only assess the concept of a rendering middle layer and not BGFX's specific API and features.\r\n\r\nThe TL;DR would be:\r\n\r\n1. A rendering middle layer wouldn't simplify things as we still need to rendering pipelines anyway.\r\n\r\n2. A rendering middle layer *is* added complexity, as we need to debug both the middle layer and the low level graphics API when facing driver-related issues.\r\n\r\n3. *If* we had to use a rendering middle layer, the Vulkan PI seems a lot more promising for our needs.\r\n\r\n4. Using Vulkan directly instead of a rendering middle layer means that we can implement new features the way we want, directly.\r\n\r\n5. We want to work with Khronos to further Vulkan's usage, and doing our own Vulkan renderer is the best approach for that.\r\n\r\nAs you can see, there is no judgement of value of BGFX itself, it's just as you said:\r\n\r\n> In the past you made statements that you want to control whole stack, and you don't want to introduce risk by adding 3rd party open source software. I find this is more honest response, since there is nothing that I can add or remove from bgfx that would make you reconsider your strategy about renderer.\r\n\r\nThat's exactly what the above points amount to.\r\n\r\nSo we're glad that BGFX exists and that it's a great solution for many applications, but as of today it's not something that we're interested in for Godot. Thanks for respecting our decision.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3012", "user": "csotiriou", "root": "ROOT30", "reply_to": "COM3011", "timestamp": "2018-09-08T11:36:57Z", "text": "I gained a lot of interesting information here, not only by the Godot members, but also from @bkaradzic . \r\n\r\nJust wanting to clarify the reasoning behind my question:\r\n\r\nPersonally, when developing, I want options. In the case of a game engine, I want it to be as flexible as it can be - this is why I would choose bgfx - because I want to be able to not be unaffected by changes and politics of the graphics ecosystem (like Apple not supporting OpenGL anymore, etc). The reasoning behind my question was if Godot shared the same thoughts.\r\n\r\nIn the case of Godot, the team wants full control over _one_ rendering stack, and flexibility comes second. This will probably allow them to implement more features and be completely unaffected by 3rd party frameworks in the long run. Which is also a very good approach.\r\n\r\n-- \r\n\r\nFrom this discussion, the thing I am keeping is that @bkaradzic was right to point out that using bgfx actually saves a ton of code (something I have seen in many testimonies around), but @akien-mga and @reduz were also right to point out that if the flexibility of supporting more than one rendering backends is not a primary goal, then relying on a 3rd party middle layer just for having only one rendering backend may hinder the process later down the road.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM3013", "user": "Alan-FGR", "root": "ROOT30", "reply_to": "COM3012", "timestamp": "2018-09-08T14:46:38Z", "text": "The problem is you need to support many APIs if you want to ship a cross-platform product of acceptable quality. If multiple backends isn't a primary goal then by consequence cross-platform support isn't a goal too. It's not pretty, it's not what people want to hear, but it's the reality we live in today. In order to ship a quality cross-platform product you can only accept that and do what it takes to conform to that reality. \r\nAnd yes, I'm ready for the thumbdowns... let them come!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3014", "user": "reduz", "root": "ROOT30", "reply_to": "COM3013", "timestamp": "2018-09-09T21:46:26Z", "text": "@csotiriou, @Alan-FGR You are both wrong. We can still rely on more rendering back-ends via lower level wrappers like Angle (OpenGL ES 2.0) and MoltenVK / GFX-RS (Vulkan), so we already get best of both worlds.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3015", "user": "jimon", "root": "ROOT30", "reply_to": "COM3014", "timestamp": "2018-10-17T19:15:01Z", "text": "My 5 cents: maintaining your own renderer is more actual work than it sounds. And it will drain your resources on fixing things that don't necessary add end user value.\r\n\r\nImage one day you need to ship a game on PS4/Switch/etc, what do you do? Spend month porting Godot to a random platform? bgfx is already ported IIRC. And then another day you get strange rendering bug reports on random Android phone that you never know existed, what you gonna do? etc.\r\n\r\nTo get real feeling of what it takes to actually ship something GL based nowadays, try to look at UE4: https://github.com/EpicGames/UnrealEngine/tree/release/Engine/Source/Runtime/OpenGLDrv/Private - it is full of hacks for random devices. Value of rendering libs is not that they are \"cross-platform\", but rather that they are proven to work on platforms.\r\n\r\nIMHO Value of Godot is not in \"%insert_your_gapi_of_choice% support\", but rather in features in the editor.", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM3016", "user": "Alan-FGR", "root": "ROOT30", "reply_to": "COM3015", "timestamp": "2018-10-17T20:13:42Z", "text": "> they are proven to work on platforms\r\n\r\nExactly. Bgfx is being used in production by renowned studios to deploy cross-platform products. So it's reasonably battle-tested and I don't see any compelling reason not to take advantage of that, not to mention the API is very well designed too. Angle isn't a good option if you care about performance.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3017", "user": "reduz", "root": "ROOT30", "reply_to": "COM3016", "timestamp": "2018-11-01T14:02:29Z", "text": "@jimon , @Alan-FGR, @neikeq : Guys, thanks a lot for your enthusiasm, but I am the one doing the rendering work in Godot, not you. I've been working on 3D rendering for 25 years so, if I am telling you that things as they are now are optimal and BGFX will just stand in the way to being productive I hope you believe me.\r\n\r\nAs always with Godot, you are free to make your own renderer with BGFX, show me that it's flawless, has better better performance, works better than mine (of course while supporting the full Godot feature set) and uses less resources and code to prove me wrong.. as well as commiting full time over the next years to maintain it.\r\n\r\nIf you want a revolution, begin with it yourself. If you want to prove your ideas, invest in them because words are free.\r\n\r\nIf not, keep pestering all you want and it will be ignored.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM3018", "user": "neikeq", "root": "ROOT30", "reply_to": "COM3017", "timestamp": "2018-11-01T16:39:52Z", "text": "I only remember ever mentioning bgfx once or maybe twice in the past. All I can find is this comment back in [2017](https://godot.eska.me/irc-logs/devel/2017-07-21.log) asking _\"What about bgfx?\"_. I don't understand why you would include me. I guess it's because I up-voted a comment I consider brings an interesting point to the table.\r\n\r\nRegarding the others, I don't understand why such a negative response. I don't see anything wrong in their comments. They are not pestering in any way...", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM3019", "user": "Qix-", "root": "ROOT30", "reply_to": "COM3018", "timestamp": "2019-02-22T23:29:20Z", "text": "> Guys, thanks a lot for your enthusiasm, but I am the one doing the rendering work in Godot, not you. I've been working on 3D rendering for 25 years so, if I am telling you that things as they are now are optimal and BGFX will just stand in the way to being productive I hope you believe me.\r\n\r\nWhat a classic example of elitism and douchebaggery. I will stay miles away from Godot and any projects you maintain, thanks.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM3020", "user": "akien-mga", "root": "ROOT30", "reply_to": "COM3019", "timestamp": "2019-02-23T06:45:13Z", "text": "This issue has long outlived its usefulness. And insulting community members is not tolerated in this community, so you are indeed more than encouraged to stay clear from this project.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT31", "user": "cui-colin", "root": "ROOT31", "reply_to": null, "timestamp": "2019-04-16T17:59:19Z", "text": "Is there a way to have a full REPL or console for vs code Python? \r I find it extremely frustrating using terminal as a REPL. There is no console. It's not a real IDE. I hope to see something like Matlab or R have done.\r \r The following is extremely inconvenient:\r 1. you can't highlight in terminal\r 2. shortcut like shift+left arrow which is used to highlight produces characters ;2D (see picture)\r 3. breaking from a loop using Ctrl+C sometimes exits Python, you have to invoke all over again.\r 4. The big fat cursor is ugly.\r \r Essentially,\r The Python extension just invokes Python from terminal. I mean, if I wanted the terminal experience, I'd do it with VIM. The whole point of VS Code Python is to step away from that.\r \r \r I'm running:\r - VS Code version: 1.33.1\r - Extension version: 2019.3.6558\r - OS and version: OS X\r - Python version: 3.6.7\r \r ![terminal](https://user-images.githubusercontent.com/14314760/56231725-2de15080-604d-11e9-99b9-f9132c60f94c.png)\r \r \r \r \r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM310", "user": "rchiodo", "root": "ROOT31", "reply_to": "ROOT31", "timestamp": "2019-04-16T20:12:53Z", "text": "If you have jupyter installed, you can use our ipython based window instead:\r\nhttps://code.visualstudio.com/docs/python/jupyter-support\r\n\r\nI believe it does everything you just asked for.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM311", "user": "cui-colin", "root": "ROOT31", "reply_to": "COM310", "timestamp": "2019-04-16T20:42:16Z", "text": "@rchiodo, Jupyter is not an IDE! It looks pretty, but pretty useless. Cells in Jupyter are pointless, it's really for a company presentation. It's not for serious code development.\r\n\r\nAnaconda comes with Jupyter Notebook.  It's quicker and better. No need to download VS Code for it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM312", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM311", "timestamp": "2019-04-16T20:46:54Z", "text": "Sorry Jupyter is overloaded here. We are using jupyter to run an IPython console. That doc link talks about if you're using Jupyter already, you can now use VS Code. The initial audience was datascientists.\r\n\r\nHowever it's really just an IPython console. Which is a REPL.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM313", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM312", "timestamp": "2019-04-16T20:48:59Z", "text": "Jupyter is both an editor and a set of APIs that we use under the covers to talk to the same backend that the Jupyter editor uses.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM314", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM313", "timestamp": "2019-04-16T20:50:44Z", "text": "And when I said you need Jupyter installed, you specifically need the jupyter python module and its dependencies. \r\n\r\n```\r\npip install jupyter \r\n```\r\n\r\nshould do it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM315", "user": "cui-colin", "root": "ROOT31", "reply_to": "COM314", "timestamp": "2019-04-16T20:53:00Z", "text": "I think it's quite stubborn to say you know what your users want.\r\n\r\nIt's also quite naive to tell users they must it your way. They will abandon your product.\r\n\r\nI have Jupyter, it's not for serious programming. Also, I have Jupyter Notebook. It's works very nice, have you tried it?\r\n\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM316", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM315", "timestamp": "2019-04-16T20:56:54Z", "text": "I think you're misunderstanding my intent.\r\n\r\nWe have this:\r\n![image](https://user-images.githubusercontent.com/19672699/56243408-5e29ee80-604f-11e9-9d8a-8225cedcfdf0.png)\r\n\r\nI'm suggesting this UI will meet your needs. \r\n\r\nIf this doesn't meet your needs, are you willing to go into more depth on what you want?\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM317", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM316", "timestamp": "2019-04-16T20:59:14Z", "text": "That window on the right behaves as a live REPL. You can type into it, you get a history of what's run, etc. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM318", "user": "cui-colin", "root": "ROOT31", "reply_to": "COM317", "timestamp": "2019-04-16T21:10:52Z", "text": "> If this doesn't meet your needs, are you willing to go into more depth on what you want?\r\n\r\nI am just asking if the Python extension can be fixed up. The current REPL is Editor+Terminal combo. Python is invoked from Terminal. \r\n\r\nTerminal interface is hard to work with. What I am asking is:\r\n1. Highlight with left+shift keyboard combo actually works, not giving characters ;2D\r\n2. Breaking from a loop using Ctrl+C does not exit Python\r\n3. Aesthetic: have a cursor, not a bold black block\r\n\r\nThese are existing problems in the extension. Just include it in the next update. \r\n\r\nBTW, why did you close the thread after my first post?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM319", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM318", "timestamp": "2019-04-16T21:19:48Z", "text": "I closed this bug because I believed the window we have now would meet your needs. \r\n\r\nIt supports\r\n- left+shift etc. Its editor is a full blown editor and not the weird terminal one line thing\r\n- interrupt button (ctrl+c actually copies in the other repl).\r\n- You can change the cursor. Actually you can change this already in the regular REPL. It's a setting (interactive terminal cursor I think)\r\n\r\nWe're not investing any effort into changing the VS code terminal, so I don't believe we can actually meet your original request. \r\n\r\nIf the new window doesn't work for you, can you explain why?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3110", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM319", "timestamp": "2019-04-16T21:32:47Z", "text": "At some point the new 'Python Interactive' window will likely become the default REPL for all python code. \r\n\r\nSo knowing why doing this doesn't work for people would be great.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3111", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM3110", "timestamp": "2019-04-16T21:36:41Z", "text": "The marketplace is kinda confusing. The 'Jupyter' extension is not the owner of this window. \r\n\r\nThe 'Python Extension' owns the window you took a screenshot of.\r\n\r\nStartup time is a problem we're trying to handle (all of it is starting the separate console in the background). \r\n\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3112", "user": "cui-colin", "root": "ROOT31", "reply_to": "COM3111", "timestamp": "2019-04-16T21:37:40Z", "text": "I actually just tried it---the Jupyter extension. Boy, it was very slow. It hung for a few seconds while importing numpy, there was no response. Multi-line code run did not run smoothly. (see picture for error message)\r\n\r\nAlso, the Marketplace says the Jupyter extension is no longer being maintained!\r\n\r\n![Screen Shot 2019-04-16 at 5 36 50 PM](https://user-images.githubusercontent.com/14314760/56245841-65142980-606e-11e9-9ead-a8a65abf7dae.png)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3113", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM3112", "timestamp": "2019-04-16T21:38:02Z", "text": "The error you have there is what an exception looks like. The code you ran must have had a relative path in it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3114", "user": "cui-colin", "root": "ROOT31", "reply_to": "COM3113", "timestamp": "2019-04-16T21:49:33Z", "text": "I wouldn't close the ticket so quickly. A lot people were also frustrated, you should let them talk!\r\n\r\n> Startup time is a problem we're trying to handle (all of it is starting the separate console in the background).\r\n\r\nIt's probably faster to fix Python extension by adding few keyboard combos, rather fixing Jupyter with startup problems. But then again, you believe you know what we want better than what we tell you we actually want.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3115", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM3114", "timestamp": "2019-04-16T21:54:46Z", "text": "The impression I'm getting is that closing a ticket is the same as ignoring your feedback. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3116", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM3115", "timestamp": "2019-04-16T21:56:31Z", "text": "With regards to the regular terminal, are you saying you wouldn't like if the default REPL became this new window? ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3117", "user": "cui-colin", "root": "ROOT31", "reply_to": "COM3116", "timestamp": "2019-04-16T22:05:48Z", "text": "I feel two people with oppositing opinions can sound more like a duel than a discussion.\r\n\r\nI am surprised that asking to include a few features in the next update is met with such resistance.\r\n\r\nREPL should have editor + console. It's standard and expected. \r\n\r\nThe Jupyter extension looks just..Jupyter. All the white spaces between lines. You can even x out the code chunk in console (see my picture). Why? We are testing and debugging code. We really don't care we had a piece of wrong code.\r\n\r\nThe Jupyter extension looks more like a repackage Jupyter wanting to be the Python extension.\r\n\r\n![jupyter](https://user-images.githubusercontent.com/14314760/56247146-ee792b00-6071-11e9-8dda-a495fbf984d8.png)\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3118", "user": "cui-colin", "root": "ROOT31", "reply_to": "COM3117", "timestamp": "2019-04-16T22:11:07Z", "text": "Anyways, I think you get my point and what I am requesting. \r\n\r\nIf you refuse to, then you do. I will let others be the judge.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3119", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM3118", "timestamp": "2019-04-16T22:12:12Z", "text": "So you don't like the look of it. It's too Jupyterish? \r\n\r\nModifying the current REPL is a large work item. We don't own it. VS Code proper does. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3120", "user": "cui-colin", "root": "ROOT31", "reply_to": "COM3119", "timestamp": "2019-04-16T22:21:36Z", "text": "If you believe looks over functionality, then the Jupyter extension wins.\r\n\r\nVIM and Emacs have no looks. You can only go so far with what's on the outside.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3121", "user": "cui-colin", "root": "ROOT31", "reply_to": "COM3120", "timestamp": "2019-04-16T22:29:37Z", "text": "TBH, you really can't force down the throat of what tastes bland. Some, like me, will complain, others will quietly walk away.\r\n\r\nPeople are more likely to use a product recommended by their friend, than you trying to promote it on your website or social media.\r\n\r\nYour users are your best PR, listen to them! ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3122", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM3121", "timestamp": "2019-04-16T22:35:06Z", "text": "If you don't like the new window, that's fine.\r\n\r\nIf you don't want to give feedback on the new idea, because you just want us to fix the original REPL, that's fine too. \r\n\r\nThe likely plan moving forward is to replace the REPL with the new window though. \r\n\r\nSomething is obviously off with this plan (at least for you). \r\n\r\nI'm trying to figure out what you don't like about it.\r\n\r\nThe information I have so far is:\r\n- The UI isn't what you wanted\r\n- It's slow\r\n- You might as well just use Jupyter\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3123", "user": "cui-colin", "root": "ROOT31", "reply_to": "COM3122", "timestamp": "2019-04-16T22:37:26Z", "text": "Actually, please don't fix it. I am not paying you. And you believe you have the best idea, and that my request is too much.\r\n\r\nHave a good day!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3124", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM3123", "timestamp": "2019-04-16T22:40:36Z", "text": "No I don't believe I have the best idea. If that was the case I would have ignored your request. Why else am I asking for feedback?\r\n\r\nOh actually you also mentioned Matlab or R. Their REPL is what you're asking for?\r\n\r\n\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3125", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM3124", "timestamp": "2019-04-16T22:43:52Z", "text": "I think you have a legitimate concern and I'm sorry if you feel like I'm ignoring you. \r\n\r\nWe really just want to do what it is users want. \r\n\r\nOf course there's time constraints on all of the work we do. \r\n\r\nSo trying to meet user's expectations while also actually shipping stuff is what we attempt to do.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3126", "user": "butterkaffee", "root": "ROOT31", "reply_to": "COM3125", "timestamp": "2021-01-13T08:35:00Z", "text": "> I think you're misunderstanding my intent.\r\n> \r\n> We have this:\r\n> ![image](https://user-images.githubusercontent.com/19672699/56243408-5e29ee80-604f-11e9-9d8a-8225cedcfdf0.png)\r\n> \r\n> I'm suggesting this UI will meet your needs.\r\n> \r\n> If this doesn't meet your needs, are you willing to go into more depth on what you want?\r\n\r\n\r\n@rchiodo \r\nHow can I get to that setup? It looks like what I would need if I can run code fragments in my .py file with a shortcut (like shift+enter in terminal). So far I followed the links you provided and got to this stage \r\n![image](https://user-images.githubusercontent.com/10497301/104426631-7b705180-5582-11eb-8450-1ba1b31ff728.png)\r\n\r\nI don't know how to run code on the left with a shortcut in the interactive window though. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3127", "user": "rchiodo", "root": "ROOT31", "reply_to": "COM3126", "timestamp": "2021-01-13T17:12:05Z", "text": "@butterkaffee you can do a couple of things to get code in a python file to run in the interactive window.\r\n\r\n1. Add the ```# %%``` comment above a group of code you want to mark as a cell. Hit the 'Run Cell' link that appears after that.\r\n![image](https://user-images.githubusercontent.com/19672699/104485477-647c3000-557f-11eb-95e4-860d376dfe19.png)\r\n\r\nActually that seems to be the only one working at the moment. There's supposed to be a command to run the current selection in the interactive window. Thanks for asking as you helped us find a bug.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT32", "user": "CyrusNajmabadi", "root": "ROOT32", "reply_to": null, "timestamp": "2020-12-23T19:59:09Z", "text": "ref-struct errors can be suppressed in VB. ```vb\r Class C\r     Public Shared Sub FooWithoutAnyErrorsOrWarnings()\r #Disable Warning BC40008 ' Type or member is obsolete\r         Foo()\r #Enable Warning BC40008 ' Type or member is obsolete\r     End Sub\r \r     <Obsolete(\"\", False)>\r     Private Shared Sub Foo()\r         Dim x = New Span(Of Byte)({1, 2, 3})\r     End Sub\r End Class\r ```\r \r This turns out to be pretty dangerous.  It's easy to create code now that captures spans and reads/writes from them long after their backing store is invalid:\r \r ```vb\r <Obsolete(\"\", False)>\r Class C\r     Private s As Span(Of Byte)\r \r     Public Sub Capture(s As Span(Of Byte))\r         Me.s = s\r     End Sub\r \r     Public Function Read() As Byte()\r         Return s.ToArray()\r     End Function\r End Class\r ```\r \r This was discovered as a way to workaround the restriction against using ref-structs in VB where lifetimes are not tracked.  However, even though there is no usage of any unsafe apis, it's now trivial to get into very unsafe scenarios that could trivially lead to memory corruption.\r \r When we discussed 'obsolete' as the mechanism to disable access to this type, i'm not sure if it was ever recognized that there was this loophole.  I personally never realized an 'obsolete error' could be suppressed by an 'obsolete warning'.  \r \r Should we introduce a new category of obsolete (similar to how we added diagnostics to them)?  i.e. one that is an error, but is always an error no matter what?", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM320", "user": "CyrusNajmabadi", "root": "ROOT32", "reply_to": "ROOT32", "timestamp": "2020-12-23T19:59:17Z", "text": "Tagging @jaredpar ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM321", "user": "AdamSpeight2008", "root": "ROOT32", "reply_to": "COM320", "timestamp": "2020-12-25T01:54:24Z", "text": "Or you could allow VB.net to **consume** types of this kind.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM322", "user": "CyrusNajmabadi", "root": "ROOT32", "reply_to": "COM321", "timestamp": "2020-12-25T01:57:07Z", "text": "@AdamSpeight2008 i believe the decisoin was already made on that that this was not supported.  Hence the use of ObsoleteAttribute in the first place.  Note that this issue applies to C# as well as VB. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM323", "user": "paul1956", "root": "ROOT32", "reply_to": "COM322", "timestamp": "2020-12-25T09:19:38Z", "text": "The issue is assignment, if all I do is pass a Span or Ref Struct to another API that understands them the concern would not hold. That way VB could access all the New high performance API's and not get into the complexity they require to implement API's using these unsafe features. This is similar as VB's IntPtr it gets from Windows and is only safe to pass back to Windows.\r\n\r\nTo be clear I don't want to write any code in VB that accesses these Obsolete types\r\nThis would be allowed\r\n```\r\nDim json As String = JsonSerializer.Serialize(people, New JsonSerializerOptions With\r\n   {\r\n    .WriteIndented = True,\r\n    .ReferenceHandler = New ReferenceHandler(Of GuidReferenceResolver)\r\n   }\r\n)\r\n\r\n```\r\nObsolete reference would not be allowed to leak out of a statement. so below would not be allowed.\r\n```\r\nDim options As JsonSerializerOptions = New JsonSerializerOptions With\r\n  {\r\n    .WriteIndented = True,\r\n    .ReferenceHandler = New ReferenceHandler(Of GuidReferenceResolver)\r\n  }\r\n\r\nDim json As String = JsonSerializer.Serialize(people, options)\r\n```\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM324", "user": "VBAndCs", "root": "ROOT32", "reply_to": "COM323", "timestamp": "2020-12-25T10:01:23Z", "text": "In fact, VB can't violate ref structs rules, as this throws external runtime exceptions, so, it is not that dangerous as it will not work!\r\nSo, I strongly recommend that you take no action about that. I came up with this Obsolete workaround to allow VB to use important libraries such as System.Text.Json, and it worked. All we need is to read the rsf types, not to copy or box them in any way. We can stick to that and hold responsible for any outcome. \r\nI see no benefits of denying VB access to new .NET core APIs that use ref structs. I found a cheap workaround, but seems @CyrusNajmabadi  wants to put money and effort to take it out of our hands. This seems a loose/loose situation for the team and VB devs, and serves no purpose at all except sending a repeated message that VB is being deliberately killed, otherwise, why it only gets changes when it is not of favor of anyone? \r\nI think VB will do much better if you left it as is. No more damage please.\r\nThanks.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM325", "user": "VBAndCs", "root": "ROOT32", "reply_to": "COM324", "timestamp": "2020-12-25T13:28:25Z", "text": "I think we need to hear VB community voice here:\r\n@Happypig375  @pricerc @hartmair @franzalex  @gilfusion @ekolis @tfukumori @RevensofT @jrmoreno1 @salelele @DzonnyDZ @rskar-git @cristianlt23 @aarondglover @tverweij @KathleenDollard @ocdtrekkie  @Nukepayload2 @vbcodec  @Padanian @sahil48 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM326", "user": "Nukepayload2", "root": "ROOT32", "reply_to": "COM325", "timestamp": "2020-12-25T13:55:00Z", "text": "@CyrusNajmabadi  Please don't change the behavior of `ObsoleteAttribute`. Because my projects are already using obsolete warnings to suppress obsolete errors.\r\nFor example:\r\nhttps://github.com/Nukepayload2/ryu/blob/1a59a71a23e948cf07be0d7d7e8e493f40ad49e5/visualbasic/D2s.vb#L483 \r\n\r\nOur commercial products are also using this behavior to workaround limitations of 3rd-party libraries. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM327", "user": "DzonnyDZ", "root": "ROOT32", "reply_to": "COM326", "timestamp": "2020-12-25T18:12:04Z", "text": "It seems here that Microsoft is taking an active approach to kill VB actively (as opposed to passive approach - just let it die by abandoning it). :-(", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM328", "user": "Padanian", "root": "ROOT32", "reply_to": "COM327", "timestamp": "2020-12-25T18:15:34Z", "text": "Not interested. Unsubscribing.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM329", "user": "CyrusNajmabadi", "root": "ROOT32", "reply_to": "COM328", "timestamp": "2020-12-25T19:20:04Z", "text": ">  Please don't change the behavior of ObsoleteAttribute.\r\n\r\nAs I said:\r\n\r\n> Should we introduce a new category of obsolete (similar to how we added diagnostics to them)? i.e. one that is an error, but is always an error no matter what?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3210", "user": "CyrusNajmabadi", "root": "ROOT32", "reply_to": "COM329", "timestamp": "2020-12-25T19:21:29Z", "text": "> as this throws external runtime exceptions\r\n\r\nThat seems like a worse outcome. Code will compile without any indications if an issue, but then at runtime you will get cryptic runtime errors that don't even indicate where the problem exists. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3211", "user": "CyrusNajmabadi", "root": "ROOT32", "reply_to": "COM3210", "timestamp": "2020-12-25T19:24:48Z", "text": "> I see no benefits of denying VB access to new .NET core APIs that use ref structs.\r\n\r\nThe benefit for me is the clarity that this just isn't supported or usable at all. Rather than being in this position where somethings work, but some do not, and now random cryptic runtime errors might get thrown all over the place. That doesn't seem to be a good thing.  I'd rather this either just be supported and usable, or not supported and not usable.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3212", "user": "CyrusNajmabadi", "root": "ROOT32", "reply_to": "COM3211", "timestamp": "2020-12-25T19:25:16Z", "text": "Locking the convo until the team can decide on the best path forward here. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT33", "user": "dagwieers", "root": "ROOT33", "reply_to": null, "timestamp": "2018-09-27T12:44:17Z", "text": "Feature: Allow until-loops on blocks or includes ##### SUMMARY\r It would be quite useful if you can loop over more than one single tasks.\r \r For instance if you have to poll a remote system for some progress and at the same time you want to push this progress to another backend, you could be doing:\r \r ```yaml\r - hosts: localhost\r   tasks:\r   - name: Start a long-running task\r     uri:\r       url: https://some-service/v1/put/new_job\r       body: { foo: bar }\r     register: new_job\r \r   - until: job_status.json.message in ['Finished', 'Failed']\r     block:\r     - name: Get job status\r       uri:\r         url: https://some-service/v1/get/new_job\r       register: job_status\r \r     - name: Report job status to web service\r       uri:\r         url: https://backend-system/v1/post/job_status\r         body: '{{ job_status.json }}'\r ```\r \r There are many uses to this.\r \r ##### ISSUE TYPE\r - Feature Idea\r \r ##### COMPONENT NAME\r Core", "meta": {"posReactions": "68", "negReactions": "0"}}
{"id": "COM330", "user": "mkrizek", "root": "ROOT33", "reply_to": "ROOT33", "timestamp": "2018-09-27T13:17:02Z", "text": "https://github.com/ansible/ansible/issues/13262", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM331", "user": "dagwieers", "root": "ROOT33", "reply_to": "COM330", "timestamp": "2018-09-27T13:35:34Z", "text": "@mkrizek Hmm, I searched for various combination of keywords, and that one did not stick out :-(\r\n\r\nThat said, I tried using `until:` with `block:`, `include:` and `include_tasks`, but the first one fails, and the 2 others only run the included file once.\r\n\r\n```yaml\r\n- hosts: localhost\r\n  tasks:\r\n  - include: taskboot.yml\r\n    until: 5|random == 5\r\n```\r\n\r\nBut apparently looping only works when using `loop:` ?\r\n\r\n```yaml\r\n- hosts: localhost\r\n  tasks:\r\n  - include: taskboot.yml\r\n    loop: [ 1, 2, 3, 4, 5 ]\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM332", "user": "dagwieers", "root": "ROOT33", "reply_to": "COM331", "timestamp": "2018-09-27T13:38:01Z", "text": "Whatever I try, using `until:` does not work with `include:` and `include_tasks:`.\r\n\r\n```yaml\r\n- hosts: localhost\r\n  tasks:\r\n  - include: taskbook.yml\r\n    until: false\r\n    retries: 5\r\n    delay: 1\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM333", "user": "mkrizek", "root": "ROOT33", "reply_to": "COM332", "timestamp": "2018-09-27T13:54:41Z", "text": "Yeah, `until` is not a valid argument for includes, see https://github.com/ansible/ansible/pull/46177.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM334", "user": "dagwieers", "root": "ROOT33", "reply_to": "COM333", "timestamp": "2018-09-27T13:58:09Z", "text": "@mkrizek In other words, what we need is not possible, neither on blocks or on includes.\r\n\r\nSo I will keep this one open, but changed the title.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM335", "user": "sivel", "root": "ROOT33", "reply_to": "COM334", "timestamp": "2018-09-27T14:10:59Z", "text": "We do have an open proposal to \"taskify\" includes, which would allow things like until to work on them.\r\n\r\nhttps://github.com/ansible/proposals/issues/136\r\n\r\nI, however, do not believe that blocks should be extended to support this feature.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM336", "user": "dagwieers", "root": "ROOT33", "reply_to": "COM335", "timestamp": "2018-09-27T14:15:10Z", "text": "@sivel And what would be the reason for not extending the functionality to blocks ? As it would be a natural thing if it would work. (i.e. being able to loop every construction within a play)", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM337", "user": "bcoca", "root": "ROOT33", "reply_to": "COM336", "timestamp": "2018-09-27T14:17:10Z", "text": "blocks are currently 'static' groupings, enabling loops on them (not just having tasks inherit them) would require making them dynamic ... as we saw with `include:` this has many consequences that are not immediately apparent.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM338", "user": "sivel", "root": "ROOT33", "reply_to": "COM337", "timestamp": "2018-09-27T14:20:58Z", "text": "To extend what @bcoca mentions, doing so would require us to deprecate `block` and replace with something like `block_dynamic` and `block_static`.\r\n\r\nAlso, _every_ user of ansible utilizes blocks, whether explicit, or our internal implicit use of them.  They are a fundamental building block of how tasks are represented and executed.  Changing such an integral feature is sure to lead to unforeseen issues.", "meta": {"posReactions": "3", "negReactions": "1"}}
{"id": "COM339", "user": "dagwieers", "root": "ROOT33", "reply_to": "COM338", "timestamp": "2018-09-28T15:35:37Z", "text": "In any case, the documentation does not give any detail, or even does not discuss what is supposed to work and what not. There's no real distinction between \"loops\" and until-loops, not sure how we can make this more clear overal. The expectation is that what works for \"loops\" also works for until-loops.", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM3310", "user": "bcoca", "root": "ROOT33", "reply_to": "COM339", "timestamp": "2018-09-28T15:46:45Z", "text": "i would do both, allow until/retry loops to work with includes and then clearly document how they work ... so we have something to point at when it does not meet some people's expectations", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM3311", "user": "sivel", "root": "ROOT33", "reply_to": "COM3310", "timestamp": "2018-09-28T16:35:13Z", "text": "Just to provide a small amount of detail about how includes work, is that dynamic includes are more of an internal trigger, as opposed to something that wraps execution.\r\n\r\nAs such, the task_executor short circuits early on an include, indicating to the strategy that it should read a file and insert task blocks into the TQM, that will later be processed by the task_executor.\r\n\r\nDue to this, there is no tracking of state as a roll up to the parent include.  So an until loop, which would rely on some version of a failed when/success scenario, would only refer to whether or not the strategy was told to do as detailed above.  In which case, it should always succeed.\r\n\r\nIn any case, the mode of operation is that we short circuit far before an until conditions are inspected.  If we just \"made it work\" right now, it definitely wouldn't do what a person expects.  To do what people expect, would require ansible/proposals#136 to be implemented.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3312", "user": "bcoca", "root": "ROOT33", "reply_to": "COM3311", "timestamp": "2018-09-28T16:38:07Z", "text": "the until in this case would have to rely on vars set or registered from the included tasks as the registration of the include itself would be useless ... it would still 'work' just not how most other cases do.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3313", "user": "dreamcat4", "root": "ROOT33", "reply_to": "COM3312", "timestamp": "2018-09-28T21:01:02Z", "text": "@dagwieers The other thread is locked now. But this recent suggestion (@sivel comment above) is brand new:\r\n\r\nhttps://github.com/ansible/ansible/issues/46203#issuecomment-425111123\r\n\r\nAnd you are saying we might want to leave open the possibility of someone else coming along later, to do a PR for looping over blocks off their own backs. Then at least we could make it crystal clear to them, as to make it as a separate and new `block_dynamic:`, and not touching the traditional static `block:` intact? Would that not make more sense to everybody ? Can we all agree upon that ahead of time? Because I agree with this idea. For all the same reasons - it's going to help prevent breaking other existing stuff which we rely on. Whilst still allowing the possibility of someone to come along, try making a PR for actually implementing it. Should we really want them to be making the best possible job and such. Then we should at least be clearly specifying this. If we already know that ahead of time. Which seems to be the case now? ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3314", "user": "mkrizek", "root": "ROOT33", "reply_to": "COM3313", "timestamp": "2018-10-31T14:29:00Z", "text": "Linking this here https://github.com/ansible/ansible/issues/16621", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3315", "user": "deatheros", "root": "ROOT33", "reply_to": "COM3314", "timestamp": "2018-11-05T13:00:06Z", "text": "+1 For implementing this feature", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM3316", "user": "ramon-garcia", "root": "ROOT33", "reply_to": "COM3315", "timestamp": "2018-11-30T16:24:45Z", "text": "It is natural that a block should be repeatable. Otherwise, it is very counterintuitive. It confuses.\r\n\r\nAnd there seems to be no way to write a playbook with loop with more than one statement. No programming language is so limited.", "meta": {"posReactions": "25", "negReactions": "0"}}
{"id": "COM3317", "user": "ramon-garcia", "root": "ROOT33", "reply_to": "COM3316", "timestamp": "2018-11-30T21:02:25Z", "text": "It looks like in Ansible, if one needs to do something complex, one should write an action plugin. This is what we are going to do.\r\n\r\nHere one has many examples:\r\nhttps://github.com/ansible/ansible/tree/devel/lib/ansible/plugins/action\r\n\r\nBest regards", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3318", "user": "Freeze", "root": "ROOT33", "reply_to": "COM3317", "timestamp": "2019-03-26T20:48:14Z", "text": "This is absolutely a shortcoming.  Ansible has been perfect for most of my needs so far, but it seems like expanding the capabilities of blocks would make Ansible a lot better solution. ", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM3319", "user": "lucasbasquerotto", "root": "ROOT33", "reply_to": "COM3318", "timestamp": "2019-03-26T23:37:19Z", "text": "I tried to use `until` in a `include_tasks` and it didn't worked. \r\n\r\nWhat I did as a workaround was to create a yml file that include the task (`loop.yml`) and call itself recursively (`recursive.yml`) while the condition is still not satisfied.\r\n\r\n_recursive.yml:_\r\n\r\n```yml\r\n---\r\n\r\n- name: 'checking {{ watch_job }} status (recursive)'\r\n  include_tasks: 'loop.yml'\r\n\r\n- name: 'count ({{ watch_count | int + 1 }})'\r\n  set_fact:\r\n    watch_count: '{{ watch_count | int + 1 }}'\r\n\r\n- name: 'retries ({{ (watch_timeout | int / watch_poll | int) | int }})'\r\n  set_fact:\r\n    watch_retries: '{{ (watch_timeout | int / watch_poll | int) | int }}'\r\n\r\n- name: 'timeout ({{ watch_timeout }} seconds)'\r\n  fail: \r\n    msg: \"Timeout of {{ watch_timeout }} seconds exceeded ({{ watch_retries }} retries)\"\r\n  when: (not watch_status.finished) and (watch_count | int > watch_retries | int)\r\n\r\n- name: 'wait for {{ watch_poll }} seconds'\r\n  wait_for:\r\n    timeout: '{{ watch_poll | int }}'\r\n  when: not watch_status.finished\r\n\r\n- name: 'call itself recursively'\r\n  include_tasks: 'recursive.yml'\r\n  when: not watch_status.finished\r\n```\r\n\r\nIn the above file, I included a timeout in the case of taking too long (this is in a role that [shows the output of what is running in the hosts](https://github.com/ansible/ansible/issues/30411#issuecomment-471277785)).\r\n\r\nNot the ideal solution, but worked for me and was relatively easy to change using `until` to do the above.", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM3320", "user": "efazenda", "root": "ROOT33", "reply_to": "COM3319", "timestamp": "2019-05-07T09:11:49Z", "text": "+1 for this feature !", "meta": {"posReactions": "6", "negReactions": "5"}}
{"id": "COM3321", "user": "woopstar", "root": "ROOT33", "reply_to": "COM3320", "timestamp": "2019-05-07T20:16:18Z", "text": "+1", "meta": {"posReactions": "6", "negReactions": "5"}}
{"id": "COM3322", "user": "wahab-icp", "root": "ROOT33", "reply_to": "COM3321", "timestamp": "2019-05-27T15:44:08Z", "text": "+1 for until loops on blocks", "meta": {"posReactions": "1", "negReactions": "5"}}
{"id": "COM3323", "user": "matanbaru", "root": "ROOT33", "reply_to": "COM3322", "timestamp": "2019-05-28T14:38:49Z", "text": "I have been searching a way to do `until` (infinitely) for a success on all modules on the block and I managed to do this with `include_tasks` with `rescue`\r\n\r\nI could not use regular `until` because the IP is changing over time and had to modify it on the run\r\n\r\n> wait_until_success.yml\r\n\r\n```\r\n- name: 'Wait until success'\r\n  block:\r\n    - name: Get server updated ip\r\n      uri:\r\n        url: https://localhost/ip\r\n        return_content: yes\r\n        status_code: 200\r\n      register: ip\r\n\r\n    - name: ssh to the server\r\n      wait_for:\r\n        host: \"{{ ip }}\"\r\n        port: 22\r\n        timeout: 30\r\n        state: started\r\n  rescue:\r\n    - debug:\r\n        msg: \"Failed to connect - Retrying...\"\r\n    - include_tasks: wait_until_success.yml\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3324", "user": "Ovski4", "root": "ROOT33", "reply_to": "COM3323", "timestamp": "2019-11-20T13:56:11Z", "text": "Same as @matanbaru with a way to fail after multiple retries\r\n\r\n```yml\r\n- name: 'Wait until success'\r\n  block:\r\n    - name: Set the retry count\r\n      set_fact:\r\n        retry_count: \"{{ 0 if retry_count is undefined else retry_count|int + 1 }}\"\r\n\r\n    - name: Get server updated ip\r\n      uri:\r\n        url: https://localhost/ip\r\n        return_content: yes\r\n        status_code: 200\r\n      register: ip\r\n\r\n    - name: ssh to the server\r\n      wait_for:\r\n        host: \"{{ ip }}\"\r\n        port: 22\r\n        timeout: 30\r\n        state: started\r\n  rescue:\r\n    - fail:\r\n        msg: Ended after 5 retries\r\n      when: retry_count|int == 5\r\n\r\n    - debug:\r\n        msg: \"Failed to connect - Retrying...\"\r\n\r\n    - include_tasks: wait_until_success.yml\r\n```", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM3325", "user": "frsauvage", "root": "ROOT33", "reply_to": "COM3324", "timestamp": "2020-06-21T06:27:26Z", "text": "+1 could you please add retry-until in loops !\r\nAbsolutely \"Must Have\" feature !", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM3326", "user": "chris93111", "root": "ROOT33", "reply_to": "COM3325", "timestamp": "2020-07-03T22:10:03Z", "text": "+1\r\n", "meta": {"posReactions": "1", "negReactions": "2"}}
{"id": "COM3327", "user": "karolyi", "root": "ROOT33", "reply_to": "COM3326", "timestamp": "2020-07-29T16:46:36Z", "text": "+1", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3328", "user": "sivel", "root": "ROOT33", "reply_to": "COM3327", "timestamp": "2020-07-29T16:50:34Z", "text": "I've locked this to contributors for now.  Adding `+1` comments is too noisy.  For future reference, add a reaction to the issue body, and don't comment.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT34", "user": "Danielx64", "root": "ROOT34", "reply_to": null, "timestamp": "2019-12-19T10:22:04Z", "text": "The removal of Santa Hat on vscode insiders is very offensive and has nothing to do with religion  \r Steps to Reproduce:\r Install latest build of insiders.\r \r Does this issue occur when all extensions are disabled?: No\r \r Sorry but the guy who created https://github.com/microsoft/vscode/issues/87268 has it all wrong. Having a santa hat on a cog icon (to go to settings/options) has nothing to do with religion in any shape or form.\r \r I find it offensive that the hat was removed and it should never have been removed in the first place.\r ", "meta": {"posReactions": "144", "negReactions": "1"}}
{"id": "COM340", "user": "vscodebot[bot]", "root": "ROOT34", "reply_to": "ROOT34", "timestamp": "2019-12-19T10:22:10Z", "text": "(Experimental duplicate detection)\nThanks for submitting this issue. Please also check if it is already covered by an existing one, like:\n- [Removal of the Santa hat and kowtowing to a single fake user is offensive to me (#87328)](https://www.github.com/microsoft/vscode/issues/87328) <!-- score: 0.579 -->\n- [Removal of the Santa Hat on vscode insiders is very offensive to me (#87296)](https://www.github.com/microsoft/vscode/issues/87296) <!-- score: 0.567 -->\n- [Santa Hat on vscode insiders and pushing of religion is very offensive to me (#87268)](https://www.github.com/microsoft/vscode/issues/87268) <!-- score: 0.526 -->\n- [Santa Hat removal on vscode insiders and bending to one jew is very offensive to me (#87291)](https://www.github.com/microsoft/vscode/issues/87291) <!-- score: 0.504 -->\n- [Removal of the Santa Hat and kowtowing to SJWs (#87314)](https://www.github.com/microsoft/vscode/issues/87314) <!-- score: 0.47 -->\n<!-- potential_duplicates_comment -->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM341", "user": "arkadiuszwojcik", "root": "ROOT34", "reply_to": "COM340", "timestamp": "2019-12-19T10:53:37Z", "text": "Two more things to add. @Christian-Schiffer have something against santa hat and releats it to religion. Pardon me but he dosn't distinguish between Saint Nicholas that was bishop and had totally diffrent hat and Santa Claus from popular culture who have other hat. Besides his name \"Christian\" smells like some kind of religious agitation and I think he should remove his account or be baned by highter autorities using his own argumentation preented in issue #87268 . Should I create separate issue for that?", "meta": {"posReactions": "36", "negReactions": "1"}}
{"id": "COM342", "user": "MaKiPL", "root": "ROOT34", "reply_to": "COM341", "timestamp": "2019-12-19T10:56:12Z", "text": "User Christian-Schiffer that created such awful request offended many users and Microsoft just standing there like nothing happened. Bring back the Santa's hat!", "meta": {"posReactions": "19", "negReactions": "1"}}
{"id": "COM343", "user": "MaKiPL", "root": "ROOT34", "reply_to": "COM342", "timestamp": "2019-12-19T10:59:33Z", "text": "to also add to that- The original requestor for this ridiculous change has 14 repositories from which 13 are forks. I doubt he's even a developer, just random troll that you- Microsoft fell for. Shame", "meta": {"posReactions": "14", "negReactions": "1"}}
{"id": "COM344", "user": "prometheus61", "root": "ROOT34", "reply_to": "COM343", "timestamp": "2019-12-19T11:07:41Z", "text": "I liked the santa hat, it brought a little joy to my day. Very sad that it has been removed.", "meta": {"posReactions": "11", "negReactions": "1"}}
{"id": "COM345", "user": "Hissvard", "root": "ROOT34", "reply_to": "COM344", "timestamp": "2019-12-19T11:07:52Z", "text": "I demand syntax highlighting be removed, as it reminds me of the other night when I puked out the three plates of ravioli I'd eaten. It is very offensive to me and instantly brings back memories of a very bad stomachache.\r\n\r\nSee this? That's how silly that was. We can't take people seriously just because they slap religion on something completely unrelated and pretend it's a serious issue.\r\n\r\nThat's offensive to **real** religious issues if anything. That's how real issues end up being taken as jokes.", "meta": {"posReactions": "13", "negReactions": "1"}}
{"id": "COM346", "user": "Phillipus", "root": "ROOT34", "reply_to": "COM345", "timestamp": "2019-12-19T11:34:35Z", "text": "I find the \"V\" in \"VS Code\" offensive. It represents two fingers being held up in an obscene gesture and could be read as \"F*ck You\".", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM347", "user": "leonardodelfinodev", "root": "ROOT34", "reply_to": "COM346", "timestamp": "2019-12-19T11:47:53Z", "text": "I agree. Nowadays everyone is offended by everything. The fact that he doesn't like the hat has nothing to do with religion. I find Hissvard's comment \"That's offensive to real religious issues\" completely right. There are real religious issues by now, and classifying such a thing (the hat) as \"offensive\" should be considered shameful.", "meta": {"posReactions": "10", "negReactions": "1"}}
{"id": "COM348", "user": "ip413", "root": "ROOT34", "reply_to": "COM347", "timestamp": "2019-12-19T12:03:10Z", "text": "Sad thing is that some of us are afraid of writing anything about it and they are writing from newly created accounts and... and I understand it. No one know who will be targeted and his life/career be destroyed by \"tolerance troops\" which have nothing to do with tolerance.\r\n\r\nWe are going into very, very gloomy era. \r\nChinese government (which is widely criticized by us) is doing the very same thing as \"political correctness\" is doing to us.\r\n\r\n**Whoever is afraid is a slave** - Seneca the Younger\r\nAnd we all are afraid - especially MS, as we could see.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM349", "user": "wolfensg", "root": "ROOT34", "reply_to": "COM348", "timestamp": "2019-12-19T13:21:34Z", "text": "UpVote for Santa Hat! \ud83c\udf85 Bring it back! Don't fall for the troll!", "meta": {"posReactions": "2", "negReactions": "2"}}
{"id": "COM3410", "user": "dioptryk", "root": "ROOT34", "reply_to": "COM349", "timestamp": "2019-12-19T13:41:45Z", "text": "We're moving to digital totalitarianism, pure and simple. In totalitarian state, anyone who voiced a different opinion than the state's, was forcibly silenced or 'disappeared'. Now, we have threads locked, accounts banned and single people deciding what's best for entire communities based on their 'feelings'. Well, I 'feel' it's pure evil masquerading as tolerance.", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM3411", "user": "shakeyourbunny", "root": "ROOT34", "reply_to": "COM3410", "timestamp": "2019-12-19T14:07:59Z", "text": "It is very telling the true colours on the side of the Microsoft team that this is still up in the air instead of making - as it would be a proper reaction - to write a short apology for the mistake, revert the change and be done with it. \r\n\r\nAdded bonus would have been that the whole issue would be forgotten for everyone in some days. \r\n\r\nSo, this leaves a very sour taste regarding the whole thing and it has already the very opposite intented effect of \"quick political correct reaction and stay clean\" for the whole Microsoft and only will be worse if this will not be corrected and sit out.\r\n\r\n\"Microsoft the Christmas Killer / Santa Killer\" in the press... not a nice thought and I guess this has the potential to escalate to widely known bad press for the organisation.\r\n\r\nMy advice to the managing team here:\r\n- don't wait it out and don't try to purge the taint when nobody's looking.\r\n- reinstate  the santa hat, at least make it a togglable option (default: on)\r\n- write a short paragraph that it was a mistake, include some funny joke for deescalation.\r\n- be done with it.\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM3412", "user": "chrisdias", "root": "ROOT34", "reply_to": "COM3411", "timestamp": "2019-12-19T21:53:39Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines. \r\n\r\nHappy Coding! ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT35", "user": "Danielx64", "root": "ROOT35", "reply_to": null, "timestamp": "2019-12-19T10:33:00Z", "text": "Please don't remove the dark theme, because it will make it harder to read large block of code. The title pretty much says what needed to be said. Having a white background with different coloured text can make thing extremely hard to read and can do more harm to your eyes than having a black (or dark grey) background with different coloured text makes it far easier to read.", "meta": {"posReactions": "2", "negReactions": "2"}}
{"id": "COM350", "user": "dbaeumer", "root": "ROOT35", "reply_to": "ROOT35", "timestamp": "2019-12-19T10:49:25Z", "text": "@Danielx64 can you please explain what exactly you are concerned about. We don't have any plans to remove the dark theme.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM351", "user": "Danielx64", "root": "ROOT35", "reply_to": "COM350", "timestamp": "2019-12-19T10:51:40Z", "text": "> \r\n> \r\n> @Danielx64 can you please explain what exactly you are concerned about. We don't have any plans to remove the dark theme.\r\n\r\nThere's this issue (https://github.com/microsoft/vscode/issues/87341 ) asking for dark theme to be removed.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM352", "user": "Glamhoth", "root": "ROOT35", "reply_to": "COM351", "timestamp": "2019-12-19T10:52:57Z", "text": "Is this even one more layer of trolling?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM353", "user": "Danielx64", "root": "ROOT35", "reply_to": "COM352", "timestamp": "2019-12-19T10:54:06Z", "text": "> \r\n> \r\n> Is this even one more layer of trolling?\r\n\r\nThis issue, no, it was a big concern till @dbaeumer stated that they have no plans to remove the dark theme.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM354", "user": "jedenastka", "root": "ROOT35", "reply_to": "COM353", "timestamp": "2019-12-19T13:02:54Z", "text": "r/woooosh", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM355", "user": "chrisdias", "root": "ROOT35", "reply_to": "COM354", "timestamp": "2019-12-19T19:00:45Z", "text": "We are not removing the dark theme, sorry for the confusion.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT36", "user": "DaniilAnichin", "root": "ROOT36", "reply_to": null, "timestamp": "2020-12-25T12:54:33Z", "text": "Last jedi release (0.18.0) is incompatible with ipython (7.19 and 7.18 tested); reason - column arg was deprecated, and now removed <!-- This is the repository for IPython command line, if you can try to make sure this question/bug/feature belong here and not on one of the Jupyter repositories. \r \r If it's a generic Python/Jupyter question, try other forums or discourse.jupyter.org.\r \r If you are unsure, it's ok to post here, though, there are few maintainer so you might not get a fast response. \r \r Ability of maintainers to spend time and resources on project like IPython is heavily influenced by US politics, and the current government policies have been harmful to the IPython Maintainers and Community. \r \r If you are on the fence on who to vote for or wether to vote, please cast your vote in for the democrat party in the US.\r -->\r Relevant traceback reads as follows: \r ```\r   File \"../venv/lib/python3.8/site-packages/IPython/core/completer.py\", line 2029, in _complete\r     completions = self._jedi_matches(\r   File \"../venv/lib/python3.8/site-packages/IPython/core/completer.py\", line 1373, in _jedi_matches\r     interpreter = jedi.Interpreter(\r   File \"../venv/lib/python3.8/site-packages/jedi/api/__init__.py\", line 725, in __init__\r     super().__init__(code, environment=environment,\r TypeError: __init__() got an unexpected keyword argument 'column'\r ```\r \r sys info: \r ```\r {'commit_hash': '62779a198',\r  'commit_source': 'installation',\r  'default_encoding': 'utf-8',\r  'ipython_path': '../venv/lib/python3.8/site-packages/IPython',\r  'ipython_version': '7.18.0',\r  'os_name': 'posix',\r  'platform': 'Linux-4.15.0-128-generic-x86_64-with-glibc2.17',\r  'sys_executable': '../venv/bin/python',\r  'sys_platform': 'linux',\r  'sys_version': '3.8.5 (default, Jul 20 2020, 19:50:14) \\n[GCC 5.4.0 20160609]'}\r ```\r same reported in jedi repo too", "meta": {"posReactions": "251", "negReactions": "0"}}
{"id": "COM360", "user": "benwu95", "root": "ROOT36", "reply_to": "ROOT36", "timestamp": "2020-12-25T17:15:20Z", "text": "https://github.com/ipython/ipython/commit/dcd9dc90aee7e4c5c52ce44c18e7518934790612\r\n\r\nThe code has been already updated, but `7.19.0` did not include this. :(", "meta": {"posReactions": "17", "negReactions": "0"}}
{"id": "COM361", "user": "davidhalter", "root": "ROOT36", "reply_to": "COM360", "timestamp": "2020-12-25T17:20:36Z", "text": "As a temporary fix for anyone just trying to get things working again:\r\n\r\n```\r\npip install jedi==0.17.2\r\n```\r\n\r\n----\r\n\r\nIt would be really nice if you could quickly release a 7.19.1. (It's already fixed on master).\r\n\r\nSorry for that. I did not realize that IPython with that fix was not released yet. I usually test IPython completions before doing a Jedi release, but not this time :/. It will probably also not happen in the future anymore, because I'm going to release Jedi 1.0 soon, so this is probably the last time for a long time that you have to deal with deprecations in Jedi.\r\n\r\nStill wish you a Merry Christmas!", "meta": {"posReactions": "239", "negReactions": "0"}}
{"id": "COM362", "user": "davidhalter", "root": "ROOT36", "reply_to": "COM361", "timestamp": "2020-12-25T17:26:00Z", "text": "By the way, a `7.19.1` release with the dependency `jedi<0.18.0` would also suffice.", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM363", "user": "jkryanchou", "root": "ROOT36", "reply_to": "COM362", "timestamp": "2020-12-27T04:33:25Z", "text": "@davidhalter Thanks for your solution. it finally work.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM364", "user": "SamuelDSR", "root": "ROOT36", "reply_to": "COM363", "timestamp": "2020-12-27T14:53:49Z", "text": "I had the same problem with ipython and thanks to the solution of @davidhalter , it works again. :+1: ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM365", "user": "digglife", "root": "ROOT36", "reply_to": "COM364", "timestamp": "2020-12-28T07:28:08Z", "text": "Thank you for opening this issue.  Happy holiday!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM366", "user": "yurzo", "root": "ROOT36", "reply_to": "COM365", "timestamp": "2020-12-28T23:57:08Z", "text": "Posted a pr to pin the dependency as suggested: #12746", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM367", "user": "bremme", "root": "ROOT36", "reply_to": "COM366", "timestamp": "2020-12-29T02:25:19Z", "text": "Thanks a lot. I thought my shell was broken. Every time when I tried to use tab completion in IPython it crashed. Glad I found a solution.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM368", "user": "aprilahijriyan", "root": "ROOT36", "reply_to": "COM367", "timestamp": "2020-12-29T05:05:58Z", "text": "Finally found a solution! thank you @davidhalter \ud83c\udf89 ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM369", "user": "tik9", "root": "ROOT36", "reply_to": "COM368", "timestamp": "2020-12-31T19:47:45Z", "text": "When would the problem be fixed so that every Jedi version is compatible with ipython?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3610", "user": "NeilGirdhar", "root": "ROOT36", "reply_to": "COM369", "timestamp": "2020-12-31T23:52:55Z", "text": "@tik9 Does installing from master work for you?\r\n\r\n    pip install git+https://github.com/ipython/ipython\r\n\r\nIf so, whenever ipython releases a new version, it will be fixed for everyone.", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM3611", "user": "tik9", "root": "ROOT36", "reply_to": "COM3610", "timestamp": "2021-01-01T11:07:25Z", "text": "@NeilGirdhar , when doing\r\n`pip install git+https://github.com/ipython/ipython`\r\n\r\nIt seems to work, I still have to update to the current Jedi.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM3612", "user": "omarish", "root": "ROOT36", "reply_to": "COM3611", "timestamp": "2021-01-03T02:12:41Z", "text": "Got this issue as well. Pinning `jedi==0.17.2` worked for me, thanks @davidhalter.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3613", "user": "stefanschlipfi", "root": "ROOT36", "reply_to": "COM3612", "timestamp": "2021-01-03T13:05:27Z", "text": "> As a temporary fix for anyone just trying to get things working again:\r\n> \r\n> ```\r\n> pip install jedi==0.17.2\r\n> ```\r\n> \r\n> It would be really nice if you could quickly release a 7.19.1. (It's already fixed on master).\r\n> \r\n> Sorry for that. I did not realize that IPython with that fix was not released yet. I usually test IPython completions before doing a Jedi release, but not this time :/. It will probably also not happen in the future anymore, because I'm going to release Jedi 1.0 soon, so this is probably the last time for a long time that you have to deal with deprecations in Jedi.\r\n> \r\n> Still wish you a Merry Christmas!\r\n\r\nThank you for your solution.\r\nI got the same issue and IPython worked after I installed Jedi", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3614", "user": "nicksama88", "root": "ROOT36", "reply_to": "COM3613", "timestamp": "2021-01-04T02:03:25Z", "text": "installing 0.17.2 of jedi also worked for me.  Was chasing my tail trying to figure out why it wasn't working in a new virtual environment, glad to have found this!  Hope the fix is out soon.  Luckily this showed up as the top link in Google for me when searching \"ipython init got an unexpected keyword argument 'column'\".", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM3615", "user": "bl-ue", "root": "ROOT36", "reply_to": "COM3614", "timestamp": "2021-01-04T15:30:44Z", "text": "This works:\r\n```console\r\n$ pip install 'jedi<0.18'\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3616", "user": "ABODFTW", "root": "ROOT36", "reply_to": "COM3615", "timestamp": "2021-01-04T15:54:29Z", "text": "Thanks @bl-ue\r\n\r\nFor reference, the autocomplete on my Jupyter notebook wasn't working and I was getting this same error on the terminal.\r\n\r\nAnd now it's working as expected after downgrading jedi to 0.17.2 by just executing the command @bl-ue mentioned.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM3617", "user": "BallsyWalnuts", "root": "ROOT36", "reply_to": "COM3616", "timestamp": "2021-01-05T13:10:27Z", "text": "Confirmed that downgrading jedi to `0.17.2` fixed the issue for me as well. Thanks @davidhalter ", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM3618", "user": "gabrielebndn", "root": "ROOT36", "reply_to": "COM3617", "timestamp": "2021-01-05T18:57:28Z", "text": "Hi everyone, I've stumbled on this issue while creating docker images for myself.\r\nIf I understand correctly from [this comment](https://github.com/ipython/ipython/issues/12740#issuecomment-751273086) the problem has already been solved on master, but so far no release including the fix has been issued.\r\nIn order to better organize my own work, may I know when do you plan a new release? Somebody [here](https://github.com/ipython/ipython/issues/12740#issuecomment-751273584) was suggesting to quickly release 7.19.1, including this patch, is it still an option?", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM3619", "user": "HosseinDahaei", "root": "ROOT36", "reply_to": "COM3618", "timestamp": "2021-01-07T19:06:42Z", "text": "> As a temporary fix for anyone just trying to get things working again:\r\n> \r\n> ```\r\n> pip install jedi==0.17.2\r\n> ```\r\n> \r\n> It would be really nice if you could quickly release a 7.19.1. (It's already fixed on master).\r\n> \r\n> Sorry for that. I did not realize that IPython with that fix was not released yet. I usually test IPython completions before doing a Jedi release, but not this time :/. It will probably also not happen in the future anymore, because I'm going to release Jedi 1.0 soon, so this is probably the last time for a long time that you have to deal with deprecations in Jedi.\r\n> \r\n> Still wish you a Merry Christmas!\r\n\r\nthanks a lot", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM3620", "user": "LuanComputacao", "root": "ROOT36", "reply_to": "COM3619", "timestamp": "2021-01-09T16:45:50Z", "text": "pip install -U jedi==0.17.2 parso==0.7.1", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3621", "user": "mostealth", "root": "ROOT36", "reply_to": "COM3620", "timestamp": "2021-01-11T09:12:16Z", "text": "I wonder, when you have a dependency (jedi) that is in version 0.x.y (not reached major 1), if it is not wiser to pin the minor as >=0.17,<0.18.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM3622", "user": "yurzo", "root": "ROOT36", "reply_to": "COM3621", "timestamp": "2021-01-11T17:39:25Z", "text": "FYI https://github.com/ipython/ipython/pull/12751#issuecomment-758065462", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM3623", "user": "violet4", "root": "ROOT36", "reply_to": "COM3622", "timestamp": "2021-01-13T23:40:31Z", "text": "> As a temporary fix for anyone just trying to get things working again:\r\n> \r\n> ```\r\n> pip install jedi==0.17.2\r\n> ```\r\n> \r\n> It would be really nice if you could quickly release a 7.19.1. (It's already fixed on master).\r\n> \r\n> Sorry for that. I did not realize that IPython with that fix was not released yet. I usually test IPython completions before doing a Jedi release, but not this time :/. It will probably also not happen in the future anymore, because I'm going to release Jedi 1.0 soon, so this is probably the last time for a long time that you have to deal with deprecations in Jedi.\r\n> \r\n> Still wish you a Merry Christmas!\r\n\r\nnote: in anaconda, this has to be done in the same kernel you're using from within the jupyter notebook, not the one you're using the `jupyter notebook` command from!\r\n\r\ntook me about 30 minutes to finally figure that one out once i found @davidhalter's pip install tip (i used `conda install jedi==0.17.2` instead of pip).\r\n\r\nthank you all!", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM3624", "user": "gapster", "root": "ROOT36", "reply_to": "COM3623", "timestamp": "2021-01-15T17:24:05Z", "text": "Can you explain what you mean by \"same kernel ...\" vs \"using the jupyter notebook ...\"   i.e.,  will conda install jedi==0.17.2 from the shell command line do the trick?  (it seems to)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3625", "user": "marvinbernhardt", "root": "ROOT36", "reply_to": "COM3624", "timestamp": "2021-01-16T22:26:28Z", "text": "> Can you explain what you mean by \"same kernel ...\" vs \"using the jupyter notebook ...\" i.e., will conda install jedi==0.17.2 from the shell command line do the trick? (it seems to)\r\n\r\nYou can run Jupyter in one env and use it with a kernel from another env. See for example [this SO question](https://stackoverflow.com/questions/53004311/how-to-add-conda-environment-to-jupyter-lab). Jedi version of the latter env matters. If you are not aware of this, you probably use one conda env for jupyter and kernel.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM3626", "user": "dowenk", "root": "ROOT36", "reply_to": "COM3625", "timestamp": "2021-01-19T18:00:21Z", "text": "The following works in ipython/jupyter.   I assume it gets jedi out of the way of the built-in completer.   Good enough for me until fix is released.\r\n\r\n%config Completer.use_jedi = False\r\n", "meta": {"posReactions": "7", "negReactions": "2"}}
{"id": "COM3627", "user": "bl-ue", "root": "ROOT36", "reply_to": "COM3626", "timestamp": "2021-01-20T14:05:31Z", "text": "It does work! \ud83d\udc4d\ud83c\udffb \r\nNice find @dowenk! \ud83d\ude0d ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3628", "user": "davidhalter", "root": "ROOT36", "reply_to": "COM3627", "timestamp": "2021-01-20T17:37:46Z", "text": "Because people at this point probably don't scroll up to my comment (https://github.com/ipython/ipython/issues/12740#issuecomment-751273584), this is what you should do temporarily:\r\n\r\n```\r\npip install jedi==0.17.2\r\n```", "meta": {"posReactions": "16", "negReactions": "0"}}
{"id": "COM3629", "user": "bl-ue", "root": "ROOT36", "reply_to": "COM3628", "timestamp": "2021-01-23T21:39:34Z", "text": "When is the team going to fix this? In just a month hundreds of users have encountered this issue.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "ROOT37", "user": "DartBot", "root": "ROOT37", "reply_to": null, "timestamp": "2013-04-28T07:35:03Z", "text": "Dart VM on FreeBSD _This issue was originally filed by efes...&#064;gmail.com_  ---  Is there posibility that Dart VM will support BSD (like Go)? ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM370", "user": "kasperl", "root": "ROOT37", "reply_to": "ROOT37", "timestamp": "2013-04-29T12:32:42Z", "text": "_Added [Area-VM](../labels/Area-VM), [Triaged](../labels/Triaged) labels._\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM371", "user": "iposva-google", "root": "ROOT37", "reply_to": "COM370", "timestamp": "2013-06-05T21:20:29Z", "text": "_Removed [Priority-Medium](../labels/Priority-Medium) label._\n_Added [Priority-Unassigned](../labels/Priority-Unassigned) label._\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM372", "user": "DartBot", "root": "ROOT37", "reply_to": "COM371", "timestamp": "2014-01-22T03:24:57Z", "text": "_This comment was originally written by beatg...&#064;gmail.com_\n\n---\n\nI got this error on a gclient runhooks:\n\n________ running '/usr/local/bin/python dart/tools/gyp_dart.py runtime' in '/usr/home/otto'\ngyp: Undefined variable dart_target_os in dart/runtime/dart-runtime.gyp while trying to load dart/runtime/dart-runtime.gyp\nError: Command /usr/local/bin/python dart/tools/gyp_dart.py runtime returned non-zero exit status 1 in /usr/home/otto\n\nIt looks like it's not set up to run on FreeBSD, but I don't know where to make changes (I don't know anything about gyp).\n\nI searched for dart_target_os, and I found tools/gyp/configurations.gypi, which seemed like the place to add something in (configurations.gypi.patch, it's not very interesting). When I did this, I got the following error:\n\n________ running '/usr/local/bin/python dart/tools/gyp_dart.py runtime' in '/usr/home/otto'\nTraceback (most recent call last):\n&nbsp;&nbsp;File \"dart/third_party/gyp/gyp_main.py\", line 18, in &lt;module>\n&nbsp;&nbsp;&nbsp;&nbsp;sys.exit(gyp.script_main())\n&nbsp;&nbsp;File \"dart/third_party/gyp/pylib/gyp/**init**.py\", line 547, in script_main\n&nbsp;&nbsp;&nbsp;&nbsp;return main(sys.argv[1:])\n&nbsp;&nbsp;File \"dart/third_party/gyp/pylib/gyp/**init**.py\", line 540, in main\n&nbsp;&nbsp;&nbsp;&nbsp;return gyp_main(args)\n&nbsp;&nbsp;File \"dart/third_party/gyp/pylib/gyp/**init**.py\", line 516, in gyp_main\n&nbsp;&nbsp;&nbsp;&nbsp;options.circular_check)\n&nbsp;&nbsp;File \"dart/third_party/gyp/pylib/gyp/**init**.py\", line 131, in Load\n&nbsp;&nbsp;&nbsp;&nbsp;params['parallel'])\n&nbsp;&nbsp;File \"dart/third_party/gyp/pylib/gyp/input.py\", line 2714, in Load\n&nbsp;&nbsp;&nbsp;&nbsp;SetUpConfigurations(target, target_dict)\n&nbsp;&nbsp;File \"dart/third_party/gyp/pylib/gyp/input.py\", line 2175, in SetUpConfigurations\n&nbsp;&nbsp;&nbsp;&nbsp;target_dict, configuration, [])\n&nbsp;&nbsp;File \"dart/third_party/gyp/pylib/gyp/input.py\", line 2116, in MergeConfigWithInheritance\n&nbsp;&nbsp;&nbsp;&nbsp;target_dict, parent, visited + [configuration])\n&nbsp;&nbsp;File \"dart/third_party/gyp/pylib/gyp/input.py\", line 2116, in MergeConfigWithInheritance\n&nbsp;&nbsp;&nbsp;&nbsp;target_dict, parent, visited + [configuration])\n&nbsp;&nbsp;File \"dart/third_party/gyp/pylib/gyp/input.py\", line 2111, in MergeConfigWithInheritance\n&nbsp;&nbsp;&nbsp;&nbsp;configuration_dict = target_dict['configurations'][configuration]\nKeyError: 'Dart_FreeBSD_Base'\nError: Command /usr/local/bin/python dart/tools/gyp_dart.py runtime returned non-zero exit status 1 in /usr/home/otto\n\nIt looks like the string Dart_FreeBSD_Base is dynamically generated from dart_target_os, but I wasn't sure where to define it. I feel like I'm going down a deep rabbit hole that won't lead me to the solution. I'm sure it's easy, I just don't know where to look.\n\nI don't know anything about gclient or gyp, and I didn't see any documentation in the repo to lead me in the right direction (except the README, which tells me I should be looking in tools/).\n\nIf I get time, I'll try to wrap my head around gyp and see if I can figure out where to go from here. Issue #6929 would make this *much* easier (something like chromium's source tarballs that Arch Linux uses).\n\n---\n\n**Attachment:**\n[configurations.gypi.patch](https://storage.googleapis.com/google-code-attachments/dart/issue-10260/comment-4/configurations.gypi.patch) (673 Bytes)\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM373", "user": "iposva-google", "root": "ROOT37", "reply_to": "COM372", "timestamp": "2014-01-22T04:27:04Z", "text": "Regarding the patch in comment 4:\n\nYou might have a much easier time if you did say \"[ 'OS==\"freebsd\"', { 'dart_target_os': 'Linux', } ],\" as this will pickup all of the relevant build configurations for a make/gcc based build.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM374", "user": "DartBot", "root": "ROOT37", "reply_to": "COM373", "timestamp": "2014-01-22T16:46:38Z", "text": "_This comment was originally written by beatgam...&#064;gmail.com_\n\n---\n\nMaking that change I get further. \"glient sync\", \"gclient runhooks\" and \"tools/build.py -mrelease -ax64 runtime\" (instructions from Issue #6929). Both returned 0 exit status, but there's no \"out\" directory in the dart directory.\n\nAll I get is: gmake: Nothing to be done for `runtime`\n\nFor reference, I'm using \"glient config http://dart.google.com/svn/branches/1.1/deps/standalone.deps\" (I figure that will be the easiest to get working). My build env is FreeBSD 9.2 with minimal software installed (e.g. no bash so I'm running gclient.py directly).\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM375", "user": "DartBot", "root": "ROOT37", "reply_to": "COM374", "timestamp": "2014-05-31T16:20:08Z", "text": "_This comment was originally written by ef...&#064;gmail.com_\n\n---\n\nI gave up when building NSPR. Original Mozilla version has files for building with FreeBSD but in patched Dart branch are files somewhat missing. Even with proper files i am unable to compile it :(\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM376", "user": "DartBot", "root": "ROOT37", "reply_to": "COM375", "timestamp": "2014-11-06T15:39:15Z", "text": "_This comment was originally written by sms3...&#064;gmail.com_\n\n---\n\nHas there been any update on this?\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM377", "user": "DartBot", "root": "ROOT37", "reply_to": "COM376", "timestamp": "2014-11-18T10:46:48Z", "text": "_This comment was originally written by ets3rodama...&#064;gmail.com_\n\n---\n\nhttp://ugetdm.com/blog/3-stable/68-uget-for-bsd-is-now-available\n\nDoes that perhaps help?\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM378", "user": "DartBot", "root": "ROOT37", "reply_to": "COM377", "timestamp": "2015-04-20T13:47:20Z", "text": "_This comment was originally written by @mulander_\n\n---\n\nI started work on a port for OpenBSD (https://github.com/mulander/openbsd-dart).\n\nHacky at this point but I want to get at least the runtime built to see how the whole thing will feel. I'll start adding proper platform support for OpenBSD as soon as I get a single binary going (work limited to weekend so don't expect fast progress).\n\nPeople wanting to help out are of course welcome.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM379", "user": "DartBot", "root": "ROOT37", "reply_to": "COM378", "timestamp": "2015-04-20T15:13:08Z", "text": "_This comment was originally written by sms3h...&#064;gmail.com_\n\n---\n\nThanks for working on this! I'll try to jump in and help a little bit at\nsome point but the schedule is full!\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3710", "user": "DartBot", "root": "ROOT37", "reply_to": "COM379", "timestamp": "2015-05-10T18:23:19Z", "text": "_This comment was originally written by @mulander_\n\n---\n\nHi all, short status update on the porting effort.\n\nThe build got pretty far, as in most of dart runtime builds without issues with small modifications to use kqueue/pthreads in some places - so far I 'patched' 36 files where most of them is 'use the mac one instead of linux' or 'use the android one instead of linux' with really rare cases when I actually had to edit the code. I obviously took the recommended \"[ 'OS==\"openbsd\"', { 'dart_target_os': 'Linux', } ],\" from comment #&#173;5.\n\nUnfortunately I'm also having huge issues with building NSPR similarly to what was reported in comment #&#173;7 over an year ago. I'm afraid that without guidance/help I won't be able to move far with the port.\n\nRegardless, it would be nice if the project had a porting guide for new platforms. I did not find any documentation that would tell me how the project build system works & how it should be configured. I don't know why the third party libs are bundled with the distribution & how to untangle them to use the system wide installed & already ported libraries. I assume the project has reasons for that but this leads to duplicate effort in software porting on the platform side.\n\nThe current state is of course uploaded to the github account linked in comment #&#173;10.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3711", "user": "sgjesse", "root": "ROOT37", "reply_to": "COM3710", "timestamp": "2015-05-11T07:27:57Z", "text": "We are working on moving the TLS support from Mozilla NSS to Boring SSL. If the NSS library and its dependencies are providing issues, then maybe just stubbing it out for now, and not support TLS until the change to use Boring SSL has landed.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3712", "user": "DartBot", "root": "ROOT37", "reply_to": "COM3711", "timestamp": "2015-05-11T10:13:43Z", "text": "_This comment was originally written by @mulander_\n\n---\n\nHi sgjesse@, thanks for the response.\n\nI will give stubbing out a shot over the next weekend, good to know that you are moving to Boring SSL.\n\nTwo little requests, please make it possible to pick up system wide Boring SSL during the build. Additionally I would be interested in using LibreSSL for dart on OpenBSD. Considering that both projects are an OpenSSL fork it should not be that hard if the build is not hard wired to Boring SSL.\n\nRegards,\nAdam\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3713", "user": "mulander", "root": "ROOT37", "reply_to": "COM3712", "timestamp": "2015-09-02T20:01:26Z", "text": "Hi guys, I'm @mulander from the migrated code.google.com comments (the guy trying to get Dart running on #OpenBSD).\n\nI didn't give up and I'm really happy that BoringSSL replaced nss/nspr.\n\nThough since the changes are only on head and adding OpenBSD support will be a much larger endeavour than just patching a file or two here & there I made a fork off the official repository and plan to do a proper port hopefully working with the upstream to make adding the BSD platform in a smooth way that's acceptable on both sides.\n\nAccording to the [Contributing](https://github.com/dart-lang/sdk/wiki/Contributing) guide I should give an up front notice with larger changes possibly coming down the line to coordinate.\n\nGoals for my branch:\n- build the base runtime on OpenBSD\n- build the whole SDK\n- allow using LibreSSL instead of BoringSSL\n- eventually build the Dartium browser\n\nThere's no action that upstream needs to take now of course. The initial porting effort with an updated status can be found [here](https://github.com/mulander/openbsd-dart), the new fork is under my account [here](https://github.com/mulander/sdk).\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3714", "user": "sethladd", "root": "ROOT37", "reply_to": "COM3713", "timestamp": "2015-09-02T20:03:37Z", "text": "cc @whesse  and @mit-mit \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3715", "user": "whesse", "root": "ROOT37", "reply_to": "COM3714", "timestamp": "2015-09-07T09:31:03Z", "text": "Have you considered trying to make the ninja build work, rather than the make build?  It may be that this new build system is more rational, and the generation of the build files by gyp is clearer, than the \"make\" gyp_generator.  Documentation for gyp is at https://chromium.googlesource.com/external/gyp/+/md-pages/index.md\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3716", "user": "mulander", "root": "ROOT37", "reply_to": "COM3715", "timestamp": "2015-09-07T15:59:08Z", "text": "@whesse I didn't try the ninja build. Essentially I got this one working flawlessly by putting symlinks to gcc, g++ & cc in a local directory that is in front of $PATH.\n\nI would personally say the build feels to be going quite well so far and I think I'm not that far away from having a working runtime. Though the porting effort is paused until the next weekend.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3717", "user": "pbgc", "root": "ROOT37", "reply_to": "COM3716", "timestamp": "2015-12-23T16:09:54Z", "text": "@mulander any update on your effort? I would really love to see DartVM on the BSD's (FreeBSD in particular) ... and I would like to help .. just don't think I have the needed skills.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3718", "user": "mulander", "root": "ROOT37", "reply_to": "COM3717", "timestamp": "2015-12-23T16:32:15Z", "text": "@pbgc I was able to last work on this port on September 19th. Unfortunately since then work has been busy which left no time for further dart work. I did not abandon the porting effort - it's just on hold for now.\n\nInitial porting effort: https://github.com/mulander/openbsd-dart\nNormal branch to work on upstreaming proper support: https://github.com/mulander/sdk/commits/OpenBSD-support\n\n@krytarowski started a similar effort to port Dart to NetBSD based on my current status, his repository is here: https://github.com/krytarowski/sdk (also on hold from what I know)\n\n@pbgc though it should be noted I am porting this for OpenBSD not FreeBSD though as you might be aware the work should be really similar (same with NetBSD as we found out). You can start by forking the dart repository and adding *_freebsd.cc/h files based on the ones I added in my repository. That should get you pretty far building the code on FreeBSD.\n\n> > and I would like to help .. just don't think I have the needed skills.\n\nIt just needs time. I'm also not the best person to do this but look at the age of this ticket. If people like me and you don't attempt it then we can wait another 3 years without anyone else picking the issue up. I will gladly help you get to the same spot on FreeBSD that I am with OpenBSD. Feel free to ask me question or just grab query with me on IRC @ freenode nick mulander.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3719", "user": "pbgc", "root": "ROOT37", "reply_to": "COM3718", "timestamp": "2015-12-24T14:52:47Z", "text": "@mulander Thanks! I decided that trying to accomplish this will be one of my new year resolutions. On January I will setup my machine to be able to build and then will start. I will then contact you on freenode (nick pbgc)\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3720", "user": "pbgc", "root": "ROOT37", "reply_to": "COM3719", "timestamp": "2015-12-29T23:33:47Z", "text": "Hi!\nA quick status update!\nI was able to build the runtime on FreeBSD by patching 25 files (using linux plataform as base with some files from macos), including several gyp files.\nI will now try to build all the sdk and then make a proper Platform for FreeBSD and will try to coordinate my effort with @mulander so we can have FreeBSD and OpenBSD (NetBSD will be also easy).\nCurrently I have 10/3785 failed tests:\n\n= 10 tests failed\n\n[08:16 | 100% | + 3775 | -   10]\n\n--- Total time: 08:16 ---\n0:05:06.454286 - vm - none-vm-checked release_x64/language/factory_redirection_test/04\n0:05:06.440066 - vm - none-vm-checked release_x64/language/factory_redirection_test/05\n0:05:06.435563 - vm - none-vm-checked release_x64/language/factory_redirection_test/06\n0:05:06.430600 - vm - none-vm-checked release_x64/language/factory_redirection_test/07\n0:03:23.218128 - vm - none-vm-checked release_x64/language/large_class_declaration_test\n0:02:43.406611 - vm - none-vm-checked release_x64/language/async_await_syntax_test/b11d\n0:02:37.621098 - vm - none-vm-checked release_x64/language/async_await_test/03\n0:02:37.266058 - vm - none-vm-checked release_x64/language/async_await_test/02\n0:02:14.180701 - vm - none-vm-checked release_x64/language/classes_static_method_clash_test\n0:01:15.562117 - vm - none-vm-checked release_x64/language/closure_cycles_test\n0:00:41.783698 - vm - none-vm-checked release_x64/language/gc_test\n0:00:35.128110 - vm - none-vm-checked release_x64/language/hello_dart_test\n0:00:27.538508 - vm - none-vm-checked release_x64/language/factory_redirection_test/08\n0:00:25.880236 - vm - none-vm-checked release_x64/language/async_await_test/none\n0:00:21.531277 - vm - none-vm-checked release_x64/language/ct_const2_test\n0:00:19.084653 - vm - none-vm-checked release_x64/language/await_for_test\n0:00:18.226716 - vm - none-vm-checked release_x64/language/disassemble_test\n0:00:10.358696 - vm - none-vm-checked release_x64/language/vm/debug_break_enabled_vm_test/01\n0:00:09.750202 - vm - none-vm-checked release_x64/language/async_await_syntax_test/b13a\n0:00:09.183596 - vm - none-vm-checked release_x64/language/vm/optimized_stacktrace_test\n\nI don't know if the tests are failing because of the port ... or because of the PRE-1.14 status of the rep.\n\npbeck@dart:~/dart/sdk % ./out/ReleaseX64/dart --version\nDart VM version: 1.14.0-edge.6602644bb3fd094cddc638a8e963c6a49d9cbdc8 (Tue Dec 29 08:46:27 2015) on \"linux_x64\"\n\npbeck@dart:~/dart/sdk % uname -a\nFreeBSD dart 10.2-RELEASE-p7 FreeBSD 10.2-RELEASE-p7 #0: Mon Nov  2 14:19:39 UTC 2015     root@amd64-builder.daemonology.net:/usr/obj/usr/src/sys/GENERIC  amd64\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3721", "user": "pbgc", "root": "ROOT37", "reply_to": "COM3720", "timestamp": "2015-12-29T23:58:59Z", "text": "Running the tests with:\n\n./out/ReleaseX64/dart tools/test.dart --compiler none --runtime vm --progress color --arch x64 --mode release --checked --report --time --tasks 6 -t60 language\n\nI get 8 tests failed\n\n[08:20 | 100% | + 3777 | -    8]\n\n--- Total time: 08:20 ---\n0:07:56.502934 - vm - none-vm-checked release_x64/language/async_await_syntax_test/a15c\n0:07:56.375965 - vm - none-vm-checked release_x64/language/async_await_syntax_test/a15d\n0:06:03.708446 - vm - none-vm-checked release_x64/language/ct_const2_test\n0:05:48.473868 - vm - none-vm-checked release_x64/language/disassemble_test\n0:03:23.058061 - vm - none-vm-checked release_x64/language/large_class_declaration_test\n0:02:21.911094 - vm - none-vm-checked release_x64/language/async_await_syntax_test/b00a\n0:01:34.449744 - vm - none-vm-checked release_x64/language/classes_static_method_clash_test\n0:01:17.627236 - vm - none-vm-checked release_x64/language/closure_cycles_test\n0:00:42.253910 - vm - none-vm-checked release_x64/language/gc_test\n0:00:37.057008 - vm - none-vm-checked release_x64/language/vm/optimized_stacktrace_test\n0:00:36.798708 - vm - none-vm-checked release_x64/language/hello_dart_test\n0:00:26.233428 - vm - none-vm-checked release_x64/language/async_await_test/none\n0:00:19.042199 - vm - none-vm-checked release_x64/language/await_for_test\n0:00:14.891542 - vm - none-vm-checked release_x64/language/async_await_syntax_test/b00c\n0:00:11.004358 - vm - none-vm-checked release_x64/language/vm/debug_break_enabled_vm_test/01\n0:00:09.445221 - vm - none-vm-checked release_x64/language/async_await_syntax_test/e1\n0:00:07.805136 - vm - none-vm-checked release_x64/language/async_star_test\n0:00:06.947421 - vm - none-vm-checked release_x64/language/vm/closure_memory_retention_test\n0:00:04.021573 - vm - none-vm-checked release_x64/language/inferrer_constructor5_test/none\n0:00:02.996990 - vm - none-vm-checked release_x64/language/allocate_test\n\nExecuting a test in isolation I get this information:\n\nTotal: 3788 tests\n- 3 tests will be skipped (0 skipped by design)\n- 0 tests are expected to be flaky but not crash\n- 0 tests are expected to flaky crash\n- 3746 tests are expected to pass\n- 22 tests are expected to fail that we won't fix\n- 15 tests are expected to fail that we should fix\n- 0 tests are expected to crash that we should fix\n- 0 tests are allowed to timeout\n- 0 tests are skipped on browsers due to compile-time error\n- 2 could not be categorized or are in multiple categories\n\nSo ... I'm confused .....\n\nCan someone give me some guidance on what to look for (thread implementation, etc..) if any of the failed tests are unexpected failures?\n\nI forgot to mention ... The build is done with CLANG:\n\npbeck@dart:~/dart/sdk % clang --version\nFreeBSD clang version 3.4.1 (tags/RELEASE_34/dot1-final 208032) 20140512\nTarget: x86_64-unknown-freebsd10.2\nThread model: posix\n\nThanks in advance!\nPedro Costa\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3722", "user": "krytarowski", "root": "ROOT37", "reply_to": "COM3721", "timestamp": "2015-12-30T01:37:38Z", "text": "Please upstream BSD bits as soon as possible, I will mirror them for NetBSD.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3723", "user": "mulander", "root": "ROOT37", "reply_to": "COM3722", "timestamp": "2016-01-01T19:08:46Z", "text": "I now have a fully built runtime & sdk on OpenBSD added as a proper 'target platform'.\n\nWhat's left:\n- ~~run runtime tests~~ :+1: 3780 passed; :red_circle:  5 failed;\n- ~~build sdk~~\n- build all\n- review and implement runtime specifics (like procfs path)\n\nCan someone from the dart team update on how the upstream wants to move forward?\n\nAll of my changes are in a feature branch of my repo https://github.com/mulander/sdk/commits/OpenBSD-support merged periodically with latest upstream so the code is not stale.\n\nShould I open a pull request now? Do you want me to first go through other steps? I think the code could be merged early as none of the existing files are modified in a way that would impact other build targets (I'm just adding openbsd entries to gypi files + *_openbsd.cc/h files).\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3724", "user": "mulander", "root": "ROOT37", "reply_to": "COM3723", "timestamp": "2016-01-01T20:05:00Z", "text": "Here is a full test run from a debug runtime + sdk build. 5 tests failed 3780 passed.\n\n```\n$ ./DebugX64/dart ../tools/test.dart --compiler none --runtime vm --progress color --arch x64 --mode debug --checked --report --time --tasks 6 -t60 l\nanguage\nTest configuration: none_vm_debug_x64_checked\n[00:27 |  --% | +   22 | -    0]Total: 3788 tests\n * 3 tests will be skipped (0 skipped by design)\n * 0 tests are expected to be flaky but not crash\n * 0 tests are expected to flaky crash\n * 3746 tests are expected to pass\n * 22 tests are expected to fail that we won't fix\n * 15 tests are expected to fail that we should fix\n * 0 tests are expected to crash that we should fix\n * 0 tests are allowed to timeout\n * 0 tests are skipped on browsers due to compile-time error\n * 2 could not be categorized or are in multiple categories\n\n[05:53 |  12% | +  474 | -    0]\nFAILED: none-vm-checked debug_x64 language/closure_cycles_test\nExpected: Pass \nActual: Timeout\nCommandOutput[vm]:\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /h\nome/mulander/github.com/mulander/sdk/tests/language/closure_cycles_test.dart\nTook 0:01:00.185584\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t60 language/closure_cycles_test\n\n[10:52 |  24% | +  920 | -    1]\nFAILED: none-vm-checked debug_x64 language/ct_const2_test\nExpected: Pass \nActual: Timeout\nCommandOutput[vm]:\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --compile_all --ignore-unrecognized-flags --package-root=DebugX6\n4/packages/ /home/mulander/github.com/mulander/sdk/tests/language/ct_const2_test.dart\nTook 0:01:00.506468\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t60 language/ct_const2_test\n\n[18:45 |  43% | + 1628 | -    2]\nFAILED: none-vm-checked debug_x64 language/hello_dart_test\nExpected: Pass \nActual: Timeout\nCommandOutput[vm]:\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --compile_all --error-on-bad-type --error-on-bad-override --igno\nre-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/language/hello_dart_test.dart\nTook 0:01:00.166028\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t60 language/hello_dart_test\n\n[21:53 |  49% | + 1879 | -    3]\nFAILED: none-vm-checked debug_x64 language/vm/optimized_stacktrace_test\nExpected: Pass \nActual: Timeout\nCommandOutput[vm]:\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --stacktrace-every=3 --optimization-counter-threshold=10 --enabl\ne-inlining-annotations --no-background-compilation --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests\n/language/vm/optimized_stacktrace_test.dart\nTook 0:01:01.369802\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t60 language/vm/optimized_stacktrace_test\n\n[23:55 |  54% | + 2053 | -    4]\nFAILED: none-vm-checked debug_x64 language/large_class_declaration_test\nExpected: Pass \nActual: Timeout\nCommandOutput[vm]:\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /h\nome/mulander/github.com/mulander/sdk/tests/language/large_class_declaration_test.dart\nTook 0:01:00.195278\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t60 language/large_class_declaration_test\n\n[43:12 | 100% | + 3780 | -    5]\n=== Failure summary:\n\nFAILED: none-vm-checked debug_x64 language/closure_cycles_test\nExpected: Pass \nActual: Timeout\nCommandOutput[vm]:\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /h\nome/mulander/github.com/mulander/sdk/tests/language/closure_cycles_test.dart\nTook 0:01:00.185584\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t60 language/closure_cycles_test\n\n\nFAILED: none-vm-checked debug_x64 language/ct_const2_test\nExpected: Pass \nActual: Timeout\nCommandOutput[vm]:\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --compile_all --ignore-unrecognized-flags --package-root=DebugX6\n4/packages/ /home/mulander/github.com/mulander/sdk/tests/language/ct_const2_test.dart\nTook 0:01:00.506468\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t60 language/ct_const2_test\n\n\nFAILED: none-vm-checked debug_x64 language/hello_dart_test\nExpected: Pass \nActual: Timeout\nCommandOutput[vm]:\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --compile_all --error-on-bad-type --error-on-bad-override --igno\nre-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/language/hello_dart_test.dart\nTook 0:01:00.166028\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t60 language/hello_dart_test\n\nFAILED: none-vm-checked debug_x64 language/vm/optimized_stacktrace_test\nExpected: Pass \nActual: Timeout\nCommandOutput[vm]:\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --stacktrace-every=3 --optimization-counter-threshold=10 --enabl\ne-inlining-annotations --no-background-compilation --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests\n/language/vm/optimized_stacktrace_test.dart\nTook 0:01:01.369802\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t60 language/vm/optimized_stacktrace_test\n\n\nFAILED: none-vm-checked debug_x64 language/large_class_declaration_test\nExpected: Pass \nActual: Timeout\nCommandOutput[vm]:\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /h\nome/mulander/github.com/mulander/sdk/tests/language/large_class_declaration_test.dart\nTook 0:01:00.195278\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t60 language/large_class_declaration_test\n\n===\n=== 5 tests failed\n===\n\n\n[43:12 | 100% | + 3780 | -    5]\n\n--- Total time: 43:12 ---\n0:01:01.369802 - vm - none-vm-checked debug_x64/language/vm/optimized_stacktrace_test\n0:01:00.506468 - vm - none-vm-checked debug_x64/language/ct_const2_test\n0:01:00.195278 - vm - none-vm-checked debug_x64/language/large_class_declaration_test\n0:01:00.185584 - vm - none-vm-checked debug_x64/language/closure_cycles_test\n0:01:00.166028 - vm - none-vm-checked debug_x64/language/hello_dart_test\n0:00:34.960820 - vm - none-vm-checked debug_x64/language/gc_test\n0:00:24.287353 - vm - none-vm-checked debug_x64/language/symbol_conflict_test\n0:00:21.027712 - vm - none-vm-checked debug_x64/language/disassemble_test\n0:00:19.957616 - vm - none-vm-checked debug_x64/language/bit_operations_test/03\n0:00:18.686961 - vm - none-vm-checked debug_x64/language/bit_operations_test/none\n0:00:17.678434 - vm - none-vm-checked debug_x64/language/osr_test\n0:00:17.561074 - vm - none-vm-checked debug_x64/language/bit_operations_test/04\n0:00:17.259620 - vm - none-vm-checked debug_x64/language/issue23244_test\n0:00:17.112266 - vm - none-vm-checked debug_x64/language/named_parameters_with_conversions_test\n0:00:17.101167 - vm - none-vm-checked debug_x64/language/compound_assignment_operator_test\n0:00:17.049203 - vm - none-vm-checked debug_x64/language/bit_operations_test/01\n0:00:16.142086 - vm - none-vm-checked debug_x64/language/async_star_test\n0:00:15.990715 - vm - none-vm-checked debug_x64/language/sync_generator1_test/01\n0:00:15.614790 - vm - none-vm-checked debug_x64/language/deferred_inlined_test\n0:00:15.595091 - vm - none-vm-checked debug_x64/language/await_future_test\n\n```\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3725", "user": "mezoni", "root": "ROOT37", "reply_to": "COM3724", "timestamp": "2016-01-02T11:15:53Z", "text": "If this do not need Google, why this need you?\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3726", "user": "iposva-google", "root": "ROOT37", "reply_to": "COM3725", "timestamp": "2016-01-04T07:50:26Z", "text": "@mulander Thanks for the promising progress updates.\n\nPlease make sure to run the full test suite and report its failure rate (e.g. omitting the \"language\" parameter). Also note that the default timeout for debug builds is 120 seconds and you would likely want to run with \"-t120\" or let the harness chose the right default value for you.\n\nOnce you have run the full test harness, please follow the steps at https://github.com/dart-lang/sdk/wiki/Contributing to create a CL and send it to me for comments. Thanks!\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3727", "user": "mulander", "root": "ROOT37", "reply_to": "COM3726", "timestamp": "2016-01-04T16:16:49Z", "text": "@iposva-google here are the test results for a full harness with a default timeout.\n\nThe tests took 182 minutes and 38 seconds. 13514 tests passed & 71 failed. I included everything that fitted in my backlog in the snippet below.\n\nTest commmand: `./DebugX64/dart ../tools/test.dart --compiler none --runtime vm --progress color --arch x64 --mode debug --checked --report --time --tasks 6`\n\n```\nPASS: ExitDetectorTest | test_forStatement_initialization\nPASS: ExitDetectorTest | test_forStatement_true\nPASS: ExitDetectorTest | test_forStatement_true_break\nPASS: ExitDetectorTest | test_forStatement_true_continue\nPASS: ExitDetectorTest | test_forStatement_true_if_return\nPASS: ExitDetectorTest | test_forStatement_true_noBreak\nPASS: ExitDetectorTest | test_forStatement_updaters\nPASS: ExitDetectorTest | test_forStatement_variableDeclaration\nPASS: ExitDetectorTest | test_functionExpression\nPASS: ExitDetectorTest | test_functionExpression_bodyThrows\nPASS: ExitDetectorTest | test_functionExpressionInvocation\nPASS: ExitDetectorTest | test_functionExpressionInvocation_argumentThrows\nPASS: ExitDetectorTest | test_functionExpressionInvocation_targetThrows\nPASS: ExitDetectorTest | test_identifier_prefixedIdentifier\nPASS: ExitDetectorTest | test_identifier_simpleIdentifier\nPASS: ExitDetectorTest | test_if_false_else_return\nPASS: ExitDetectorTest | test_if_false_noReturn\nPASS: ExitDetectorTest | test_if_false_return\nPASS: ExitDetectorTest | test_if_noReturn\nPASS: ExitDetectorTest | test_if_return\nPASS: ExitDetectorTest | test_if_true_noReturn\nPASS: ExitDetectorTest | test_if_true_return\nPASS: ExitDetectorTest | test_ifElse_bothReturn\nPASS: ExitDetectorTest | test_ifElse_elseReturn\nPASS: ExitDetectorTest | test_ifElse_noReturn\nPASS: ExitDetectorTest | test_ifElse_thenReturn\nPASS: ExitDetectorTest | test_ifNullAssign\nPASS: ExitDetectorTest | test_ifNullAssign_rhs\nPASS: ExitDetectorTest | test_indexExpression\nPASS: ExitDetectorTest | test_indexExpression_index\nPASS: ExitDetectorTest | test_indexExpression_target\nPASS: ExitDetectorTest | test_instanceCreationExpression\nPASS: ExitDetectorTest | test_instanceCreationExpression_argumentThrows\nPASS: ExitDetectorTest | test_isExpression\nPASS: ExitDetectorTest | test_isExpression_throws\nPASS: ExitDetectorTest | test_labeledStatement\nPASS: ExitDetectorTest | test_labeledStatement_throws\nPASS: ExitDetectorTest | test_literal_boolean\nPASS: ExitDetectorTest | test_literal_double\nPASS: ExitDetectorTest | test_literal_integer\nPASS: ExitDetectorTest | test_literal_null\nPASS: ExitDetectorTest | test_literal_String\nPASS: ExitDetectorTest | test_methodInvocation\nPASS: ExitDetectorTest | test_methodInvocation_argument\nPASS: ExitDetectorTest | test_methodInvocation_target\nPASS: ExitDetectorTest | test_parenthesizedExpression\nPASS: ExitDetectorTest | test_parenthesizedExpression_throw\nPASS: ExitDetectorTest | test_propertyAccess\nPASS: ExitDetectorTest | test_propertyAccess_throws\nPASS: ExitDetectorTest | test_rethrow\nPASS: ExitDetectorTest | test_return\nPASS: ExitDetectorTest | test_superExpression\nPASS: ExitDetectorTest | test_switch_allReturn\nPASS: ExitDetectorTest | test_switch_defaultWithNoStatements\nPASS: ExitDetectorTest | test_switch_fallThroughToNotReturn\nPASS: ExitDetectorTest | test_switch_fallThroughToReturn\nPASS: ExitDetectorTest | test_switch_noDefault\nPASS: ExitDetectorTest | test_switch_nonReturn\nPASS: ExitDetectorTest | test_thisExpression\nPASS: ExitDetectorTest | test_throwExpression\nPASS: ExitDetectorTest | test_tryStatement_noReturn\nPASS: ExitDetectorTest | test_tryStatement_return_catch\nPASS: ExitDetectorTest | test_tryStatement_return_finally\nPASS: ExitDetectorTest | test_tryStatement_return_try\nPASS: ExitDetectorTest | test_variableDeclarationStatement_noInitializer\nPASS: ExitDetectorTest | test_variableDeclarationStatement_noThrow\nPASS: ExitDetectorTest | test_variableDeclarationStatement_throw\nPASS: ExitDetectorTest | test_whileStatement_false_nonReturn\nPASS: ExitDetectorTest | test_whileStatement_throwCondition\nPASS: ExitDetectorTest | test_whileStatement_true_break\nPASS: ExitDetectorTest | test_whileStatement_true_continue\nPASS: ExitDetectorTest | test_whileStatement_true_if_return\nPASS: ExitDetectorTest | test_whileStatement_true_noBreak\nPASS: ExitDetectorTest | test_whileStatement_true_return\nPASS: ExitDetectorTest | test_whileStatement_true_throw\nPASS: ExitDetectorTest2 | test_switch_withEnum_false_noDefault\nPASS: ExitDetectorTest2 | test_switch_withEnum_false_withDefault\nPASS: ExitDetectorTest2 | test_switch_withEnum_true_noDefault\nPASS: ExitDetectorTest2 | test_switch_withEnum_true_withDefault\nPASS: FileBasedSourceTest | test_equals_false_differentFiles\nPASS: FileBasedSourceTest | test_equals_false_null\nPASS: FileBasedSourceTest | test_equals_true\nPASS: FileBasedSourceTest | test_fileReadMode\nPASS: FileBasedSourceTest | test_fileReadMode_changed\nPASS: FileBasedSourceTest | test_fileReadMode_normalize_eol_always\nPASS: FileBasedSourceTest | test_getEncoding\nPASS: FileBasedSourceTest | test_getFullName\nPASS: FileBasedSourceTest | test_getShortName\nPASS: FileBasedSourceTest | test_hashCode\nFAIL: FileBasedSourceTest | test_isInSystemLibrary_contagious\n  Expected: not null\n    Actual: <null>\n\n  package:unittest/src/simple_configuration.dart 128:34         SimpleConfiguration.onExpectFailure\n  package:unittest/src/simple_configuration.dart 24:13          _ExpectFailureHandler.fail\n  package:unittest/src/matcher/expect.dart 121:5                DefaultFailureHandler.failMatch\n  package:unittest/src/matcher/expect.dart 95:20                expect\n  ../pkg/analyzer/test/generated/all_the_rest_test.dart 7847:5  FileBasedSourceTest.test_isInSystemLibrary_contagious\n  dart:mirrors-patch/mirrors_impl.dart 533                      _LocalInstanceMirror._invoke\n  dart:mirrors-patch/mirrors_impl.dart 529                      _LocalInstanceMirror.invoke\n  ../pkg/analyzer/test/reflective_tests.dart 105:35             _runTest.<fn>\n  dart:async/zone.dart 914                                      _rootRunUnary\n  dart:async/zone.dart 810                                      _CustomZone.runUnary\n  dart:async/future_impl.dart 551                               _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                               _Future._propagateToListeners\n  dart:async/future_impl.dart 424                               _Future._completeWithValue\n  dart:async/future_impl.dart 479                               _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                                      _rootRun\n  dart:async/zone.dart 802                                      _CustomZone.run\n  dart:async/zone.dart 708                                      _CustomZone.runGuarded\n  dart:async/zone.dart 733                                      _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                         _microtaskLoop\n  dart:async/schedule_microtask.dart 50                         _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394                        _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414                        _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148                     _RawReceivePortImpl._handleMessage\nPASS: FileBasedSourceTest | test_isInSystemLibrary_false\nPASS: FileBasedSourceTest | test_issue14500\nPASS: FileBasedSourceTest | test_resolveRelative_dart_fileName\nPASS: FileBasedSourceTest | test_resolveRelative_dart_filePath\nPASS: FileBasedSourceTest | test_resolveRelative_dart_filePathWithParent\nPASS: FileBasedSourceTest | test_resolveRelative_file_fileName\nPASS: FileBasedSourceTest | test_resolveRelative_file_filePath\nPASS: FileBasedSourceTest | test_resolveRelative_file_filePathWithParent\nPASS: FileBasedSourceTest | test_resolveRelative_package_fileName\nPASS: FileBasedSourceTest | test_resolveRelative_package_fileNameWithoutPackageName\nPASS: FileBasedSourceTest | test_resolveRelative_package_filePath\nPASS: FileBasedSourceTest | test_resolveRelative_package_filePathWithParent\nPASS: FileBasedSourceTest | test_system\nPASS: FileUriResolverTest | test_creation\nPASS: FileUriResolverTest | test_resolve_file\nPASS: FileUriResolverTest | test_resolve_nonFile\nPASS: FileUriResolverTest | test_restore\nPASS: ReferenceFinderTest | test_visitSimpleIdentifier_const\nPASS: ReferenceFinderTest | test_visitSimpleIdentifier_nonConst\nPASS: ReferenceFinderTest | test_visitSuperConstructorInvocation_const\nPASS: ReferenceFinderTest | test_visitSuperConstructorInvocation_nonConst\nPASS: ReferenceFinderTest | test_visitSuperConstructorInvocation_unresolved\nPASS: SDKLibrariesReaderTest | test_readFrom_dart2js\nPASS: SDKLibrariesReaderTest | test_readFrom_empty\nPASS: SDKLibrariesReaderTest | test_readFrom_normal\nPASS: UriKindTest | test_fromEncoding\nPASS: UriKindTest | test_getEncoding\n\n838 PASSED, 8 FAILED, 0 ERRORS\n\n\nstderr:\nUnhandled exception:\nException: Some tests failed.\n#0      SimpleConfiguration.onDone (package:unittest/src/simple_configuration.dart:197:9)\n#1      _completeTests (package:unittest/unittest.dart:368:10)\n#2      _runTest (package:unittest/unittest.dart:308:5)\n#3      _nextTestCase (package:unittest/unittest.dart:256:3)\n#4      _microtaskLoop (dart:async/schedule_microtask.dart:41)\n#5      _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)\n#6      _Timer._runTimers (dart:isolate-patch/timer_impl.dart:394)\n#7      _Timer._handleMessage (dart:isolate-patch/timer_impl.dart:414)\n#8      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/pkg/analyzer/test/generated/all_the_rest_test.dart\nTook 0:01:40.232980\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 pkg/analyzer/test/generated/all_the_rest_test\n\n\nFAILED: none-vm-checked debug_x64 pkg/analyzer/test/generated/compile_time_error_code_test\nExpected: Pass\nActual: Timeout\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/pkg/analyzer/test/generated/compile_time_error_code_test.dart\nTook 0:02:00.179501\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 pkg/analyzer/test/generated/compile_time_error_code_test\n\n\nFAILED: none-vm-checked debug_x64 pkg/analyzer/test/generated/non_error_resolver_test\nExpected: Pass\nActual: Timeout\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/pkg/analyzer/test/generated/non_error_resolver_test.dart\nTook 0:02:00.160646\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 pkg/analyzer/test/generated/non_error_resolver_test\n\n\nFAILED: none-vm-checked debug_x64 pkg/analyzer/test/generated/resolver_test\nExpected: Pass\nActual: Timeout\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/pkg/analyzer/test/generated/resolver_test.dart\nTook 0:02:00.236365\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 pkg/analyzer/test/generated/resolver_test\n\n\nFAILED: none-vm-checked debug_x64 pkg/analyzer/test/src/context/cache_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\nPASS: AnalysisCacheTest | test_creation\nPASS: AnalysisCacheTest | test_get\nPASS: AnalysisCacheTest | test_getContextFor\nPASS: AnalysisCacheTest | test_getSourcesWithFullName\nPASS: AnalysisCacheTest | test_getState_hasEntry_flushed\nPASS: AnalysisCacheTest | test_getState_hasEntry_valid\nPASS: AnalysisCacheTest | test_getState_noEntry\nPASS: AnalysisCacheTest | test_getValue_hasEntry_valid\nPASS: AnalysisCacheTest | test_getValue_noEntry\nPASS: AnalysisCacheTest | test_iterator\nPASS: AnalysisCacheTest | test_put\nPASS: AnalysisCacheTest | test_remove\nPASS: AnalysisCacheTest | test_remove_invalidateResults_sameTarget\nPASS: AnalysisCacheTest | test_size\nPASS: AnalysisCacheTest | test_sources\nPASS: CacheEntryTest | test_dispose\nPASS: CacheEntryTest | test_explicitlyAdded\nPASS: CacheEntryTest | test_fixExceptionState_error_exception\nPASS: CacheEntryTest | test_fixExceptionState_noError_exception\nPASS: CacheEntryTest | test_fixExceptionState_noError_noException\nPASS: CacheEntryTest | test_getState\nPASS: CacheEntryTest | test_getValue_default\nPASS: CacheEntryTest | test_getValue_flushResults\nPASS: CacheEntryTest | test_hasErrorState_false\nPASS: CacheEntryTest | test_hasErrorState_true\nPASS: CacheEntryTest | test_invalidateAllInformation\nPASS: CacheEntryTest | test_setErrorState\nPASS: CacheEntryTest | test_setErrorState_invalidateDependent\nPASS: CacheEntryTest | test_setErrorState_noDescriptors\nPASS: CacheEntryTest | test_setErrorState_noException\nPASS: CacheEntryTest | test_setErrorState_nullDescriptors\nPASS: CacheEntryTest | test_setState_error\nPASS: CacheEntryTest | test_setState_flushed\nPASS: CacheEntryTest | test_setState_inProcess\nPASS: CacheEntryTest | test_setState_invalid\nPASS: CacheEntryTest | test_setState_invalid_dependencyCycle\nPASS: CacheEntryTest | test_setState_invalid_invalidateDependent\nPASS: CacheEntryTest | test_setState_invalid_keepEmpty_ifExplicitlyAdded\nPASS: CacheEntryTest | test_setState_invalid_removeEmptyEntry\nPASS: CacheEntryTest | test_setState_invalid_withDelta_keepDependency\nPASS: CacheEntryTest | test_setState_valid\nPASS: CacheEntryTest | test_setValue\nPASS: CacheEntryTest | test_setValue_flushResults\nPASS: CacheEntryTest | test_setValue_keepDependent\nPASS: CacheEntryTest | test_setValueIncremental\nPASS: CacheEntryTest | test_toString_empty\nPASS: CacheEntryTest | test_toString_nonEmpty\nPASS: CacheFlushManagerTest | test_madeActive\nPASS: CacheFlushManagerTest | test_madeIdle\nPASS: CacheFlushManagerTest | test_new\nPASS: CacheFlushManagerTest | test_resultAccessed\nPASS: CacheFlushManagerTest | test_resultAccessed_negativeMaxSize\nPASS: CacheFlushManagerTest | test_resultAccessed_noSuchResult\nPASS: CacheFlushManagerTest | test_resultStored\nPASS: CacheFlushManagerTest | test_resultStored_negativeMaxSize\nPASS: CacheFlushManagerTest | test_targetRemoved\nPASS: SdkCachePartitionTest | test_creation\nPASS: SdkCachePartitionTest | test_dispose\nPASS: SdkCachePartitionTest | test_entrySet\nPASS: SdkCachePartitionTest | test_get\nPASS: SdkCachePartitionTest | test_put_alreadyInPartition\nPASS: SdkCachePartitionTest | test_put_noFlush\nPASS: SdkCachePartitionTest | test_remove_absent\nPASS: SdkCachePartitionTest | test_remove_present\nPASS: SdkCachePartitionTest | test_contains_false\nERROR: SdkCachePartitionTest | test_contains_true\n  Test failed: Caught The null object does not have a getter 'source'.\n\n  NoSuchMethodError: method not found: 'source'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                      Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                      Object.noSuchMethod\n  package:analyzer/src/context/cache.dart 1224:28           SdkCachePartition.isResponsibleFor\n  ../pkg/analyzer/test/src/context/cache_test.dart 1068:22  SdkCachePartitionTest.test_contains_true\n  dart:mirrors-patch/mirrors_impl.dart 533                  _LocalInstanceMirror._invoke\n  dart:mirrors-patch/mirrors_impl.dart 529                  _LocalInstanceMirror.invoke\n  ../pkg/analyzer/test/reflective_tests.dart 105:35         _runTest.<fn>\n  dart:async/zone.dart 914                                  _rootRunUnary\n  dart:async/zone.dart 810                                  _CustomZone.runUnary\n  dart:async/future_impl.dart 551                           _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                           _Future._propagateToListeners\n  dart:async/future_impl.dart 424                           _Future._completeWithValue\n  dart:async/future_impl.dart 479                           _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                                  _rootRun\n  dart:async/zone.dart 802                                  _CustomZone.run\n  dart:async/zone.dart 708                                  _CustomZone.runGuarded\n  dart:async/zone.dart 733                                  _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                     _microtaskLoop\n  dart:async/schedule_microtask.dart 50                     _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394                    _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414                    _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148                 _RawReceivePortImpl._handleMessage\nPASS: UniversalCachePartitionTest | test_creation\nPASS: UniversalCachePartitionTest | test_dispose\nPASS: UniversalCachePartitionTest | test_entrySet\nPASS: UniversalCachePartitionTest | test_get\nPASS: UniversalCachePartitionTest | test_put_alreadyInPartition\nPASS: UniversalCachePartitionTest | test_put_noFlush\nPASS: UniversalCachePartitionTest | test_remove_absent\nPASS: UniversalCachePartitionTest | test_remove_present\nPASS: UniversalCachePartitionTest | test_contains\nPASS: ResultDataTest | test_creation\nPASS: ResultDataTest | test_flush\n\n76 PASSED, 0 FAILED, 1 ERRORS\n\n\nstderr:\nUnhandled exception:\nException: Some tests failed.\n#0      SimpleConfiguration.onDone (package:unittest/src/simple_configuration.dart:197:9)\n#1      _completeTests (package:unittest/unittest.dart:368:10)\n#2      _runTest (package:unittest/unittest.dart:308:5)\n#3      _nextTestCase (package:unittest/unittest.dart:256:3)\n#4      _microtaskLoop (dart:async/schedule_microtask.dart:41)\n#5      _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)\n#6      _Timer._runTimers (dart:isolate-patch/timer_impl.dart:394)\n#7      _Timer._handleMessage (dart:isolate-patch/timer_impl.dart:414)\n#8      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/pkg/analyzer/test/src/context/cache_test.dart\nTook 0:00:24.568282\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 pkg/analyzer/test/src/context/cache_test\n\n\nFAILED: none-vm-checked debug_x64 pkg/analyzer/test/src/task/dart_test\nExpected: Pass\nActual: Timeout\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/pkg/analyzer/test/src/task/dart_test.dart\nTook 0:02:00.208476\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 pkg/analyzer/test/src/task/dart_test\n\n\nFAILED: none-vm-checked debug_x64 pkg/analyzer_cli/test/options_test\nExpected: Pass\nActual: Fail\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nstderr:\nNo Dart SDK found.\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/pkg/analyzer_cli/test/options_test.dart\nTook 0:00:16.737089\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 pkg/analyzer_cli/test/options_test\n\n\nFAILED: none-vm-checked debug_x64 pkg/analyzer_cli/test/driver_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\nERROR: Driver | options | custom processor\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 63:16      main.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/isolate_patch.dart 96             _runPendingImmediateCallback\n  dart:isolate-patch/isolate_patch.dart 149            _RawReceivePortImpl._handleMessage\nERROR: Driver | exit codes | fatal hints\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 75:9       main.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | exit codes | not fatal hints\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 80:9       main.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | exit codes | fatal errors\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 85:9       main.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | exit codes | not fatal warnings\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 90:9       main.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | exit codes | fatal warnings\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 95:9       main.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | exit codes | missing options file\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 100:9      main.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | exit codes | missing dart file\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 105:9      main.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | exit codes | part file\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 110:9      main.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | exit codes | non-dangling part file\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 116:16     main.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | exit codes | extra part file\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 125:16     main.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | linter | lints in options | gets analysis options\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 137:31     main.<fn>.<fn>.<fn>.<fn>\n  ../pkg/analyzer_cli/test/driver_test.dart 142:20     main.<fn>.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | linter | lints in options | generates lints\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 137:31     main.<fn>.<fn>.<fn>.<fn>\n  ../pkg/analyzer_cli/test/driver_test.dart 153:20     main.<fn>.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | linter | default lints | gets default lints\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 161:31     main.<fn>.<fn>.<fn>.<fn>\n  ../pkg/analyzer_cli/test/driver_test.dart 166:20     main.<fn>.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | linter | default lints | generates lints\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 161:31     main.<fn>.<fn>.<fn>.<fn>\n  ../pkg/analyzer_cli/test/driver_test.dart 177:20     main.<fn>.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | linter | no `--lints` flag (none in options) | lints disabled\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 185:31     main.<fn>.<fn>.<fn>.<fn>\n  ../pkg/analyzer_cli/test/driver_test.dart 189:20     main.<fn>.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | linter | no `--lints` flag (none in options) | no registered lints\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 185:31     main.<fn>.<fn>.<fn>.<fn>\n  ../pkg/analyzer_cli/test/driver_test.dart 194:20     main.<fn>.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | linter | no `--lints` flag (none in options) | no generated warnings\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 185:31     main.<fn>.<fn>.<fn>.<fn>\n  ../pkg/analyzer_cli/test/driver_test.dart 199:20     main.<fn>.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nPASS: Driver | containsLintRuleEntry\nERROR: Driver | options processing | basic config | filters\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 233:29     main.<fn>.<fn>.<fn>.<fn>\n  ../pkg/analyzer_cli/test/driver_test.dart 237:18     main.<fn>.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | options processing | basic config | language\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 233:29     main.<fn>.<fn>.<fn>.<fn>\n  ../pkg/analyzer_cli/test/driver_test.dart 262:18     main.<fn>.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Driver | options processing | with flags | override fatal warning\n  Test failed: Caught The null object does not have a getter 'dartSdkPath'.\n\n  NoSuchMethodError: method not found: 'dartSdkPath'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/driver.dart 548:60          Driver._setupEnv\n  package:analyzer_cli/src/driver.dart 103:5           Driver.start\n  ../pkg/analyzer_cli/test/driver_test.dart 429:10     drive\n  ../pkg/analyzer_cli/test/driver_test.dart 269:29     main.<fn>.<fn>.<fn>.<fn>\n  ../pkg/analyzer_cli/test/driver_test.dart 274:18     main.<fn>.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Bootloader | plugin processing | bad format\n  Test failed: Caught The null object does not have a getter 'analysisOptionsFile'.\n\n  NoSuchMethodError: method not found: 'analysisOptionsFile'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/bootloader.dart 131:28      BootLoader._processAnalysisOptions\n  package:analyzer_cli/src/bootloader.dart 122:5       BootLoader.createImage\n  ../pkg/analyzer_cli/test/driver_test.dart 358:16     main.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nERROR: Bootloader | plugin processing | plugin config\n  Test failed: Caught The null object does not have a getter 'analysisOptionsFile'.\n\n  NoSuchMethodError: method not found: 'analysisOptionsFile'\n  Receiver: null\n  Arguments: []\n  dart:core-patch/object_patch.dart 42                 Object._noSuchMethod\n  dart:core-patch/object_patch.dart 45                 Object.noSuchMethod\n  package:analyzer_cli/src/bootloader.dart 131:28      BootLoader._processAnalysisOptions\n  package:analyzer_cli/src/bootloader.dart 122:5       BootLoader.createImage\n  ../pkg/analyzer_cli/test/driver_test.dart 371:30     main.<fn>.<fn>.<fn>\n  package:unittest/src/internal_test_case.dart 120:37  InternalTestCase.run.<fn>\n  dart:async/zone.dart 914                             _rootRunUnary\n  dart:async/zone.dart 810                             _CustomZone.runUnary\n  dart:async/future_impl.dart 551                      _Future._propagateToListeners.handleValueCallback\n  dart:async/future_impl.dart 637                      _Future._propagateToListeners\n  dart:async/future_impl.dart 424                      _Future._completeWithValue\n  dart:async/future_impl.dart 479                      _Future._asyncComplete.<fn>\n  dart:async/zone.dart 907                             _rootRun\n  dart:async/zone.dart 802                             _CustomZone.run\n  dart:async/zone.dart 708                             _CustomZone.runGuarded\n  dart:async/zone.dart 733                             _CustomZone.bindCallback.<fn>\n  dart:async/schedule_microtask.dart 41                _microtaskLoop\n  dart:async/schedule_microtask.dart 50                _startMicrotaskLoop\n  dart:isolate-patch/timer_impl.dart 394               _Timer._runTimers\n  dart:isolate-patch/timer_impl.dart 414               _Timer._handleMessage\n  dart:isolate-patch/isolate_patch.dart 148            _RawReceivePortImpl._handleMessage\nPASS: Bootloader | plugin processing | plugin validation | requires class name\nPASS: Bootloader | plugin processing | plugin validation | requires library URI\nPASS: Bootloader | plugin processing | plugin validation | check\n\n4 PASSED, 0 FAILED, 23 ERRORS\n\n\nstderr:\nUnhandled exception:\nException: Some tests failed.\n#0      SimpleConfiguration.onDone (package:unittest/src/simple_configuration.dart:197:9)\n#1      _completeTests (package:unittest/unittest.dart:368:10)\n#2      _runTest (package:unittest/unittest.dart:308:5)\n#3      _nextTestCase (package:unittest/unittest.dart:256:3)\n#4      _microtaskLoop (dart:async/schedule_microtask.dart:41)\n#5      _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)\n#6      _Timer._runTimers (dart:isolate-patch/timer_impl.dart:394)\n#7      _Timer._handleMessage (dart:isolate-patch/timer_impl.dart:414)\n#8      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/pkg/analyzer_cli/test/driver_test.dart\nTook 0:00:26.019867\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 pkg/analyzer_cli/test/driver_test\n\n\nFAILED: none-vm-checked debug_x64 pkg/analyzer/tool/task_dependency_graph/check_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nAnalysisException: Cannot compute RESOLVED_UNIT for /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart in /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart\nCaused by Invalid input descriptor (null, LIBRARY_ELEMENT1) for Run BuildDirectiveElementsTask on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/src/generated/engine.dart\nPath:\nRun StrongModeVerifyUnitTask on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart in /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart|\nRun EvaluateUnitConstantsTask on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart in /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart|\nRun ResolveLibraryReferencesTask on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart|\nRun PropagateVariableTypesInLibraryClosureTask on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart|\nRun ReadyLibraryElement6Task on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart|\nRun PropagateVariableTypesInLibraryTask on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart|\nRun PropagateVariableTypesInUnitTask on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart in /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart|\nRun PartiallyResolveUnitReferencesTask on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart in /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart|\nRun ReadyLibraryElement5Task on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart|\nRun ResolveLibraryTypeNamesTask on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart|\nRun ResolveUnitTypeNamesTask on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart in /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/task/model.dart|\nRun BuildExportNamespaceTask on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/src/generated/engine.dart|\nRun BuildPublicNamespaceTask on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/src/generated/engine.dart|\nRun BuildDirectiveElementsTask on /home/mulander/github.com/mulander/sdk/pkg/analyzer/lib/src/generated/engine.dart\n#0      WorkItem.gatherInputs (package:analyzer/src/task/driver.dart:699:11)\n#1      _WorkOrderDependencyWalker.getNextInput (package:analyzer/src/task/driver.dart:850:17)\n#2      CycleAwareDependencyWalker.getNextStronglyConnectedComponent (package:analyzer/src/task/driver.dart:400:35)\n#3      WorkOrder.moveNext.<anonymous closure> (package:analyzer/src/task/driver.dart:816:31)\n#4      _PerformanceTagImpl.makeCurrentWhile (package:analyzer/src/generated/utilities_general.dart:188:15)\n#5      WorkOrder.moveNext (package:analyzer/src/task/driver.dart:808:44)\n#6      AnalysisDriver.computeResult (package:analyzer/src/task/driver.dart:111:26)\n#7      AnalysisContextImpl.computeResult (package:analyzer/src/context/context.dart:622:14)\n#8      AnalysisContextImpl.resolveCompilationUnit2 (package:analyzer/src/context/context.dart:1141:12)\n#9      Driver.getUnit (file:///home/mulander/github.com/mulander/sdk/pkg/analyzer/tool/task_dependency_graph/generate.dart:218:15)\n#10     Driver.generateFileContents (file:///home/mulander/github.com/mulander/sdk/pkg/analyzer/tool/task_dependency_graph/generate.dart:148:43)\n#11     target.<anonymous closure> (file:///home/mulander/github.com/mulander/sdk/pkg/analyzer/tool/task_dependency_graph/generate.dart:50:45)\n#12     GeneratedFile.check (package:analyzer/src/codegen/tools.dart:442:46)\n#13     GeneratedContent.checkAll (package:analyzer/src/codegen/tools.dart:304:19)\n#14     main (file:///home/mulander/github.com/mulander/sdk/pkg/analyzer/tool/task_dependency_graph/check_test.dart:21:20)\n#15     _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#16     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\n#0      AnalysisContextImpl.computeResult (package:analyzer/src/context/context.dart:626:7)\n#1      AnalysisContextImpl.resolveCompilationUnit2 (package:analyzer/src/context/context.dart:1141:12)\n#2      Driver.getUnit (file:///home/mulander/github.com/mulander/sdk/pkg/analyzer/tool/task_dependency_graph/generate.dart:218:15)\n#3      Driver.generateFileContents (file:///home/mulander/github.com/mulander/sdk/pkg/analyzer/tool/task_dependency_graph/generate.dart:148:43)\n#4      target.<anonymous closure> (file:///home/mulander/github.com/mulander/sdk/pkg/analyzer/tool/task_dependency_graph/generate.dart:50:45)\n#5      GeneratedFile.check (package:analyzer/src/codegen/tools.dart:442:46)\n#6      GeneratedContent.checkAll (package:analyzer/src/codegen/tools.dart:304:19)\n#7      main (file:///home/mulander/github.com/mulander/sdk/pkg/analyzer/tool/task_dependency_graph/check_test.dart:21:20)\n#8      _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#9      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/pkg/analyzer/tool/task_dependency_graph/check_test.dart\nTook 0:00:55.583794\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 pkg/analyzer/tool/task_dependency_graph/check_test\n\n\nFAILED: none-vm-checked debug_x64 pkg/analyzer_cli/test/perf_report_test\nExpected: Pass\nActual: Fail\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nstderr:\nNo Dart SDK found.\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/pkg/analyzer_cli/test/perf_report_test.dart\nTook 0:00:19.959414\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 pkg/analyzer_cli/test/perf_report_test\n\n\nFAILED: none-vm-checked debug_x64 pkg/analyzer_cli/test/super_mixin_test\nExpected: Pass\nActual: Fail\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/pkg/analyzer_cli/test/super_mixin_test.dart\nTook 0:00:20.640635\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 pkg/analyzer_cli/test/super_mixin_test\n\n\nFAILED: none-vm-checked debug_x64 pkg/analyzer/test/src/summary/summary_test\nExpected: Pass\nActual: Timeout\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/pkg/analyzer/test/src/summary/summary_test.dart\nTook 0:02:00.176776\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 pkg/analyzer/test/src/summary/summary_test\n\n\nFAILED: none-vm-checked debug_x64 vm/dart/spawn_shutdown_test\nExpected: Pass\nActual: Crash\nCommandOutput[vm]:\n\nstdout:\nStarting 50 workers...\n\n\nstderr:\nterminate called recursively\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/runtime/tests/vm/dart/spawn_shutdown_test.dart\nTook 0:00:41.701839\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 vm/dart/spawn_shutdown_test\n\n\nFAILED: none-vm-checked debug_x64 samples/sample_extension/test/sample_extension_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nExpect.fail('Unknown operating system openbsd')\n#0      Expect._fail (package:expect/expect.dart:385:5)\n#1      Expect.fail (package:expect/expect.dart:154:5)\n#2      getNativeLibraryPath (file:///home/mulander/github.com/mulander/sdk/samples/sample_extension/test/sample_extension_test.dart:37:14)\n#3      main (file:///home/mulander/github.com/mulander/sdk/samples/sample_extension/test/sample_extension_test.dart:50:23)\n#4      _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#5      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/samples/sample_extension/test/sample_extension_test.dart\nTook 0:00:01.761229\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 samples/sample_extension/test/sample_extension_test\n\n\nFAILED: none-vm-checked debug_x64 language/closure_cycles_test\nExpected: Pass\nActual: Timeout\nCommandOutput[vm]:\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/language/closure_cycles_test.dart\nTook 0:02:00.576703\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 language/closure_cycles_test\n\n\nFAILED: none-vm-checked debug_x64 language/large_class_declaration_test\nExpected: Pass\nActual: Timeout\nCommandOutput[vm]:\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/language/large_class_declaration_test.dart\nTook 0:02:00.866380\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 language/large_class_declaration_test\n\n\nFAILED: none-vm-checked debug_x64 lib/convert/streamed_conversion_json_utf8_decode_test\nExpected: Pass\nActual: Crash\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nstderr:\nVerifying before marking...Verifying before marking... done.\n done.\nVerifying before sweeping...Verifying before sweeping... done.\n done.\nVerifying before marking...Verifying before marking... done.\n done.\nVerifying before sweeping...Verifying before sweeping... done.\n done.\nVerifying before marking... done.\nVerifying before sweeping... done.\nVerifying before marking... done.\nVerifying before sweeping... done.\nVerifying before marking... done.\nVerifying before sweeping... done.\nVerifying before marking... done.\nVerifying before sweeping... done.\nVerifying before marking...terminate called after throwing an instance of 'std::bad_alloc'\n  what():  std::bad_alloc\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --verified_mem --verify_before_gc --verify_after_gc --old_gen_growth_rate=1 --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/lib/convert/streamed_conversion_json_utf8_decode_test.dart\nTook 0:00:17.531747\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 lib/convert/streamed_conversion_json_utf8_decode_test\n\n\nFAILED: none-vm-checked debug_x64 lib/mirrors/immutable_collections_test\nExpected: Pass\nActual: Timeout\nCommandOutput[vm]:\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/lib/mirrors/immutable_collections_test.dart\nTook 0:02:00.146838\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 lib/mirrors/immutable_collections_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/dart_std_io_pipe_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nProcessException: No such file or directory\n  Command: ../tests/standalone/io/dart_std_io_pipe_test.sh DebugX64/dart ../tests/standalone/io/dart_std_io_pipe_script.dart 0 /tmp/dart_dart_std_io_pipeZL0clG/pipe /tmp/dart_dart_std_io_pipeZL0clG/redirect file\n#0      _rootHandleUncaughtError.<anonymous closure> (dart:async/zone.dart:895)\n#1      _microtaskLoop (dart:async/schedule_microtask.dart:41)\n#2      _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)\n#3      _Timer._runTimers (dart:isolate-patch/timer_impl.dart:394)\n#4      _Timer._handleMessage (dart:isolate-patch/timer_impl.dart:414)\n#5      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/io/dart_std_io_pipe_test.dart\nTook 0:00:02.976535\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/dart_std_io_pipe_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/dart_std_io_pipe_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nProcessException: No such file or directory\n  Command: ../tests/standalone/io/dart_std_io_pipe_test.sh DebugX64/dart ../tests/standalone/io/dart_std_io_pipe_script.dart 0 /tmp/dart_dart_std_io_pipesIpSm2/pipe /tmp/dart_dart_std_io_pipesIpSm2/redirect file\n#0      _rootHandleUncaughtError.<anonymous closure> (dart:async/zone.dart:895)\n#1      _microtaskLoop (dart:async/schedule_microtask.dart:41)\n#2      _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)\n#3      _Timer._runTimers (dart:isolate-patch/timer_impl.dart:394)\n#4      _Timer._handleMessage (dart:isolate-patch/timer_impl.dart:414)\n#5      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --short_socket_write --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/io/dart_std_io_pipe_test.dart\nTook 0:00:02.558014\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/dart_std_io_pipe_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/dart_std_io_pipe_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nProcessException: No such file or directory\n  Command: ../tests/standalone/io/dart_std_io_pipe_test.sh DebugX64/dart ../tests/standalone/io/dart_std_io_pipe_script.dart 0 /tmp/dart_dart_std_io_pipeZJ8as3/pipe /tmp/dart_dart_std_io_pipeZJ8as3/redirect file\n#0      _rootHandleUncaughtError.<anonymous closure> (dart:async/zone.dart:895)\n#1      _microtaskLoop (dart:async/schedule_microtask.dart:41)\n#2      _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)\n#3      _Timer._runTimers (dart:isolate-patch/timer_impl.dart:394)\n#4      _Timer._handleMessage (dart:isolate-patch/timer_impl.dart:414)\n#5      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --short_socket_read --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/io/dart_std_io_pipe_test.dart\nTook 0:00:02.813094\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/dart_std_io_pipe_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/dart_std_io_pipe_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nProcessException: No such file or directory\n  Command: ../tests/standalone/io/dart_std_io_pipe_test.sh DebugX64/dart ../tests/standalone/io/dart_std_io_pipe_script.dart 0 /tmp/dart_dart_std_io_pipecYvdPv/pipe /tmp/dart_dart_std_io_pipecYvdPv/redirect file\n#0      _rootHandleUncaughtError.<anonymous closure> (dart:async/zone.dart:895)\n#1      _microtaskLoop (dart:async/schedule_microtask.dart:41)\n#2      _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)\n#3      _Timer._runTimers (dart:isolate-patch/timer_impl.dart:394)\n#4      _Timer._handleMessage (dart:isolate-patch/timer_impl.dart:414)\n#5      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --short_socket_read --short_socket_write --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/io/dart_std_io_pipe_test.dart\nTook 0:00:05.374968\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/dart_std_io_pipe_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/file_error_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nstderr:\nUnhandled exception:\nExpect.throws fails: Did not throw\n#0      Expect._fail (package:expect/expect.dart:385:5)\n#1      Expect.throws (package:expect/expect.dart:378:5)\n#2      testResolveSymbolicLinksOnNonExistentDirectory (file:///home/mulander/github.com/mulander/sdk/tests/standalone/io/file_error_test.dart:149:10)\n#3      main (file:///home/mulander/github.com/mulander/sdk/tests/standalone/io/file_error_test.dart:427:3)\n#4      _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#5      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/io/file_error_test.dart\nTook 0:00:02.689778\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/file_error_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/file_read_special_device_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nExpect.equals(expected: <0>, actual: <255>) fails.\n#0      Expect._fail (package:expect/expect.dart:385:5)\n#1      Expect.equals (package:expect/expect.dart:102:5)\n#2      openAndWriteScript.<anonymous closure>.<anonymous closure> (file:///home/mulander/github.com/mulander/sdk/tests/standalone/io/file_read_special_device_test.dart:16:18)\n#3      _RootZone.runUnary (dart:async/zone.dart:1149)\n#4      _Future._propagateToListeners.handleValueCallback (dart:async/future_impl.dart:551)\n#5      _Future._propagateToListeners (dart:async/future_impl.dart:637)\n#6      _Future._completeWithValue (dart:async/future_impl.dart:424)\n#7      _Future._asyncComplete.<anonymous closure> (dart:async/future_impl.dart:479)\n#8      _microtaskLoop (dart:async/schedule_microtask.dart:41)\n#9      _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)\n#10     _runPendingImmediateCallback (dart:isolate-patch/isolate_patch.dart:96)\n#11     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:149)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/io/file_read_special_device_test.dart\nTook 0:00:26.106004\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/file_read_special_device_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/full_coverage_test\nExpected: Pass\nActual: Timeout\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/full_coverage_test.dart\nTook 0:02:00.101170\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/full_coverage_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/platform_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nExpect.isTrue(false) fails.\n#0      Expect._fail (package:expect/expect.dart:385:5)\n#1      Expect.isTrue (package:expect/expect.dart:111:5)\n#2      test (file:///home/mulander/github.com/mulander/sdk/tests/standalone/io/platform_test.dart:15:10)\n#3      main (file:///home/mulander/github.com/mulander/sdk/tests/standalone/io/platform_test.dart:147:3)\n#4      _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#5      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/io/platform_test.dart\nTook 0:00:02.341048\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/platform_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/raw_datagram_socket_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nstderr:\nUnhandled exception:\nExpect.isTrue(false) fails.\n#0      Expect._fail (package:expect/expect.dart:385:5)\n#1      Expect.isTrue (package:expect/expect.dart:111:5)\n#2      testDatagramBroadcastOptions.test.<anonymous closure> (file:///home/mulander/github.com/mulander/sdk/tests/standalone/io/raw_datagram_socket_test.dart:29:16)\n#3      _RootZone.runUnary (dart:async/zone.dart:1149)\n#4      _Future._propagateToListeners.handleValueCallback (dart:async/future_impl.dart:551)\n#5      _Future._propagateToListeners (dart:async/future_impl.dart:637)\n#6      _Future._completeWithValue (dart:async/future_impl.dart:424)\n#7      _Future._asyncComplete.<anonymous closure> (dart:async/future_impl.dart:479)\n#8      _microtaskLoop (dart:async/schedule_microtask.dart:41)\n#9      _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)\n#10     _runPendingImmediateCallback (dart:isolate-patch/isolate_patch.dart:96)\n#11     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:149)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/io/raw_datagram_socket_test.dart\nTook 0:00:02.920261\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/raw_datagram_socket_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/platform_resolved_executable_test/none\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nThe null object does not have a method 'split'.\n\nNoSuchMethodError: method not found: 'split'\nReceiver: null\nArguments: [\"/\"]\n#0      Object._noSuchMethod (dart:core-patch/object_patch.dart:42)\n#1      Object.noSuchMethod (dart:core-patch/object_patch.dart:45)\n#2      Uri._makeFileUri (dart:core/uri.dart:871)\n#3      Uri.Uri.file (dart:core/uri.dart:731)\n#4      platformExeName (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_none.dart:127:17)\n#5      testDartExecShouldNotBeInCurrentDir (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_none.dart:42:40)\n#6      main (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_none.dart:143:3)\n#7      _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#8      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_none.dart\nTook 0:00:01.902623\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/platform_resolved_executable_test/none\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/platform_resolved_executable_test/01\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nThe null object does not have a method 'split'.\n\nNoSuchMethodError: method not found: 'split'\nReceiver: null\nArguments: [\"/\"]\n#0      Object._noSuchMethod (dart:core-patch/object_patch.dart:42)\n#1      Object.noSuchMethod (dart:core-patch/object_patch.dart:45)\n#2      Uri._makeFileUri (dart:core/uri.dart:871)\n#3      Uri.Uri.file (dart:core/uri.dart:731)\n#4      platformExeName (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_01.dart:127:17)\n#5      testDartExecShouldNotBeInCurrentDir (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_01.dart:42:40)\n#6      main (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_01.dart:143:3)\n#7      _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#8      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_01.dart\nTook 0:00:01.854334\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/platform_resolved_executable_test/01\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/platform_resolved_executable_test/00\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nThe null object does not have a method 'split'.\n\nNoSuchMethodError: method not found: 'split'\nReceiver: null\nArguments: [\"/\"]\n#0      Object._noSuchMethod (dart:core-patch/object_patch.dart:42)\n#1      Object.noSuchMethod (dart:core-patch/object_patch.dart:45)\n#2      Uri._makeFileUri (dart:core/uri.dart:871)\n#3      Uri.Uri.file (dart:core/uri.dart:731)\n#4      platformExeName (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_00.dart:127:17)\n#5      testDartExecShouldNotBeInCurrentDir (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_00.dart:42:40)\n#6      main (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_00.dart:143:3)\n#7      _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#8      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_00.dart\nTook 0:00:02.315919\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/platform_resolved_executable_test/00\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/platform_resolved_executable_test/04\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nThe null object does not have a method 'split'.\n\nNoSuchMethodError: method not found: 'split'\nReceiver: null\nArguments: [\"/\"]\n#0      Object._noSuchMethod (dart:core-patch/object_patch.dart:42)\n#1      Object.noSuchMethod (dart:core-patch/object_patch.dart:45)\n#2      Uri._makeFileUri (dart:core/uri.dart:871)\n#3      Uri.Uri.file (dart:core/uri.dart:731)\n#4      platformExeName (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_04.dart:127:17)\n#5      testDartExecShouldNotBeInCurrentDir (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_04.dart:42:40)\n#6      main (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_04.dart:143:3)\n#7      _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#8      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_04.dart\nTook 0:00:03.183857\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/platform_resolved_executable_test/04\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/platform_resolved_executable_test/05\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nThe null object does not have a method 'split'.\n\nNoSuchMethodError: method not found: 'split'\nReceiver: null\nArguments: [\"/\"]\n#0      Object._noSuchMethod (dart:core-patch/object_patch.dart:42)\n#1      Object.noSuchMethod (dart:core-patch/object_patch.dart:45)\n#2      Uri._makeFileUri (dart:core/uri.dart:871)\n#3      Uri.Uri.file (dart:core/uri.dart:731)\n#4      platformExeName (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_05.dart:127:17)\n#5      testDartExecShouldNotBeInCurrentDir (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_05.dart:42:40)\n#6      main (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_05.dart:143:3)\n#7      _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#8      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_05.dart\nTook 0:00:03.572672\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/platform_resolved_executable_test/05\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/platform_resolved_executable_test/02\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nThe null object does not have a method 'split'.\n\nNoSuchMethodError: method not found: 'split'\nReceiver: null\nArguments: [\"/\"]\n#0      Object._noSuchMethod (dart:core-patch/object_patch.dart:42)\n#1      Object.noSuchMethod (dart:core-patch/object_patch.dart:45)\n#2      Uri._makeFileUri (dart:core/uri.dart:871)\n#3      Uri.Uri.file (dart:core/uri.dart:731)\n#4      platformExeName (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_02.dart:127:17)\n#5      testDartExecShouldNotBeInCurrentDir (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_02.dart:42:40)\n#6      main (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_02.dart:143:3)\n#7      _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#8      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_02.dart\nTook 0:00:03.971820\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/platform_resolved_executable_test/02\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/platform_resolved_executable_test/03\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nThe null object does not have a method 'split'.\n\nNoSuchMethodError: method not found: 'split'\nReceiver: null\nArguments: [\"/\"]\n#0      Object._noSuchMethod (dart:core-patch/object_patch.dart:42)\n#1      Object.noSuchMethod (dart:core-patch/object_patch.dart:45)\n#2      Uri._makeFileUri (dart:core/uri.dart:871)\n#3      Uri.Uri.file (dart:core/uri.dart:731)\n#4      platformExeName (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_03.dart:127:17)\n#5      testDartExecShouldNotBeInCurrentDir (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_03.dart:42:40)\n#6      main (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_03.dart:143:3)\n#7      _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#8      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_03.dart\nTook 0:00:05.812485\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/platform_resolved_executable_test/03\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/platform_resolved_executable_test/06\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nThe null object does not have a method 'split'.\n\nNoSuchMethodError: method not found: 'split'\nReceiver: null\nArguments: [\"/\"]\n#0      Object._noSuchMethod (dart:core-patch/object_patch.dart:42)\n#1      Object.noSuchMethod (dart:core-patch/object_patch.dart:45)\n#2      Uri._makeFileUri (dart:core/uri.dart:871)\n#3      Uri.Uri.file (dart:core/uri.dart:731)\n#4      platformExeName (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_06.dart:127:17)\n#5      testDartExecShouldNotBeInCurrentDir (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_06.dart:42:40)\n#6      main (file:///home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_06.dart:143:3)\n#7      _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#8      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/out/DebugX64/generated_tests/standalone/platform_resolved_executable_test_06.dart\nTook 0:00:03.380996\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/platform_resolved_executable_test/06\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/signals_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nstderr:\nUnhandled exception:\nExpect.equals(expected: <false>, actual: <true>) fails.\n#0      Expect._fail (package:expect/expect.dart:385:5)\n#1      Expect.equals (package:expect/expect.dart:102:5)\n#2      testSignals.<anonymous closure>.<anonymous closure> (file:///home/mulander/github.com/mulander/sdk/tests/standalone/io/signals_test.dart:40:16)\n#3      _RootZone.runUnary (dart:async/zone.dart:1149)\n#4      _Future._propagateToListeners.handleValueCallback (dart:async/future_impl.dart:551)\n#5      _Future._propagateToListeners (dart:async/future_impl.dart:637)\n#6      _Future._completeWithValue (dart:async/future_impl.dart:424)\n#7      _Future._asyncComplete.<anonymous closure> (dart:async/future_impl.dart:479)\n#8      _microtaskLoop (dart:async/schedule_microtask.dart:41)\n#9      _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)\n#10     _runPendingImmediateCallback (dart:isolate-patch/isolate_patch.dart:96)\n#11     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:149)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/io/signals_test.dart\nTook 0:00:20.939798\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/signals_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/socket_ipv6_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nstderr:\nUnhandled exception:\nSocketException: Connection failed (OS Error: Connection refused, errno = 61), address = 127.0.0.1, port = 26866\n#0      _rootHandleUncaughtError.<anonymous closure> (dart:async/zone.dart:895)\n#1      _microtaskLoop (dart:async/schedule_microtask.dart:41)\n#2      _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)\n#3      _runPendingImmediateCallback (dart:isolate-patch/isolate_patch.dart:96)\n#4      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:149)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/io/socket_ipv6_test.dart\nTook 0:00:02.935926\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/socket_ipv6_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/socket_source_address_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstdout:\nunittest-suite-wait-for-done\n\n\nstderr:\nUnhandled exception:\nSocketException: Connection failed (OS Error: Connection refused, errno = 61), address = 127.0.0.1, port = 30560\n#0      testConnect.<testConnect_async_body> (file:///home/mulander/github.com/mulander/sdk/tests/standalone/io/socket_source_address_test.dart)\n#1      _asyncErrorWrapperHelper.<anonymous closure> (dart:async-patch/async_patch.dart:34)\n#2      _RootZone.runBinary (dart:async/zone.dart:1154)\n#3      _Future._propagateToListeners.handleError (dart:async/future_impl.dart:579)\n#4      _Future._propagateToListeners (dart:async/future_impl.dart:641)\n#5      _Future._completeError (dart:async/future_impl.dart:432)\n#6      _Future._asyncCompleteError.<anonymous closure> (dart:async/future_impl.dart:488)\n#7      _microtaskLoop (dart:async/schedule_microtask.dart:41)\n#8      _startMicrotaskLoop (dart:async/schedule_microtask.dart:50)\n#9      _runPendingImmediateCallback (dart:isolate-patch/isolate_patch.dart:96)\n#10     _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:149)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/io/socket_source_address_test.dart\nTook 0:00:06.155185\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/socket_source_address_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/test_extension_fail_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nBad state: Unknown operating system openbsd\n#0      getExtensionPath (file:///home/mulander/github.com/mulander/sdk/tests/standalone/io/test_extension_fail_test.dart:33:7)\n#1      main (file:///home/mulander/github.com/mulander/sdk/tests/standalone/io/test_extension_fail_test.dart:47:23)\n#2      _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#3      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/io/test_extension_fail_test.dart\nTook 0:00:02.017040\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/test_extension_fail_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/io/test_extension_test\nExpected: Pass\nActual: RuntimeError\nCommandOutput[vm]:\n\nstderr:\nUnhandled exception:\nExpect.fail('Unknown operating system openbsd')\n#0      Expect._fail (package:expect/expect.dart:385:5)\n#1      Expect.fail (package:expect/expect.dart:154:5)\n#2      getExtensionPath (file:///home/mulander/github.com/mulander/sdk/tests/standalone/io/test_extension_test.dart:34:14)\n#3      main (file:///home/mulander/github.com/mulander/sdk/tests/standalone/io/test_extension_test.dart:47:23)\n#4      _startIsolate.<anonymous closure> (dart:isolate-patch/isolate_patch.dart:261)\n#5      _RawReceivePortImpl._handleMessage (dart:isolate-patch/isolate_patch.dart:148)\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/io/test_extension_test.dart\nTook 0:00:01.905096\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/io/test_extension_test\n\n\nFAILED: none-vm-checked debug_x64 standalone/verified_mem_test\nExpected: Pass\nActual: Crash\nCommandOutput[vm]:\n\nstderr:\nVerifying before marking...Verifying before marking... done.\nVerifying before sweeping... done.\nVerifying before sweeping... done.\n done.\nVerifying before marking... done.\nVerifying before marking...Verifying before sweeping... done.\n done.\nVerifying before sweeping... done.\nVerifying before marking... done.\nVerifying before sweeping... done.\nVerifying before marking... done.\nVerifying before sweeping... done.\nVerifying before marking... done.\nVerifying before sweeping... done.\nVerifying before marking... done.\nVerifying before sweeping... done.\nVerifying before marking...terminate called after throwing an instance of 'std::bad_alloc'\n  what():  std::bad_alloc\n\n\nCommand[vm]: DART_CONFIGURATION=DebugX64 DebugX64/dart --enable_asserts --enable_type_checks --verified_mem --verify_before_gc --verify_after_gc --old_gen_growth_rate=1 --ignore-unrecognized-flags --package-root=DebugX64/packages/ /home/mulander/github.com/mulander/sdk/tests/standalone/verified_mem_test.dart\nTook 0:00:17.561648\n\nShort reproduction command (experimental):\n    python tools/test.py --checked -t120 standalone/verified_mem_test\n\n===\n=== 71 tests failed\n===\n\n[182:38 | 100% | +13514 | -   71]\n\n--- Total time: 182:38 ---\n0:08:00.389091 - vm - none-vm-checked debug_x64/pkg/analysis_server/test/completion_test\n0:02:00.866380 - vm - none-vm-checked debug_x64/language/large_class_declaration_test\n0:02:00.656501 - vm - none-vm-checked debug_x64/co19/LibTest/collection/ListBase/ListBase_class_A01_t02\n0:02:00.576703 - vm - none-vm-checked debug_x64/language/closure_cycles_test\n0:02:00.427421 - vm - none-vm-checked debug_x64/co19/LibTest/core/int/operator_left_shift_A01_t02\n0:02:00.236365 - vm - none-vm-checked debug_x64/pkg/analyzer/test/generated/resolver_test\n0:02:00.218980 - vm - none-vm-checked debug_x64/pkg/analysis_server/test/edit/refactoring_test\n0:02:00.208476 - vm - none-vm-checked debug_x64/pkg/analyzer/test/src/task/dart_test\n0:02:00.188039 - run_vm_unittest - none-vm-checked debug_x64/vm/cc/FindCodeObject\n0:02:00.180456 - vm - none-vm-checked debug_x64/co19/LibTest/collection/ListMixin/ListMixin_class_A01_t02\n0:02:00.179501 - vm - none-vm-checked debug_x64/pkg/analyzer/test/generated/compile_time_error_code_test\n0:02:00.176776 - vm - none-vm-checked debug_x64/pkg/analyzer/test/src/summary/summary_test\n0:02:00.160646 - vm - none-vm-checked debug_x64/pkg/analyzer/test/generated/non_error_resolver_test\n0:02:00.146838 - vm - none-vm-checked debug_x64/lib/mirrors/immutable_collections_test\n0:02:00.101170 - vm - none-vm-checked debug_x64/standalone/full_coverage_test\n0:02:00.083946 - run_vm_unittest - none-vm-checked debug_x64/vm/cc/CustomIsolates\n0:02:00.044440 - vm - none-vm-checked debug_x64/pkg/analysis_server/test/integration/completion/get_suggestions_test\n0:01:59.813077 - vm - none-vm-checked debug_x64/pkg/analyzer/test/generated/incremental_resolver_test\n0:01:46.585302 - vm - none-vm-checked debug_x64/corelib/regexp/pcre_test\n0:01:46.161750 - vm - none-vm-checked debug_x64/pkg/analysis_server/test/search/element_references_test\n```\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3728", "user": "mulander", "root": "ROOT37", "reply_to": "COM3727", "timestamp": "2016-01-04T16:17:44Z", "text": "Please note that resolving the dartSdkPath failures are expected by me as I didn't yet implement a procfs replacement.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3729", "user": "mulander", "root": "ROOT37", "reply_to": "COM3728", "timestamp": "2016-01-04T17:34:22Z", "text": "@iposva-google your cl upload tool doesn't work for me (after properly logging in). Is there any other way to upload?\n\n```\n$ git cl upload\n/usr/local/lib/python2.7/site-packages/Crypto/Util/number.py:57: PowmInsecureWarning: Not using mpz_powm_sec.  You should rebuild using libgmp >= 5 to avo$\nd timing attack vulnerability.\n  _warn(\"Not using mpz_powm_sec.  You should rebuild using libgmp >= 5 to avoid timing attack vulnerability.\", PowmInsecureWarning)\nUsing 50% similarity for rename/copy detection. Override with --similarity.\nRunning presubmit upload checks ...\n\nPresubmit checks passed.\nNo output from ['git', 'diff', '--no-color', '--no-ext-diff', '--full-index', '--ignore-submodules', '--src-prefix=a/', '--dst-prefix=b/', 'b6e20f60c93aa3$\nfc7890b854b8f20dc4610c8ee', 'HEAD']\n\nGot exception while uploading -- saving description to /home/mulander/.git_cl_description_backup\n```\n\nThat's post git rebase-update which killed my master branch and forced a manuall merge with current upstream again. I'm trying a fresh checkout now...\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT38", "user": "dazinator", "root": "ROOT38", "reply_to": null, "timestamp": "2019-07-05T15:47:22Z", "text": "How to copy text? Ctrl + C isn't working? I installed the terminal from the windows app store, created a powershell tab, ran a command.\r \r I then wanted to copy that command text, so I highlighted it, then pressed ctrl + c but it doesn't appear to have copied the command text. I also tried ctrl + shift + c. Getting desperate I right clicked on the tab item itself, looking for a menu where I could select \"copy\" but no such menu seems to exist. I also tried right clicking with the text selected hoping for a menu where I could select \"copy selection\" but again no such menu exists. In desperation I gave up - copying text does not appear possible. What am I doing wrong?\r ", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM380", "user": "loganmancuso", "root": "ROOT38", "reply_to": "ROOT38", "timestamp": "2019-07-05T16:26:15Z", "text": "from what I remember this function has not yet been added to the terminal2 it still implements the copy -paste protocol from cmd and PowerShell. highlight text and press <enter> to copy and <rightclick> to paste the clipboard #1180 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM381", "user": "drk-mtr", "root": "ROOT38", "reply_to": "COM380", "timestamp": "2019-07-06T01:36:43Z", "text": "Right clicking the selected text will copy it to the clipboard.\r\n\r\nI'd like a way to do this that uses the keyboard instead.", "meta": {"posReactions": "8", "negReactions": "0"}}
{"id": "COM382", "user": "jherrera123", "root": "ROOT38", "reply_to": "COM381", "timestamp": "2019-07-06T01:51:55Z", "text": "Shoud we open a new issue requesting a feature to enable CTRL+C / CTRL+V  to copy/paste?", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM383", "user": "DHowett-MSFT", "root": "ROOT38", "reply_to": "COM382", "timestamp": "2019-07-06T02:04:58Z", "text": "Please don\u2019t! We\u2019ll just have to close it as a duplicate of a feature that made it into v0.3", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM384", "user": "nimocat", "root": "ROOT38", "reply_to": "COM383", "timestamp": "2019-07-08T04:49:37Z", "text": "actually Ctrl+C works fine in powershell in windows terminal, the real problem is the support to wsl, when I use wsl2 in windows terminal, for example, a ubuntu18.04, I can't use Ctrl+C or Ctrl+Shift+C, but in bash or wsl.exe, it works fine.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM385", "user": "andrp92", "root": "ROOT38", "reply_to": "COM384", "timestamp": "2019-07-08T17:58:28Z", "text": "It would be nice to have shift+insert or Ctrl+shift+insert to have a linux like feeling or ctrl+shift+c and ctrl+shift+v like powershell does", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM386", "user": "DHowett-MSFT", "root": "ROOT38", "reply_to": "COM385", "timestamp": "2019-07-08T21:31:44Z", "text": "This was fixed with #1093 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM387", "user": "atruskie", "root": "ROOT38", "reply_to": "COM386", "timestamp": "2019-07-10T00:53:21Z", "text": "I don't think this is fixed?\r\n\r\nThe changes in #1093:\r\n\r\n- set the default binding to `ctrl+shift+c`\r\n- and even if we could rebind the default to `ctrl+c`, doesn't implement the copy-if-text-selected-or-send-ctrl+c semantics discussed in https://github.com/microsoft/terminal/pull/1093#issuecomment-498829169\r\n\r\nI apologise if I've misread any of the code.\r\n\r\nI've been fighting years of muscle memory this last week because ctrl+c doesn't work; I realise it may seem like a triviality, but I think it's important for user experience. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM388", "user": "DHowett-MSFT", "root": "ROOT38", "reply_to": "COM387", "timestamp": "2019-07-10T01:01:36Z", "text": "I'll reopen it for our next Triage cycle.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM389", "user": "DHowett-MSFT", "root": "ROOT38", "reply_to": "COM388", "timestamp": "2019-07-15T21:12:43Z", "text": "We'll track all copy/selection issues as part of #524 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3810", "user": "Panzerbjrn", "root": "ROOT38", "reply_to": "COM389", "timestamp": "2019-07-27T11:53:03Z", "text": "Any idea when this will be fixed?\r\nCopying is a fairly standard function...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3811", "user": "Panzerbjrn", "root": "ROOT38", "reply_to": "COM3810", "timestamp": "2019-07-27T11:53:23Z", "text": "Also, shouldn't this be open since CTRL+C still doesn't copy?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3812", "user": "drk-mtr", "root": "ROOT38", "reply_to": "COM3811", "timestamp": "2019-07-27T13:42:03Z", "text": "No this should be closed, since the decided upon feature is customisable binding not hard-coded use of ctrl+c.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM3813", "user": "dazinator", "root": "ROOT38", "reply_to": "COM3812", "timestamp": "2019-07-27T13:47:53Z", "text": "Customisable is great! - but what's the default setting out of the box?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3814", "user": "zadjii-msft", "root": "ROOT38", "reply_to": "COM3813", "timestamp": "2019-07-30T13:13:55Z", "text": "The default keybindings for copy and paste are Ctrl+Shift+C/V. If your profiles.json file was created before #1093, then they won't contain that keybinding, and you'll need to add it manually.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3815", "user": "congjinruo", "root": "ROOT38", "reply_to": "COM3814", "timestamp": "2019-07-30T13:52:40Z", "text": "> Right clicking the selected text will copy it to the clipboard.\r\n> \r\n> I'd like a way to do this that uses the keyboard instead.\r\n\r\nget it, really cool.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3816", "user": "CobusKruger", "root": "ROOT38", "reply_to": "COM3815", "timestamp": "2019-08-06T11:43:42Z", "text": "> This was fixed with #1093\r\n\r\nNope, it wasn't. \r\n\r\nMaking Ctrl+Shift+C the keybinding for copy is pointless. You may as well make it anything else Ctrl+P. People expect Ctrl+C and using anything except that will just make the copy feature undiscoverable. ", "meta": {"posReactions": "1", "negReactions": "2"}}
{"id": "COM3817", "user": "Panzerbjrn", "root": "ROOT38", "reply_to": "COM3816", "timestamp": "2019-08-06T13:54:36Z", "text": "I couldn't agree more with @CobusKruger. \r\nSome things are just so common and expected, that not to use them just seems like you're actively hiding features from users. \r\nNo one expects CTRL+SHIFT+C/V, They expect CTRL+C/V; If it were otherwise, there wouldn't be so many users here clamoring for it. \r\nCTRL+C/V is what should be in the json by default. \r\nThis is very much a case of \"Old Microsoft\" rearing it's head, rather then new forward looking Microsoft.\r\nSo yes, this should not be closed until this problem has actually been fixed...", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM3818", "user": "miniksa", "root": "ROOT38", "reply_to": "COM3817", "timestamp": "2019-08-06T16:39:36Z", "text": "> This is very much a case of \"Old Microsoft\" rearing it's head, rather then new forward looking Microsoft.\r\n\r\n@Panzerbjrn, please let me refresh you on the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). We can disagree here and have debates, but please halt yourself before assuming the motivations of others and attacking individuals personally or their work.\r\n\r\nWe are happy to continue to discuss the way that this prerelease product should evolve before it meets v1.0 (and even after 1.0!) Please exercise patience and understanding when working with us and members of the community as the software develops.\r\n", "meta": {"posReactions": "3", "negReactions": "1"}}
{"id": "COM3819", "user": "zadjii-msft", "root": "ROOT38", "reply_to": "COM3818", "timestamp": "2019-08-06T16:45:28Z", "text": "In fact, I'd suggest that the new keybindings are very \"new\"-Microsoft.\r\n\r\n> [Gnome Terminal](https://help.gnome.org/users/gnome-terminal/stable/txt-copy-paste.html) has a consistent keybinding that's not intuitive at first, but easy to adopt, and not too far from the usual <kbd>CTRL + C</kbd> for copy.\r\n> <kbd>CTRL + C</kbd> : Cancel\r\n> <kbd>CTRL + Shift + C</kbd> : Copy\r\n> <kbd>CTRL + Shift + V</kbd> : Paste\r\n\r\nThis is the style of copy/paste keybindings for every other terminal on the planet, and the style we've chosen as the defaults. If you're unhappy with them, you're absolutely free to change them. ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM3820", "user": "Panzerbjrn", "root": "ROOT38", "reply_to": "COM3819", "timestamp": "2019-08-06T17:26:50Z", "text": "> \r\n> please halt yourself before assuming the motivations of others and attacking individuals personally or their work.\r\n\r\nPlease feel free to point out what I said that was even remotely an attack on *anyone* or an assumption of motivations?\r\nOr did you perhaps recognise the truth of what I wrote and felt defensive?", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM3821", "user": "drk-mtr", "root": "ROOT38", "reply_to": "COM3820", "timestamp": "2019-08-06T19:10:13Z", "text": "I am so tempted to chime in with something more confrontational but I don't think it'll add to the debate so I'll just say this:\r\n\r\n- The devs have been very responsive, and have been  accommodating of the many (often mutually conflicting) requests coming in from users. By this token the \"old Microsoft\" assertion seems unfounded and potentially disheartening for the people who have plowed a lot of work in to this.\r\n- This is a beta product, if you expect it to meet all your needs straight away you probably need to realign your expectations.\r\n- Some decisions will be made that won't work in your favour. Many won't work in my favour. However these are educated decisions made in the interest of supporting the average user (not just you), by talented devs who are acknowledging some compromise but are making pragmatic decisions nonetheless. By assuming your needs are paramount, you are potentially dismissing the needs of other users (e.g. WSL users like me who support the sensible decision to align with Gnome bindings and avoid escape sequence characters for default bindings).\r\n- This is open source. If you feel you have the expertise to override their decisions, then you are free to implement changes in your own fork. If you don't have that expertise, you can't reasonably claim that the decision taken is actually wrong. \"It's not what I'm familiar with\" is probably not a good enough justification (in my view).\r\n\r\nI won't reply to responses as I know it won't add anything and that I shouldn't have even posted the above, but I couldn't resist throwing my two cents in - sorry!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT39", "user": "Devligue", "root": "ROOT39", "reply_to": null, "timestamp": "2018-06-03T18:25:47Z", "text": "Unable to delete files on Fedora 28 (gvfs-trash is deprecated) <!--\r \r Have you read Atom's Code of Conduct? By filing an Issue, you are expected to comply with it, including treating everyone with respect: https://github.com/atom/atom/blob/master/CODE_OF_CONDUCT.md\r \r Do you want to ask a question? Are you looking for support? The Atom message board is the best place for getting support: https://discuss.atom.io\r \r -->\r \r ### Prerequisites\r \r * [x] Put an X between the brackets on this line if you have done all of the following:\r     * Reproduced the problem in Safe Mode: https://flight-manual.atom.io/hacking-atom/sections/debugging/#using-safe-mode\r     * Followed all applicable steps in the debugging guide: https://flight-manual.atom.io/hacking-atom/sections/debugging/\r     * Checked the FAQs on the message board for common solutions: https://discuss.atom.io/c/faq\r     * Checked that your issue isn't already filed: https://github.com/issues?utf8=\u2713&q=is%3Aissue+user%3Aatom\r     * Checked that there is not already an Atom package that provides the described functionality: https://atom.io/packages\r \r ### Description\r \r My issue is the same as in #15949 except it is not fixed. \r \r I am unable to delete file (or directory). When trying, the following message appears: `Is gvfs-trash installed?`\r \r ### Steps to Reproduce\r \r 1. Try to delete any file or directory\r 2. ???\r 3. Profit\r \r **Expected behavior:** Deleting file should delete file\r \r **Actual behavior:** The file is not deleted\r \r **Reproduces how often:** Every time\r \r ### Versions\r \r ```\r Atom    : 1.27.1\r Electron: 1.7.15\r Chrome  : 58.0.3029.110\r Node    : 7.9.0\r ```\r ```\r apm  1.19.0\r npm  3.10.10\r node 6.9.5 x64\r atom 1.27.1\r python 2.7.15\r git 2.17.1\r ```\r ```\r OS: Fedora 28\r ```\r \r ### Additional Information\r ```\r $ gvfs-trash\r This tool has been deprecated, use 'gio trash' instead.\r See 'gio help trash' for more info.\r ```\r The `gio trash` is supposedly implemented since electron 1.7.2 and for some folks out there this problem was fixed with `Atom 1.25` (which included upgrade to `Electron 1.7.11`) but apparently I am on even newer Atom version, with even newer Electron and it still happens.\r \r ### EDIT1\r #### More insight on the problem provided by @cutephoton:\r > @Devligue This is a legit bug. The _tldr answer_ is that `_g_file_trash` may not be supported. In order for `_g_file_trash` to succeed, the following conditions must be met:\r > \r > * The file being moved to trash is on the same partition as your home folder\r >   **OR**\r > * A trash folder already exists or can be created at the mount point and,\r > * The trash folder is considered 'safe/secure' by verifying UID and restrictive permissions\r > \r > **How this should probably be fixed...**\r > \r > Atom does not have a fallback mechanism like offering the ability to permanently remove a file instead. This would address bring atom in line with gnome's graceful behaviour. The attached image show how Gnome Files (aka Nautilus) prompt the user to permanently delete the file (when trash not supported)\r > \r > ![gnome's solution](https://user-images.githubusercontent.com/19512121/43511743-0dac32c0-952e-11e8-8af8-e0ef6cb916d0.png)\r > \r > **Impact: Users with multiple disks and partitions**\r > \r > Fedora/Redhat/etc: _Impacted_ due to default partition scheme that separates `/` and `/home` in to partitions. Files outside of the `/home` partition cannot be moved to trash.\r > \r > Ubuntu: Less likely due to partition layout (`/home` is part of the `/` partition)\r > \r > Conditions where users will be impacted:\r > \r > * File systems with unix permissions:\r >   \r >   * _Impacted with workaround_ due to typical restrictive top-level directory permissions (root)\r > * FAT/non-unix file systems:\r >   \r >   * User Session Mount (i.e. `/run/media/$USER/disk-label`): _No Impact_\r >   * Fstab: _Impacted_ even with permissive umask. The default uid/gid is root. It will be unable to satisfy the requirements of a trash folder without additional options (uid/gid/umask).\r > * Network shared folders: _Unknown/Did not test._\r > \r > **Notes/Testing the Root Cause**\r > \r > Note: Though I am confident that my analysis is decent enough, much of the code I was referencing was unfamiliar/new to me.\r > \r > Initially I encountered this issue when I put files in a certain location like the reporter above. I created a delete-me file test as suggested above in the relevant directory, `/opt/cupenv`. I ran the command `strace gio trash delete-me.txt`. A abridged version of the output is here:\r > \r > ```\r > lstat(\"/opt/cupenv/delete-me.txt\", {st_mode=S_IFREG|0664, st_size=6, ...}) = 0\r > ...\r > lstat(\"/.Trash-1000\", 0x7ffde5ffb5b0)   = -1 ENOENT (No such file or directory)\r > mkdir(\"/.Trash-1000\", 0700)             = -1 EACCES (Permission denied)\r > ```\r > That's unexpected. The API documentation for [g_file_trash](https://developer.gnome.org/gio/stable/GFile.html#g-file-trash) lacks some level of specificity.\r > \r > > Sends file to the \"Trashcan\", if possible. This is similar to deleting it, but the user can recover it before emptying the trashcan. Not all file systems support trashing, so this call can return the G_IO_ERROR_NOT_SUPPORTED error.\r > \r > One might assume (as I did): Given a path, if the user has permission to modify/delete the file, then GIO's g_file_trash API should succeed at removing the file in some manner. Perhaps, if trash functionality is not available, then there might be a fallback mechanism. In the case of `gio trash` I expected there to be a -f force option that would prioritize trash over permanently deleting the file. (`gio trash -f` only ignores files that don't exist)\r > \r > Glib appears to implement GIO local file access using [glocalfile.c](https://github.com/GNOME/glib/blob/83a4cab12c2d00dbfe6013d071cff2da310109a4/gio/glocalfile.c#L1899). The trash algorithm looks like this:\r > \r > * Is the path on the same partition as the user's home directory? If so, move the file to the home trash folder if possible and exit.\r > * Given the path, locate the mount point top level directory (denoted as `$topdir` in source)\r >   \r >   * In my case, `/opt/cupenv/delete_me.txt` -> `/` (the primary partition)\r >   * A more typical case: `/run/media/$USER/disk-label/a/b/c/d` would be `/run/media/$USER/disk-label`\r > * If `$topdir` is found, pick one of `$topdir/.Trash/$UID` or `$topdir/.Trash-UID` folder.\r >   \r >   * If `$topdir/.Trash-UID` and `$topdir/.Trash/$UID` exists: Validate proper UID and file permission (or fail)\r >   * Try to create folder `$topdir/.Trash-$UID`. Validate proper UID and file permission (or fail)\r > \r > At the end of the function we find [`G_IO_ERROR_NOT_SUPPORTED` is returned](https://github.com/GNOME/glib/blob/83a4cab12c2d00dbfe6013d071cff2da310109a4/gio/glocalfile.c#L2059) when such a folder is not found and cannot be created.\r > \r > ```\r > if (trashdir == NULL)\r > \t{\r > \t  g_free (topdir);\r >           g_set_io_error (error,\r >                           _(\"Unable to find or create trash directory for %s\"),\r >                           file, G_IO_ERROR_NOT_SUPPORTED);\r > \t  return FALSE;\r > }\r > ```\r > I confirmed my understanding by creating a top level trash folder and using gio trash command.\r > \r > ```\r > sudo mkdir /.Trash-1000\r > sudo chmod 0700 /.Trash-1000\r > sudo chown fosterb:fosterb /.Trash-1000\r > cd /opt/cupenv && echo hello > delete-me.txt; gio trash delete-me.txt\r > ```\r > Files located on the same partition as your home directory can always be moved to your user trash folder. On my operating system, the paths `/` and `/home` are separate partitions. I created a file `/home/tmp/x` where `tmp` and `x` are owned by my user. In this case, the files get moved to your `$HOME/.local/share/Trash` folder.\r > \r > ```\r > lstat(\"/home/tmp/x\", {st_mode=S_IFREG|0644, st_size=0, ...}) = 0\r > stat(\"/home/fosterb\", {st_mode=S_IFDIR|0700, st_size=4096, ...}) = 0\r > access(\"/home\", F_OK)                   = 0\r > ....\r > stat(\"/home/fosterb/.local/share\", {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0\r > access(\"/home/fosterb/.local/share/Trash\", F_OK) = 0\r > stat(\"/home/fosterb/.local/share/Trash\", {st_mode=S_IFDIR|0700, st_size=4096, ...}) = 0\r > mkdir(\"/home/fosterb/.local/share/Trash/info\", 0700) = -1 EEXIST (File exists)\r > mkdir(\"/home/fosterb/.local/share/Trash/files\", 0700) = -1 EEXIST (File exists)\r > openat(AT_FDCWD, \"/home/fosterb/.local/share/Trash/info/x.trashinfo\", O_RDONLY|O_CREAT|O_EXCL, 0666) = 7\r > ```\r > But when mounting disks (external or internal) using fstab or mount commands (as opposed to session-based mounting) issues can arise. I tested a FAT file system with umask=0000 and uid/gid set to root.\r > \r > ```\r > lstat(\"/mnt/giotest\", {st_mode=S_IFDIR|0777, st_size=8192, ...}) = 0\r > lstat(\"/mnt\", {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0\r > lstat(\"/mnt/giotest/.Trash\", 0x7fffec5502c0) = -1 ENOENT (No such file or directory)\r > lstat(\"/mnt/giotest/.Trash-1000\", 0x7fffec550230) = -1 ENOENT (No such file or directory)\r > mkdir(\"/mnt/giotest/.Trash-1000\", 0700) = 0\r > lstat(\"/mnt/giotest/.Trash-1000\", {st_mode=S_IFDIR|0777, st_size=8192, ...}) = 0\r > unlink(\"/mnt/giotest/.Trash-1000\")      = -1 EISDIR (Is a directory)\r > rmdir(\"/mnt/giotest/.Trash-1000\")       = 0\r > file:///mnt/giotest/x: Unable to find or create trash directory for /mnt/giotest/x\r > ```\r > You can see gio trash going through the motions. The operations succeeds but the command still reports an error.\r > \r > ```\r > [fosterb@rose giotest]$ ls -lah\r > total 12K\r > drwxrwxrwx. 2 root root 8.0K Aug  1 00:36 .\r > drwxr-xr-x. 4 root root 4.0K Aug  1 00:30 ..\r > -rwxrwxrwx. 1 root root    0 Aug  1 01:23 x\r > ```\r > GLib/Gio will not write to a trash directory with incorrect permissions/ownership. (Security?) Without unix permissions, trash will always fail on these mount points. Modifying fstab to appear similar to options used during session mounts (UID/GID set to user vs root, umask is set appropriately). Conveniently the [source code](https://github.com/GNOME/glib/blob/83a4cab12c2d00dbfe6013d071cff2da310109a4/gio/glocalfile.c#L2046) has a comment that seems to strongly imply this is a known/expected.\r > \r > ```\r > \t\t  /* Ensure that the created dir has the right uid etc.\r > \t\t     This might fail on e.g. a FAT dir */\r > ```\r > Most of this was unnecessary, but I figured I'd show my work.\r \r ### EDIT2\r #### More insight, to not get confused as of the nature of the bug, and how to reproduce it (by @cutephoton as well):\r > Yes, as reported, the ELECTRON_TRASH environment variable is needed. This is the issue referenced #15949 bug. The issue reported here is not related to #15949. The error message related to gvfs-trash is a blunt tool (even access denied errors produce the same error message) so I understand why people are responding here.\r > \r > The reporter clarifies one of the key symptoms here:\r > [#17452 (comment)](https://github.com/atom/atom/issues/17452#issuecomment-396407349)\r > \r > And that led to my deep dive. My deep dive details the specific cases where trash becomes unavailable (i.e. when a trash folder cannot be safely created).\r > [#17452 (comment)](https://github.com/atom/atom/issues/17452#issuecomment-409518547)\r > \r > **I just revalidated my findings and unsurprisingly gio trash still fails.**\r > \r > Anyhow, I wanted to clarify this so it doesn't get lost when/if atom devs look in to this issue.\r \r \r ", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM390", "user": "rsese", "root": "ROOT39", "reply_to": "ROOT39", "timestamp": "2018-06-04T20:01:19Z", "text": "Thanks for opening a new issue - is `gio` available on Fedora 28?  ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM391", "user": "Devligue", "root": "ROOT39", "reply_to": "COM390", "timestamp": "2018-06-04T20:06:35Z", "text": "Yes, `gio` is available and installed by default", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM392", "user": "rsese", "root": "ROOT39", "reply_to": "COM391", "timestamp": "2018-06-05T02:12:33Z", "text": "Hmmm, not sure why it's not working then - any difference if you specifically set an `ELECTRON_TRASH` environment variable to `gio` and then restart Atom?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM393", "user": "Devligue", "root": "ROOT39", "reply_to": "COM392", "timestamp": "2018-06-05T22:31:29Z", "text": "It changes nothing :thinking: \r\n\r\n```\r\n$ gio --version\r\n2.56.1\r\n```\r\n\r\n```\r\necho $ELECTRON_TRASH\r\ngio\r\n```\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM394", "user": "rsese", "root": "ROOT39", "reply_to": "COM393", "timestamp": "2018-06-11T21:35:37Z", "text": "And if you just use `gio trash` from the command line it works fine?  E.g.:\r\n\r\n```\r\necho hello > delete-me.txt\r\ngio trash delete-me.txt\r\n```\r\n\r\nAlso, are you getting the exact same error message you mentioned (\"When trying, the following message appears: Is gvfs-trash installed?\") after you set the `ELECTRON_TRASH` environment variable to `gio`?  ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM395", "user": "Devligue", "root": "ROOT39", "reply_to": "COM394", "timestamp": "2018-06-11T22:28:55Z", "text": "The `echo hello > delete-me.txt; gio trash delete-me.txt` works just fine normally but crashes on the ntfs partition. As I see this, it is not an Atom bug, however the error message it kept returning me was quite misleading.\r\n\r\nI didn't solve the problem yet, but I am closing this since it is not related to Atom. Sorry for trouble!", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM396", "user": "50Wliu", "root": "ROOT39", "reply_to": "COM395", "timestamp": "2018-06-12T01:13:03Z", "text": "> however the error message it kept returning me was quite misleading.\r\n\r\nYeah, that's the default error message.  Unfortunately, Electron's moveToTrash method doesn't say _why_ it failed, just that it did.  We've found that the most common reason is that `gvfs-trash` isn't installed, which is why we decided to include it in the error message.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM397", "user": "cutephoton", "root": "ROOT39", "reply_to": "COM396", "timestamp": "2018-08-01T09:48:16Z", "text": "@Devligue This is a legit bug. The _tldr answer_ is that `_g_file_trash` may not be supported. In order for `_g_file_trash` to succeed, the following conditions must be met:\r\n\r\n- The file being moved to trash is on the same partition as your home folder\r\n**OR**\r\n- A trash folder already exists or can be created at the mount point and,\r\n- The trash folder is considered 'safe/secure' by verifying UID and restrictive permissions\r\n\r\n**How this should probably be fixed...**\r\n\r\nAtom does not have a fallback mechanism like offering the ability to permanently remove a file instead. This would address bring atom in line with gnome's graceful behaviour. The attached image show how  Gnome Files (aka Nautilus) prompt the user to permanently delete the file (when trash not supported)\r\n\r\n![gnome's solution](https://user-images.githubusercontent.com/19512121/43511743-0dac32c0-952e-11e8-8af8-e0ef6cb916d0.png)\r\n\r\n**Impact: Users with multiple disks and partitions**\r\n\r\nFedora/Redhat/etc: _Impacted_ due to default partition scheme that separates `/` and `/home` in to partitions. Files outside of the `/home` partition cannot be moved to trash.\r\n\r\nUbuntu: Less likely due to partition layout (`/home` is part of the `/` partition)\r\n\r\nConditions where users will be impacted:\r\n- File systems with unix permissions:\r\n  - _Impacted with workaround_ due to typical restrictive top-level directory permissions (root)\r\n- FAT/non-unix file systems:\r\n  - User Session Mount (i.e. `/run/media/$USER/disk-label`): _No Impact_\r\n  - Fstab: _Impacted_ even with permissive umask. The default uid/gid is root. It will be unable to satisfy the requirements of a trash folder without additional options (uid/gid/umask).\r\n- Network shared folders: _Unknown/Did not test._\r\n\r\n**Notes/Testing the Root Cause**\r\n\r\nNote: Though I am confident that my analysis is decent enough, much of the code I was referencing was unfamiliar/new to me.\r\n\r\nInitially I encountered this issue when I put files in a certain location like the reporter above. I created a delete-me file test as suggested above in the relevant directory, `/opt/cupenv`. I ran the command  `strace gio trash delete-me.txt`. A abridged version of the output is here:\r\n\r\n```\r\nlstat(\"/opt/cupenv/delete-me.txt\", {st_mode=S_IFREG|0664, st_size=6, ...}) = 0\r\n...\r\nlstat(\"/.Trash-1000\", 0x7ffde5ffb5b0)   = -1 ENOENT (No such file or directory)\r\nmkdir(\"/.Trash-1000\", 0700)             = -1 EACCES (Permission denied)\r\n```\r\nThat's unexpected. The API documentation for [g_file_trash](https://developer.gnome.org/gio/stable/GFile.html#g-file-trash) lacks some level of specificity.\r\n\r\n> Sends file to the \"Trashcan\", if possible. This is similar to deleting it, but the user can recover it before emptying the trashcan. Not all file systems support trashing, so this call can return the G_IO_ERROR_NOT_SUPPORTED error. \r\n\r\nOne might assume (as I did): Given a path, if the user has permission to modify/delete the file, then GIO's g_file_trash API should succeed at removing the file in some manner. Perhaps, if trash functionality is not available, then there might be a fallback mechanism. In the case of `gio trash` I expected there to be a -f force option that would prioritize trash over permanently deleting the file. (`gio trash -f` only ignores files that don't exist)\r\n\r\nGlib appears to implement GIO local file access using [glocalfile.c](https://github.com/GNOME/glib/blob/83a4cab12c2d00dbfe6013d071cff2da310109a4/gio/glocalfile.c#L1899). The trash algorithm looks like this:\r\n\r\n- Is the path on the same partition as the user's home directory? If so, move the file to the home trash folder if possible and exit.\r\n- Given the path, locate the mount point top level directory (denoted as `$topdir` in source)\r\n  - In my case, `/opt/cupenv/delete_me.txt` -> `/` (the primary partition)\r\n  - A more typical case: `/run/media/$USER/disk-label/a/b/c/d` would be `/run/media/$USER/disk-label`\r\n- If `$topdir` is found, pick one of `$topdir/.Trash/$UID` or `$topdir/.Trash-UID` folder.\r\n  - If `$topdir/.Trash-UID` and `$topdir/.Trash/$UID` exists: Validate proper UID and file permission (or fail)\r\n  - Try to create folder `$topdir/.Trash-$UID`. Validate proper UID and file permission (or fail)\r\n\r\nAt the end of the function we find [`G_IO_ERROR_NOT_SUPPORTED` is returned](https://github.com/GNOME/glib/blob/83a4cab12c2d00dbfe6013d071cff2da310109a4/gio/glocalfile.c#L2059) when such a folder is not found and cannot be created.\r\n\r\n```\r\nif (trashdir == NULL)\r\n\t{\r\n\t  g_free (topdir);\r\n          g_set_io_error (error,\r\n                          _(\"Unable to find or create trash directory for %s\"),\r\n                          file, G_IO_ERROR_NOT_SUPPORTED);\r\n\t  return FALSE;\r\n}\r\n```\r\n\r\nI confirmed my understanding by creating a top level trash folder and using gio trash command.\r\n\r\n```\r\nsudo mkdir /.Trash-1000\r\nsudo chmod 0700 /.Trash-1000\r\nsudo chown fosterb:fosterb /.Trash-1000\r\ncd /opt/cupenv && echo hello > delete-me.txt; gio trash delete-me.txt\r\n```\r\nFiles located on the same partition as your home directory can always be moved to your user trash folder. On my operating system, the paths `/` and `/home` are separate partitions. I created a file `/home/tmp/x` where `tmp` and `x` are owned by my user. In this case, the files get moved to your `$HOME/.local/share/Trash` folder.\r\n\r\n```\r\nlstat(\"/home/tmp/x\", {st_mode=S_IFREG|0644, st_size=0, ...}) = 0\r\nstat(\"/home/fosterb\", {st_mode=S_IFDIR|0700, st_size=4096, ...}) = 0\r\naccess(\"/home\", F_OK)                   = 0\r\n....\r\nstat(\"/home/fosterb/.local/share\", {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0\r\naccess(\"/home/fosterb/.local/share/Trash\", F_OK) = 0\r\nstat(\"/home/fosterb/.local/share/Trash\", {st_mode=S_IFDIR|0700, st_size=4096, ...}) = 0\r\nmkdir(\"/home/fosterb/.local/share/Trash/info\", 0700) = -1 EEXIST (File exists)\r\nmkdir(\"/home/fosterb/.local/share/Trash/files\", 0700) = -1 EEXIST (File exists)\r\nopenat(AT_FDCWD, \"/home/fosterb/.local/share/Trash/info/x.trashinfo\", O_RDONLY|O_CREAT|O_EXCL, 0666) = 7\r\n```\r\nBut when mounting disks (external or internal) using fstab or mount commands (as opposed to session-based mounting) issues can arise. I tested a FAT file system with umask=0000 and uid/gid set to root.\r\n\r\n```\r\nlstat(\"/mnt/giotest\", {st_mode=S_IFDIR|0777, st_size=8192, ...}) = 0\r\nlstat(\"/mnt\", {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0\r\nlstat(\"/mnt/giotest/.Trash\", 0x7fffec5502c0) = -1 ENOENT (No such file or directory)\r\nlstat(\"/mnt/giotest/.Trash-1000\", 0x7fffec550230) = -1 ENOENT (No such file or directory)\r\nmkdir(\"/mnt/giotest/.Trash-1000\", 0700) = 0\r\nlstat(\"/mnt/giotest/.Trash-1000\", {st_mode=S_IFDIR|0777, st_size=8192, ...}) = 0\r\nunlink(\"/mnt/giotest/.Trash-1000\")      = -1 EISDIR (Is a directory)\r\nrmdir(\"/mnt/giotest/.Trash-1000\")       = 0\r\nfile:///mnt/giotest/x: Unable to find or create trash directory for /mnt/giotest/x\r\n```\r\n\r\nYou can see gio trash going through the motions. The operations succeeds but the command still reports an error.\r\n```\r\n[fosterb@rose giotest]$ ls -lah\r\ntotal 12K\r\ndrwxrwxrwx. 2 root root 8.0K Aug  1 00:36 .\r\ndrwxr-xr-x. 4 root root 4.0K Aug  1 00:30 ..\r\n-rwxrwxrwx. 1 root root    0 Aug  1 01:23 x\r\n```\r\n\r\nGLib/Gio will not write to a trash directory with incorrect permissions/ownership. (Security?) Without unix permissions, trash will always fail on these mount points. Modifying fstab to appear similar to options used during session mounts (UID/GID set to user vs root, umask is set appropriately). Conveniently the [source code](https://github.com/GNOME/glib/blob/83a4cab12c2d00dbfe6013d071cff2da310109a4/gio/glocalfile.c#L2046) has a comment that seems to strongly imply this is a known/expected.\r\n\r\n```\r\n\t\t  /* Ensure that the created dir has the right uid etc.\r\n\t\t     This might fail on e.g. a FAT dir */\r\n```\r\nMost of this was unnecessary, but I figured I'd show my work.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM398", "user": "yodatak", "root": "ROOT39", "reply_to": "COM397", "timestamp": "2018-10-31T22:49:15Z", "text": "I got the same problem on feodra 29 on a fresh install can we reopen this bug ?", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM399", "user": "cutephoton", "root": "ROOT39", "reply_to": "COM398", "timestamp": "2018-10-31T23:14:47Z", "text": "@Devligue can reopen this", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3910", "user": "no-response[bot]", "root": "ROOT39", "reply_to": "COM399", "timestamp": "2018-11-01T14:20:10Z", "text": "This issue has been automatically closed because there has been no response to our request for more information from the original author. With only the information that is currently in the issue, we don't have enough information to take action. Please reach out if you have or find the answers we need so that we can investigate further.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3911", "user": "Devligue", "root": "ROOT39", "reply_to": "COM3910", "timestamp": "2018-11-01T14:52:10Z", "text": "I may have no additional information about the issue, but I am sure @cutephoton provided enough insight. There are also other people who have similar unsolved problems. I am reopening this.", "meta": {"posReactions": "10", "negReactions": "0"}}
{"id": "COM3912", "user": "yodatak", "root": "ROOT39", "reply_to": "COM3911", "timestamp": "2018-11-05T22:24:01Z", "text": "I got no problem with the flatpak version by the way", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3913", "user": "cutephoton", "root": "ROOT39", "reply_to": "COM3912", "timestamp": "2018-11-06T00:54:29Z", "text": "I reproduced on the latest version still. **shrug** I don't see how flatpak and rpm/deb would differ. It only fails when the preconditions listed above are met -- a partition where you don't have permission to create a trash folder under your user ID.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3914", "user": "yodatak", "root": "ROOT39", "reply_to": "COM3913", "timestamp": "2018-11-06T21:31:27Z", "text": "With flatpak i got no error but it don't get delete sorry about this misinformation. I try to disable selinux it don't change.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3915", "user": "cutephoton", "root": "ROOT39", "reply_to": "COM3914", "timestamp": "2018-11-06T21:48:03Z", "text": "No. Not selinux. It has to do with how trash folders work. My rather verbose explanation gets in to the nitty gritty for where atom's behavior is deficient.  The short answer is that atom only asks to move files to trash and does not delete files. If a trash folder cannot be created (multiple causes all related to permissions) than it fails. Atom should inquire with user if they should permanently delete the files instead of failing.  ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3916", "user": "mkungla", "root": "ROOT39", "reply_to": "COM3915", "timestamp": "2018-11-13T11:29:03Z", "text": "As @yodatak also mentioned that Fedora 29 fresh install has this problem since `gvfs-trash` has finally after many deprecation notices been removed  and replaced with  `gio`. So as @rsese mentioned you need to set `ELECTRON_TRASH=gio` e.g. add it to your `~/.bash_profile`. \r\n\r\nlogout and login or `source ~/.bash_profile` and trashing will work\r\n\r\nor\r\n```\r\necho 'export ELECTRON_TRASH=gio' >> $HOME/.bashrc\r\nsource $HOME/.bashrc\r\n```", "meta": {"posReactions": "14", "negReactions": "1"}}
{"id": "COM3917", "user": "cutephoton", "root": "ROOT39", "reply_to": "COM3916", "timestamp": "2018-11-13T12:54:30Z", "text": "Gio operates the same way. I used the Gio command line to manually step through this...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3918", "user": "mh-cbon", "root": "ROOT39", "reply_to": "COM3917", "timestamp": "2018-12-06T12:06:34Z", "text": "running fedora 29, i have installed atom from packages, since recently I faced the same error as described here.\r\n\r\n```\r\nsudo dnf list installed atom\r\nPaquets install\u00e9s\r\natom.x86_64                                                1.33.0-0.1                                                 @Atom\r\n```\r\n\r\nI think this bug deserves an action in order to improve the package installation, or the runtime, to detect gio/gvfs and make this work out of the box.\r\n\r\nThis really is an ugly bug for the end user experience.", "meta": {"posReactions": "8", "negReactions": "0"}}
{"id": "COM3919", "user": "cristianlivella", "root": "ROOT39", "reply_to": "COM3918", "timestamp": "2018-12-09T12:32:04Z", "text": "Is there any workaround to delete files with Atom on Fedora 29?", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM3920", "user": "edlefebvre", "root": "ROOT39", "reply_to": "COM3919", "timestamp": "2018-12-12T08:32:45Z", "text": "> So as @rsese mentioned you need to set `ELECTRON_TRASH=gio` e.g. add it to your `~/.bash_profile`.\r\n> \r\n> logout and login or `source ~/.bash_profile` and trashing will work\r\n\r\nThis is not working on fedora 29, even with gio installed and ELECTRON_TRASH variable set to gio.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM3921", "user": "cutephoton", "root": "ROOT39", "reply_to": "COM3920", "timestamp": "2018-12-12T14:03:28Z", "text": "There are no workarounds.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3922", "user": "olegjs", "root": "ROOT39", "reply_to": "COM3921", "timestamp": "2018-12-17T19:44:08Z", "text": "> > So as @rsese mentioned you need to set `ELECTRON_TRASH=gio` e.g. add it to your `~/.bash_profile`.\r\n> > logout and login or `source ~/.bash_profile` and trashing will work\r\n> \r\n> This is not working on fedora 29, even with gio installed and ELECTRON_TRASH variable set to gio.\r\n\r\nWorks on my Fedora 29 -- had to restart terminal and restart atom from that terminal.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM3923", "user": "cutephoton", "root": "ROOT39", "reply_to": "COM3922", "timestamp": "2018-12-17T20:30:24Z", "text": "That is a not a fix. There are preconditions as documented above to reproduce the bug.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3924", "user": "shivdhar", "root": "ROOT39", "reply_to": "COM3923", "timestamp": "2018-12-28T08:30:30Z", "text": "Would love for this to be fixed (on my Fedora 29 installed via the official RPM).", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM3925", "user": "histamineblkr", "root": "ROOT39", "reply_to": "COM3924", "timestamp": "2019-01-06T22:47:58Z", "text": "This bug is also affecting me on a fresh install of Fedora 29 and Atom 1.33.1.\r\n\r\nIf I try to delete a file within atom, I get the following error:\r\n![gvfs-gio-error](https://user-images.githubusercontent.com/5628330/50742193-8be3d980-11bc-11e9-9d98-8c307d563839.png)\r\n\r\nIf I use gio on the command line:\r\n```\r\n$ gio trash /home/bauthier/Tools/ansible_local/roles/work_packages/files/test.txt\r\n$\r\n```\r\nno issue and it deletes as expected.\r\n\r\nMy system partitions are broken up like so:\r\n```\r\n$ df -h\r\nFilesystem               Size  Used Avail Use% Mounted on\r\ndevtmpfs                 7.8G     0  7.8G   0% /dev\r\ntmpfs                    7.8G  225M  7.6G   3% /dev/shm\r\ntmpfs                    7.8G  2.0M  7.8G   1% /run\r\ntmpfs                    7.8G     0  7.8G   0% /sys/fs/cgroup\r\n/dev/mapper/fedora-root   49G   11G   36G  24% /\r\ntmpfs                    7.8G  236K  7.8G   1% /tmp\r\n/dev/sda2                976M  160M  750M  18% /boot\r\n/dev/mapper/fedora-home  414G  892M  392G   1% /home\r\n/dev/sda1               1022M   21M 1002M   3% /boot/efi\r\ntmpfs                    1.6G  8.4M  1.6G   1% /run/user/1000\r\n```\r\nIf I explicitly set an environment variable like this within my **~/.bashrc**:\r\n```\r\nexport ELECTRON_TRASH=gio\r\n```\r\nit does delete within atom correctly.\r\n\r\nHaving to set this environment variable is less than ideal. I read through cutephoton's research, testing, and analysis and I believe mine works because **/home** and **/** are on different mounts, but the same partition. Perhaps LVM versus standard partitions?\r\n\r\nEither way, I would imagine the handling of \"gvfs\" or \"gio\" would be done by atom and set correctly during start time of the application. I haven't read through the atom code so there may have been a reason to couple that functionality to \"gvfs\" rather than dynamically choosing a suitable trash program and application startup.\r\n", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM3926", "user": "yodatak", "root": "ROOT39", "reply_to": "COM3925", "timestamp": "2019-01-06T23:11:32Z", "text": "https://github.com/electron/electron/issues/15011\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM3927", "user": "den-is", "root": "ROOT39", "reply_to": "COM3926", "timestamp": "2019-01-11T08:44:24Z", "text": "same here with fedora 29 and atom 1.34.0\r\n\r\nthat workaround has helped me https://github.com/atom/atom/issues/15949#issuecomment-434231263", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM3928", "user": "abudawud", "root": "ROOT39", "reply_to": "COM3927", "timestamp": "2019-01-14T12:58:36Z", "text": "same here with fedora 29 and atom 1.33.0x64\r\n`~$ lsb_release -a`\r\n```\r\nLSB Version:\t:core-4.1-amd64:core-4.1-noarch\r\nDistributor ID:\tFedora\r\nDescription:\tFedora release 29 (Twenty Nine)\r\nRelease:\t29\r\nCodename:\tTwentyNine\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM3929", "user": "nelson6e65", "root": "ROOT39", "reply_to": "COM3928", "timestamp": "2019-01-27T22:23:37Z", "text": "> @histamineblkr If I explicitly set an environment variable like this within my **~/.bashrc**:\r\n> \r\n> ```\r\n> export ELECTRON_TRASH=gio\r\n> ```\r\n\r\nThis did work for me, in Fedora 29. ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "ROOT40", "user": "dhh", "root": "ROOT40", "reply_to": null, "timestamp": "2018-08-21T23:48:12Z", "text": "Replace use of whitelist with allowlist and blacklist with denylist Per https://twitter.com/dhh/status/1032050325513940992, I'd like for Rails to set a good example and tone by using better terminology when we can. An easy fix would be to replace our use of whitelist with allowlist and blacklist with denylist.\r \r We can even just use them as verbs directly, as we do with the former terms. So something is allowlisted or denylisted.\r \r I took a quick look and it seems like this change is mostly about docs. We only have one piece of the code that I could find on a search that uses the term whitelist with `enforce_raw_sql_whitelist`. Need to consider whether we need an alias and a deprecation for that.", "meta": {"posReactions": "61", "negReactions": "21"}}
{"id": "COM400", "user": "shalvah", "root": "ROOT40", "reply_to": "ROOT40", "timestamp": "2018-08-22T00:57:07Z", "text": "Good intentions, but I doubt there's any relation of the origin of the terms blacklist/whitelist to race. There are many idioms and phrases in the English language that make use of colours without any racial backstories.\r\nI haven't met any black person (myself included) who was ever offended by the use of \"blacklist\". Frankly, a good number find it patronising to make this kind of change.", "meta": {"posReactions": "39", "negReactions": "0"}}
{"id": "COM401", "user": "ghost", "root": "ROOT40", "reply_to": "COM400", "timestamp": "2018-08-22T01:11:49Z", "text": "At least [one source from a search](https://www.etymonline.com/word/blacklist) suggests the word had its origins around union members. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM402", "user": "dhh", "root": "ROOT40", "reply_to": "COM401", "timestamp": "2018-08-22T01:15:48Z", "text": "Regardless of origin, allow/deny are simply clearer terms that does not require tracing the history of black/white as representations of that meaning. We can simply use the meaning directly.", "meta": {"posReactions": "27", "negReactions": "5"}}
{"id": "COM403", "user": "glaszig", "root": "ROOT40", "reply_to": "COM402", "timestamp": "2018-08-22T01:26:22Z", "text": "1. [etymology is quite important](\r\nhttps://www.quora.com/Is-the-term-blacklist-racist?share=1). in the end, we might consider plain words \u201eblack\u201c and \u201ewhite\u201c racist and enter the realms of newspeak which i figure you especially, @dhh, are familiar with.\r\n\r\n2. \u201callow/deny are simply clearer terms\u201d \u2014 now that\u2019s an actual, technically useful argument.\r\n\r\n3. can we please stop jumping onto political bandwagons? i am here for the sanity.", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM404", "user": "Alamoz", "root": "ROOT40", "reply_to": "COM403", "timestamp": "2018-08-22T01:33:59Z", "text": "The terms **Blocklist** and **Clearlist** are sometimes used in place of Blacklist and Whitelist.\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM405", "user": "minaslater", "root": "ROOT40", "reply_to": "COM404", "timestamp": "2018-08-22T02:23:21Z", "text": "I'm gonna go ahead and get started on this... \ud83d\ude04 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM406", "user": "cbarton", "root": "ROOT40", "reply_to": "COM405", "timestamp": "2018-08-22T03:03:42Z", "text": "One could also argue that in color theory, black is the absence of color (photons which make up the spectrum) and white is the accumulation of all colors. Thus a blacklist is a list which contains elements that are to be absent and a whitelist to be allowed...", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM407", "user": "justizin", "root": "ROOT40", "reply_to": "COM406", "timestamp": "2018-08-22T03:07:33Z", "text": "I think this is a great idea, I have proposed internally at multiple companies I've worked at changing master/slave and blacklist/whitelist to leader/replica and allowlist/denylist, if only because in an industry with poor representation it feels incredibly overt to be standing in a room full of mostly white people using these terms outloud.\r\n\r\nIt doesn't matter what the origin or intent of this was, or whether people can find a narrow lens through which to see it as not a problem.  Consider using these terms in a coding or systems interview with someone you have just met.\r\n\r\nI understand that some black people may not consider these terms offensive, but I would rather someone not want to work with me because they think I am too politically correct than because they think I am too insensitive and blind.\r\n\r\n@minaslater thanks for beating me to the first PR on this. :) \ud83d\udcaf ", "meta": {"posReactions": "0", "negReactions": "4"}}
{"id": "COM408", "user": "cbarton", "root": "ROOT40", "reply_to": "COM407", "timestamp": "2018-08-22T12:21:31Z", "text": "@bitmonk I respectfully disagree with your opinion that your (or my) future colleagues would impose that kind of cultural bias on words that exist in the [English](https://www.merriam-webster.com/dictionary/white%20list) [language](https://www.merriam-webster.com/dictionary/blacklist) as well as are well-defined [on](https://en.wikipedia.org/wiki/Whitelisting) [Wikipedia](https://en.wikipedia.org/wiki/Blacklist_(disambiguation)), of which `blacklist` has far more far reaching disciplines than just comp-sci. \r\n\r\nThat said and since I think this issue will garner overwhelming support in this community, I do support a compromise suggested by @rafaelfranca's review to replace the actual words with their definition or some other phrase that is more fluid than a single term.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM409", "user": "9jaswag", "root": "ROOT40", "reply_to": "COM408", "timestamp": "2018-08-22T13:55:35Z", "text": "I think the question here should be: is replacing `whitelist` and `blacklist` with `allowlist` and `denylist` a better option? If presented with the word `blacklist` and `denylist`, which is most likely self-explanatory as to the action to be performed?", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM4010", "user": "rafaelfranca", "root": "ROOT40", "reply_to": "COM409", "timestamp": "2019-04-12T13:52:44Z", "text": "A quick search and replace in the codebase shows that all entries for those words were already changed. I'll close this issue.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT41", "user": "dincamihai", "root": "ROOT41", "reply_to": null, "timestamp": "2018-06-08T15:11:40Z", "text": "Provide python version mismatch solutions ### What does this PR do?\r \r Improves the error message when Python version mismatch detected by providing solutions.\r \r ### What issues does this PR fix or reference?\r \r See below.\r \r ### Previous Behavior (Python3 origin - Python2.7 target)\r \r ```bash\r bash-4.4# salt-ssh -l quiet -i --out json --key-deploy --passwd admin123 container__wjQFc test.ping\r {\r     \"container__wjQFc\": {\r         \"stdout\": \"ERROR: salt requires python 2.6 or newer on target hosts, must have same major version as origin host\",                                                                                                                  \r         \"stderr\": \"\",\r         \"retcode\": 10\r     }\r }\r ```\r \r ### New Behavior (Python3 origin - Python2.7 target)\r \r ```bash\r bash-4.4# salt-ssh -l quiet -i --out json --key-deploy --passwd admin123 container__wjQFc test.ping\r {\r     \"container__wjQFc\": {\r         \"stdout\": \"ERROR: Depending on the Python version on the target, you need to install python2-salt on origin to add support for Python2.7 targets or install py26-compat-salt on origin to add support for Python2.6 targets or upgrade to Python==3.x on target\",\r         \"stderr\": \"\",\r         \"retcode\": 10\r     }\r }\r ```\r \r ### Tests written?\r \r No\r \r ### Commits signed with GPG?\r \r No\r \r Please review [Salt's Contributing Guide](https://docs.saltstack.com/en/latest/topics/development/contributing.html) for best practices.\r \r See GitHub's [page on GPG signing](https://help.github.com/articles/signing-commits-using-gpg/) for more information about signing commits with GPG.\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM410", "user": "cachedout", "root": "ROOT41", "reply_to": "ROOT41", "timestamp": "2018-06-08T17:10:18Z", "text": "@dincamihai There are a few lint errors here: https://jenkins.saltstack.com/job/PR/job/salt-pr-lint-n/22487/violations/file/salt/client/ssh/__init__.py/", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM411", "user": "isbm", "root": "ROOT41", "reply_to": "COM410", "timestamp": "2018-06-08T23:39:17Z", "text": "@terminalmage I've forgot to change the last error message, which is \"invalid Python\". That just misleads people and they don't understand what is going on, hence the fix. Salt SSH still needs to have both library sets (dependencies) on the Master for the specific Python versions, so the `.tar.gz` is carrying over those in `py<major version>` subdirectories.\r\n\r\n@dincamihai NOTE: actually if you are running Salt on a Master from the specific version, you _do not_ need to install Salt again for the alternative version, as it is anyway works for both versions. This is just packaging convenience. But in fact you need only couple of version-specific libraries to be installed so they will be picked up by the `thin` creation procedure. That is, probably we should not say \"install Salt for alternative Python X\" (which implies you will get all the needed dependencies automatically), but \"install Salt _dependencies_ only for the alternative Python X\".\r\n\r\n@gtmanfred nope, this is only needed in Fluorine.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM412", "user": "dincamihai", "root": "ROOT41", "reply_to": "COM411", "timestamp": "2018-06-11T09:16:58Z", "text": "@cachedout i've fixed the lint errors but now, after rebase, it seems to have some unrelated lint errors in the tests.\r\n\r\n@terminalmage Bo and Daniel already provided an explanation. sorry, for not being clear enough about this in the description.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM413", "user": "isbm", "root": "ROOT41", "reply_to": "COM412", "timestamp": "2018-06-11T10:22:26Z", "text": "@dincamihai I would still minimise the text according to the example I showed above. As well as the \"3.x\" thing.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM414", "user": "dincamihai", "root": "ROOT41", "reply_to": "COM413", "timestamp": "2018-06-11T11:26:33Z", "text": "@isbm  having 3.x there means that it matches all the 3 subversions. if I remove the .x someone might think it would only apply to 3 and this would make it more confusing.\r\n\r\nAdding new line to the text is ignored and I'm not sure I should spend more time on this.\r\n\r\nYour example seems to remove some of the useful information and has this \"on a Master\" that I don't understand. Is that intended or should it be \"on the Master\"?\r\nI was using origin and target in order to avoid Master and Minion because none of these machines have salt-master or salt-minion running.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM415", "user": "isbm", "root": "ROOT41", "reply_to": "COM414", "timestamp": "2018-06-11T11:37:24Z", "text": "@dincamihai the \"3.x\" is the same as \"3\", as I see it. I also suggested to use integers as in the `version_info` instead of just strings. And so if we have some issue with the 3.8 (e.g.) one would just add a minor version key. Otherwise default should go. But \"3.x\" is more to me looks like a hack.\r\n\r\nThe \"origin\" is something that might not be understood. Personally to me it is very odd terminology here. And you are running \"SaltSSH\" from the Master (or want-to-be-master).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM416", "user": "dincamihai", "root": "ROOT41", "reply_to": "COM415", "timestamp": "2018-06-11T11:47:32Z", "text": "@isbm i'm checking first for major.minor, so if we add 3.8 it will go to that first. only if there is not major.minor it will match major.x. i think we are fine here.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM417", "user": "isbm", "root": "ROOT41", "reply_to": "COM416", "timestamp": "2018-06-11T11:57:16Z", "text": "@dincamihai correct. So that means there **is something** that needs to be shown _instead of_ the default message. And if you have none of '8', then you will get the default one:\r\n\r\n```python\r\nmsg = {\r\n    2: {\r\n        6: 'Too old',\r\n        7: 'Soon to be dead',\r\n        'default': 'Problem between the keyboard and the chair',\r\n    },\r\n    3: {\r\n        4: 'Many things are missing in this release',\r\n        6: 'Many things are incompatible with the previous release, ha-ha!',\r\n        8: 'Larry Wall was hired to design new Python language syntax',\r\n        'default': 'I like you begging, do it again',\r\n    }\r\n}\r\n\r\nimport sys\r\nmj, mn = sys.version_info[:2]\r\nprint(msg[mj].get(mn, msg[mj]['default']))\r\n```\r\n\r\nP.S. keep the code, replace the messages. :wink: ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM418", "user": "dincamihai", "root": "ROOT41", "reply_to": "COM417", "timestamp": "2018-06-11T12:03:23Z", "text": "@isbm if there is no 3.8 specific message, 3.x would be shown. is this not enough?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM419", "user": "isbm", "root": "ROOT41", "reply_to": "COM418", "timestamp": "2018-06-11T12:07:36Z", "text": "The code I exampled above does this. I am just not in favour of your structure that keeps strings that needs to be parsed instead of just direct map to versions. And your messages are too big and using foreign terminology for Salt-specific domain. And so therefore I would change that.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4110", "user": "dincamihai", "root": "ROOT41", "reply_to": "COM419", "timestamp": "2018-06-11T12:09:34Z", "text": "@isbm ok. thanks for the suggestion, but if the upstream is fine with my version (changes approved) please merge the PR. thanks!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4111", "user": "isbm", "root": "ROOT41", "reply_to": "COM4110", "timestamp": "2018-06-11T12:11:17Z", "text": "@terminalmage you like the proposed error messages and the structure?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4112", "user": "isbm", "root": "ROOT41", "reply_to": "COM4111", "timestamp": "2018-06-11T13:39:49Z", "text": "OK, as per speaking with @dincamihai it would be also an option to:\r\n\r\n- Add all the options into the documentation.\r\n- Add short minimally intrusive to the target machine option (i.e. update the SaltSSH side w/o touching the target)\r\n\r\nThat said, CLI would return something like:\r\n```\r\nThe \"my-to-be-minion.greatdomain.com\" machine is running Python 2.6 version.\r\nPlease install Salt for 2.6 Python on the Salt SSH machine and set it up.\r\n```\r\n\r\nor:\r\n```\r\nThe \"my-to-be-minion.greatdomain.com\" machine is running Python 2.7 version.\r\nPlease install Salt for 2.7 Python on the Salt SSH machine.\r\n```\r\n\r\nSo such info on the CLI would suggest what to do now, quickly and easiest way. And the following would go to the documentation (rephrased into more extended version):\r\n\r\n\"Depending on the Python version on the target, you need to install Python2.7 compatible salt on origin to add support for Python2.7 targets or install Python2.6 compatible salt on origin to add support for Python2.6 targets or upgrade to Python==3.x on target\"\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4113", "user": "dincamihai", "root": "ROOT41", "reply_to": "COM4112", "timestamp": "2018-06-11T13:46:21Z", "text": "One note:\r\nsometimes, when targeting 1000 machines, maybe 999 are ok but one has an old python. there are two options and we don't know what it is better for the user:\r\n - update the origin machine (that works on 999 of the clients) or\r\n - update the one client that doesn't work\r\n\r\nOther than that, this is open source, so I don't have any problem with adapting my PR to whatever is a better fit for saltstack/salt.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4114", "user": "isbm", "root": "ROOT41", "reply_to": "COM4113", "timestamp": "2018-06-11T13:50:23Z", "text": "I would only say that \"target\" is that part between `salt` and the `command`... More here: https://docs.saltstack.com/en/latest/topics/targeting/ So calling it \"target\" and \"origin\" brings lots of confusion from this POV.  I would definitely keep it Master, especially if SaltSSH is \"to execute salt commands and states over ssh without installing a salt-minion\". Which implies \"Master\" at first place!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4115", "user": "dincamihai", "root": "ROOT41", "reply_to": "COM4114", "timestamp": "2018-06-11T13:52:53Z", "text": "@terminalmage i am not an expert in salt terminology. I just proposed what I thought it would be appropriate and so far saltstack did not disagree. sure, please propose better messages.\r\nthe changes were already approved so why should i make more changes to the PR or invest more time into it?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4116", "user": "dincamihai", "root": "ROOT41", "reply_to": "COM4115", "timestamp": "2018-06-11T13:56:03Z", "text": "@terminalmage by the way https://cse.google.com/cse?cx=004624818632696854117:yfmprrbw3pk&q=target", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4117", "user": "isbm", "root": "ROOT41", "reply_to": "COM4116", "timestamp": "2018-06-11T13:57:58Z", "text": "@dincamihai actually \"approved\" here means _everyone_ agrees, JFYI. And your google result is suggesting exactly what I mean.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4118", "user": "dincamihai", "root": "ROOT41", "reply_to": "COM4117", "timestamp": "2018-06-11T14:06:03Z", "text": "@isbm and @terminalmage I have tested my changes on different combinations.\r\nIt would not make any sense to make additional changes and test the whole thing again with python2.6, 2.7 and 3 and combinations of them just because someone likes it more is some way. (i'm not talking here about the formulation of the messages, that is a valid change that is worth doing). but changing some structure to another structure just because... is not enough reason to redo the whole testing again.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4119", "user": "dincamihai", "root": "ROOT41", "reply_to": "COM4118", "timestamp": "2018-06-11T14:18:31Z", "text": "@isbm what about target in the context of rosters https://docs.saltstack.com/en/latest/topics/ssh/roster.html", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4120", "user": "terminalmage", "root": "ROOT41", "reply_to": "COM4119", "timestamp": "2018-06-11T19:55:01Z", "text": "I would have loved to work with you, but since you were not willing to accept any recommendations, I am closing this and we will do any remaining work in https://github.com/saltstack/salt/pull/48058.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT42", "user": "donny-dont", "root": "ROOT42", "reply_to": null, "timestamp": "2016-09-28T18:32:48Z", "text": "Support Web Components v1 The `dart:html` library should deprecate the current v0 specifications of Custom Elements and Shadow DOM and move to using v1 of both specifications. ", "meta": {"posReactions": "21", "negReactions": "0"}}
{"id": "COM420", "user": "donny-dont", "root": "ROOT42", "reply_to": "ROOT42", "timestamp": "2016-09-28T19:20:54Z", "text": "DDC related issue https://github.com/dart-lang/sdk/issues/27311\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM421", "user": "donny-dont", "root": "ROOT42", "reply_to": "COM420", "timestamp": "2016-10-17T20:46:29Z", "text": "@floitschG anything to follow for this? Chrome 54 shipped and comes with the v1 specs enabled.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM422", "user": "kevmoo", "root": "ROOT42", "reply_to": "COM421", "timestamp": "2016-11-24T00:50:12Z", "text": "@donny-dont there are a *LOT* of things we need to fixup in `dart:html` \u2013\u00a0we're holding off until DDC is locked and loaded. It'll be *much* easier to get everything working when our dev story is 100% javascript.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM423", "user": "kulshekhar", "root": "ROOT42", "reply_to": "COM422", "timestamp": "2016-11-24T07:10:36Z", "text": "> when our dev story is 100% javascript\r\n\r\nI'm not sure I understand this. Could you please add some more info. Is it JS compatibility you're referring to or the possible inclusion of javascript specific tools in the build step, along with DDC?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM424", "user": "zoechi", "root": "ROOT42", "reply_to": "COM423", "timestamp": "2016-11-24T07:27:01Z", "text": "@kulshekhar the problem is the Dart VM in Dartium where during development some Dart code is directly executed by the Dart VM  but other stuff runs in JS land. \r\nWith Bazel and DDC they are working on building a developer story with fast edit-reload cycles with standard Chrome (without a Dart VM being involved) to simplify interop between the Dart code (transpiled to JS) and the native JS world.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM425", "user": "kulshekhar", "root": "ROOT42", "reply_to": "COM424", "timestamp": "2016-11-24T07:28:13Z", "text": "Thanks @zoechi \r\n\r\nThat makes sense now :sweat_smile: ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM426", "user": "eukreign", "root": "ROOT42", "reply_to": "COM425", "timestamp": "2017-08-22T04:17:38Z", "text": "Any updates on this, we're in 2017 now :-D", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM427", "user": "matanlurey", "root": "ROOT42", "reply_to": "COM426", "timestamp": "2017-08-22T04:29:38Z", "text": "I imagine there won't be any progress on this until Dart 2.0 rolls out completely removing Dartium.\r\n\r\nI'd check back in a few more months, or use JS interop to \"build your own\":\r\nhttps://pub.dartlang.org/packages/html5", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM428", "user": "eukreign", "root": "ROOT42", "reply_to": "COM427", "timestamp": "2018-02-19T02:11:48Z", "text": "Who's still following this issue in 2018? Sorry, couldn't resist. Maybe 2018 will be the year Dart finally gets Web Components v1!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM429", "user": "kevmoo", "root": "ROOT42", "reply_to": "COM428", "timestamp": "2018-03-01T18:17:32Z", "text": "We're in the process of updating our `dart:html` APIs \u2013 https://dart-review.googlesource.com/c/sdk/+/24501\r\n\r\nThat roll \u2013 and getting rid of Dartium \u2013\u00a0should make it easier to support the latest Browser features.\r\n\r\nHaving said that, our primary framework \u2013\u00a0AngularDart \u2013\u00a0is not using WebComponent features, so it's not a big priority for us.\r\n\r\nMy suggestion: once we've updated `dart:html` and friends, let us know specific APIs that are missing/broken\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4210", "user": "elmcrest", "root": "ROOT42", "reply_to": "COM429", "timestamp": "2018-03-11T10:42:24Z", "text": "That's really sad.\r\nIn my mind a serious \"community centered\" effort should kind of use and depend on different independent blocks. to make the idea more clear, `AngularDart` for sure needs some stuff handling DOM and it seems sane to me to use something like `dart:html` as a basis.\r\nso, every work from google would be contributed back to the basis and others building on top of this basis would automatically benefit - somehow like the whole OpenSource-Idea, no? ;) \r\n\r\ncurrently ` Dart` is more like: \"You want to do web? Sure, use AngularDart.\" (Hint: AngularDart != \"the web\")\r\n\r\nthat said, I'm not the guy who can actually judge what you're doing and why - just saying this from a rather distant and abstract point of view and trying to support `Dartlang` itself against common attacks. (you know those.... \"meh, google is going to throw it away anyways...\" etc.)\r\n\r\nMaybe I should add, that webComponents are the reason why our app is only running on Chrome...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4211", "user": "matanlurey", "root": "ROOT42", "reply_to": "COM4210", "timestamp": "2018-03-11T18:43:56Z", "text": "@elmcrest Hi Marius.\r\n\r\nI realize and understand you are disappointed. I'm one of the TLs of AngularDart, and let me make it clear I think web components are awesome, and would love Dart to support them well. The primary take away here is _well_ though, and that will take a little bit of effort, because the current HTML libraries and browser bindings aren't well suited for this.\r\n\r\nWe could probably get some _hacky_ support quicker, but it won't be something useful to most customers. It's something we'd like to revisit after Dart2 launches, but until then - again to be very honest - it's just not a priority. We care, but we have limited time and resources, and have to use them efficiently, like I'm sure you do on your project(s) and company.\r\n\r\nFWIW, most popular web frameworks are not utilizing web components today:\r\n* React\r\n* Vue\r\n* Angular (JS/TS/Dart)\r\n\r\n... so it's not clear web components is the \"killer\" feature for most people.\r\n\r\nThanks for your patience!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4212", "user": "eukreign", "root": "ROOT42", "reply_to": "COM4211", "timestamp": "2018-03-11T19:15:36Z", "text": "The *entire* point of Web Components is that it's a \"framework\" that is built-in to browsers. You can just use it, without any extra libs or 3rd party frameworks.\r\n\r\nAngularDart emulates many features of Web Components, why does it do that instead of just using Web Components directly?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4213", "user": "matanlurey", "root": "ROOT42", "reply_to": "COM4212", "timestamp": "2018-03-11T19:24:44Z", "text": "@eukreign:\r\n\r\n> The entire point of Web Components is that it's a \"framework\" that is built-in to browsers\r\n\r\nWell, sort of. It has [yet to be supported in Microsoft Edge](https://caniuse.com/#feat=custom-elementsv1), for example, which is quite a large market segment still, and the polyfill performs quite badly. So until it works everywhere, it's not free.\r\n\r\n> AngularDart emulates many features of Web Components, why does it do that instead of just using Web Components directly\r\n\r\nAngularDart (and JS/TS, and React, and Vue, and Ember) all were created before web components were a thing. A lot of these framework authors have evaluated web components and found them severely lacking. Here is [one of the leads of React](https://docs.google.com/document/d/1QZxArgMwidgCrAbuSikcB2iBxkffH6w0YB0C1qCsuH0/edit), arguably the most popular framework today:\r\n\r\n> We\u2019re not going to use it at all at Facebook. We\u2019re not going to build React on it because there\u2019s a strong model difference \u2013 imperative in Web Components to declarative in React. Web Components doesn\u2019t have an idiomatic way to define things like where events go. How do you pass data when everything is a string? We see it more as an interop layer that lets various frameworks talk to each other.\r\n> \r\n> In talking to the Atom team, this doesn\u2019t solve different framework idioms as it doesn\u2019t have an opinion on how they relate.\r\n\r\nAgain, it's not that support will never be offered, but it's unlikely to happen in any immediate time frame. There are other APIs that are more useful for our users, like web workers, service workers, and more right now.\r\n\r\nFrom a _personal_ perspective (not the Dart team's), I'd use JavaScript or TypeScript if I was highly interested in web components - its much better suited for this lightweight model than Dart is (more suited for larger web applications, not scripts/standalone components/buttons).\r\n\r\nThanks for understanding!\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4214", "user": "eukreign", "root": "ROOT42", "reply_to": "COM4213", "timestamp": "2018-03-11T21:39:46Z", "text": "_This post has been deleted for violating the [code of conduct][]._\r\n\r\n[code of conduct]: https://www.dartlang.org/code-of-conduct", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4215", "user": "elmcrest", "root": "ROOT42", "reply_to": "COM4214", "timestamp": "2018-03-11T21:50:26Z", "text": "I also disagree to prefer typescript over dart for little snippets. The undefined, NaN, 0, false, null, whatever hell is one point, imports and package management still another...\r\nDart can really shine even for small snippets and if your build system is already setup anyway, why wouldn\u2018t I want to use dart for everything?\r\nOne truth tends to get hidden/ignored more and more these days: Javascript sucks! ;)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4216", "user": "matanlurey", "root": "ROOT42", "reply_to": "COM4215", "timestamp": "2018-03-11T21:57:07Z", "text": "I'm locking this conversation for now since it's getting non-productive. This is something that is interesting to us, but it's not on the immediate roadmap at this time. Thanks for the feedback.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4217", "user": "kevmoo", "root": "ROOT42", "reply_to": "COM4216", "timestamp": "2019-03-08T21:02:39Z", "text": "We don't plan to support this API in the short term. None of our core users require it and would involve substantial effort to implement it correctly.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT43", "user": "duyanghao", "root": "ROOT43", "reply_to": null, "timestamp": "2020-09-17T02:27:28Z", "text": "add http2 health check for SetTransportDefaults Signed-off-by: duyanghao <1294057873@qq.com>\r \r **What type of PR is this?**\r /kind bug\r \r **What this PR does / why we need it**:\r \r Fixes [Client should expose a mechanism to close underlying TCP connections](https://github.com/kubernetes/client-go/issues/374).\r \r This PR should be merged after [add http2 health check parameters for ConfigureTransport](https://github.com/golang/net/pull/84) merged.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM430", "user": "k8s-ci-robot", "root": "ROOT43", "reply_to": "ROOT43", "timestamp": "2020-09-17T02:27:29Z", "text": "@duyanghao: Adding the \"do-not-merge/release-note-label-needed\" label because no release-note block was detected, please follow our [release note process](https://git.k8s.io/community/contributors/guide/release-notes.md) to remove it.\n\n<details>\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.\n</details>", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM431", "user": "k8s-ci-robot", "root": "ROOT43", "reply_to": "COM430", "timestamp": "2020-09-17T02:27:36Z", "text": "Hi @duyanghao. Thanks for your PR.\n\nI'm waiting for a [kubernetes](https://github.com/orgs/kubernetes/people) member to verify that this patch is reasonable to test. If it is, they should reply with `/ok-to-test` on its own line. Until that is done, I will not automatically test new commits in this PR, but the usual testing commands by org members will still work. Regular contributors should [join the org](https://git.k8s.io/community/community-membership.md#member) to skip this step.\n\nOnce the patch is verified, the new status will be reflected by the `ok-to-test` label.\n\nI understand the commands that are listed [here](https://go.k8s.io/bot-commands?repo=kubernetes%2Fkubernetes).\n\n<details>\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.\n</details>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM432", "user": "duyanghao", "root": "ROOT43", "reply_to": "COM431", "timestamp": "2020-09-17T02:30:35Z", "text": "/assign @caesarxuchao", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM433", "user": "lavalamp", "root": "ROOT43", "reply_to": "COM432", "timestamp": "2020-09-17T15:34:53Z", "text": "/ok-to-test\r\n/approve\r\n/lgtm", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM434", "user": "warmchang", "root": "ROOT43", "reply_to": "COM433", "timestamp": "2020-09-17T15:42:35Z", "text": "/retest", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM435", "user": "duyanghao", "root": "ROOT43", "reply_to": "COM434", "timestamp": "2020-09-18T03:20:28Z", "text": "@lavalamp This PR requires [add http2 health check parameters for ConfigureTransport](https://github.com/golang/net/pull/84) merged, and I'm doing this currently.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM436", "user": "aojea", "root": "ROOT43", "reply_to": "COM435", "timestamp": "2020-09-21T11:56:48Z", "text": "/cc", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM437", "user": "aramase", "root": "ROOT43", "reply_to": "COM436", "timestamp": "2020-09-22T06:29:58Z", "text": "/cc", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM438", "user": "fisherxu", "root": "ROOT43", "reply_to": "COM437", "timestamp": "2020-10-27T07:28:05Z", "text": "Looks like it should be based on this change in golang. https://github.com/golang/net/commit/08b38378de702b893ee869b94b32f833e2933bd2", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM439", "user": "k8s-ci-robot", "root": "ROOT43", "reply_to": "COM438", "timestamp": "2020-10-27T08:41:18Z", "text": "New changes are detected. LGTM label has been removed.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4310", "user": "k8s-ci-robot", "root": "ROOT43", "reply_to": "COM439", "timestamp": "2020-10-27T08:46:38Z", "text": "@duyanghao: Adding label `do-not-merge/contains-merge-commits` because PR contains merge commits, which are not allowed in this repository.\nUse `git rebase` to reapply your commits on top of the target branch. Detailed instructions for doing so can be found [here](https://git.k8s.io/community/contributors/guide/github-workflow.md#4-keep-your-branch-in-sync).\n\n<details>\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.\n</details>", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4311", "user": "duyanghao", "root": "ROOT43", "reply_to": "COM4310", "timestamp": "2020-10-27T08:47:30Z", "text": "> Looks like it should be based on this change in golang. [golang/net@08b3837](https://github.com/golang/net/commit/08b38378de702b893ee869b94b32f833e2933bd2)\r\n\r\nYeah, I have update this PR using the latest http2.ConfigureTransports method.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4312", "user": "duyanghao", "root": "ROOT43", "reply_to": "COM4311", "timestamp": "2020-10-27T08:49:20Z", "text": "/retest", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4313", "user": "aojea", "root": "ROOT43", "reply_to": "COM4312", "timestamp": "2020-10-27T09:13:02Z", "text": "@duyanghao have you run `hack/update-vendor.sh`?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4314", "user": "duyanghao", "root": "ROOT43", "reply_to": "COM4313", "timestamp": "2020-10-27T09:34:41Z", "text": "> @duyanghao have you run `hack/update-vendor.sh`?\r\n\r\nNot yet, I will have a try.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4315", "user": "k8s-ci-robot", "root": "ROOT43", "reply_to": "COM4314", "timestamp": "2020-10-27T09:40:40Z", "text": "[APPROVALNOTIFIER] This PR is **APPROVED**\n\nThis pull-request has been approved by: *<a href=\"https://github.com/kubernetes/kubernetes/pull/94844#\" title=\"Author self-approved\">duyanghao</a>*, *<a href=\"https://github.com/kubernetes/kubernetes/pull/94844#issuecomment-694316787\" title=\"LGTM\">lavalamp</a>*\n\nThe full list of commands accepted by this bot can be found [here](https://go.k8s.io/bot-commands?repo=kubernetes%2Fkubernetes).\n\nThe pull request process is described [here](https://git.k8s.io/community/contributors/guide/owners.md#the-code-review-process)\n\n<details >\nNeeds approval from an approver in each of these files:\n\n- ~~[OWNERS](https://github.com/kubernetes/kubernetes/blob/master/OWNERS)~~ [lavalamp]\n- ~~[staging/src/k8s.io/api/OWNERS](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/api/OWNERS)~~ [lavalamp]\n\nApprovers can indicate their approval by writing `/approve` in a comment\nApprovers can cancel approval by writing `/approve cancel` in a comment\n</details>\n<!-- META={\"approvers\":[]} -->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4316", "user": "aojea", "root": "ROOT43", "reply_to": "COM4315", "timestamp": "2020-10-27T09:48:20Z", "text": "@duyanghao can you squash all the commits please?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4317", "user": "aojea", "root": "ROOT43", "reply_to": "COM4316", "timestamp": "2020-10-27T09:50:19Z", "text": "it also fails with the following error\r\n```\r\nVendor Verify failed.\r\nIf you're seeing this locally, run the below command to fix your directories:\r\nhack/update-vendor.sh\r\nThese modules are pinned to versions different than the minimal preferred version.\r\nThat means that without replace directives, a different version would be selected,\r\nwhich breaks consumers of our published modules.\r\n1. Use hack/pin-dependency.sh to switch to the preferred version for each module\r\n2. Run hack/update-vendor.sh to rebuild the vendor directory\r\n3. Run hack/lint-dependencies.sh to verify no additional changes are required\r\n\r\ngolang.org/x/sys\r\n    pinned:    v0.0.0-20200622214017-ed371f2e16b4\r\n    preferred: v0.0.0-20200930185726-fdedc70b468f\r\n    hack/pin-dependency.sh golang.org/x/sys v0.0.0-20200930185726-fdedc70b468f\r\nAll pinned versions of checked dependencies match their preferred version.\r\n```\r\nyou can check it in the `pull-kubernetes-dependencies` , I think that you can run `make verify` local to verify it", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4318", "user": "dims", "root": "ROOT43", "reply_to": "COM4317", "timestamp": "2020-10-27T10:47:07Z", "text": "/retest\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4319", "user": "duyanghao", "root": "ROOT43", "reply_to": "COM4318", "timestamp": "2020-10-27T11:54:39Z", "text": "/retest", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4320", "user": "povsister", "root": "ROOT43", "reply_to": "COM4319", "timestamp": "2020-10-27T13:00:42Z", "text": "I may have opposition to hard-coding those Timeout values.\r\nInternally, there are several ways to detect dead connections. For example: error on `readLoop`, connection idle timeout .. etc.\r\n\r\nMost of detections kick-in during the `readLoop` except the one referred here.  The http2 Transport health check will kick-in when the `readLoop` is completely idle for `ReadIdleTimeout` seconds. \r\nIt aims to do an additional health check when there is no incoming traffic for amount of time, but before `IdleConnTimeout` triggers idle connection recycling.\r\nThus, I think the `ReadIdleTimeout ` should be smaller than `IdleConnTimeout` to achieve it's designed purpose.\r\n\r\nIn addition, I suggest keep the minimum `PingTimeout` value to default 15s. \r\n[From the source code in golang.org/x/net/http2/transport.go](https://github.com/golang/net/blob/08b38378de702b893ee869b94b32f833e2933bd2/http2/transport.go#L1806-L1816), It uses `time.AfterFunc()`, not `time.Ticker()`, to trigger health check, and only `Reset()` the timer when the next `readLoop` kicks-in.\r\nIt means that the health check will be performed ONLY ONCE when the `readLoop` blocks for amout of time. In such situation, there should be only one PingFrame on the fly, so the `PingTimeout` does not matter much.\r\nBut setting the `PingTimeout` too low (eg: 2s in this PR) may lead to incorrect connection recycling during a network jitter or system load spike.\r\n\r\nMeanwhile, as the wide acceptance of http2, Kubernetes may have more additional default http2 Transport options to apply in the future. I suggest making a independent and well-commented helper function for the future configuration.\r\n\r\nWhat I described above has already been done in my PR https://github.com/kubernetes/kubernetes/pull/95898\r\nPlease consider my solution against this PR.\r\n\r\nTo be honest(just technically, no offence), this PR looks nasty. It needs rebase&squash, and more comments in the code to describe the purpose of configuration and those \"magic number\".", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4321", "user": "k8s-ci-robot", "root": "ROOT43", "reply_to": "COM4320", "timestamp": "2020-10-27T13:06:47Z", "text": "@duyanghao: The following tests **failed**, say `/retest` to rerun all failed tests:\n\nTest name | Commit | Details | Rerun command\n--- | --- | --- | ---\npull-kubernetes-dependencies | bf2bd4792f2284a8753dc439aa2ec53a34aea7d2 | [link](https://prow.k8s.io/view/gs/kubernetes-jenkins/pr-logs/pull/94844/pull-kubernetes-dependencies/1321057783335882752) | `/test pull-kubernetes-dependencies`\npull-kubernetes-e2e-azure-disk-windows | bf2bd4792f2284a8753dc439aa2ec53a34aea7d2 | [link](https://prow.k8s.io/view/gs/kubernetes-jenkins/pr-logs/pull/94844/pull-kubernetes-e2e-azure-disk-windows/1321056204989927424) | `/test pull-kubernetes-e2e-azure-disk-windows`\n\n[Full PR test history](https://prow.k8s.io/pr-history?org=kubernetes&repo=kubernetes&pr=94844). [Your PR dashboard](https://prow.k8s.io/pr?query=is%3Apr%20state%3Aopen%20author%3Aduyanghao). Please help us cut down on flakes by [linking to](https://git.k8s.io/community/contributors/devel/sig-testing/flaky-tests.md#filing-issues-for-flaky-tests) an [open issue](https://github.com/kubernetes/kubernetes/issues?q=is:issue+is:open) when you hit one in your PR.\n\n<details>\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://go.k8s.io/bot-commands).\n</details>\n<!-- test report -->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4322", "user": "duyanghao", "root": "ROOT43", "reply_to": "COM4321", "timestamp": "2020-10-27T13:55:11Z", "text": "> I may have opposition to hard-coding those Timeout values.\r\n> Internally, there are several ways to detect dead connections. For example: error on `readLoop`, connection idle timeout .. etc.\r\n> \r\n> Most of detections kick-in during the `readLoop` except the one referred here. The http2 Transport health check will kick-in when the `readLoop` is completely idle for `ReadIdleTimeout` seconds.\r\n> It aims to do an additional health check when there is no incoming traffic for amount of time, but before `IdleConnTimeout` triggers idle connection recycling.\r\n> Thus, I think the `ReadIdleTimeout ` should be smaller than `IdleConnTimeout` to achieve it's designed purpose.\r\n> \r\n> In addition, I suggest keep the minimum `PingTimeout` value to default 15s.\r\n> [From the source code in golang.org/x/net/http2/transport.go](https://github.com/golang/net/blob/08b38378de702b893ee869b94b32f833e2933bd2/http2/transport.go#L1806-L1816), It uses `time.AfterFunc()`, not `time.Ticker()`, to trigger health check, and only `Reset()` the timer when the next `readLoop` kicks-in.\r\n> It means that the health check will be performed ONLY ONCE when the `readLoop` blocks for amout of time. In such situation, there should be only one PingFrame on the fly, so the `PingTimeout` does not matter much.\r\n> But setting the `PingTimeout` too low (eg: 2s in this PR) may lead to incorrect connection recycling during a network jitter or system load spike.\r\n> \r\n> Meanwhile, as the wide acceptance of http2, Kubernetes may have more additional default http2 Transport options to apply in the future. I suggest making a independent and well-commented helper function for the future configuration.\r\n> \r\n> What I described above has already been done in my PR #95898\r\n> Please consider my solution against this PR.\r\n> \r\n> To be honest(just technically, no offence), this PR looks nasty. It needs rebase&squash, and more comments in the code to describe the purpose of configuration and those \"magic number\".\r\n\r\n@povsister I'm open to any reasonable suggestions, and I also want to share my opinions:\r\nFirst of all, I do think users should not care much about the http2 health check, and it's not something Kubernetes even want users to notice, therefore I still suggest to set it by some reasonable default values. Besides, in your \u2018proud\u2019 PR, the http2 Transport `ReadIdleTimeout` is configured as the half of http Transport `IdleConnTimeout`, Is this reasonable and not nasty?\r\nSecondly, there's never a 'law' against the PR which needs rebase and squash.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4323", "user": "JensErat", "root": "ROOT43", "reply_to": "COM4322", "timestamp": "2020-10-27T20:52:11Z", "text": "Just adding a [reference to my comments on #95898)](https://github.com/kubernetes/kubernetes/pull/95898#pullrequestreview-518105901), which in the end is discussing both approaches.\r\n\r\nJens Erat <jens.erat@daimler.com>, Daimler TSS GmbH, [Imprint](https://github.com/Daimler/daimler-foss/blob/master/LEGAL_IMPRINT.md)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4324", "user": "duyanghao", "root": "ROOT43", "reply_to": "COM4323", "timestamp": "2020-10-28T13:22:01Z", "text": "@JensErat @aojea Since there is no need for uses to configure http2 health check, I do think we should add http2 health check by some reasonable default values, and if you guys think pingTimeout=2s is two short, we can tune it larger, maybe default 15s is a good option.\r\nBesides I can't find any significance that setting http2 Transport ReadIdleTimeout as the half of http Transport IdleConnTimeout, Is there any relationship between these two configurations? \r\nPR #95898 looks pretty but unnecessary, again, I insist my way to fix this problem, which is no doubt the most simple and efficient approach to this problem.\r\nAnd I don't care about which PR will be merged finally, but I do care about the most reasonable solution for this problem.\r\nIf you guys could give reasons for setting http2 Transport ReadIdleTimeout as the half of http Transport IdleConnTimeout instead of some reasonable defaults, I'll be happy to close this PR ASAP.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4325", "user": "liggitt", "root": "ROOT43", "reply_to": "COM4324", "timestamp": "2020-10-28T13:35:12Z", "text": "See https://github.com/kubernetes/kubernetes/pull/95898#issuecomment-717934741 for context on locking.\r\n\r\n@caesarxuchao, can you take a look at this and #95898 and give feedback on the best way to configure the PingTimeout/ReadIdleTimeout options?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4326", "user": "lavalamp", "root": "ROOT43", "reply_to": "COM4325", "timestamp": "2020-10-28T22:20:26Z", "text": "This isn't how we have technical disagreements. No amount of technical correctness can make up for treating other people poorly; please don't repeat that behavior. I will close both of these PRs. I'm available via slack or email if more explanation is needed. (additional note: please seek assistance rather than escalating.)\r\n\r\nInstead, I've asked @caesarxuchao to send a fix for the issue in question.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT44", "user": "emergy", "root": "ROOT44", "reply_to": null, "timestamp": "2018-02-13T09:10:21Z", "text": "(Title renamed to remove explicit language) https://github.com/ansible/ansible/blob/66743f33faa71d092557f2c89788868ca32061aa/lib/ansible/module_utils/facts/network/generic_bsd.py#L80", "meta": {"posReactions": "23", "negReactions": "6"}}
{"id": "COM440", "user": "ansibot", "root": "ROOT44", "reply_to": "ROOT44", "timestamp": "2018-02-13T09:13:28Z", "text": "@emergy Greetings! Thanks for taking the time to open this issue. In order for the community to handle your issue effectively, we need a bit more information. \n\nHere are the items we could not find in your description:\n- issue type\n- ansible version\n- component name\n\nPlease set the description of this issue with this template:\nhttps://raw.githubusercontent.com/ansible/ansible/devel/.github/ISSUE_TEMPLATE.md\n\n[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)\n<!--- boilerplate: issue_missing_data --->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM441", "user": "iavael", "root": "ROOT44", "reply_to": "COM440", "timestamp": "2018-02-13T11:19:52Z", "text": "Don\u2019t be so agitated. It\u2019s just a lookup for route in local routing table, no network queries are actually performed.", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM442", "user": "kevinreddot", "root": "ROOT44", "reply_to": "COM441", "timestamp": "2018-02-13T12:46:29Z", "text": "Possibly, using a more generic \"`route -n get 0.0.0.0/0`\" would be a better way of finding the default route. Using a well-known address is not necessarily a good practice.", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM443", "user": "duke66", "root": "ROOT44", "reply_to": "COM442", "timestamp": "2018-02-13T13:03:20Z", "text": "ipv6 default route lookup is also broken \"v6=[route_path, '-n', 'get', '-inet6', '2404:6800:400a:800::1012'])\"", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM444", "user": "reverofevil", "root": "ROOT44", "reply_to": "COM443", "timestamp": "2018-02-13T13:09:00Z", "text": "@Akasurde Wow, was it fixed that fast?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM445", "user": "Akasurde", "root": "ROOT44", "reply_to": "COM444", "timestamp": "2018-02-13T13:11:18Z", "text": "@polkovnikov-ph $title seems offensive so I closed it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM446", "user": "webknjaz", "root": "ROOT44", "reply_to": "COM445", "timestamp": "2018-02-13T13:11:55Z", "text": "@emergy Ansible community heavily relies on [Code of Conduct](https://docs.ansible.com/ansible/latest/community.html#community-code-of-conduct) being followed, which lets us address issues more effectively and be respectful to each other. Posting issues with offensive content is definitely not going to encourage productive discussion, but normally results in confrontation.\r\nFor best outcome please consider writing your messages mindfully and calmly explaining both your problem and what is the suggested resolution or expectation for it.\r\nTIA.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM447", "user": "reverofevil", "root": "ROOT44", "reply_to": "COM446", "timestamp": "2018-02-13T13:21:43Z", "text": "@Akasurde I don't see how offensive title makes it less of an issue. The code in the issue seems self-descriptive to several people in this thread. Do you really need any additional feedback from issue author?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM448", "user": "Akasurde", "root": "ROOT44", "reply_to": "COM447", "timestamp": "2018-02-13T13:24:50Z", "text": "@polkovnikov-ph I agree that this an issue. But there is a certain way to describe an issue in Open Source Community. Using sexual abusive language is not the way to express your opinion. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM449", "user": "Akasurde", "root": "ROOT44", "reply_to": "COM448", "timestamp": "2018-02-13T13:26:01Z", "text": "@polkovnikov-ph Please refer [Code of Conduct](https://docs.ansible.com/ansible/latest/community.html#community-code-of-conduct) for more details.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4410", "user": "webknjaz", "root": "ROOT44", "reply_to": "COM449", "timestamp": "2018-02-13T13:34:30Z", "text": "@polkovnikov-ph please feel free to create a new issue with well-stated problem. Your assumption about that it's self-descriptiveness is only _partially_ correct when you refer to several ppl you mentioned. Still, there are lots of other people who won't understand it. I myself try avoiding to assume that other people see and understand things exactly the same way as me, because every individual has their own unique experience. That said I encourage you to not make such assumptions here.\r\nI'm locking this issue, since I don't see what can be done here to turn it into an effective conversation.\r\n\r\nIf you'd like to contribute into the issue resolution, I encourage you to file another issue with clear description of the problem. Thanks and have a nice day!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT45", "user": "enragedginger", "root": "ROOT45", "reply_to": null, "timestamp": "2020-01-29T16:42:45Z", "text": "Rename \"taint\" to something less vulgar **What would you like to be added**:\r Rename \"taint\" to something less vulgar.\r \r **Why is this needed**:\r In common English, a taint is an area in the nether regions of the human body. This makes discussing Kubernetes \"taints\" very difficult in a professional or public setting, especially if anyone who doesn't already know of Kubernetes \"taints\" is present.\r \r We should rename \"taint\" to be either \"perineum\", the official name for the taint, or something more fitting like \"restriction\" or \"stigma.\"", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM450", "user": "enragedginger", "root": "ROOT45", "reply_to": "ROOT45", "timestamp": "2020-01-29T16:51:08Z", "text": "/sig docs", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM451", "user": "neolit123", "root": "ROOT45", "reply_to": "COM450", "timestamp": "2020-01-29T20:48:43Z", "text": "it might be too late for this one, without breaking thousands of users.\r\nbut \"taint\" in general is already used in computing and i don't think many people have a problem with that.\r\n\r\n/sig architecture node\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM452", "user": "enragedginger", "root": "ROOT45", "reply_to": "COM451", "timestamp": "2020-01-29T23:57:10Z", "text": "I don't agree with that rationale. I think we can all agree that we should avoid using vulgarities in our code, documentation, and general professional communication. Regardless of whether or not the word was once accepted in computation, it is now a common vulgarity. Therefore, we should move away from it. Doing so will only increase the appeal of Kubernetes by making it appear more mature and forward thinking.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM453", "user": "smarterclayton", "root": "ROOT45", "reply_to": "COM452", "timestamp": "2020-01-30T00:38:43Z", "text": "Thanks for the feedback.  Since these issues historically attract a lot of unhelpful arguments and attacks in the threads, I'm going to lock this issue for now and when we add this to sig-architecture agenda I'll update with details for discussion there.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM454", "user": "smarterclayton", "root": "ROOT45", "reply_to": "COM453", "timestamp": "2020-01-30T18:36:43Z", "text": "I'll bring this up at the sig-arch meeting today, however as neolit noted \r\n\r\n* our API guarantees prevent these sorts of renames on short time scales (we might introduce a new name, but the old name would be preserved effectively for the rest of the v1 lifetime)\r\n* the term is well established in both having common descriptive usage (outside of the less-common vulgar usage)\r\n\r\nso I think it's unlikely we would change this.  Will update after the meeting.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM455", "user": "timothysc", "root": "ROOT45", "reply_to": "COM454", "timestamp": "2020-01-30T19:07:28Z", "text": "I'm opposed to the change at this stage due to the overall impact it would have, there is plenty of history and literature that does not pertain to the urban-dictionary definition. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM456", "user": "liggitt", "root": "ROOT45", "reply_to": "COM455", "timestamp": "2020-01-30T19:14:36Z", "text": "Agreed. A rename at this point is not practical due to API compatibility guarantees, and the term as used corresponds to the legitimate and inoffensive definition of the word.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM457", "user": "timothysc", "root": "ROOT45", "reply_to": "COM456", "timestamp": "2020-01-30T19:16:37Z", "text": "We discussed this issue on the SIG-arch call of 20200130, and have unanimously agreed that we will keep the current naming for the aforementioned reasons. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT46", "user": "ericmorand", "root": "ROOT46", "reply_to": null, "timestamp": "2018-03-12T15:34:02Z", "text": "Twig syntax highlighting broken Hi,\r \r Jekyll syntax highlighting is broken with Twig. Consider the following code block containing a perfectly valid Twig syntax:\r \r ```\r {% highlight twig %}\r {% raw %}\r {% set a = 'b' %}\r {% endraw %}\r {% endhighlight %}\r ```\r \r It outputs the following HTML:\r \r ```\r <code class=\"language-twig\" data-lang=\"twig\">\r     <span class=\"cp\">{%</span> \r     <span class=\"k\">set</span> \r     <span class=\"nv\">a</span> \r     <span class=\"err\">=</span>\r     <span class=\"s1\">'b'</span> \r     <span class=\"cp\">%}</span>\r </code>\r ```\r \r Notice the **err** class attributed to the equal sign.\r \r ## Steps to reproduce\r \r * Follow the official quick-start guide: https://jekyllrb.com/docs/quickstart/\r * Replace the content of the post created by the installation with this:\r \r ```\r ---\r layout: post\r title:  \"Welcome to Jekyll!\"\r categories: jekyll update\r ---\r \r {% highlight twig %}\r {% raw %}\r {% set a = 'b' %}\r {% endraw %}\r {% endhighlight %}\r \r ```\r \r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM460", "user": "ashmaroli", "root": "ROOT46", "reply_to": "ROOT46", "timestamp": "2018-03-12T15:47:43Z", "text": "How is the resulting output if you were to use triple-backticks instead?\r\n\r\n    ```twig\r\n    {% raw %}\r\n      {% set a = 'b' %}\r\n    {% endraw %}\r\n    ```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM461", "user": "ericmorand", "root": "ROOT46", "reply_to": "COM460", "timestamp": "2018-03-12T15:58:33Z", "text": "@ashmaroli, same.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM462", "user": "ashmaroli", "root": "ROOT46", "reply_to": "COM461", "timestamp": "2018-03-12T16:01:19Z", "text": "So you see the issue is not with Jekyll but rather with Rouge that `highlight` and the triple-backticks block uses to highlight code.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM463", "user": "ericmorand", "root": "ROOT46", "reply_to": "COM462", "timestamp": "2018-03-12T16:35:16Z", "text": "No, the problem also happens with the `{% highlight %}` syntax.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM464", "user": "ashmaroli", "root": "ROOT46", "reply_to": "COM463", "timestamp": "2018-03-12T16:44:29Z", "text": "Yes, that's because the `highlight` tag uses `Rouge` for syntax-highlighting by default\r\nhttps://github.com/jekyll/jekyll/blob/86d86258a8bc912c906776d8f2f9a58b3d376519/lib/jekyll/tags/highlight.rb#L38-L46\r\n\r\nIf you want to use `pygments` instead of `rouge` as your site's highlighter, add the following to your `_config.yml`:\r\n```yml\r\nhighlighter: pygments\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM465", "user": "pathawks", "root": "ROOT46", "reply_to": "COM464", "timestamp": "2018-03-12T16:52:22Z", "text": "This sounds like an issue with https://github.com/jneen/rouge rather than Jekyll. Jekyll has no knowledge of syntax of any language.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM466", "user": "ericmorand", "root": "ROOT46", "reply_to": "COM465", "timestamp": "2018-03-12T16:57:14Z", "text": "@pathawks, why did you close this? It's not fixed and I'm not the one explicitely using Rouge. The maintainers of the project are using a dependency that is buggy, they should take care of this. What do you want me to do? I don't even know what Rouge is!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM467", "user": "pathawks", "root": "ROOT46", "reply_to": "COM466", "timestamp": "2018-03-12T17:37:54Z", "text": "> What do you want me to do? I don't even know what Rouge is!\r\n\r\nI\u2019ve provided a link to the repository so that you can open an issue there and explain the problem you are having.\r\n\r\nI do not know what \u201cTwig\u201d is, so it would not make sense for me to be the one to explain what needs changing in Rogue.\r\n\r\nThere is nothing in Jekyll\u2019s code that can be changed to fix this issue; the fix will have to come from Rogue.\r\n\r\nHere is a link to Rogue\u2019s Twig lexar: https://github.com/jneen/rouge/blob/master/lib/rouge/lexers/twig.rb", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM468", "user": "ericmorand", "root": "ROOT46", "reply_to": "COM467", "timestamp": "2018-03-12T17:45:35Z", "text": "> There is nothing in Jekyll\u2019s code that can be changed to fix this issue; the fix will have to come from Rogue.\r\n\r\nThat's not my point. You are the one using Rouge to implement a feature that you advertise explitely on your docs! That's your responsibility to take care of things that don't work as expected in the dependencies of your project. As a consumer of your product, I expect it to work as advertised:\r\n\r\nhttps://jekyllrb.com/docs/templates/#code-snippet-highlighting\r\n\r\nYou are advertising syntax highlighting, you are supposed to deliver! And if you don't, you are supposed to take care of whatever is needed to have your product work as expected.\r\n\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM469", "user": "ashmaroli", "root": "ROOT46", "reply_to": "COM468", "timestamp": "2018-03-12T18:01:54Z", "text": "@ericmorand We're sorry that you're facing issues while using Jekyll.\r\nI agree that you as an end-user shouldn't concern yourself about bugs in dependencies.\r\n\r\nOne of the maintainers will get in touch with the developers at Rouge and sort things out for you.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4610", "user": "ericmorand", "root": "ROOT46", "reply_to": "COM469", "timestamp": "2018-03-12T18:03:52Z", "text": "@ashmaroli, thanks a lot. I already created an issue, maybe a maintainer could comment on it if the issue is not clear enough or if some things can be added:\r\n\r\nhttps://github.com/jneen/rouge/issues/881", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4611", "user": "ghost", "root": "ROOT46", "reply_to": "COM4610", "timestamp": "2018-03-12T18:04:57Z", "text": "@ericmorand Please take a step back and consider that this is an entirely volunteer-run project. We're not contractually obligated to work on every bug and answer every question, seeing as we simply don't have enough resources. So our apologies if some things take too long, or don't end up happening, but it's wrong to blame the maintainers for this.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4612", "user": "ericmorand", "root": "ROOT46", "reply_to": "COM4611", "timestamp": "2018-03-12T18:18:17Z", "text": "@oe, I totally understand that and i can relate: maintaining open source projects is very time-consuming. But I'm not having that discussion because I want to see that bug fixed immediately, to be honest this is a low priority bug even by my own standards. My point is that if, when a bug happens, maintainers blame a dependency, close the issue and ask for the reporter to open an issue elsewhere, that could go that way:\r\n\r\nJekyll\r\n\r\nOh, sorry this is a bug with Rouge, go open an issue there.\r\n\r\n -> Rouge\r\n\r\nOh, sorry this is a bug with Ruby, go open an issue there.\r\n\r\n-> Ruby\r\n\r\nOh, sorry this is a bug with GCC, go open an issue there.\r\n\r\n...and so on. At one point, my issue will be invalid because I won't even know what and how to report the bug. Already, Rouge maintainers could totally close my issue as invalid because I'm giving a way to reproduce that imply Jekyll - it would be legitimate for them to say that it's a Jekyll bug or that they want a reproducible example using only Rouge.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4613", "user": "ghost", "root": "ROOT46", "reply_to": "COM4612", "timestamp": "2018-03-12T18:23:12Z", "text": "@ericmorand The way I see it, this issue could pop up in any software that uses Rouge, and is therefore not specific to Jekyll. I agree however that it could have been better communicated before it was closed, sorry about that.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4614", "user": "ashmaroli", "root": "ROOT46", "reply_to": "COM4613", "timestamp": "2018-03-12T18:28:30Z", "text": "@ericmorand I re-opened the issue to convey that we have not abandoned this report straight away..\r\nDo know that I've kept a tab on the issue-ticket at Rouge and will follow its proceedings as time permits..", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4615", "user": "jekyllbot", "root": "ROOT46", "reply_to": "COM4614", "timestamp": "2018-07-01T18:11:11Z", "text": "\nThis issue has been automatically marked as stale because it has not been commented on for at least two months.\n\nThe resources of the Jekyll team are limited, and so we are asking for your help.\n\nIf this is a **bug** and you can still reproduce this error on the <code>3.3-stable</code> or <code>master</code> branch, please reply with all of the information you have about it in order to keep the issue open.\n\nIf this is a **feature request**, please consider building it first as a plugin. Jekyll 3 introduced [hooks](http://jekyllrb.com/docs/plugins/#hooks) which provide convenient access points throughout the Jekyll build pipeline whereby most needs can be fulfilled. If this is something that cannot be built as a plugin, then please provide more information about why in order to keep this issue open.\n\nThis issue will automatically be closed in two months if no further activity occurs. Thank you for all your contributions.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT47", "user": "esakal", "root": "ROOT47", "reply_to": null, "timestamp": "2017-06-28T08:33:57Z", "text": "[Feature] Allow custom publish subdirectory <!--- Provide a general summary of the issue in the Title above -->\r Many libraries in the Angular ecosystem publish to NPM from a subdirectory that was cooked during the build process. The process is usually as followed:\r - build the library in a subdirectory (i.e `dist` directory)\r - copy package.json, license and readme to the `dist` directory\r - do some package.json cleanups in the `dist` directory (delete devDepedencies, move dependencies to peerDependencies, remove scripts...)\r - npm publish from the `dist` directory.\r \r I understand that it is not a common technique for node.js package developers but i think it is common for web package developers and my libraries uses the same technique..\r \r While embedding `lerna` into our shared packages monorepo - [kaltura-ng](https://github.com/kaltura/kaltura-ng) I read a lot of issues in lerna and googled about this topic. I read carefully the conversation of issue #91 and even used the same subject with my issue. Unless I missed new issues that address this feature it was marked as 'wontfix' with a recommendation to use the 'package.json:files' array instead.\r \r The reasons for using this approach instead of `package.json:files` array are:\r - Many known libraries in the Angular ecosystem does it ([angular/angular](https://github.com/angular/angular), [ReactiveX/rxjs](https://github.com/ReactiveX/rxjs), [cyclejs/cyclejs](https://github.com/cyclejs/cyclejs)) so they must have a reason.\r - There is a lot of hoo-ha/complexity with the way node.js resolve modules  for the **web projects** since during the bundling process you **must** refer to the same instance of the library. Unless the bundler (typescript, webpack etc...) provide a hack/workaround/solution to force the library to use its' own node_modules, it will not work. Publishing from sub-directory works just because the `dist/node_modules` not exists.\r - During development if the symlink is done against the root, when you import nested class which was not exported in the main index, you will need to refer to the `dist` as part of the path `import { something } from 'my-package/dist/something`. but once you publish from `dist` folder directly, you should somehow fix the pass by removing the `dist` during the tranpiling which is not a valid option.\r - The libraries being used as dependencies during development should be assigned as peerDependencies at runtime because you want the application to provide them.\r \r so to recap, we cannot just publish the package with a `dist` folder, we need to publish from `dist` directly\r \r There are some caveats that I could think about with my suggested approach:\r 1. The dist folder must exists with a package.json inplace before the `lerna bootstrap` process symlink the folders. \r 2. The build process should not delete the 'dist' folder, instead it should just clear its content otherwise the symlink of dependent libraries will be broken.\r \r IMO those two caveats are manageable as:\r 1. we can use a preinstall script to create the folder and a simple package.json file (with at least 'id','name').\r 2. the build scripts should clear the folder content instead of `rm -rf` the folder itself.\r  \r ## Expected Behavior\r <!--- If you're describing a bug, tell us what should happen -->\r <!--- If you're suggesting a change/improvement, tell us how it should work -->\r when bootstrapping/publishing a package the package.json is being queried for the following config:\r \r ```\r \"config\" : {\r \t\"npmDistDirectory\" : \"dist\"\r },\r ```\r \r if this config exists, it will symlink to that folder during bootstrap command and will publish from that folder during  publish command\r \r using the 'config' attribute allow using the same configuration both in `lerna` and in other [node scripts](https://docs.npmjs.com/files/package.json#config).\r  \r I already modified the 'bootstrap' command in a fork [esakal/lerna](https://github.com/esakal/lerna). I didn't create a PR yet because I'm missing the 'publish' command. I will be happy to continue my work if you are going to consider this feature.\r \r You can see it in action in our repo -  [kaltura-ng](https://github.com/kaltura/kaltura-ng) :\r ```\r $ git clone https://github.com/kaltura/kaltura-ng.git\r $ yarn\r $ npm run setup\r $ cd kaltura-ui/node_modules/@kaltura-ng\r $ ll # you should see a symlink to kaltura-common/dist and kaltura-client/dist\r ```\r **NOTE** - your yarn version should be 0.24.6 and above\r \r ## Current Behavior\r <!--- If describing a bug, tell us what happens instead of the expected behavior -->\r <!--- If suggesting a change/improvement, explain the difference from current behavior -->\r n/a\r \r \r ## Your Environment\r <!--- Include as many relevant details about the environment you experienced the bug in -->\r \r | Executable | Version |\r | ---: | :--- |\r | `lerna --version` | 2.0.0-rc.5 |\r | `yarn --version` |  v0.24.6 |\r \r | OS | Version |\r | --- | --- |\r | macOS El Capitan | 10.11.6 |\r <!-- For example:\r | macOS Sierra | 10.12.3 |\r | Windows 10 | 1607 |\r | Ubuntu | 16.10 |\r -->\r ", "meta": {"posReactions": "18", "negReactions": "0"}}
{"id": "COM470", "user": "mickaelvalmier", "root": "ROOT47", "reply_to": "ROOT47", "timestamp": "2017-07-08T09:11:41Z", "text": "Hi,\r\n\r\nI have a same problem in a project developed with a lot of Angular 4 libraries.\r\nIf dist folder cant' be symlinked directly, the services don't be injected correctly.\r\n\r\nI dislike this way proposed by angular (define a package in dist). But if customization of package dir can't be defined, Lerna can't be used with an angular project.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM471", "user": "ghost", "root": "ROOT47", "reply_to": "COM470", "timestamp": "2017-09-16T10:41:11Z", "text": "up", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM472", "user": "xealot", "root": "ROOT47", "reply_to": "COM471", "timestamp": "2017-11-22T16:01:24Z", "text": "I recently tried using Lerna for the first time and immediately ran into this issue. Any heavy Typescript development is going to get hamstrung by the omission of this NPM feature.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM473", "user": "alan-agius4", "root": "ROOT47", "reply_to": "COM472", "timestamp": "2017-12-04T17:13:51Z", "text": "Same issue here I ran into this problem, when developing its fine however I want to publish only contents under a sub directory. would love to get this feature, I am even ready to do a PR.\r\n\r\n@evocateur any thoughts?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM474", "user": "Bratn", "root": "ROOT47", "reply_to": "COM473", "timestamp": "2017-12-08T23:40:45Z", "text": "As far as I know this is the only way to accomplish \"flat\" package structure (without the `/dist` or `/lib` section in the import path) unless skipping `src`/`dist` directories entirely, which isn't practicable if your source requires transpilation.\r\n\r\nLet's say I want to import only the `tinyUtil` module from the `utils` namespace inside my `big-obese-package`, what I would like it to look like is:\r\n```javascript\r\nimport tinyUtil from 'big-obese-package/utils/tiny-util';\r\n```\r\nIf the source is ts/jsx/esnext etc, the recommended way of distributing the package is to transpile it to a `dist` directory (\"npmDistDirectory\" in @esakal's proposal), include `package.json` and publish. This doesn't seem to be possible with lerna at this moment, which is a pity. \r\n\r\nInstead I will need to transpile it to `./dist`, reference it from the `files` prop in `package.json` and then accept the following import:\r\n```javascript\r\nimport tinyUtil from 'big-obese-package/dist/utils/tiny-util';\r\n```\r\nAfter spending precious time on your API design, naming convention etc, this is a bitter tradeoff.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM475", "user": "evocateur", "root": "ROOT47", "reply_to": "COM474", "timestamp": "2017-12-09T00:09:21Z", "text": "I don\u2019t understand why this \u201cflat\u201d package structure is better than just another npm package. \u201cbig-obese-monolith\u201d packages are an anti-pattern in npm. If you want to expose submodules directly, extract them into a separate package. *Literally* the reason Lerna was created in the first place.\n\n> On Dec 8, 2017, at 15:40, Andreas Brantmo <notifications@github.com> wrote:\n> \n> As far as I know this is the only way to accomplish \"flat\" package structure (without the /dist or /lib section in the import path) unless skipping src/dist directories entirely, which isn't practicable if your source requires transpilation.\n> \n> Let's say I want to import only the tinyUtil module from the utils namespace inside my big-obese-package, what I would like it to look like is:\n> \n> import tinyUtil from 'big-obese-package/utils/tiny-util';\n> If the source is ts/jsx/esnext etc, the recommended way of distributing the package is to transpile it to a dist directory (\"npmDistDirectory\" in @esakal's proposal), include package.json and publish. This doesn't seem to be possible with lerna at this moment, which is a pity.\n> \n> Instead I will need to transpile it to ./dist, reference it from the files prop in package.json and then accept the following import:\n> \n> import tinyUtil from 'big-obese-package/dist/utils/tiny-util';\n> After spending precious time on your API design, naming convention etc, this is a bitter tradeoff.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n> \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM476", "user": "Bratn", "root": "ROOT47", "reply_to": "COM475", "timestamp": "2017-12-09T01:06:03Z", "text": "@evocateur: I will not go into argument whether x is better than y - most often I am wrong. But if we ignore my poor choice of lorem-ipsum name (we can call it something else, such as \"tiny-lodash\"), I can't really see why lerna should hinder the author from using a nested structure within a package and at the same time provide \"semantic imports\". \r\n\r\nI came here to evaluate lerna as _a tool for managing JavaScript projects with multiple packages_, not as a tool to limit me on how to structure the internals of my packages (whether good or bad).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM477", "user": "evocateur", "root": "ROOT47", "reply_to": "COM476", "timestamp": "2017-12-09T04:34:22Z", "text": "In my experience, as well as observation of community packages over many years, coupling consumption of a given export to the literal directory structure of a tarball is an extremely hostile anti-pattern. Especially nowadays with ES module exports and whatnot combined with tree-shaking module bundlers, there\u2019s really no fundamental _necessity_ for false-basedir publishing.\n\nLerna is designed around the way npm works. Packages are published from the same directory as the package.json, and construct their tarball from metadata contained therein. Publishing from a different directory with a modified dependency tree is not idiomatic npm, and lerna will not support it.\n\n> On Dec 8, 2017, at 17:06, Andreas Brantmo <notifications@github.com> wrote:\n> \n> @evocateur: I will not go into argument whether x is better than y - most often I am wrong. But if we ignore my poor choice of lorem-ipsum name (we can call it something else, such as \"tiny-lodash\"), I can't really see why lerna should hinder the author from using a nested structure within a package and at the same time provide \"semantic imports\".\n> \n> I came here to evaluate lerna as a tool for managing JavaScript projects with multiple packages, not as a tool to limit me on how to structure the internals of my packages (whether good or bad).\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n> \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM478", "user": "alan-agius4", "root": "ROOT47", "reply_to": "COM477", "timestamp": "2017-12-09T08:33:17Z", "text": "This will be a major limitation for TypeScript and Angular developers, and in fact some people using lerna with typescript had to do their own publish, or patch the existing implementation.  I myself want to publish from a subdirectory which does contain a `package.json` for several reasons;\r\n\r\n1) I don't want to transpile my TS in the `src` folder because I'll end up having a messy file system. `.ts`, `.metadata.json`, `.js`, `.d.ts` all next to each other, and than to `clean` after build will be a total mess.\r\n2) I want to following Google's Angular Package format https://docs.google.com/document/d/1CZC2rcpxffTDfRDs6p1cfbmKNLA6x5O-NtkJglDaBVs/preview\r\n3) Seperation of concerns, why should I have my `dist` files within the same folder of the `src`?\r\n\r\nMy folder structure\r\n```bash\r\n-- my-lib\r\n---- package.json\r\n---- src\r\n------ index.ts\r\n----dist\r\n------ package.json\r\n------ index.d.ts\r\n------ index.metadata.json\r\n------ esm2015\r\n-------- index.js\r\n------ esm5\r\n-------- index.js\r\n------ bundles\r\n-------- index.js\r\n```\r\nSo in reality i can publish from a subfolder as I do have a `package.json`", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM479", "user": "joewoodhouse", "root": "ROOT47", "reply_to": "COM478", "timestamp": "2017-12-29T05:58:15Z", "text": "Author of several typescript modules here who has hit the exact same issue, all my modules publish from a `dist` folder. Wish I'd known this before starting to use lerna! Would love this feature to be implemented, but will probably have to switch to something else instead now.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4710", "user": "evocateur", "root": "ROOT47", "reply_to": "COM479", "timestamp": "2017-12-29T15:45:43Z", "text": "I fail to see what typescript has to do with this non-idiomatic subdirectory pattern. You can publish npm modules with transpiled code and typings under `dist` just fine, no mangling of package.json required.\n\n> On Dec 28, 2017, at 21:58, Joe Woodhouse <notifications@github.com> wrote:\n> \n> Author of several typescript modules here who has hit the exact same issue, all my modules publish from a dist folder. Wish I'd known this before starting to use lerna! Would love this feature to be implemented, but will probably have to switch to something else instead now.\n> \n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n> \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4711", "user": "alan-agius4", "root": "ROOT47", "reply_to": "COM4710", "timestamp": "2017-12-29T16:08:53Z", "text": "That won\u2019t  work if you\u2019d need secondary entry points like\n@scope/my-lib/testing\n\n\n\n\nOn Fri, 29 Dec 2017 at 16:45, Daniel Stockman <notifications@github.com>\nwrote:\n\n> I fail to see what typescript has to do with this non-idiomatic\n> subdirectory pattern. You can publish npm modules with transpiled code and\n> typings under `dist` just fine, no mangling of package.json required.\n>\n> > On Dec 28, 2017, at 21:58, Joe Woodhouse <notifications@github.com>\n> wrote:\n> >\n> > Author of several typescript modules here who has hit the exact same\n> issue, all my modules publish from a dist folder. Wish I'd known this\n> before starting to use lerna! Would love this feature to be implemented,\n> but will probably have to switch to something else instead now.\n> >\n> > \u2014\n> > You are receiving this because you modified the open/close state.\n> > Reply to this email directly, view it on GitHub, or mute the thread.\n> >\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/lerna/lerna/issues/901#issuecomment-354461926>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AQv-Wvv5lUEqgM_8TBbmjFtE3rTZ3C1Nks5tFQkqgaJpZM4OHpyp>\n> .\n>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4712", "user": "austingreendev", "root": "ROOT47", "reply_to": "COM4711", "timestamp": "2018-01-10T20:24:42Z", "text": "For those that are still trying to get \"flat-pack\" imports working: `import Bar from 'foo/Bar'` \r\n\r\nI was able to solve it by leveraging the `preversion`, `version`, and `postversion` scripts that were added in https://github.com/lerna/lerna/issues/774\r\n\r\nFor me I got it working by:\r\n- Disabling NPM publishing during the lerna publish command\r\n  - `lerna publish --skip-npm`\r\n- Performing my linting and build during the `preversion` NPM script (or before) which would be built into a `dist` folder\r\n- Copy necessary files into the `dist` folder during the `postversion` NPM script and then call `npm publish dist`. This is handled in a gulp file but I've simplified below.\r\n  - The `package.json` version has been bumped prior to the `postversion` script being called\r\n  - `postversion` is only called if you do not include the `--skip-git` command to lerna publish\r\n  - `\"postversion\": \"cp package.json dist && npm publish dist\"`\r\n\r\nI still think a config option for `npmDistDirectory` could be beneficial since it would allow a consumer to leverage the `prepublish` lifecycle-hook which seems a little more intuitive.", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM4713", "user": "sandangel", "root": "ROOT47", "reply_to": "COM4712", "timestamp": "2018-01-17T11:33:40Z", "text": "that's why angular repos not using lerna", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4714", "user": "yordis", "root": "ROOT47", "reply_to": "COM4713", "timestamp": "2018-02-01T10:20:03Z", "text": "@austin94 that is painful \ud83d\udc94 \r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4715", "user": "yordis", "root": "ROOT47", "reply_to": "COM4714", "timestamp": "2018-02-04T15:24:39Z", "text": "@evocateur in my case is not because of Angular or because I want to have a fat package but the fact that I can't just export everything throw a single file (pkg.main) because that will work as long as you do not have any naming collision.\r\n\r\nI would be great if  in the deployment at least I could specify which folder to actually publish to npm. For the simple reason that you will no need to be adding `/lib` or `/dist` or what have you.\r\n\r\nIt is not necessary this to be agains anything related to `npm` but the lack of changes on npm itself. 2018 most of the packages uses specific folder for the compiled version of the package, webpack does it, babel community suggest it, parcel does it, rollup community suggest it.\r\n\r\nSo why could just see the need of this? \r\n\r\nWhy we couldn't have specific folder where you will have the final npm package `package.json + code` and we could avoid any weird name on the file path of the package?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4716", "user": "yordis", "root": "ROOT47", "reply_to": "COM4715", "timestamp": "2018-02-04T15:38:32Z", "text": "@evocateur btw, I do not see this related to Typescript only but any package that requires a build process and normally they will put the final package inside specific folder.\r\n\r\nAlso, https://docs.npmjs.com/cli/publish the command already allow you to specify a folder so it should be the matter of adding the config and use for run the `npm publish` with the configured path \u2764\ufe0f \r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4717", "user": "evocateur", "root": "ROOT47", "reply_to": "COM4716", "timestamp": "2018-02-04T17:13:29Z", "text": "That\u2019s literally what the `main` field is for. If you transpile into `dist`, and you have `index.js` as your entry, `\u201dmain\u201d: \u201cdist/index.js\u201d` works perfectly fine in your package.json file.\n\n> On Feb 4, 2018, at 07:38, Yordis Prieto <notifications@github.com> wrote:\n> \n> @evocateur btw, I do not see this related to Typescript only but any package that requires a build process and normally they will put the final package inside specific folder.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n> \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4718", "user": "evocateur", "root": "ROOT47", "reply_to": "COM4717", "timestamp": "2018-02-04T17:16:13Z", "text": "> I can't just export everything [through] a single file (pkg.main) because that will work as long as you do not have any naming collision.\n\nYour packages are too big if that is the case. Embrace the patterns of the npm ecosystem.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4719", "user": "noherczeg", "root": "ROOT47", "reply_to": "COM4718", "timestamp": "2018-02-04T19:06:35Z", "text": "@yordis \r\n\r\n\"I would be great if in the deployment at least I could specify which folder to actually publish to npm\"\r\n\r\nYou can tell npm what folders/files to put inside a package via the [files](https://docs.npmjs.com/files/package.json#files) param. I never tried it for sub-directories, but if I got what you are aiming at this could be enough to solve the mentioned problem right?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4720", "user": "yordis", "root": "ROOT47", "reply_to": "COM4719", "timestamp": "2018-02-04T19:21:57Z", "text": "> Your packages are too big if that is the case. Embrace the patterns of the npm ecosystem.\r\n\r\nBased on what you can say that?\r\n\r\n```js\r\n// factory1.js\r\n\r\nexport const perform = () => {\r\n  return 'factory1'\r\n}\r\n```\r\n\r\n```js\r\n// factory2.js\r\n\r\nexport const perform = () => {\r\n  return 'factory2'\r\n}\r\n```\r\n\r\n```js\r\n// pkg.main: main.js\r\n\r\nexport * from './factory1'\r\nexport * from './factory2'\r\n```\r\n\r\nbecause you can't do the previous example you will end up requiring specific file\r\n\r\n```js\r\n// somefile.js\r\n\r\nimport * as Something from 'libname/factory2'\r\n\r\nconsole.log(\r\n  Something.perform()\r\n)\r\n```\r\n\r\nSo, based on what you can assume that you are right saying that the package is too big? \r\n\r\nWhat will be your argument that I have to pay attention to re-exporting on the main file?\r\n\r\nWell, I wouldn't re-export anything if that is your case, the whole point of having files that behave as a module scope in NodeJS.\r\n\r\nCould you show me how to resolve this issue please?\r\n\r\nAlso, I am trying to prevent to add `libnam/lib/factory2` so it is a flat package.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4721", "user": "yordis", "root": "ROOT47", "reply_to": "COM4720", "timestamp": "2018-02-04T19:25:13Z", "text": "> Embrace the patterns of the npm ecosystem.\r\n\r\nWhat do you mean by that? What is the npm ecosystem?\r\n\r\n\r\nHaving one function package so you will end up with 100 dependencies when they can live all together in the same package? \r\n\r\nBefore Tree-shaking exists, probably makes sense because you didn't want to export the whole thing but now the tooling is advance enough.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4722", "user": "austingreendev", "root": "ROOT47", "reply_to": "COM4721", "timestamp": "2018-02-04T19:36:29Z", "text": "Hi @yordis :wave: I think there might be a few different conversations going on at once here.\r\n\r\n> I would be great if in the deployment at least I could specify which folder to actually publish to npm\r\n\r\nExpanding on what @noherczeg mentioned, this is possible with the `main` and/or `files` options within `package.json`\r\n\r\n```\r\n// example package.json\r\n...\r\nmain: 'dist/index.js',\r\nfiles: ['dist'],\r\n...\r\n```\r\n\r\nLet say your files were all under a `dist` folder. A consumer could retrieve the files in the following way:\r\n\r\n```\r\nimport * as Everything from 'package';\r\nimport * as FactoryOne from 'package/dist/FactoryOne';\r\nimport * as FactoryTwo from 'package/dist/FactoryTwo';\r\netc.\r\n```\r\n\r\nThere is no _technical_ difference between the code above and \r\n\r\n```\r\nimport * as Everything from 'package';\r\nimport * as FactoryOne from 'package/FactoryOne';\r\nimport * as FactoryTwo from 'package/FactoryTwo';\r\n```\r\n\r\nwhich is what I was looking for. The only reason I was looking for this was to have a \"cleaner\" import structure.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM4723", "user": "yordis", "root": "ROOT47", "reply_to": "COM4722", "timestamp": "2018-02-04T19:42:24Z", "text": "@austin94 right now what I am trying to do is removing `dist` from the path indeed.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4724", "user": "yordis", "root": "ROOT47", "reply_to": "COM4723", "timestamp": "2018-02-04T20:41:19Z", "text": "@austin94 \r\n\r\n> Expanding on what @noherczeg mentioned, this is possible with the main and/or files options within package.json\r\n\r\nYes, I am aware of that but that but when you use a folder it will just copy the file inside the folder name so `files: [\"lib\"]` it will put the files inside `lib`\r\n\r\n> There is no technical difference between the code above and\r\n\r\nOnes comes from `lib` and the other comes from the root of the project. \r\n\r\nIdeologically, yes you are right, there is not differences (maybe, who knows, this is based on the situation).\r\n\r\nTechnically,\r\n\r\nThere is a different indeed, in fact, I could have `package/FactoryOne` and `package/lib/FactoryOne` in the same project and have for whatever reason differences between each other.\r\n\r\nBut I am seeking the same you are seeking, have a clear importing structure.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4725", "user": "evocateur", "root": "ROOT47", "reply_to": "COM4724", "timestamp": "2018-02-04T23:05:54Z", "text": "If anyone wants this, fork lerna and do it yourself. This conversation is over.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT48", "user": "ExpensiveKoala", "root": "ROOT48", "reply_to": null, "timestamp": "2018-03-16T16:11:10Z", "text": "Add event to allow for rendering additional overlays on items in guis I have a tool which needs to have two durability bars. In order to draw the second one, I would have to ASM my own hook into `RenderItem`, or do some wonky rendering on the `GuiContainerEvent.DrawForeground` and `RenderGameOverlayEvent.Post` events. This prompted a PR for the hook instead.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM480", "user": "CLAassistant", "root": "ROOT48", "reply_to": "ROOT48", "timestamp": "2018-03-16T16:11:18Z", "text": "[![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/MinecraftForge/MinecraftForge?pullRequest=4803) <br/>All committers have signed the CLA.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM481", "user": "HenryLoenwind", "root": "ROOT48", "reply_to": "COM480", "timestamp": "2018-03-16T20:03:42Z", "text": "Save your energy. Lex has rejected this again and again.\r\n\r\nPut your overlays as extra quads into your item model, he says.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM482", "user": "LexManos", "root": "ROOT48", "reply_to": "COM481", "timestamp": "2018-03-16T20:46:55Z", "text": "Threatening to coremods shit because you haven't spent 10 mins looking into other solutions is not the way to get things added to forge.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM483", "user": "elifoster", "root": "ROOT48", "reply_to": "COM482", "timestamp": "2018-03-16T21:31:55Z", "text": "It's pretty useless to complain about someone not looking without pointing them in the right direction. I have searched the issues of this repository without finding anything. There is literally no reason to assume or accuse that people haven't looked for something just because they didn't find the solution. It's excruciatingly abrasive and dickish and impedes fostering a community that actually wants to contribute to a project.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM484", "user": "ExpensiveKoala", "root": "ROOT48", "reply_to": "COM483", "timestamp": "2018-03-16T21:37:40Z", "text": "Going off on someone because you assume they haven't searched for other solutions makes you look like a dick. I asked around on several modding discords, looked at the source of several mods which implement such thing that I'm trying to and came to the conclusion that ASM is the only good way. I'm not threatening to coremod anything. The solutions I found were to coremod and I wanted to avoid that. **Which is why I made this PR.**", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM485", "user": "LexManos", "root": "ROOT48", "reply_to": "COM484", "timestamp": "2018-03-16T22:09:35Z", "text": "Documentation on everything is always a issue, this will never go away. However its a simple concept, you're trying to add one quad to your item when rendered in the inventory.\r\nWe have MANY things related to extending the item model, So I would tell you to start looking at the IModel interface, as well as the renderItemAndEffectIntoGUI/renderItemOverlayIntoGUI which gathers the model and passes through a hadleState function which you can easily build the extra bar onto. \r\nWe also expose a model based font renderer so there's help with that. \r\nCombined with the MANY MANY posts and arguments that we've had on this issue tracker and the forums about the point of the model system is to REMOVE direct GL access from the mods/items. Your solution is to add a new hook that encourages modders to break GL.\r\nAll you wont is your model to have one extra textured quad. Why does this need to be/encourage direct GL access?\r\nI don't care if you consider my response dickish, your initial post was. And im getting tired of people posting under the same veiled threats every damn time. \"Do this now or i'll hack it with a coremod!\" You may not intend for your post to come across that way but it does.\r\nSo some takeaways: Don't open your Prs with 'Im gunna ASM this if you dont add it' Which is what your post comes under. Don't go against the entire point of moving to a model system buy adding YetAnother place of calling direct GL code. If you find something that you THINK you can't do in Forge open a issue, or use the forums. Explore your options. State what options you have explored. And again DO NOT open your argument with do this or i'll asm it!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM486", "user": "HenryLoenwind", "root": "ROOT48", "reply_to": "COM485", "timestamp": "2018-03-16T23:17:51Z", "text": "[Edited to remove being a dick]\r\n\r\nLex, you solution has 2 major drawbacks:\r\n\r\n1. It requires a a code-based model. The step from putting a png and a 3-line json model into the resources folder to coding a custom IModel is huge.\r\n2. The quads you add with your model are in model space. They will then be transformed using the Matrix4f derived from the json model. To add a quad that aligns to screen pixels, you need to apply those transforms in reverse and also know what the target coordinates (y!) are.\r\n\r\nBoth of these tasks are not trivial. Using the BufferBuilder to throw a single colored quad onto the screen *is* trivial, especially as anyone who has ever made a GUI for any block knows how to do it. (and if they don't, the code in renderItemOverlayIntoGUI already does exactly that and can be copied very easily.)\r\n\r\nNow, is direct GL access the only way to do that? No, it isn't. I can think of dozens of ways to supply overlays that don't need GL calls but still are much simpler to use than baking models on-the-fly. Even a callback that asks for a texture path + u/v/w/h to overpaint over the item would fulfill 95% of all usescases. But the number 1 solution people will propose when they run into this problem is \"do it like vanilla\". And killing any discussion at that point will ensure that the same will happen again and again.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM487", "user": "LexManos", "root": "ROOT48", "reply_to": "COM486", "timestamp": "2018-03-16T23:47:15Z", "text": "If you would like to readdress this as a series of prebuilt utilities to render extra bars or numbers over items in the inventory. Then we can readdress it as that.\r\nBut moving things back 5 years by encouraging people to do even more direct GL access is not going to fly.\r\nFeel free to create a new issue or PR to discuss that avenue of things.\r\n\r\nAs for the whole topic of ASM. Let me state this directly and for the record.\r\nIt is, by definition, possible to do ANYTHING in a coremod.\r\nStating that you can/are using a coremod in a PR serves literally NO purpose.\r\nIt is NOTHING but a threat that gets tranted to \"Do this or i'll hack shit with a coremod\"\r\nI do not bed to threats.\r\n\r\nSo, new guideline (I've instructed Mezz to make it official). Any mention of ASM or hints at using a coremod to do shit in your issue will result in the thread being locked, and potentially you being banned from the Forge repo.\r\nEnd of story, i'm sick of being threatened by people and coremods.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT49", "user": "fabiospampinato", "root": "ROOT49", "reply_to": null, "timestamp": "2018-02-03T16:12:05Z", "text": "Marketplace: searching by an extension's name is practically broken There are a few major problems when searching by an extension's name. First of all, if I remember correctly, the marketplace had this thing on every extension's page:\r \r ![](https://cloud.githubusercontent.com/assets/2685357/25901135/734e34fc-359e-11e7-8a0b-a4ee9171ef4c.png)\r \r So I've added an analogous message to all of my extensions' readme files, and I think other extension authors have done this too.\r \r I have an extension called [Todo+](https://marketplace.visualstudio.com/items?itemName=fabiospampinato.vscode-todo-plus) (full id: `fabiospampinato.vscode-todo-plus`). This is what happens when the command `ext install vscode-todo-plus` is executed:\r \r ![](https://user-images.githubusercontent.com/17926167/35692049-868ae976-077a-11e8-8ecc-debf7c71c558.gif)\r \r - `vscode-todo-plus` in an exact match of the id minus my username, and the extension is not even in the top 10 results.\r - Searching for `fabiospampinato.vscode-todo-plus`, which is an exact match of the full id, leads to the same results.\r - Searching for `@id:fabiospampinato.vscode-todo-plus` works, **but only inside VSC**, it doesn't work on [marketplace.visualstudio.com](https://marketplace.visualstudio.com)\r - Where are these `ext install` and `@id:` commands documented anyway?\r \r Let's try to search for another extension of mine, [Open in Browsers](https://marketplace.visualstudio.com/items?itemName=fabiospampinato.vscode-open-in-browsers) (full id: `fabiospampinato.vscode-open-in-browsers`):\r \r <img width=\"1102\" alt=\"screen shot 2018-02-03 at 16 51 16\" src=\"https://user-images.githubusercontent.com/1812093/35768894-f918c7e0-0902-11e8-8876-8386a2c52078.png\">\r \r - Not only `vscode-open-in-browsers` is an exact match of the extention id minus my username, but \"Open in Browsers\" is the extension's title, and \"vscode\" is practically a meaningless keyword, as is \"in\". What's the first result for this search? [vscode-ins-support](https://marketplace.visualstudio.com/items?itemName=wk-j.vscode-ins-support) \ud83d\ude15\r \r I hope we do agree there's a problem here.\r \r If I may suggest a few improvements: \r \r 1. Always check if an extension's id (minus the username) is an exact match of the current query.\r 2. Implement [stop words](https://en.wikipedia.org/wiki/Stop_words).\r \r _Please don't close this issue as \"non actionable\"._", "meta": {"posReactions": "18", "negReactions": "0"}}
{"id": "COM490", "user": "eamodio", "root": "ROOT49", "reply_to": "ROOT49", "timestamp": "2018-02-03T22:36:47Z", "text": "This has been a long standing issue -- it is the reason I had to rename my extension to *Git Lens* rather than its actual name *GitLens* (no space), because when searching for git it would never show up. And even with that rename -- I had to pack in other words into the title (SEO hacking style) to even get it to show up on some other keywords -- even if those keywords were in the package.json keywords list.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM491", "user": "fabiospampinato", "root": "ROOT49", "reply_to": "COM490", "timestamp": "2018-02-04T00:15:47Z", "text": "So those keywords I've been adding are actually useless you say? Nice...\r\n\r\nI'm not sure if it's worse that the search engine works as badly as it does or that it hasn't been fixed already.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM492", "user": "eamodio", "root": "ROOT49", "reply_to": "COM491", "timestamp": "2018-02-05T08:07:34Z", "text": "Not useless, but just ranked quite a lot below what is in the name -- at least that used to be the case", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM493", "user": "joaomoreno", "root": "ROOT49", "reply_to": "COM492", "timestamp": "2018-02-05T09:08:12Z", "text": "cc @viradhamMS @pkuma-msft", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM494", "user": "joaomoreno", "root": "ROOT49", "reply_to": "COM493", "timestamp": "2018-02-06T08:58:09Z", "text": "@fabiospampinato \r\n\r\nDisregarding the fact that the Marketplace doesn't return any results when searching for an extension's id, we have fixed the Marketplace instructions since a while. `ext install` was our way of guiding users to install extensions inside VS Code. Since we now have URL handlers for Mac and Windows, those instructions became almost irrelevant. We now only show them for Linux users:\r\n\r\n![image](https://user-images.githubusercontent.com/22350/35850126-1510cbaa-0b24-11e8-88da-f21d798b53b3.png)\r\n\r\nRunning this in VS Code will correctly trigger the search for `@id.name`. The `name` format should've never been there. Only the`id.name` is unequivocal in order to find an extension in the Marketplace.\r\n\r\nOne idea I have for alleviating this pain is to improve the `ext install name` (without `id`) experience: what if we showed in quick open a list of extensions which match that name? This would simply mitigate the fact that there are instructions for `ext install name` out there. But in any case, I recommend switching your instructions to `ext install id.name`.\r\n\r\nWe've notified the Marketplace of the search issues.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM495", "user": "fabiospampinato", "root": "ROOT49", "reply_to": "COM494", "timestamp": "2018-02-06T15:58:05Z", "text": "> we have fixed the Marketplace instructions since a while\r\n\r\nI've only recently noticed the change (from `ext-name` to `owner.ext-name`) because somebody opened an issue about that in one of my repositories, has this change been mentioned in any changelog in the past?\r\n\r\n> Since we now have URL handlers for Mac and Windows, those instructions became almost irrelevant\r\n\r\nI would have replaced those `ext install (...)` instructions with URL handlers, but I've tried them once and after that, for a few days/weeks, a \"Do you want to install (...)\" message kept popping up every time I opened a new window. By the time that was fixed I guess I had forgotten about them.\r\n\r\n> what if we showed in quick open a list of extensions which match that name? \r\n\r\nWhy providing 2 different interfaces for discovering extensions?\r\n\r\nShouldn't searching \"just work\"?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM496", "user": "joaomoreno", "root": "ROOT49", "reply_to": "COM495", "timestamp": "2018-02-07T16:39:34Z", "text": "> I've only recently noticed the change (from ext-name to owner.ext-name) because somebody opened an issue about that in one of my repositories, has this change been mentioned in any changelog in the past?\r\n\r\nI guess it wasn't, since it was a Markeplace change... Sorry about that.\r\n\r\n> Shouldn't searching \"just work\"?\r\n\r\nIt should. We've notified the Marketplace of the search issues.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM497", "user": "fabiospampinato", "root": "ROOT49", "reply_to": "COM496", "timestamp": "2018-05-27T15:41:03Z", "text": "Just to reiterate on how bad the search engine works:\r\n\r\n- I've just published an extension named `Open in node_modules`\r\n- Searching for `open in node modules` (without the underscore) won't even show said extension within the first 60 results \ud83e\udd37\u200d\u2642\ufe0f", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM498", "user": "gaurav42", "root": "ROOT49", "reply_to": "COM497", "timestamp": "2018-05-28T15:02:16Z", "text": "@fabiospampinato, regarding the issue of searching your new extension:\r\n\r\nWhile searching an extension, we also take into account the community inputs like number of downloads, number of ratings and average rating along with the string matching. Among the string matching, exact string matches carry a higher weight than prefix match. \r\n\r\nSince `node_modules` is one word in your extension name, word `node` in search text gets prefix match here. However, there are lot of extensions on Marketplace which have exact word 'node' in their extension name. So they carry a higher weight for matching the word 'node'. Additionally, since your extension is new, download count and ratings of other extensions are way higher, pushing their total score to the top.\r\n\r\nOne way to improve your extension rank is to break word `node_modules` into separate words `node modules`. This will increase the string matching score and push your extension up in the result.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM499", "user": "fabiospampinato", "root": "ROOT49", "reply_to": "COM498", "timestamp": "2018-05-28T15:38:02Z", "text": "@gaurav42 Well, I would still consider whatever algorithm you guys are using broken because if I search for \"open in node modules\" I get these search results (some samples ~~randomly picked):\r\n\r\n| Rank    | Ext. Name    | Ext. Description | My comments  |\r\n|--------|-------------|-----------------|----------------|\r\n| `#6`  | [Node Exec](https://marketplace.visualstudio.com/items?itemName=miramac.vscode-exec-node) | Execute the current file or your selected code with node.js. | 80k downloads, but no mention of \"open\" or \"module(s)\" anywhere.\r\n| `#10` | [CSS Modules](https://marketplace.visualstudio.com/items?itemName=clinyong.vscode-css-modules) | Visual Studio Code extension for CSS Modules | 22k downloads, but no mention of \"open\" or \"node\" anywhere.\r\n| `#17` | [Node TDD](https://marketplace.visualstudio.com/items?itemName=prashaantt.node-tdd) | Ease test-driven development in Node and JavaScript | 9k downloads, no mention of \"module(s)\", but at least it has a few \"opened\" in its readme.\r\n| `#64` | [Open in Vim](https://marketplace.visualstudio.com/items?itemName=jonsmithers.open-in-vim) | Opens current file in vim | 2k downloads, this is not even mentioning \"node\" anywhere, let alone \"module(s)\". But at least it has \"open\" and \"in\" in it's title.\r\n| `#65` | [Open in node_modules](https://marketplace.visualstudio.com/items?itemName=fabiospampinato.vscode-open-in-node-modules) | Open the current selection or arbitrary string in node_modules. | 2 downloads, it matches all the provided keywords, **in its title**.\r\n\r\nIf I had to guess what's wrong with your approach I'd say:\r\n\r\n- Lack of stopwords, kind of meaningless keywords like \"vscode\" or \"in\" are given too much weight.\r\n- Poor query parsing, if keywords are joined in some sort or another the whole thing falls apart (vscode-foo-bar, foo_bar, GitLens etc.)\r\n- Maybe you're giving too much weight to downloads and ratings, the first thing to sort for is relevancy.\r\n\r\n> One way to improve your extension rank is to break word node_modules into separate words node modules. This will increase the string matching score and push your extension up in the result.\r\n\r\nI'm not going to rename the extension to something wrong (`node_modules` is a folder, I'm not talking about `node modules`, as in \"NPM packages\", here) just to work around this.", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM4910", "user": "Almenon", "root": "ROOT49", "reply_to": "COM499", "timestamp": "2018-06-11T14:02:25Z", "text": "I agree, the search ranking seems wierd.\r\n\r\nSome examples (when searching for \"python\"):\r\n\r\nPy Files generator is above autoDocString, despite having about 50k less installs and 0 reviews\r\nSame thing with ladieratheme - it is above autoDocString despite having about 49k less installs and 3 less reviews\r\n\r\nTrustcode odo snippets and kvlang is above docker linter, despite having 47k less installs\r\n\r\nPython paste and indent has 3 stars but apparently it's 2k extra downloads trumps Python (pydev)'s 5 star rating.  Seems like download count is weighted more heavily than rating in the ranking (or maybe python paste and indent has better keywords)\r\n\r\nPython Coding Conventions has 773 downloads and is unrated, yet somehow is above magicpython (with 742 _thousand_ downloads and 3.5 stars) and several other extensions with far more downloads / good ratings.  So you could have a very popular or well-rated extension but if you don't have the right keywords you will still be ranked down.\r\n\r\nWait..,. but looking at the Python Coding Conventions package.json, it doesn't even have any keywords!\r\n\r\nhttps://github.com/harip/python-coding-conventions/blob/master/package.json  \ud83e\udd14\ud83e\udd14\ud83e\udd14\r\n\r\n> While searching an extension, we also take into account the community inputs like number of downloads, \r\n\r\nYou mean the download count that is _also_ the update count?  This has been a outstanding issue ever since 2016 - when you release an update the marketplace shows your downloads as having increased.\r\nThe update count should not effect the search ranking.\r\n\r\n> number of ratings and average rating \r\n\r\nThat's good, but what algorithim are you using to calculate the weighted rating?  Not sure if that is open source but hopefully it isn't something like RatingA - RatingB or RatingA/RatingB\r\n\r\nhttp://www.evanmiller.org/how-not-to-sort-by-average-rating.html", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4911", "user": "fabiospampinato", "root": "ROOT49", "reply_to": "COM4910", "timestamp": "2018-06-11T14:22:03Z", "text": "> Python Coding Conventions has 773 downloads and is unrated, yet somehow is above magicpython \r\n\r\nThis probably happens because of this:\r\n\r\n> Poor query parsing, if keywords are joined in some sort of another the whole thing falls apart (vscode-foo-bar, foo_bar, GitLens etc.)\r\n\r\n> You mean the download count that is also the update count? This has been a outstanding issue ever since 2016 - when you release an update the marketplace shows your downloads as having increased.\r\nThe update count should not effect the search ranking.\r\n\r\nYeah that's another major problem, one could automatically push a new update every day and downloads will go through the roof even though the same number of people are using it.\r\n\r\nI guess technically those users are _downloading_ the update, but once this things are counted the downloads counter becomes less meaningful. \r\n\r\nThe download counter for extensions on Chrome's store decreases when somebody uninstalls your extension and I think it doesn't increase just because the extension gets updated.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4912", "user": "pkuma-msft", "root": "ROOT49", "reply_to": "COM4911", "timestamp": "2018-06-14T05:02:55Z", "text": "Hey guys, I want to thank you for all the feedback. Please keep them coming. We are discussing this issue internally and I'll update this thread as soon as we have something to share.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM4913", "user": "fabiospampinato", "root": "ROOT49", "reply_to": "COM4912", "timestamp": "2018-07-18T11:22:07Z", "text": "Here there's another weird one, searching for \"monokai\" and ordering by downloads returns those language packs at the top. The only place where those language packs mention \"monokai\" is inside their `package.json` as the value of some `contributes.localizations[0].translations[x].id` keys, why are you guys even indexing those fields?\r\n\r\n<img width=\"1193\" alt=\"screen shot 2018-07-18 at 13 09 36\" src=\"https://user-images.githubusercontent.com/1812093/42878075-112f643c-8a8c-11e8-93a2-1c5f54f57589.png\">", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4914", "user": "fabiospampinato", "root": "ROOT49", "reply_to": "COM4913", "timestamp": "2018-09-20T16:34:48Z", "text": "I've just realized that the readmes aren't indexed at all. \r\n\r\nI searched for \"cyclomatic\" in the marketplace, and I've got this result:\r\n\r\n<img width=\"674\" alt=\"screen shot 2018-09-20 at 18 27 56\" src=\"https://user-images.githubusercontent.com/1812093/45832685-ebe46c00-bd02-11e8-85ec-3cf9dc21ad82.png\">\r\n\r\nThen I tried searching for \"marketplace cyclomatic\" on Google, and this is the result:\r\n\r\n<img width=\"846\" alt=\"screen shot 2018-09-20 at 18 25 18\" src=\"https://user-images.githubusercontent.com/1812093/45832583-95772d80-bd02-11e8-875b-473a56d814a1.png\">\r\n\r\nThis is a bit ridiculous. \r\n\r\nI'm not saying that the search functionalities in the marketplace should be as good as Google's under **all** circumstances, but that's a full-word match in the readme, this query just can't return 0 results.\r\n\r\n@pkuma-msft do you have any updates for us?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4915", "user": "pkuma-msft", "root": "ROOT49", "reply_to": "COM4914", "timestamp": "2018-09-21T21:11:09Z", "text": "@fabiospampinato Yes, unfortunately we do not index readme.md.. sorry about that. We use SQL FTS in our backend today and that's kind of the limiting factor. There's only so much custom logic we can run over the results returned by FTS to make it 'more' relevant - and more importantly it doesn't scale in the long run.\r\n\r\nWe are exploring moving our search platform to Azure Search or Bing which are techologies that are being actively developed and should provide us with more features and capabilities.\r\n\r\nI'm afraid we are not going to invest more in trying to optimize search with FTS.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM4916", "user": "Almenon", "root": "ROOT49", "reply_to": "COM4915", "timestamp": "2018-09-21T23:06:22Z", "text": "@pkuma-msft thanks for the update.  Any timeframe for when the move will happen?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4917", "user": "Almenon", "root": "ROOT49", "reply_to": "COM4916", "timestamp": "2018-09-22T15:50:45Z", "text": "Holy crap changing my extension name to \"AREPL for python\" moved it to the *third* position in the search rankings when searching for python.  Thanks for the tip @eamodio and @gaurav42  !", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4918", "user": "pkuma-msft", "root": "ROOT49", "reply_to": "COM4917", "timestamp": "2018-09-26T07:42:24Z", "text": "@Almenon Sorry we are still in early exploration stages, cannot comment on a timeline yet.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4919", "user": "joaomoreno", "root": "ROOT49", "reply_to": "COM4918", "timestamp": "2019-01-04T07:52:29Z", "text": "From @octref \r\n\r\n> Previously: https://github.com/Microsoft/vscode/issues/24511\r\n> \r\n> Now if you search for Vue, Vetur doesn't even show up in the first page despite being the most popular Vue extension. The install count of the 24 Vue extensions in first page combined is not even half of Vetur's install count.\r\n> \r\n> ![image](https://user-images.githubusercontent.com/4033249/50652857-a6a81b00-0f3c-11e9-95e2-e2838082acfc.png)\r\n> \r\n> A new Vue user coming to VS Code have a hard time finding Vetur by organic search. He might be misled to install a lot of the random extensions in Marketplace and believe VS Code has poor support for Vue files.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4920", "user": "octref", "root": "ROOT49", "reply_to": "COM4919", "timestamp": "2019-01-04T19:02:08Z", "text": "~~@kesane-msft~~\r\n\r\n~~Which~~\r\n\r\nOops, misclick.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4921", "user": "octref", "root": "ROOT49", "reply_to": "COM4920", "timestamp": "2019-01-04T19:10:53Z", "text": "> our search algorithm gives more weightage to matches in the extension's display name. If you add the \"vue\" term in your display name your extension would start showing as the top result.\r\n\r\n@kesane-msft Which I would refuse. What do I call it? `Vetur Vue`?\r\n\r\nAnother example: Searching for \"Golang\"\r\n\r\n![image](https://user-images.githubusercontent.com/4033249/50705744-a2e5c880-1010-11e9-941e-5a1d68cc6848.png)\r\n\r\nWhat should [Go extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode.Go) do? Renaming it to Golang? After which the query `Go` wouldn't return it as top result?\r\n\r\nMaybe it's better to start a community curation of good extensions for each language/framework. http://howistart.org/ is a good example. At least it wouldn't be impossible for new users to find which extension to use, because the search results are not ranked helpfully.\r\n", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM4922", "user": "eamodio", "root": "ROOT49", "reply_to": "COM4921", "timestamp": "2019-01-04T19:24:19Z", "text": "Maybe there could be a keyword (maybe the first one?), that is ranked as if it was part of the title. So that way GitLens could have _git_, Vetur could have _vue_, Go could have _golang_, etc.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4923", "user": "octref", "root": "ROOT49", "reply_to": "COM4922", "timestamp": "2019-01-04T19:28:11Z", "text": "@eamodio Already did that, just need marketplace to index the `keywords` in package.json:\r\n\r\n![image](https://user-images.githubusercontent.com/4033249/50706819-cc542380-1013-11e9-8786-e286bb014c2a.png)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4924", "user": "eamodio", "root": "ROOT49", "reply_to": "COM4923", "timestamp": "2019-01-04T19:29:36Z", "text": "@octref yup, exactly", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4925", "user": "fabiospampinato", "root": "ROOT49", "reply_to": "COM4924", "timestamp": "2019-01-04T19:36:24Z", "text": "> Maybe there could be a keyword (maybe the first one?), that is ranked as if it was part of the title. So that way GitLens could have git, Vetur could have vue, Go could have golang, etc.\r\n\r\nThis sounds too specific to me, IMHO the solution is transitioning from full-text search to a real search engine. Readmes, titles, descriptions and keywords should be properly indexed and the search query should be properly parsed too. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4926", "user": "eamodio", "root": "ROOT49", "reply_to": "COM4925", "timestamp": "2019-01-04T20:42:34Z", "text": "@fabiospampinato While I don't disagree -- I was just trying to offer an alternative that would hopefully be easy to implement but improves things somewhat and therefore likely to happen \ud83d\ude09 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4927", "user": "bardware", "root": "ROOT49", "reply_to": "COM4926", "timestamp": "2019-02-27T21:07:26Z", "text": "Just wanted to open this as an issue. I often read `search for [xxx] and install the first result`.\r\nI search the exact name of an extension and the one I'm looking for never is the first result :(\r\n\r\n![image](https://user-images.githubusercontent.com/802702/53523036-073a7b00-3adc-11e9-8000-2b2b802ba1e5.png)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4928", "user": "jeff-hykin", "root": "ROOT49", "reply_to": "COM4927", "timestamp": "2019-03-31T10:31:42Z", "text": "I can confirm this is still a bad issue. \r\n### This isn't a 'bad' search algorithm, something is broken here.\r\n\r\nWhen searching for \"line endings\" (picture below)<br>\r\nThe following 4 circles are all similar extensions. The red circles have MORE downloads, installs, and better ratings, and I checked the `package.json` all of them have \"line endings\" in the title and as keywords.<br>\r\n\r\nHow can 'Line Note' (4th result) which\r\n- doesn't have 'endings' in the title\r\n- has 203 downloads\r\n- no reviews\r\n- doesn't even have 'endings' in the package.json or readme \r\n\r\nBeat out both 'line-endings' and 'code-eol (2019) Line Endings'\r\n- both contain the full search term in the title\r\n- they have 4K and 6K downloads respectively\r\n- they have 4 stars and 5 stars respectively\r\n-  and have 'line endings', 'line', 'endings' in the keywords of the package.json and readme\r\n\r\nAnd it's not like 'Line Note' is some anomaly, there are 25 just as bad results that come before the relevant one. \r\n\r\n<img width=\"1221\" alt=\"Screen Shot 2019-03-31 at 5 02 32 AM\" src=\"https://user-images.githubusercontent.com/17692058/55287759-c059d280-5372-11e9-8c99-21549a98d33f.png\">", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM4929", "user": "jeff-hykin", "root": "ROOT49", "reply_to": "COM4928", "timestamp": "2019-03-31T10:39:16Z", "text": "My only theory to how these are being ranked, is that the marketplace has grabbed 200 results and accidentally sorted them by trending-ness instead of search-query relevance.\r\n\r\nSince this is an upstream problem, is there a more direct repo we can reach out to? @auchenberg. \r\n\r\nIf not then I agree with @octref, its been 2 months, it's probably time for the community to start building their own solution. I don't understand how something this critical can fail without tests catching it and a rollback being issued.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT50", "user": "fasterfish", "root": "ROOT50", "reply_to": null, "timestamp": "2017-03-16T18:09:31Z", "text": "Using include asynchronously with with_items <!---\r Verify first that your issue/request is not already reported on GitHub.\r Also test if the latest release, and master branch are affected too.\r -->\r \r ##### ISSUE TYPE\r <!--- Pick one below and delete the rest: -->\r  - Feature Idea\r \r ##### COMPONENT NAME\r <!--- Name of the module/plugin/task/feature -->\r i don't know\r \r ##### ANSIBLE VERSION\r <!--- Paste verbatim output from \u201cansible --version\u201d between quotes below -->\r ```\r 2.2.1.0\r ```\r \r ##### CONFIGURATION\r <!---\r Mention any settings you have changed/added/removed in ansible.cfg\r (or using the ANSIBLE_* environment variables).\r -->\r \r \r ##### OS / ENVIRONMENT\r <!---\r Mention the OS you are running Ansible from, and the OS you are\r managing, or say \u201cN/A\u201d for anything that is not platform-specific.\r -->\r Ubuntu 14.0.4 amd64\r \r ##### SUMMARY\r <!--- Explain the problem briefly -->\r \r ##### STEPS TO REPRODUCE\r <!---\r For bugs, show exactly how to reproduce the problem, using a minimal test-case.\r For new features, show how the feature would be used.\r -->\r I want to play the task list asynchronously for several group vars.\r \r <!--- Paste example playbooks or commands between quotes below -->\r ```yaml\r tasks:\r - include: sync.yml\r   async: 1000\r   poll: 0\r   with_items: \"{{groups['groupname']}}\"\r   loop_control:\r     loop_var: variable\r ```\r \r <!--- You can also paste gist.github.com links for larger files -->\r \r ##### EXPECTED RESULTS\r <!--- What did you expect to happen when running the steps above? -->\r The task list executed asynchronously.\r \r ##### ACTUAL RESULTS\r <!--- What actually happened? If possible run with extra verbosity (-vvvv) -->\r The task list is executed in sequence for each variable.\r ", "meta": {"posReactions": "48", "negReactions": "0"}}
{"id": "COM500", "user": "krzysztof-magosa", "root": "ROOT50", "reply_to": "ROOT50", "timestamp": "2017-03-17T17:13:43Z", "text": "If i'm correct async makes entire task and not each item asynchronous.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM501", "user": "bcoca", "root": "ROOT50", "reply_to": "COM500", "timestamp": "2017-03-17T20:11:28Z", "text": "include is not an actual module, its hardcoded into the engine and as such does not fork and cannot be async.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM502", "user": "krzysztof-magosa", "root": "ROOT50", "reply_to": "COM501", "timestamp": "2017-03-17T22:39:13Z", "text": "I think it would be good idea to raise warning/error when unsupported parameter is provided.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM503", "user": "bcoca", "root": "ROOT50", "reply_to": "COM502", "timestamp": "2017-03-17T23:06:41Z", "text": "it can be inherited, we are planning on an update to make this clearer 'import vs include'", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM504", "user": "yfoelling", "root": "ROOT50", "reply_to": "COM503", "timestamp": "2018-01-03T07:34:59Z", "text": "+1\r\nI think this feature is very interesting to speed up things a bit. :-)\r\n\r\nAlso an warning/error message should be raised as mentioned before, it took some time debugging why the async has no effect on include statements.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM505", "user": "lordkret", "root": "ROOT50", "reply_to": "COM504", "timestamp": "2019-01-17T15:30:20Z", "text": "+1\r\n\r\nin most cases - especially from  re-usability perspective - there is a sequence of tasks runs against an entity. Running those in parallel will be huge gain", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM506", "user": "realhawker", "root": "ROOT50", "reply_to": "COM505", "timestamp": "2019-04-04T09:28:09Z", "text": "+1", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM507", "user": "bcoca", "root": "ROOT50", "reply_to": "COM506", "timestamp": "2019-04-04T13:30:42Z", "text": "@lordkret i think you are making some assumptions that are not true:\r\n- async does not increase paralellization\r\n-  imports/includes work by adding new tasks/hosts to the iteration, they don't run on the spot, they are a 'addition to the queue'\r\n - parallelization  is based on forks (and limited by serial)\r\n\r\nasync is about waiting for a task inline or polling for it, if polling is 0 we don't wait for its results ... but these either get ignored or require a follow up task to do async_pol. This effectively 'ends the task' from the controller's point of view even if it is still running on the target, this is kind of a 'de facto' increase in parallel tasks, but not from the perspective of the controller. \r\n\r\nIf the task is about changing the controller loop of tasks .. this HAS to be a locking (serialized) task, so even making it async, would just mean we don't wait for the result but would be LOCKED waiting for the queue being updated before we can proceed. At best 'async' include means we fire up EACH included task in async (w/o increase in forks nor parallelization) and don't wait for results (poll: 0?)  which means we won't know if the tasks succeeded or not (unless you introduce async_pol which then gets back to a limited sync to get results).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM508", "user": "nikita-b", "root": "ROOT50", "reply_to": "COM507", "timestamp": "2019-07-11T15:23:05Z", "text": "+1\r\nLooks very handy. I need it for my k8s tasks", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM509", "user": "chaitu-tk", "root": "ROOT50", "reply_to": "COM508", "timestamp": "2020-05-21T15:03:55Z", "text": "+1 most handy, esp. for intensive and time taking tasks (Eg: testing multiple Linux kernels in QEMU)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5010", "user": "viane", "root": "ROOT50", "reply_to": "COM509", "timestamp": "2020-08-03T12:57:03Z", "text": "+1 I have a perfect use case needs this feature where I need to provision X bare metal nodes for OCP and each of the them takes 45+ min to be fully up, there is no reason that I have to provision them individually in automation and wait 45 * X minutes to do next task.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5011", "user": "sivel", "root": "ROOT50", "reply_to": "COM5010", "timestamp": "2020-08-03T14:31:40Z", "text": "I've locked this to contributors for now. Adding +1 comments is too noisy. For future reference, add a reaction to the issue body, and don't comment.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5012", "user": "sivel", "root": "ROOT50", "reply_to": "COM5011", "timestamp": "2021-08-20T15:41:53Z", "text": "We've discussed this, and have agreed to not move forward with allowing this to work.  To effectively allow `async` on a `block` would only support a very narrow feature of fire and forget.  And any other use case, you would still have to put `register` on every task within, so you could reference the multiple `jid` values for the different tasks.  In which case, since you are touching every task anyway to get a useful action out of it, might as well just apply `async` to each task individually.\r\n\r\nAs such, we're going to close this.\r\n\r\nIf you have further questions please stop by IRC or the mailing list:\r\n\r\n   * IRC: #ansible on irc.libera.chat\r\n   * mailing list: https://groups.google.com/forum/#!forum/ansible-project ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT51", "user": "Felx-B", "root": "ROOT51", "reply_to": null, "timestamp": "2019-04-25T11:42:07Z", "text": "[Proposal] CSS Variables I know CSS variables has already been discussed (#26596) and I saw this reply\r https://github.com/twbs/bootstrap/issues/26596#issuecomment-403342215 \r \r So I come with a proposal which not requires heavy refactoring \r \r ## Proposal\r \r Instead of using directly native functions like `darken` or `lighten` we should use wrappers\r Ex : `try-darken`\r \r ``` scss\r @function try-darken($color, $percent) {\r \r   @if (not $enable-variables){\r     @return darken($color, $percent);\r   }\r \r   @if str_slice(\"#{$color}\", 0, 3) == \"var\" {\r     $percent-str: \"#{$percent * 100}\";\r     $percent-value: str_slice($percent-str, 0, str_length($percent-str) - 1);\r     $original: str_slice($color, 7, str_length($color) - 1);\r     $variable: --#{$original}-darken-#{$percent-value};\r     @return var($variable);\r   }\r \r   @return darken($color, $percent);\r }\r ```\r This wrapper handles the variable construction and create shades of colors.\r \r Then we need to generate all shades of variables\r ``` scss \r :root {\r   @if ($enable-variables){\r     @each $color, $value in $theme-colors-values {\r       --#{$color}: #{$value};\r       --#{$color}-yiq: #{color-yiq($value)};\r \r       @each $shade in $theme-colors-shades {\r         --#{$color}-darken-#{$shade * 100}: #{darken($value, $shade)};\r         --#{$color}-darken-#{$shade * 100}-yiq: #{color-yiq(darken($value, $shade))};\r         --#{$color}-lighten-#{$shade * 100}: #{lighten($value, $shade)};\r         --#{$color}-lighten-#{$shade * 100}-yiq: #{color-yiq(lighten($value, $shade))};\r       }\r     }\r   }\r   @else{\r     @each $color, $value in $theme-colors {\r       --#{$color}: #{$value};\r     }\r   }\r }\r ```\r This creates all necessary variables.\r As you see, this requires to list all necessary shades, and concret theme color values \r \r ``` scss \r $primary:    var(--primary) !default;\r $secondary:  var(--secondary) !default;\r $success:    var(--success) !default;\r $info:       var(--info) !default;\r $warning:    var(--warning) !default;\r $danger:     var(--danger) !default;\r $light:      var(--light) !default;\r $dark:       var(--dark) !default;\r \r $theme-colors-values: map-merge(\r   (\r     \"primary\":     $blue,\r     \"secondary\":   $gray-600,\r     \"success\":     $green,\r     \"info\":        $cyan,\r     \"warning\":     $yellow,\r     \"danger\":      $red,\r     \"light\":       $gray-100,\r     \"dark\":        $gray-800,\r   ),\r   $theme-colors-values\r );\r \r $theme-colors-shades: (7.5, 10, 12.5, 25, 35, 40) !default;\r ```\r \r With theses few tricks I managed to create all variables I needed for theme colors, and I can change it on the fly with few javascript\r \r ## Demo\r Here is a demo site with an implementation \r https://felx-b.github.io/docs/4.3/getting-started/introduction/\r You can change the primary color on fly in the nav bar\r \r ## Source\r Here are the sources\r https://github.com/Felx-B/bootstrap-css-variable\r \r ## Alternative\r If the proposal is rejected, it would worth nothing to wrap native function calls (like `darken/lighten/mix` ...) into upper functions (`try-darken`, `try-lighten` ...) so we could override these behaviors to implement CSS variable ourselves.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM510", "user": "adhayward", "root": "ROOT51", "reply_to": "ROOT51", "timestamp": "2019-04-25T12:46:35Z", "text": "While this seems useful, I can see issues supporting IE which doesn't support CSS Variables at all.\r\nBootstrap 4.X lists support for IE10+ (not sure where BS5 will go)\r\n[https://caniuse.com/#feat=css-variables](https://caniuse.com/#feat=css-variables)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM511", "user": "patrickhlauke", "root": "ROOT51", "reply_to": "COM510", "timestamp": "2019-04-25T23:37:08Z", "text": "BS5 will (last time I checked into our internal discussions) still support IE11", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM512", "user": "Felx-B", "root": "ROOT51", "reply_to": "COM511", "timestamp": "2019-04-26T06:54:42Z", "text": "This feature should not be default, this should remain optional until all supported browsers handle it.\r\n`$enable-variables` options is here to opt-in for this", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM513", "user": "MartijnCuppens", "root": "ROOT51", "reply_to": "COM512", "timestamp": "2019-04-26T09:28:59Z", "text": "This won't work in not-IE browsers:\r\n```\r\n$primary:    var(--primary) !default;\r\n$secondary:  var(--secondary) !default;\r\n$success:    var(--success) !default;\r\n$info:       var(--info) !default;\r\n$warning:    var(--warning) !default;\r\n$danger:     var(--danger) !default;\r\n$light:      var(--light) !default;\r\n$dark:       var(--dark) !default;\r\n\r\n$theme-colors-values: map-merge(\r\n  (\r\n    \"primary\":     $blue,\r\n    \"secondary\":   $gray-600,\r\n    \"success\":     $green,\r\n    \"info\":        $cyan,\r\n    \"warning\":     $yellow,\r\n    \"danger\":      $red,\r\n    \"light\":       $gray-100,\r\n    \"dark\":        $gray-800,\r\n  ),\r\n  $theme-colors-values\r\n);\r\n\r\n$theme-colors-shades: (7.5, 10, 12.5, 25, 35, 40) !default;\r\n```\r\n\r\n> `$enable-variables` options is here to opt-in for this\r\n\r\nMaybe we can find a solution for this, but I'm a bit worried we'll overcomplicate everything just to make it possible to support css variables.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM514", "user": "mdo", "root": "ROOT51", "reply_to": "COM513", "timestamp": "2019-04-26T15:30:44Z", "text": "Yeah, agreed on overcomplicating things here. Unless we move entirely to PostCSS with the build system to support it, we should continue to prioritize great Sass code.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM515", "user": "piernik", "root": "ROOT51", "reply_to": "COM514", "timestamp": "2019-04-27T09:47:05Z", "text": "@Felx-B I love Your idea. I think css variables is `must-have` in bootstrap. With that every user could change interface colors - It's great!", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM516", "user": "guledali", "root": "ROOT51", "reply_to": "COM515", "timestamp": "2019-04-28T20:24:53Z", "text": "@piernik and it\u2019s easy too, not that the current scss is difficult but this is \u201ceasier\u201d ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM517", "user": "MartijnCuppens", "root": "ROOT51", "reply_to": "COM516", "timestamp": "2019-04-29T06:38:27Z", "text": "I'm going to lock this conversation because a lot of people will ask for this while we cannot provide support due to the IE11 support. Providing a solution with functions like `try-darken` could help us out, but we'll overcomplicate our codebase too much to make this possible. Maintaining this & tackling all edge cases will slow us down.\r\n\r\nWe 'll definitely have a look at support for css variables in the future (`v6`), but for now we 'll pass on this and focus on improving & extending other Bootstrap functionality.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT52", "user": "feross", "root": "ROOT52", "reply_to": null, "timestamp": "2019-08-19T23:02:47Z", "text": "npm install funding # The experiment is over \u2013\u00a0read the [recap](https://feross.org/funding-experiment-recap/) here!\r \r Hey folks! \ud83d\udc4b\r \r I've already spoken to a few of you about this idea, but I'd like to share it with the broader community now that `standard` 14 has shipped.\r \r **Background:** I think that the current model of sustaining open source is not working and we need more experimentation. This is one such experiment.\r \r **What's the experiment?** Whenever `standard` 14 is installed, we'll display a message from a company that supports open source. The sponsorship pays directly for maintainer time. That is, writing new features, fixing bugs, answering user questions, and improving documentation.\r \r **What's the goal?** My goal with this experiment is to make `standard` healthier. If we learn that the experiment works, perhaps we can help make all open source healthier, too.\u00a0For complex reasons, companies are generally hesitant or unwilling to fund OSS directly. When it does happen, it's never enough and it never reaches packages which are transitive dependencies (i.e. packages that no one installs explicitly and therefore no one knows exists). Essentially, we have a public good which is consumed by huge numbers of users, but which almost no one pays for. Fortunately, there exists a funding model that usually works for public goods like this \u2013\u00a0ads. The goal of this experiment is to answer the question: Can we use ethical ads \u2013\u00a0ads that don't track users or collect data \u2013\u00a0to fund open source software?\r \r **What does the code do?** The code for this experiment is available here: [`feross/funding`](https://github.com/feross/funding). Essentially, it calls `console.log()` on some text. There is no tracking, data collecting, or unexpected behavior. You can look at the code to verify \u2013 indeed, this is the beauty of open source!\r \r **What will the funds be used for?** The funds raised so far ($2,000) have paid for Feross's time to [release Standard 14](https://standardjs.com/changelog.html#1400---2019-08-19) which has taken around five days. If we are able to raise additional funds, the next thing I'd like to focus on is out-of-the-box TypeScript support in StandardJS (one of the most common feature requests!) and modernizing the various text editor plugins (many of which are currently unmaintained). If others in the community are interested in taking the lead on any of these issues, I'd like to direct some funds to you.\r \r Feedback welcome!\r \r ---\r \r ## EDIT: This thread is now locked :lock:\r \r For why + next steps, [scroll to the end >>](https://github.com/standard/standard/issues/1381#issuecomment-524589455)\r \r ## EDIT: The experiment is over \u2013 Feross posted [a recap](https://feross.org/funding-experiment-recap/) on his blog", "meta": {"posReactions": "47", "negReactions": "704"}}
{"id": "COM520", "user": "billiegoose", "root": "ROOT52", "reply_to": "ROOT52", "timestamp": "2019-08-20T15:09:29Z", "text": "> Feedback welcome!\r\n\r\nI noticed the (fairly large bright bold) banner. It reminds me of the OpenCollective-style banners used by webpack / corejs.\r\n\r\n![image](https://user-images.githubusercontent.com/587740/63358843-b47aa700-c339-11e9-991a-0c9f78f51373.png)\r\n\r\nI think it's OK... I do worry that `npm install` will just become a long trail of banner ads though eventually and it won't scale. Because if _every_ npm package adds ads, the noticeability of each ad will diminish. (Interestingly, the most valuable \"realestate\" will be packages whose banner is displayed _last_, so if it becomes a literal \"race-to-the-bottom\" people might add `sleep` statements to their post-install scripts so they are displayed nearest the bottom. What a dystopian installation experience!)\r\n\r\nFun fact: `yarn` does not display the output of post-install scripts. One might say yarn has built-in ad-blocking.", "meta": {"posReactions": "232", "negReactions": "4"}}
{"id": "COM521", "user": "evantahler", "root": "ROOT52", "reply_to": "COM520", "timestamp": "2019-08-20T19:36:57Z", "text": "While I'm totally OK with this on development machines, I think this is strange behavior for staging/production/etc.  Perhaps https://github.com/feross/funding/blob/master/index.js should have a NODE_ENV check?\r\n\r\nThen again, I don't imagine `standard` is going to be installed outside of NODE_ENV={test, development} anyway... so it's probably OK!", "meta": {"posReactions": "1", "negReactions": "62"}}
{"id": "COM522", "user": "mixmix", "root": "ROOT52", "reply_to": "COM521", "timestamp": "2019-08-21T23:17:55Z", "text": "I am whole-heartedly behind this experiment.\r\nIt's not the perfect end solution, but that's not the point - it's about moving the conversation about how to build healthy relationships between our commons and companies forward.\r\n\r\nThanks for taking leadership on this @feross . ", "meta": {"posReactions": "9", "negReactions": "126"}}
{"id": "COM523", "user": "zoeyTM", "root": "ROOT52", "reply_to": "COM522", "timestamp": "2019-08-21T23:31:27Z", "text": "Admittedly, I haven't contributed an immense amount to open source code, so I realize I don't have the same perspective on this issue. That being said, I sincerely hope that this solution does not become standard. \r\n\r\nI agree wholeheartedly that this is a problem that needs a solution, and I am glad that the conversation is being pushed forward by this experiment. Advertisements in my terminal is not the solution.\r\n\r\nFor me, `yarn` or `\"standard\": \"^13.0.0\"` is going to have to be my \"standard\" until this is removed.\r\n\r\n[Fifteen Million Installs](https://en.wikipedia.org/wiki/Fifteen_Million_Merits)", "meta": {"posReactions": "161", "negReactions": "3"}}
{"id": "COM524", "user": "mhogerheijde", "root": "ROOT52", "reply_to": "COM523", "timestamp": "2019-08-22T14:51:51Z", "text": "I'm with @morgansliman, of any place I don't want to see ads, my terminal is on the top of that list.\r\n\r\nI would a low a \"buy me a coffee\"-link, but that's about it.\r\n\r\nOn another note: For me, it was totally not clear that this ad was for a company that donates to `standard`. So it took me a while to figure out where this ad came from. So I'm not sure what the ad should convey, but I don't think it is the feeling \"what is this and how do I get rid of it?\".", "meta": {"posReactions": "89", "negReactions": "0"}}
{"id": "COM525", "user": "ckipp01", "root": "ROOT52", "reply_to": "COM524", "timestamp": "2019-08-22T16:02:01Z", "text": "First off, I love standard and use it in all my JS projects. Thank you so much for your hard work in making a fantastic, easy-to-use, and solid linter.\r\n\r\nI was really taken off guard seeing this in my terminal today. It's the last place I expect to see an ad, and really the last place I want to. While I get the idea behind it, and I agree that we must think of innovative ways to support open-source, relying on displaying an ad in a place that typically doesn't have them opens up the doors to new behavior of ad spamming when I simply want to install a dependency.\r\n\r\nI'm not saying this is the case here, but let's say that this really frustrates a percentage of developers and they decide to no longer use the project/tool/library, but the project does see an uptick in sponsorship. More than likely they'd see that as a win, and this could slowly shift the focus from a community-driven project to a sponsorship-driven project (and not as in individual sponsors, but company sponsorship). Again, I'm not saying this is the case here, but you can sort of see how that could happen if this becomes a normal practice in how we try to support open-source projects.\r\n\r\nI'd much rather see an innovative solution that tries to encourage individual community members to give more to projects they want to support rather than relying on sponsorship ads.\r\n\r\nFinally, I also agree with @mhogerheijde, when I first saw this I was confused, and my initial thought was to immediately find the package and to remove it since it wasn't clear at all where this was coming from or why an ad was in my terminal.\r\n\r\nEDIT: spelling\r\n\r\n", "meta": {"posReactions": "29", "negReactions": "0"}}
{"id": "COM526", "user": "mixmix", "root": "ROOT52", "reply_to": "COM525", "timestamp": "2019-08-22T20:00:33Z", "text": "Great point that it could be more clear why the ads there, and specifically\nthat it's making the tools you love maintainable.\n\nI think if you're not into it, then the obligation is in you to put some\nwork in to come up with more aligned solutions.\n\nEnthusiastic verbal support does not help maintainers thrive.\n\nAt the moment many of them are generously giving and experience a few\nbreadcrumbs of thanks in return.\n\nI want to live in a world where maintainers have enough to pay rent, eat\nfood, have health care, save money, dream about big future projects.\n\n\n\nOn Fri, 23 Aug 2019, 04:02 Chris, <notifications@github.com> wrote:\n\n> First off, I love standard and use it in all my JS projects. Thank you so\n> much for your hard work in making a fantastic, easy-to-use, and solid\n> linter.\n>\n> I was really taken off guard seeing this in my terminal today. It's the\n> last place I expect to see an add, and really the last place I want to.\n> While I get the idea behind it, and I agree that we must think of\n> innovative ways to support open-source, relying on displaying an add in a\n> place that typically doesn't have them opens up the doors to new behavior\n> of add spamming when I simply want to install a dependency.\n>\n> I'm not saying this is the case here, but let's say that this really\n> frustrates a percentage of developers and they decide to no longer use the\n> project/tool/library, but the project does see an uptick in sponsorship.\n> More than likely they'd see that as a win, and this could slowly shift the\n> focus from a community-driven project to a sponsor-driven project. Again,\n> I'm not saying this is the case here, but you can sort of see how that\n> could happen if this becomes a normal practice in how we try to support\n> open-source projects.\n>\n> I'd much rather see an innovative solution that tries to encourage\n> individual community members to give more to projects they want to support\n> rather than relying on sponsorship adds.\n>\n> Finally, I also agree with @mhogerheijde <https://github.com/mhogerheijde>,\n> when I first saw this I was confused, and my initial thought was to\n> immediately find the package and to remove it since it wasn't clear at all\n> where this was coming from or why an add was in my terminal.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/standard/standard/issues/1381?email_source=notifications&email_token=AAUK3HVSVRIKOQRBTT2VO2TQF22BFA5CNFSM4INH7WL2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD45SDTI#issuecomment-523968973>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAUK3HTGZ2JHVTQG6C4XLADQF22BFANCNFSM4INH7WLQ>\n> .\n>\n", "meta": {"posReactions": "6", "negReactions": "65"}}
{"id": "COM527", "user": "mhogerheijde", "root": "ROOT52", "reply_to": "COM526", "timestamp": "2019-08-23T07:20:08Z", "text": "This isn't about having our cake and eating it too. Selling ad-space is not innovative. And it's particularly unhelpful in my logs.\r\n\r\nI don't fully agree with @ckipp01 on the sponsorship driven OSS. It is a risk, but it already exists outside of selling ad-space in logs.\r\n\r\nFor me, the issue is more that I don't want stuff that doesn't help me in my logs. I wholeheartedly agree with putting your \"supported by company X\" in the readme. That helps me understand, it does resonate with me when I see certain companies donating money to OSS.\r\n\r\nBy the way, just stating that \"if you don't like it, come up with a better solution\" is a cop-out. There _is_ value in feedback, _especially_ when you don't agree.\r\n\r\nEDIT: PS: I too want to live in a perfect world where every developer can live, pay rent and only work on projects they like. That perfect world for me does not include ads in my terminal.\r\n\r\nEDIT2: PPS: Support of my peers for me is a _big_ reason to work on stuff. I know others that earn enough in their day-job that they enthusiastically spend time on OSS in their free time as a hobby and get value out of verbal support from their peers. That support is more often than not shown in a verbal/written way.", "meta": {"posReactions": "80", "negReactions": "0"}}
{"id": "COM528", "user": "vweevers", "root": "ROOT52", "reply_to": "COM527", "timestamp": "2019-08-23T08:21:40Z", "text": "> By the way, just stating that \"if you don't like it, come up with a better solution\" is a cop-out.\r\n\r\nFact of the matter is, OSS maintainers need money _today_. Better solutions may come along; putting up with ads in the mean time is a small price to pay. While I don't particularly like seeing ads in this space, I understand its necessity and fully support it.\r\n\r\nI do agree that:\r\n\r\n> it could be more clear why the ads there, and specifically that it's making the tools you love maintainable.", "meta": {"posReactions": "12", "negReactions": "66"}}
{"id": "COM529", "user": "ArcanisCz", "root": "ROOT52", "reply_to": "COM528", "timestamp": "2019-08-23T09:12:25Z", "text": "That reminds me of the article https://www.theatlantic.com/technology/archive/2014/08/advertising-is-the-internets-original-sin/376041/ . Basically, our hated ads-driven business model of internet (google, facebook, ...) was forced to original publishers by people.... (posting it as a slight OT because when people dont know history, they tend to make same mistakes and desicisons)", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM5210", "user": "brodybits", "root": "ROOT52", "reply_to": "COM529", "timestamp": "2019-08-23T09:32:02Z", "text": "Hi @feross, I would favor advertisements for services that you would be willing to offer, either personally or from a company that you own and run.", "meta": {"posReactions": "3", "negReactions": "11"}}
{"id": "COM5211", "user": "mhogerheijde", "root": "ROOT52", "reply_to": "COM5210", "timestamp": "2019-08-23T09:37:30Z", "text": "@vweevers Nobody is denying that money needs to flow to OSS maintainers. I don't mind putting up with ads _anywhere else_ than in the logs of my build. There is plenty of space in things like README's and landing pages for links to sponsors and patreon(-like) solutions. Logs for me are a way of doing my job. I will (try to) weed out anything that negatively impacts my ability to do work.\r\n\r\nAlso, consider the effect that letting people know that you've got sponsoring can diminish the amount of support you get from your peers, as Matthias Wandel points out in one of his videos: https://www.youtube.com/watch?v=SToyIb9tNiY\r\n\r\n@ArcanisCz interesting read!\r\n\r\n@brodybits you mean you prefer ads for services from @feross over 3rd party ads? I agree, I probably wouldn't make this much a fuss if the advertisement was a single line with a link to buy them a cup of coffee or a side-project.", "meta": {"posReactions": "38", "negReactions": "0"}}
{"id": "COM5212", "user": "brodybits", "root": "ROOT52", "reply_to": "COM5211", "timestamp": "2019-08-23T10:03:29Z", "text": "> @brodybits you mean you prefer ads for services from @feross over 3rd party ads?\r\n\r\nYes.", "meta": {"posReactions": "0", "negReactions": "3"}}
{"id": "COM5213", "user": "arcanis", "root": "ROOT52", "reply_to": "COM5212", "timestamp": "2019-08-23T11:14:28Z", "text": "As maintainer of Yarn I'm strongly against this pattern, although not for the reasons you might think. **Post-install scripts deoptimize packages and break workflows.**\r\n\r\nWhen a package has postinstall scripts, we (package managers) cannot assume anymore that it's safe to share its directory between projects. Even worse, we must extract it on the disk (in case there's a build step) even if it's actually completely unnecessary (because you only print things). We've been exploring a lot of optimisations in this space lately (Yarn 2 will keep your packages within their archives by default), and this kind of pattern will prevent your users from exploiting them to full benefits.\r\n\r\n*(Note that I'm not saying the postinstall scripts are deprecated - just that they should be reserved to the use case they were designed for, which is building a package against a local environment)*\r\n\r\nFwiw, as is mentioned somewhere in this thread, Yarn already doesn't print the build logs unless they make the installs crash, so this post-install script wouldn't have any visible effect for our users. Still, I value the health of the ecosystem a lot, both from the point of view of maintainers and users, and I would be happy to discuss how we could satisfy this use case in a more integrated and less intrusive way (for example by adding a specific field to the `package.json`). I've actually opened [an issue](https://github.com/opencollective/opencollective/issues/1625) against the OpenCollective repo to discuss that, but it got no traction until now.", "meta": {"posReactions": "110", "negReactions": "0"}}
{"id": "COM5214", "user": "tommck", "root": "ROOT52", "reply_to": "COM5213", "timestamp": "2019-08-23T12:07:57Z", "text": "I agree with a bunch of folks here that the goal here is great, but I already have enough trouble getting devs to pay attention to warnings like \"unmet peer dependencies\" when an npm install is finished. Having screens of ads go by makes it impossible to see them.\r\n('core-js' comes to mind begging for money AND a job for the lead dev)\r\n\r\n[Update: spelling]", "meta": {"posReactions": "38", "negReactions": "0"}}
{"id": "COM5215", "user": "CalinLeafshade", "root": "ROOT52", "reply_to": "COM5214", "timestamp": "2019-08-23T12:21:15Z", "text": "Companies should sponsor OSS projects because they use them. Not to get ads in front of the project's users.\r\n\r\nAlso, this kind of thing is easily blocked so it's unlikely to be a good revenue stream anyway.", "meta": {"posReactions": "56", "negReactions": "0"}}
{"id": "COM5216", "user": "ljosberinn", "root": "ROOT52", "reply_to": "COM5215", "timestamp": "2019-08-23T14:13:21Z", "text": "I'm all for (better) compensation of OSS developers but I will go lengths to avoid ads, just any ads in general. Ads are a toxic pest in modern days, wherever you go you're slammed with them. The console is not intended for this either.\n\nIf this means I have to change a dependency or library to not have ads, I will do it, not because you don't deserve money, but because you're intruding an area you're not supposed to intrude by design. \n\n_Edited a word. _ ", "meta": {"posReactions": "40", "negReactions": "0"}}
{"id": "COM5217", "user": "bunchopunch", "root": "ROOT52", "reply_to": "COM5216", "timestamp": "2019-08-23T14:13:56Z", "text": "If a company is advertising in my terminal, even if they're technically sponsoring a project as means to do so, I will do everything I can to avoid that company. Whether or not they know it, I'm pretty sure this is the exact opposite of the sort of publicity these sponsors would want among developers.", "meta": {"posReactions": "103", "negReactions": "1"}}
{"id": "COM5218", "user": "Vpet95", "root": "ROOT52", "reply_to": "COM5217", "timestamp": "2019-08-23T14:24:11Z", "text": "My terminal is the one last stronghold, the one last haven of peace that doesn't endlessly serve me ads from corporate overlords all day long. I vehemently oppose this idea as I believe it is fundamentally opposed to the open source ethos we've built up over decades. \r\n\r\nYes, it's important to help out open source contributors and project owners - but ads are not the solution. ", "meta": {"posReactions": "73", "negReactions": "0"}}
{"id": "COM5219", "user": "brodybits", "root": "ROOT52", "reply_to": "COM5218", "timestamp": "2019-08-23T16:19:15Z", "text": "-1 for that kind of non-permissive licensing, it does not even seem to fit the definition of \"open source\" ref:\r\n* https://opensource.org/osd#persons-or-groups\r\n* https://opensource.org/osd#fields-of-endeavor\r\n\r\n+1 for offer of services from the primary author, which is sometimes needed to help with open-source sustainability\r\n\r\n-1 for promotion of third-party products or services (noisy, distracting, etc.)", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM5220", "user": "lightswitch05", "root": "ROOT52", "reply_to": "COM5219", "timestamp": "2019-08-23T18:44:26Z", "text": "The package maintainers are welcome to do as they see fit. However, I would like a way to opt-out entirely from this package ever being install into my system. As far as I can tell, that is not possible with NPM.\r\n\r\nhttps://npm.community/t/blacklist-entire-packages/9659", "meta": {"posReactions": "29", "negReactions": "0"}}
{"id": "COM5221", "user": "FirstWhack", "root": "ROOT52", "reply_to": "COM5220", "timestamp": "2019-08-23T18:59:55Z", "text": "This does 2 things, 1 is objectively bad and one is subjective.\r\n\r\n1. Encourages users to run with `--silent` as an adblocker \r\n    - Bad because it means users won't see critical errors, security warnings etc\r\n    - If we can agree it's bad to encourage users to ignore key warnings, we inherently agree that polluting the output of `install` is bad _for the exact same reason_.\r\n2. It's the most annoying thing you could possibly do as a package maintainer other than remove your package.\r\n\r\nRegardless, NPM will undoubtedly decide to block any method of serving advertisements through the terminal. It doesn't matter what Standard chooses to do.", "meta": {"posReactions": "32", "negReactions": "0"}}
{"id": "COM5222", "user": "mzzfederico", "root": "ROOT52", "reply_to": "COM5221", "timestamp": "2019-08-23T19:40:55Z", "text": "If it will change the name of this project to something sensible, I will greet them with open arms ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5223", "user": "kinow", "root": "ROOT52", "reply_to": "COM5222", "timestamp": "2019-08-24T12:28:15Z", "text": "Dang it. Just enabled it the other week, already going to have to raise another PR to remove from the project now :disappointed: ", "meta": {"posReactions": "15", "negReactions": "0"}}
{"id": "COM5224", "user": "steve-perkins", "root": "ROOT52", "reply_to": "COM5223", "timestamp": "2019-08-24T12:37:33Z", "text": "Given that this package is essentially a config file and thin wrapper script for ESLint, I am curious how much of this revenue will be shared with the upstream ESLint developers.", "meta": {"posReactions": "135", "negReactions": "0"}}
{"id": "COM5225", "user": "osmarks", "root": "ROOT52", "reply_to": "COM5224", "timestamp": "2019-08-24T13:08:04Z", "text": "We are going to need adblockers for `npm install` output now...\r\n\r\nNow I'm actually wondering how that might work... maybe just blocking specific packages' postinstall scripts would do it. For now. It's not like there's some easy way to detect sponsored messages.", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM5226", "user": "rubyFeedback", "root": "ROOT52", "reply_to": "COM5225", "timestamp": "2019-08-24T13:17:58Z", "text": "This is a very bad idea. It violates the user's right to privacy and choice.\r\n\r\nI even go farther and say that it is abuse by upstream developers (does not matter WHO these developers are; feross could be replaced by any other developer who wants to abuse users).\r\n\r\nIf the goal is to seek financing, it would be better to request donations etc...\r\n\r\nNote that some users may be ok with ads, but it is NOT ok to NOT ask users whether they are fine with that. Because many are NOT fine with targeted ads.", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM5227", "user": "chriscarver", "root": "ROOT52", "reply_to": "COM5226", "timestamp": "2019-08-24T13:18:58Z", "text": "How can you be so smart and stupid at the same time. This idea is horrible.", "meta": {"posReactions": "21", "negReactions": "8"}}
{"id": "COM5228", "user": "osmarks", "root": "ROOT52", "reply_to": "COM5227", "timestamp": "2019-08-24T13:21:04Z", "text": "> Because many are NOT fine with targeted ads.\r\n\r\nIn fairness, this appears to not actually be very targeted - it's just a postinstall script in the `funding` package.\r\n\r\n", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM5229", "user": "NuroDev", "root": "ROOT52", "reply_to": "COM5228", "timestamp": "2019-08-24T13:49:49Z", "text": "I do love OSS and all the amazing open source projects available \u2764\ufe0f and I do very much understand that funding is required now for many projects and services such as Open Collective and/or GitHub Sponsors either don't work for their needs or don't meet their funding needs.\r\nHowever, my fear is that this `experiment` will result in many more OSS projects picking it up and lead to a future where CI build logs are full of banner ads and then potentially lead to other worse advertising means.\r\nThe user `u/crabbytag` [put it best](https://www.reddit.com/r/programming/comments/cus0zu/a_3mil_downloads_per_month_javascript_library/exy73hc?utm_source=share&utm_medium=web2x) for me and my concerns for what this could start in the future.\r\n\r\n> This reminds me of the early years of the web when websites were looking for funding. At that time, adding a banner or two brought in revenue. People were clicking out of sheer novelty effect. But as it became more widespread, people started ignoring it. Then websites had to resort to more aggressive ads - animated banners, pop-ups, pop-unders. When those started getting blocked, they moved to advanced tracking.\r\nThe maintainer is getting $2000 for these banners because no one else is displaying ads there. Once other library authors notice this opportunity, they'll start adding ads too. Then the average payout comes down. But since we've already accepted ads here, some authors will include more annoying ads for slightly more money. For example, 2x the payout if the developer is required to take some action ('press enter to unpause the build) and 3x if the action is more annoying ('type out \"Linode rocks\" to unpause the build).\r\n\r\nThat's just me of course but I feel like this is not the correct direction to go towards in helping to fund open source projects and we need to continue looking for another alternative.", "meta": {"posReactions": "14", "negReactions": "0"}}
{"id": "ROOT53", "user": "filmgirl", "root": "ROOT53", "reply_to": null, "timestamp": "2020-11-30T09:56:16Z", "text": "Add Stories to Windows Terminal  <!-- \r \ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\r \r I ACKNOWLEDGE THE FOLLOWING BEFORE PROCEEDING:\r 1. If I delete this entire template and go my own path, the core team may close my issue without further explanation or engagement.\r 2. If I list multiple bugs/concerns in this one issue, the core team may close my issue without further explanation or engagement.\r 3. If I write an issue that has many duplicates, the core team may close my issue without further explanation or engagement (and without necessarily spending time to find the exact duplicate ID number).\r 4. If I leave the title incomplete when filing the issue, the core team may close my issue without further explanation or engagement.\r 5. If I file something completely blank in the body, the core team may close my issue without further explanation or engagement.\r \r All good? Then proceed!\r -->\r \r # Add a \u201cStories\u201d Feature to Windows Terminal\r Stories are the new hotness. Snapchat invented Stories but the paradigm of ephemeral updates has since been adopted by Instagram, WhatsApp, Facebook, LinkedIn, Twitter, and most recently, Spotify. There is even a VS Code extension that adds this feature. \r \r Why should LinkedIn get all the fun?! Windows Terminal might be a singular experience (but with user profiles, is it really), but that doesn\u2019t mean we shouldn\u2019t create an ephemeral social layer into it. \r \r Windows Terminal \u201cStories\u201d could be in gist form (a la GitHub) or scripts in your favorite shell language (PWSH or BASH or ZSH, in da clurb we all fam), they could also be print screens of your current terminal session. Because who doesn\u2019t want to show off their latest Neofetch/winfetch ASCII art! \r \r As a longterm goal, there could even be a way to share a gist/link to your config file to share your specific terminal preferences and font/color information. \r \r # Proposed technical implementation details (optional)\r In order to see Stories from others (assuming we don\u2019t want to focus just on local users), we would need to run some sort of web server that ties into some type of social network for followers/displays. GitHub would probably be ideal for that. \r \r Having said all this, as good of a feature as I believe Stories would be, it would probably require a lot of resources and overhead, not to mention possible performance concerns. Perhaps this is a better request for Hyper, since it is Electron and basically running a web browser anyway. (No shade to Hyper \u2014 Hyper is great and beautiful and I\u2019m just teasing out of love!)\r \r In fact, the more I write about this. Maybe it\u2019s a bad idea. \r ", "meta": {"posReactions": "139", "negReactions": "41"}}
{"id": "COM530", "user": "estruyf", "root": "ROOT53", "reply_to": "ROOT53", "timestamp": "2020-11-30T09:57:45Z", "text": "You got my support on this @filmgirl. +1", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM531", "user": "LuiseFreese", "root": "ROOT53", "reply_to": "COM530", "timestamp": "2020-11-30T10:00:34Z", "text": "rooting for you @filmgirl \ud83c\udf89", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM532", "user": "girlgerms", "root": "ROOT53", "reply_to": "COM531", "timestamp": "2020-11-30T10:03:33Z", "text": "11/10, want to see this happen! \ud83d\udc9c", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM533", "user": "pandom", "root": "ROOT53", "reply_to": "COM532", "timestamp": "2020-11-30T10:05:41Z", "text": "Knowing that this is possible my life will not be the same without it", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM534", "user": "GossiTheDog", "root": "ROOT53", "reply_to": "COM533", "timestamp": "2020-11-30T10:09:26Z", "text": "We need this. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM535", "user": "Lazza", "root": "ROOT53", "reply_to": "COM534", "timestamp": "2020-11-30T10:46:04Z", "text": "I guess probably something could be hacked together with Cowsay and Fortune. This would get closer to feature parity with a real Linux machine. \ud83d\ude0f", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM536", "user": "mvandemar", "root": "ROOT53", "reply_to": "COM535", "timestamp": "2020-11-30T11:11:45Z", "text": "I can't believe it hasn't already been implemented, this is a must have feature.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM537", "user": "okms", "root": "ROOT53", "reply_to": "COM536", "timestamp": "2020-11-30T11:18:29Z", "text": "This needs a kickstarter campaign ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM538", "user": "ghost", "root": "ROOT53", "reply_to": "COM537", "timestamp": "2020-11-30T11:19:28Z", "text": "Can this be integrated with #469?", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM539", "user": "leo60228", "root": "ROOT53", "reply_to": "COM538", "timestamp": "2020-11-30T12:07:20Z", "text": "> most recently, Twitter\r\n\r\nI think Spotify was more recent", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5310", "user": "filmgirl", "root": "ROOT53", "reply_to": "COM539", "timestamp": "2020-11-30T12:08:04Z", "text": "> > most recently, Twitter\r\n> \r\n> I think Spotify was more recent\r\n\r\nRight you are! I\u2019ve updated the issue accordingly. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5311", "user": "ghost", "root": "ROOT53", "reply_to": "COM5310", "timestamp": "2020-11-30T12:21:11Z", "text": "I haven't seen any feature request in this repo having this much reactions (and upvotes) in such short amount of time. \ud83e\udd2f ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5312", "user": "snickler", "root": "ROOT53", "reply_to": "COM5311", "timestamp": "2020-11-30T12:34:24Z", "text": "This has my full support \\o/", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5313", "user": "kylesethgray", "root": "ROOT53", "reply_to": "COM5312", "timestamp": "2020-11-30T12:35:21Z", "text": "I would love to see this happen. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5314", "user": "giggio", "root": "ROOT53", "reply_to": "COM5313", "timestamp": "2020-11-30T12:38:58Z", "text": "How have I been using Terminal without this feature for so long? I'm using plain old terminal until we have it! ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM5315", "user": "Don-Vito", "root": "ROOT53", "reply_to": "COM5314", "timestamp": "2020-11-30T12:51:38Z", "text": "Wondering if Terminal users are mentally prepared to such amount of social activity in their lives.. switching from 0 social life to this directly might be... overwhelming \ud83d\ude04", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5316", "user": "ghost", "root": "ROOT53", "reply_to": "COM5315", "timestamp": "2020-11-30T12:59:39Z", "text": "> Wondering if Terminal users are mentally prepared to such amount of social activity in their lives.. switching from 0 social life to this directly might be... overwhelming \ud83d\ude04\r\n\r\n@Don-Vito Are you talking about me? \ud83d\ude04 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5317", "user": "Don-Vito", "root": "ROOT53", "reply_to": "COM5316", "timestamp": "2020-11-30T13:17:52Z", "text": "> \r\n> \r\n> > Wondering if Terminal users are mentally prepared to such amount of social activity in their lives.. switching from 0 social life to this directly might be... overwhelming \ud83d\ude04\r\n> \r\n> @Don-Vito Are you talking about me? \ud83d\ude04\r\n\r\nAbout myself actually \ud83d\ude04 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5318", "user": "suadev", "root": "ROOT53", "reply_to": "COM5317", "timestamp": "2020-11-30T13:52:23Z", "text": "Doesn't it look cool?   https://twitter.com/kose__suat/status/1329514405818732545", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5319", "user": "zadjii-msft", "root": "ROOT53", "reply_to": "COM5318", "timestamp": "2020-11-30T14:31:43Z", "text": "Well this thread was a good hilarious read to start my week. Thanks for that \ud83e\udd23 \r\n\r\nI know that this is [90% a meme post from twitter](https://twitter.com/cinnamon_msft/status/1333341760848740352), but this is also our actual work tracker, so I've gotta be at least 5% serious here:\r\n\r\nI don't believe the Terminal is the place to implement most of this. \r\n* We've already got a commandline ecosystem problem of users just executing random scripts that they download with `curl` - if we're letting users install scripts that they saw on someone's story, then i can guarantee you there'll be scripts like \"Run Graphical Applications in WSL!!!\" that actually just `rm -rf /mnt/c`. I don't want to be held responsible for contributing to that problem.\r\n* I think GitHub gists are already better suited for a lot of this - they've already got syntax highlighting for different languages, they've already got accounts set up, and authentication, and hey, they've already got a web-scale website that can host all this, and frankly I'm not prepared, nor is anyone on the team, to build that ourselves.\r\n* We've also already got #469 on the backlog for recording Terminal output to the asciinema format, for sharing on https://asciinema.org. Again, that's another site that's probably better suited for hosting recordings of terminal sessions, rather than us standing this up on our own. \r\n\r\nSo those are reasons why _I_ would reject this feature request. However, this thread is definitely @cinnamon-msft's responsibility, so I'll let them handle it.\r\n\r\n<hr>\r\n\r\nAs far as the following is concerned:\r\n>  there could even be a way to share a gist/link to your config file to share your specific terminal preferences and font/color information.\r\n\r\nI believe there's been discussion about that in the past, and that I'm on board with. \"Stories\", not so much. ", "meta": {"posReactions": "24", "negReactions": "0"}}
{"id": "COM5320", "user": "bnb", "root": "ROOT53", "reply_to": "COM5319", "timestamp": "2020-11-30T16:42:26Z", "text": "+1 this is a vital feature. pls ship @cinnamon-msft \ud83d\ude4f\ud83c\udffb ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5321", "user": "cinnamon-msft", "root": "ROOT53", "reply_to": "COM5320", "timestamp": "2020-11-30T17:42:55Z", "text": "This definitely was a fun read, but I agree with @zadjii-msft that this doesn't really make sense for Terminal. Kudos to @filmgirl for writing such an entertaining feature request, however I will have to close this issue since we aren't planning to implement it. \ud83d\ude04", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM5322", "user": "Don-Vito", "root": "ROOT53", "reply_to": "COM5321", "timestamp": "2020-11-30T19:30:42Z", "text": "On the other hand a native support for twitter could prevent us from missing the meme post:\r\n![image](https://user-images.githubusercontent.com/4639110/100654756-f8d55f00-3352-11eb-98e6-ddc9a8cedce3.png)\r\n\r\n![image](https://user-images.githubusercontent.com/4639110/100654937-3f2abe00-3353-11eb-8671-8ac3a09f75b0.png)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5323", "user": "trylaarsdam", "root": "ROOT53", "reply_to": "COM5322", "timestamp": "2020-11-30T21:45:14Z", "text": "Command + Story = Cory?", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM5324", "user": "Darth4212", "root": "ROOT53", "reply_to": "COM5323", "timestamp": "2020-11-30T21:59:31Z", "text": "No. Just no. This isn't social media this is for code ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM5325", "user": "Spriithy", "root": "ROOT53", "reply_to": "COM5324", "timestamp": "2020-11-30T22:14:09Z", "text": "@Darth4212 but is it really ?", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM5326", "user": "Supesu", "root": "ROOT53", "reply_to": "COM5325", "timestamp": "2020-11-30T22:58:43Z", "text": "@Darth4212 You use the terminal for coding?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5327", "user": "sunflsks", "root": "ROOT53", "reply_to": "COM5326", "timestamp": "2020-11-30T23:33:28Z", "text": "@Supesu Terminal? Coding? You must be insane, that is impossible! The terminal exists only for `cmatrix`\r\n\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM5328", "user": "Don-Vito", "root": "ROOT53", "reply_to": "COM5327", "timestamp": "2020-11-30T23:41:04Z", "text": "> \r\n> \r\n> @Supesu Terminal? Coding? You must be insane, that is impossible! The terminal exists only for `cmatrix`\r\n\r\n@Finermeerkat137 - you should try it. I recently switched to Terminal from VS 2019 and am really happy since then: same level of code completion and refactoring with almost twice less memory!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5329", "user": "tkore", "root": "ROOT53", "reply_to": "COM5328", "timestamp": "2020-11-30T23:54:44Z", "text": "![200 (1)](https://user-images.githubusercontent.com/4380333/100679379-3ff82b80-3324-11eb-8895-a9ec1f075fc6.gif)\r\n", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "ROOT54", "user": "FoxSamu", "root": "ROOT54", "reply_to": null, "timestamp": "2020-11-05T14:39:17Z", "text": "Add annotation-based tools for dist-based implementation of methods Today I ran into the annoying coding style issue that you have to create a complete new class just for calling a client-only method if available. Because this makes code very very ugly I created a different approach:\r \r A new `@ImplementOn` annotation can specify a method in the same class to be overwritten by another method when on a specific `Dist`. For example:\r \r ```java\r     public void myMethod() {\r \r     }\r \r     @ImplementOn(dist = Dist.CLIENT, method = \"myMethod\")\r     private void myMethod_client() {\r         System.out.println(\"Client implementation\");\r     }\r \r     @ImplementOn(dist = Dist.DEDICATED_SERVER, method = \"myMethod\")\r     private void myMethod_server() {\r         System.out.println(\"Server implementation\");\r     }\r ```\r \r Then, upon loading of this class, an ASM transformer (`net.minecraftforge.common.asm.RuntimeDistImplementor` to be precise) injects either `myMethod_client` or `myMethod_server` into the method `myMethod` and strips unused `@ImplementOn` methods so that they won't get loaded. The above example will, on `Dist.CLIENT` become:\r \r ```java\r     public void myMethod() {\r         this.myMethod_client();\r     }\r \r     @ImplementOn(dist = Dist.CLIENT, method = \"myMethod\")\r     private void myMethod_client() {\r         System.out.println(\"Client implementation\");\r     }\r ```\r \r Note how the method is directly delegated: this keeps line numbers and debug info understandable in stack traces. The system works for methods with or without return values, static and virtual methods, and any set of arguments. For `@ImplementOn` to work properly, the following conditions are checked, with the intentions specified:\r \r - The return types of the target method and the injected method must match **exactly**. This is because it finds the target method based on the name specified and the descriptor (including return type) of the injector method.\r - The argument lists of the target method and the injected method must match **exactly**. This is because it finds the target method based on the name specified and the descriptor of the injector method.\r - The `static` modifier must either be specified on both the target and injected method, or must be omitted on both methods. When one is static and the other isn't, the injection fails. This is because a static method can not reference an instance method. An instance method can access a static method but for the semantics of 'replacing the method' I forced the `static` modifiers to match exactly.\r - The injected method **must** be private. This prevents overriding which can cause strange issues as unused injected methods are stripped (subclasses might be unable to load if they call `super`). This also prevents them being called from within another class (even inner classes can't call them - this goes via a bridge method).\r - The injected method may never be called (only checked in a development environment, since it checks all instructions in a class and might drop performance a lot). This filters the cases where a method of the same class accesses the injector (including bridge methods), which must not happen either.\r - There must be, for each separate `Dist`, only one injected method: you can specify injections for the same method but for different dists. This rule is obvious: you should not inject into a method twice because you will then overwrite your own injection.\r \r Note that this works with method overloading: an `@ImplementOn` annotated method will be injected into the method with the name specified in the annotation's `method` parameter and the descriptor of the injected method. Hence this will work:\r \r ```java\r     public void myMethod() {\r         System.out.println(\"Common implementation\");\r     }\r \r     @ImplementOn(dist = Dist.CLIENT, method = \"myMethod\")\r     private void myMethod_client() {\r         System.out.println(\"Client implementation\");\r     }\r \r     public void myMethod(int argument) {\r         System.out.println(\"Common implementation, argument = \" + argument);\r     }\r \r     @ImplementOn(dist = Dist.CLIENT, method = \"myMethod\")\r     private void myMethod_client(int argument) {\r         System.out.println(\"Client implementation, argument = \" + argument);\r     }\r ```\r \r What's also notable here is that an `@ImplementOn` method is only injected when the `dist` parameter matches the `Dist` of the environment. When the `Dist`s don't match, the target method is left untouched and the injected method is stripped from the class, if the `Dist`s _do_ match, the contents of the target method are stripped **completely** and are overwritten by the necessary bytecode.\r \r ---\r \r As an alternative suggestion to the semantics I've implemented in the current pull request, it's also possible to make a `@DelegateOn` annotation which is put above the target method and using the `@OnlyIn` annotations for stripping sided methods. It would then look like this:\r \r ```java\r     @DelegateOn(client = \"myMethod_client\", server = \"myMethod_server\")\r     public void myMethod() {\r \r     }\r \r     @OnlyIn(Dist.CLIENT)\r     private void myMethod_client() {\r         System.out.println(\"Client implementation\");\r     }\r \r     @OnlyIn(Dist.DEDICATED_SERVER)\r     private void myMethod_server() {\r         System.out.println(\"Server implementation\");\r     }\r ```\r \r Drawback is here: the `myMethod_client` and `myMethod_server` render as unused and don't have an annotation indicating they are dynamically being injected, nor is there any visual reason not to call them.\r \r ---\r \r I think this is a well-working alternative to `DistExecutor.safeCallWhenOn`, since it doesn't require the targeted method to be in a separate class, it allows the use of arguments and it works with return types.\r \r ---\r \r Things that might still be necessary and which are missing now:\r \r - Checking the signatures of the methods (so that generic types and `throws` clauses do match). This is only a semantical issue though, in bytecode it's perfectly safe if a checked exception is thrown without having it in the `throws` clause and due to type erasure generics will work.", "meta": {"posReactions": "2", "negReactions": "3"}}
{"id": "COM540", "user": "diesieben07", "root": "ROOT54", "reply_to": "ROOT54", "timestamp": "2020-11-05T15:23:25Z", "text": "I don't think we should be adding more ASM based hackyness because you are too lazy to write a separate class.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM541", "user": "TheCurle", "root": "ROOT54", "reply_to": "COM540", "timestamp": "2020-11-05T15:26:53Z", "text": "I concur. Sided safe referencing is a Java pattern, and it is generally encouraged to separate code that will be used to build two different releases of the same program. In this case, client and server of a game.\r\n\r\nYour solution is no better than just using OnlyIn, which is known to break a lot of things: see #7440. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM542", "user": "FoxSamu", "root": "ROOT54", "reply_to": "COM541", "timestamp": "2020-11-05T15:42:29Z", "text": "Closed by the dictators who made `@Mod`, `@Mod.EventBusSubscriber`, `@SubscribeEvent`, `@OnlyIn`, `IExtensibleEnum`, ... neither are they java patterns in this case", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM543", "user": "TheCurle", "root": "ROOT54", "reply_to": "COM542", "timestamp": "2020-11-05T15:44:43Z", "text": "Welcome to hacking into a game that was never built to support mods. \r\nOnlyIn exists only to support vanilla, for the record.\r\nSubscribeEvent is superceded recently by DeferredRegister, and your argument is overall invalid.\r\n\r\nAlso, yes, it is a pattern. This is standard procedure...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM544", "user": "gigaherz", "root": "ROOT54", "reply_to": "COM543", "timestamp": "2020-11-05T15:53:06Z", "text": "A few things:\r\n* OnlyIn is used to mark vanilla methods that are missing, it doesn't cause them to be missing. The OnlyIn transformer is a hack, and only exists for specific exceptional situations, it's not a convenience and will never be endorsed as one.\r\n* `@Mod` and `@SubscribeEvent` are API markers, they are used to identify features, it's very much not the same as what you are proposing.\r\n* IExtensibleEnum isn't an annotation? It's a hack needed by modders.\r\n\r\nTo use client-only code correctly you just need, at most, one (1) helper class, which has some forwarders and keeps all client-only references all hidden from the shared logic. You just need to follow two simple rules:\r\n1. This helper class shouldn't have any outward references to the client-only code (no client-only extends/implement, params or fields)\r\n2. The methods in this class should avoid \"implicit casts\" (eg, assigning Minecraft#player to a PlayerEntity variable), which cause the jvm to have to classload the types so it can verify they are compatible.\r\n\r\nThat's all. One class and some basic defensive coding.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT55", "user": "ghost", "root": "ROOT55", "reply_to": null, "timestamp": "2018-01-24T17:31:36Z", "text": "Remember 5-6 months ago before C#? @reduz said on facebook something like (i'm paraphrasing here)\r \r \"C# won't really affect the core work because it's run by separate people\"\r \r Well.. look here:\r \r https://github.com/godotengine/godot/issues?utf8=%E2%9C%93&q=mono\r \r  @akien-mga and other contributors.. get your shit together. Stop shilling for $ from software conservancy ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM550", "user": "reduz", "root": "ROOT55", "reply_to": "ROOT55", "timestamp": "2018-01-24T17:37:32Z", "text": "I stand by my words, that's exactly what happened.\n\nOn Jan 24, 2018 2:33 PM, \"Poommetee Ketson\" <notifications@github.com>\nwrote:\n\n> Closed #16029 <https://github.com/godotengine/godot/issues/16029>.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/godotengine/godot/issues/16029#event-1440015379>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AF-Z2_o-xuQ4zRkhNl4QzeSrpL1ab29Uks5tN2ligaJpZM4Rroja>\n> .\n>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM551", "user": "reduz", "root": "ROOT55", "reply_to": "COM550", "timestamp": "2018-01-24T17:38:44Z", "text": "You are most likely misinterpreting the girhub list of issues.\n\nOn Jan 24, 2018 2:37 PM, \"Juan Linietsky\" <reduzio@gmail.com> wrote:\n\n> I stand by my words, that's exactly what happened.\n>\n> On Jan 24, 2018 2:33 PM, \"Poommetee Ketson\" <notifications@github.com>\n> wrote:\n>\n>> Closed #16029 <https://github.com/godotengine/godot/issues/16029>.\n>>\n>> \u2014\n>> You are receiving this because you were mentioned.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/godotengine/godot/issues/16029#event-1440015379>, or mute\n>> the thread\n>> <https://github.com/notifications/unsubscribe-auth/AF-Z2_o-xuQ4zRkhNl4QzeSrpL1ab29Uks5tN2ligaJpZM4Rroja>\n>> .\n>>\n>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM552", "user": "reduz", "root": "ROOT55", "reply_to": "COM551", "timestamp": "2018-01-24T17:46:20Z", "text": "And even if that was not the case, it's still not a problem. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM553", "user": "NathanWarden", "root": "ROOT55", "reply_to": "COM552", "timestamp": "2018-01-24T17:58:35Z", "text": "@ghost I'm certainly not the biggest contributor to Godot, but maybe 2 of my 34 contributions are related to C#. I also donate almost double my Unity subscription to Godot, I know most of that money will not be used for C# development... and I'm 100% happy with that.\r\n\r\nI've been using Unity since the 1.x days. I tried switching to Godot a couple of years ago and found it impractical to do so but am finding it pretty easy to do so now. What is finally enabling me to switch completely over to Godot? Despite it being a great engine now and also with a lot of promise in the future, the largest thing that is making the transition possible is C# :)\r\n\r\nI agree with @reduz, I think you're interpreting the issue list wrong.\r\n\r\nIt seems to me that you're assuming that:\r\n\r\n1) That no new C++ contributors are here because of C#\r\n2) That C# issues have increased, but the new contributors are unable to fix these issues, thus the core team members must pick up the slack\r\n3) The newcomers to Godot who use C# don't contribute to non-C# issues.\r\n\r\nEvery one of these points can easily be proven false and I think you'll see that the momentum of Godot is only going to increase due to C# being a standard part of the engine. :)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM554", "user": "ghost", "root": "ROOT55", "reply_to": "COM553", "timestamp": "2018-01-24T18:04:28Z", "text": "@reduz \r\n\r\nc# was the biggest mistake i've ever witnessed in godot. name me, one god damn reason why a developer would favour C# over Godot's GDScript? for the godot engine?\r\n\r\nwhat you will say is, ohh but mahh c# sharp unity users! it will help bring people from unity over!\r\nthen, on the other hand, everyone says \"we're not competing against unity!\". yeah, that's horse shit.\r\n\r\nsecond reason: \"ohhh the performance is so much better!\". oh yeah? what are the use cases to back that up? 1% of the godot users having performance issues with gdscript? i doubt it. if a developer is having a performance issue with gdscript, they'd use fucking gdnative.\r\n\r\nlook through all the **contributors** in those issues. 80% of them have participated in adding other helpful features to Godot too, not just C# stuff. this means, by nature their time is **inherently being focused** on c#.\r\n\r\noh yeah, and here's another problem with this entire \"only implement low level features\" stuff. want to tell me then, why **smiley emojis were added to the core of the engine** then? surely that's not low level is it? but when i suggest **that an inventory system** and other 2d features be added, you spit in my  face and tell me \"it's not low level!\".  meter la mula, cotoco. \r\n\r\n\r\n\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM555", "user": "reduz", "root": "ROOT55", "reply_to": "COM554", "timestamp": "2018-01-24T18:17:43Z", "text": "Whether it was a mistake or not is not decided by you, but the community as a whole. You are not the center of the universe. The community not only is happy about it, but posts about C# are by far some of the most shared and viewed. In fact, it also attracted many new developers.\r\n\r\nYou also act as if I had any control of what contributors work on. This is an open source project, contributors work on what they want, when they want. It's not a company where I pay them to work for me and they do what I order them to.\r\n\r\nThat left aside, of the main contributors (the ones writing most of the code) none changed their priorities to focus on mono instead of their usual areas.  The link you posted clearly shows that.\r\n\r\nI have no idea what you are so angry about, just chill man.", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM556", "user": "reduz", "root": "ROOT55", "reply_to": "COM555", "timestamp": "2018-01-24T18:21:53Z", "text": "Also, the only way someone can convince someone else to work on something on this project is good arguments from one side and the will to do it from the other side.\r\n\r\nNot only in this case there simply are no good arguments against implementing mono (in fact, there are only good arguments in favor of it), but also developers willing to do it. \r\n\r\nIt's unavoidable, this project has life of it's own, I am not in control of it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM557", "user": "yarwelp", "root": "ROOT55", "reply_to": "COM556", "timestamp": "2018-01-24T18:27:15Z", "text": "@ghost you come off as quite hostile.\r\n\r\nPersonally as someone that has been interested in the Godot project for quite a while, but who has never used GDScript and only used a little bit of C# I am much more inclined to use C# than GDScript because C# is a transferable skill.\r\n\r\nI think this rings true for others too.\r\n\r\nLike @reduz said, open source works by people doing what they feel like.\r\n\r\nI feel like I've seen you troll (that's what your comments amount to really) other GitHub projects also but I won't bother to check. Life is too short \ud83d\udc4b\ud83c\udffb", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM558", "user": "ghost", "root": "ROOT55", "reply_to": "COM557", "timestamp": "2018-01-24T18:43:55Z", "text": "@reduz right back at you then. since there is no \"leadership\" in this open source project, you sir, cannot claim C# is superior to gdscript then. i just gave you two god damn good reasons why gdscript > C#, and you still continue to dodge. gg faker.\r\n\r\nyou also completely dodged my point about the smiley emoji implementations. so i recommend a good feature for the engine **(inventory and other 2d stuff, that ALL GAME DEVELOPERS WILL BENEFIT FROM)**, but **you spit in my face**, claim that it's not \"low level enough\", but then go around merging PRs for \"emoji smiley\" support for fonts? that's somehow still low level though? wtf??\r\n\r\n\r\nwebsocket support still has never been implemented. are you going to pay @Faless a quarter of the $20,000 grant that mozilla gave? since he actually implemented the websocket module? or you going to say \"ahhh, software conservancy handles the funds, we don't know what to do with it!\" as you always do? then keep it for akien, you, and @karroffel? doesn't really seem fair to me.  look at it from my perspective please.\r\n\r\nin any event. complete and utter crap. but wait, @akien-mga will continue to block users, close discussions, etc. seems like i need to go make a new fucking account again for the 5th time... can't have discussions without bypassing  / cheating github it seems! so much for \"open source\".\r\n \r\n\r\n\r\n\r\n\r\n\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM559", "user": "neikeq", "root": "ROOT55", "reply_to": "COM558", "timestamp": "2018-01-24T18:58:51Z", "text": "This went out of hands. There is not a drop of constructive criticism here, only very hostile behavior and personal attacks. Locking.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT56", "user": "ghost", "root": "ROOT56", "reply_to": null, "timestamp": "2018-10-09T11:58:50Z", "text": "HTTP manipulating complete request / get raw response Hi,\r \r i need to manipulate HTTP requests before they are sent; i want no manipulate the whole request (headers, data) and i think, all this could be possible starting here at the docs: https://docs.flutter.io/flutter/package-http_http/BaseClient-class.html\r \r Is it possible? I think.\r \r But for getting **raw** response as string/byte[] to extract all needed details, where should i start? I am not sure. I want to work with the response like a normal response and i want to work besides with all headers of this response to check exactly whats in - not consumed already, only **raw response string/byte[]**\r \r Can you give me the right starting points?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM560", "user": "zoechi", "root": "ROOT56", "reply_to": "ROOT56", "timestamp": "2018-10-09T13:08:21Z", "text": "You can do in Flutter what `dart:io` can do (if not create an issue).\r\nYour issue should be filed in https://github.com/dart-lang/sdk, but better first check on StackOverflow if someone can answer your question.\r\n\r\nBeing a bit more specific what exactly package `http` or `dart:io` don't allow you to do that \"manipulating complete request\" would allow you to do, and why you think you need that, would probably help to get a good answer.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM561", "user": "ghost", "root": "ROOT56", "reply_to": "COM560", "timestamp": "2018-10-09T13:14:34Z", "text": "@zoechi whats the problem to answer this question? Thats an issue for help me writing my app. Thats a topic in your issues", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM562", "user": "ghost", "root": "ROOT56", "reply_to": "COM561", "timestamp": "2018-10-09T13:15:49Z", "text": "As you can see i am talking about your docs. So, i am not interested running around the world", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM563", "user": "ghost", "root": "ROOT56", "reply_to": "COM562", "timestamp": "2018-10-09T13:18:26Z", "text": "And there is nothing to explain on *manipulating the request*. It contains of headers and data. I want to modify it. Like thousands of tools are doing.\r\n\r\nThe same for **raw response as string/byte[]** - thats clear, too.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM564", "user": "zoechi", "root": "ROOT56", "reply_to": "COM563", "timestamp": "2018-10-09T13:29:54Z", "text": "I don't even understand what the problem is and you don't seem to be interested to explain it. \r\nEvery method to send HTTP requests allows you to set header and data. \r\nStackOverflow is the right place to ask this kind of question.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM565", "user": "ghost", "root": "ROOT56", "reply_to": "COM564", "timestamp": "2018-10-09T13:52:28Z", "text": "@zoechi LOL - you simply closed my issue - where is your interest? Because you do not know the answer about the raw response in gitter?\r\n\r\nGo home", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM566", "user": "zoechi", "root": "ROOT56", "reply_to": "COM565", "timestamp": "2018-10-09T13:56:59Z", "text": "Because this is not the right place for your question.\r\nI tried to point you in the right direction as far as the information you provided allowed.\r\n\r\nPlease also check https://flutter.io/design-principles/#code-of-conduct\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT57", "user": "ghost", "root": "ROOT57", "reply_to": null, "timestamp": "2019-11-15T11:57:41Z", "text": "Fix typo ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM570", "user": "googlebot", "root": "ROOT57", "reply_to": "ROOT57", "timestamp": "2019-11-15T11:57:52Z", "text": "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fgoogle%2Ftarpc%2Fpull%2F279) for more info**.\n\n<!-- need_sender_cla -->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM571", "user": "ghost", "root": "ROOT57", "reply_to": "COM570", "timestamp": "2019-11-15T12:00:12Z", "text": "LOL, no way. You have to be nuts. My commit is PUBLIC DOMAIN, do with it as you please.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM572", "user": "tikue", "root": "ROOT57", "reply_to": "COM571", "timestamp": "2019-11-15T17:05:19Z", "text": "I unfortunately can't accept this without a signed CLA. I double checked to see if there's an exception for trivial commits; there isn't. I guess it's easier for the lawyers this way.\r\n\r\nI probably won't get to this myself today, so feel free to reopen if you change your mind.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM573", "user": "ghost", "root": "ROOT57", "reply_to": "COM572", "timestamp": "2019-11-15T20:13:04Z", "text": "Perhaps also ask the lawyers what happens if someone later goes and fixes\nthat typo. That\u2019s basically stealing my public domain idea, regardless of\nyour CLA, and then claiming it isn\u2019t because this wasn\u2019t known to you.\nWhacky position to be in :)\n\nWe need to say no to people who make this world unreasonable\n\nSoftware wants to be Free\nAnd you can make a stand or be a tool\n\nOn Sat, Nov 16, 2019 at 2:05 Tim <notifications@github.com> wrote:\n\n> Closed #279 <https://github.com/google/tarpc/pull/279>.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/google/tarpc/pull/279?email_source=notifications&email_token=AAGCHBLJNYQ67TUTZKQZ2WDQT3JFFA5CNFSM4JNZ2EU2YY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOU4L4MBA#event-2803353092>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAGCHBNVDOA7R3L2O7CSCS3QT3JFFANCNFSM4JNZ2EUQ>\n> .\n>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM574", "user": "vorot93", "root": "ROOT57", "reply_to": "COM573", "timestamp": "2019-11-15T20:18:21Z", "text": "@krzysztofwos IANAL but the typo fix is too trivial to be protected in the court of law. And even if it wasn't it's always possible to simply rephrase the sentence.\r\n\r\nRegarding the rest of your comment, I do not think it is reasonable to put a man's livelihood in a perilous position just to make a point. One must learn to pick his fights, so to speak. :)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM575", "user": "ghost", "root": "ROOT57", "reply_to": "COM574", "timestamp": "2019-11-15T20:33:55Z", "text": "Yes and I am fighting mine trying to live a life according to immutable\nbelief in better tomorrow.\n\nOne can live a life earning less than the fabled Google salary but dream of\nbetter internet where this sort of nonsense isn\u2019t for a bunch of lawyers to\ndecide\n\nA man\u2019s effort to further the way to build software is our birthright\n\nIt\u2019s the direct exercise of LOGOS, the Divine Word, the ability that God\nhimself bestowed on man: to transform chaos into order through an act of\nspeech\n\nIn the beginning there was the word and the word was with God and the word\nwas God\n\nJohn:1, I believe\n\nYour CLA is preventing me from exercising my religious belief, a right\nenshrined in your Constitution\n\nThe world is full of nonsense because nobody makes a stand\n\nOn Sat, Nov 16, 2019 at 5:18 Artem Vorotnikov <notifications@github.com>\nwrote:\n\n> @krzysztofwos <https://github.com/krzysztofwos> IANAL but the typo fix is\n> too trivial to be protected in the court of law. And even if it wasn't it's\n> always possible to simply rephrase the sentence.\n>\n> Regarding the rest of your comment, I do not think it is reasonable to put\n> a man's livelihood in a perilous position just to make a point. One must\n> learn to pick his fights, so to speak. :)\n>\n> \u2014\n> You are receiving this because you were mentioned.\n>\n>\n> Reply to this email directly, view it on GitHub\n> <https://github.com/google/tarpc/pull/279?email_source=notifications&email_token=AAGCHBP3VXRD2PABQE5C4BTQT37Y7A5CNFSM4JNZ2EU2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEEGTBMQ#issuecomment-554512562>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAGCHBJTTRPYEEIENCIJHWLQT37Y7ANCNFSM4JNZ2EUQ>\n> .\n>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM576", "user": "ghost", "root": "ROOT57", "reply_to": "COM575", "timestamp": "2019-11-15T20:39:25Z", "text": "Someone should start a GoFundMe campaign to pay for a lawyer who will\nchallenge Google all the way to the Supreme Court, LOL\n\nThis is unquestionable example of furthering of knowledge offered freely in\ngood faith\n\nThis cannot be prohibited\n\n#Singularity\n\nOn Sat, Nov 16, 2019 at 5:33 Krzysztof Wo\u015b <krzysztof.wos@gmail.com> wrote:\n\n> Yes and I am fighting mine trying to live a life according to immutable\n> belief in better tomorrow.\n>\n> One can live a life earning less than the fabled Google salary but dream\n> of better internet where this sort of nonsense isn\u2019t for a bunch of lawyers\n> to decide\n>\n> A man\u2019s effort to further the way to build software is our birthright\n>\n> It\u2019s the direct exercise of LOGOS, the Divine Word, the ability that God\n> himself bestowed on man: to transform chaos into order through an act of\n> speech\n>\n> In the beginning there was the word and the word was with God and the word\n> was God\n>\n> John:1, I believe\n>\n> Your CLA is preventing me from exercising my religious belief, a right\n> enshrined in your Constitution\n>\n> The world is full of nonsense because nobody makes a stand\n>\n> On Sat, Nov 16, 2019 at 5:18 Artem Vorotnikov <notifications@github.com>\n> wrote:\n>\n>> @krzysztofwos <https://github.com/krzysztofwos> IANAL but the typo fix\n>> is too trivial to be protected in the court of law. And even if it wasn't\n>> it's always possible to simply rephrase the sentence.\n>>\n>> Regarding the rest of your comment, I do not think it is reasonable to\n>> put a man's livelihood in a perilous position just to make a point. One\n>> must learn to pick his fights, so to speak. :)\n>>\n>> \u2014\n>> You are receiving this because you were mentioned.\n>>\n>>\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/google/tarpc/pull/279?email_source=notifications&email_token=AAGCHBP3VXRD2PABQE5C4BTQT37Y7A5CNFSM4JNZ2EU2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEEGTBMQ#issuecomment-554512562>,\n>> or unsubscribe\n>> <https://github.com/notifications/unsubscribe-auth/AAGCHBJTTRPYEEIENCIJHWLQT37Y7ANCNFSM4JNZ2EUQ>\n>> .\n>>\n>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM577", "user": "ghost", "root": "ROOT57", "reply_to": "COM576", "timestamp": "2019-11-15T20:47:00Z", "text": "Sorry to drag you into this buddy\n\nI have OCD and I really want that typo fixed, now I know it\u2019s there, it\nannoys me LOL.\n\nHere\u2019s another argument, your CLA is against neurodiversity.\n\nFinally I think I have a human right to have my anguish relieved since it\u2019s\nat no cost to the company at all.\n\nBut your masters are trying to put a leash on me and to that I say, over my\ndead body!\n\nOn Sat, Nov 16, 2019 at 5:39 Krzysztof Wo\u015b <krzysztof.wos@gmail.com> wrote:\n\n> Someone should start a GoFundMe campaign to pay for a lawyer who will\n> challenge Google all the way to the Supreme Court, LOL\n>\n> This is unquestionable example of furthering of knowledge offered freely\n> in good faith\n>\n> This cannot be prohibited\n>\n> #Singularity\n>\n> On Sat, Nov 16, 2019 at 5:33 Krzysztof Wo\u015b <krzysztof.wos@gmail.com>\n> wrote:\n>\n>> Yes and I am fighting mine trying to live a life according to immutable\n>> belief in better tomorrow.\n>>\n>> One can live a life earning less than the fabled Google salary but dream\n>> of better internet where this sort of nonsense isn\u2019t for a bunch of lawyers\n>> to decide\n>>\n>> A man\u2019s effort to further the way to build software is our birthright\n>>\n>> It\u2019s the direct exercise of LOGOS, the Divine Word, the ability that God\n>> himself bestowed on man: to transform chaos into order through an act of\n>> speech\n>>\n>> In the beginning there was the word and the word was with God and the\n>> word was God\n>>\n>> John:1, I believe\n>>\n>> Your CLA is preventing me from exercising my religious belief, a right\n>> enshrined in your Constitution\n>>\n>> The world is full of nonsense because nobody makes a stand\n>>\n>> On Sat, Nov 16, 2019 at 5:18 Artem Vorotnikov <notifications@github.com>\n>> wrote:\n>>\n>>> @krzysztofwos <https://github.com/krzysztofwos> IANAL but the typo fix\n>>> is too trivial to be protected in the court of law. And even if it wasn't\n>>> it's always possible to simply rephrase the sentence.\n>>>\n>>> Regarding the rest of your comment, I do not think it is reasonable to\n>>> put a man's livelihood in a perilous position just to make a point. One\n>>> must learn to pick his fights, so to speak. :)\n>>>\n>>> \u2014\n>>> You are receiving this because you were mentioned.\n>>>\n>>>\n>>> Reply to this email directly, view it on GitHub\n>>> <https://github.com/google/tarpc/pull/279?email_source=notifications&email_token=AAGCHBP3VXRD2PABQE5C4BTQT37Y7A5CNFSM4JNZ2EU2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEEGTBMQ#issuecomment-554512562>,\n>>> or unsubscribe\n>>> <https://github.com/notifications/unsubscribe-auth/AAGCHBJTTRPYEEIENCIJHWLQT37Y7ANCNFSM4JNZ2EUQ>\n>>> .\n>>>\n>>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM578", "user": "vorot93", "root": "ROOT57", "reply_to": "COM577", "timestamp": "2019-11-15T22:01:40Z", "text": "I believe that this PR has run its course and it's time to move on.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM579", "user": "tikue", "root": "ROOT57", "reply_to": "COM578", "timestamp": "2019-11-16T01:30:54Z", "text": "I've fixed the typo; I'm sorry for any distress this experience has caused you.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT58", "user": "ghost", "root": "ROOT58", "reply_to": null, "timestamp": "2020-05-20T17:32:15Z", "text": "[Spec]  Name in use by a REAL open-source project This name is in use and should be changed imediately. Yes, I have seen the other issues. Yes, I am opening a new one because fuck you Microsoft.You are merely trying to cast a shadow on other, truly open source projects. \r \r https://itsfoss.com/microsoft-maui-kde-row/?fbclid=IwAR3lO4SDxw3H01YsuKZ9G5D2zc1K-OOpjInCKnnY5GBpqiAdnhqfXJGG_EI", "meta": {"posReactions": "4", "negReactions": "17"}}
{"id": "COM580", "user": "Joshua-Ashton", "root": "ROOT58", "reply_to": "ROOT58", "timestamp": "2020-05-20T17:40:06Z", "text": "It's also trademark infringement:\r\n\r\nhttps://euipo.europa.eu/eSearch/#details/trademarks/013410601", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM581", "user": "ChaseFlorell", "root": "ROOT58", "reply_to": "COM580", "timestamp": "2020-05-20T18:26:43Z", "text": "Microsoft and the PMs here are already aware and are already looking into solutions. This \"Issue\" is just inflammatory and violates the code of conduct. There is an existing (open) issue that is much more civil and constructive.\r\n\r\nhttps://github.com/dotnet/maui/issues/41 and https://github.com/dotnet/maui/issues/58#issuecomment-631436935\r\n\r\nAbove all else, be kind.", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM582", "user": "Hual", "root": "ROOT58", "reply_to": "COM581", "timestamp": "2020-05-20T19:07:48Z", "text": "This is why Linux products are the way they are, and why no one had ever heard of KDE MAUI until now -- you lot just argue about inane stuff instead of getting work done.", "meta": {"posReactions": "3", "negReactions": "1"}}
{"id": "COM583", "user": "andrewBezerra", "root": "ROOT58", "reply_to": "COM582", "timestamp": "2020-05-20T20:23:45Z", "text": "In\r\nhttps://devblogs.microsoft.com/dotnet/introducing-net-multi-platform-app-ui/\r\nis written:\r\n\r\n    \"that: .NET Multi-platform App UI, affectionately call .NET MAUI.\"\r\nNote:\r\n \r\n     \"affectionatelly call...\"\r\nand not:\r\n\r\n    \"also call\"\r\n\r\nFor me, MAUI is not the REAL name of \"product\".", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM584", "user": "legistek", "root": "ROOT58", "reply_to": "COM583", "timestamp": "2020-05-20T20:40:38Z", "text": "> It's also trademark infringement:\r\n> \r\n> https://euipo.europa.eu/eSearch/#details/trademarks/013410601\r\n\r\nAre you a lawyer? Maybe you should check with one before you potentially commit business libel.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM585", "user": "davidortinau", "root": "ROOT58", "reply_to": "COM584", "timestamp": "2020-05-20T21:00:01Z", "text": "@Native-Coder your tone and style of commenting is violating our [Code of Conduct](https://dotnetfoundation.org/about/code-of-conduct). We have marked the problematic comments as abusive and blocked you for 7 days. If this behavior persists, we\u2019re going to block you permanently.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM586", "user": "davidortinau", "root": "ROOT58", "reply_to": "COM585", "timestamp": "2020-05-20T21:00:14Z", "text": "Duplicate of #34 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT59", "user": "ghost", "root": "ROOT59", "reply_to": null, "timestamp": "2018-04-22T20:25:31Z", "text": "Jekyll 4.0 Ideas :wave: Hello everyone! Summer is coming, and so is the implementation period for Jekyll 4.0. That's right, it's time to get some breaking changes in. To accommodate for this, we're opening this issue to collect interesting ideas that people would like to see implemented in 4.0. __Keep in mind that even if an idea receives a lot of support, there's no guarantee that it'll get implemented__ \u2014 that depends on if someone is free to actually implement it. We're all volunteers here, keep that in mind.\r \r Feel free to revive old feature requests, too, just not something that we've explicitly rejected.\r \r For an organized view of how we're consolidating ideas and features, check out our Project board: https://github.com/jekyll/jekyll/projects/2", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM590", "user": "laukstein", "root": "ROOT59", "reply_to": "ROOT59", "timestamp": "2018-04-23T04:32:02Z", "text": "I vote for #6293 Markdown links bidi support, in `<>`, `[]()` by default.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM591", "user": "geraldb", "root": "ROOT59", "reply_to": "COM590", "timestamp": "2018-04-23T19:15:49Z", "text": "Adding fetch / get for datafiles to core (or as an \"official\" addon/plugin) would be great, see the unloved / public domain source @ <https://github.com/18F/jekyll-get>  The code itself is about 40 lines, see <https://github.com/18F/jekyll-get/blob/master/_plugins/jekyll_get.rb>.", "meta": {"posReactions": "11", "negReactions": "0"}}
{"id": "COM592", "user": "geraldb", "root": "ROOT59", "reply_to": "COM591", "timestamp": "2018-04-23T19:21:52Z", "text": "Using the quik library for scaffolding. If you scaffold a new jekyll theme or plugin now all the code is \"hard-coded\" / \"hard-wired\". The scaffolding code itself is also \"hard-wired\"  / \"hard-coded\", that is, not (re)usable for other projects. Using a (simple) \"generic\" scaffolding library such as quik you can turn any git(hub) repo (or directory/folder or zip archive) into a parametrized and scripted template scaffold. See the [Jekyll Quick Starter Template / Scaffold - Build Your Own (Gem-Packaged) Theme](https://github.com/quikstart/jekyll-starter-theme) as an example. \r\n\r\nPS: Background / References - Talk Notes - [Quik - The Missing Project Scaffolder (Library) for Ruby - Quick Start Your Ruby Gems, Jekyll Websites, Jekyll Themes 'n' More](https://github.com/geraldb/talks/blob/master/quik.md)", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM593", "user": "laukstein", "root": "ROOT59", "reply_to": "COM592", "timestamp": "2018-04-23T20:59:25Z", "text": "Custom HTTP headers compatibility for Github Pages (Webrick isn't planned to support https://github.com/github/pages-gem/issues/415)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM594", "user": "pathawks", "root": "ROOT59", "reply_to": "COM593", "timestamp": "2018-04-23T21:30:21Z", "text": "@laukstein Let\u2019s keep this restricted to Jekyll features. We don\u2019t have any control over GitHub Pages.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM595", "user": "letrastudio", "root": "ROOT59", "reply_to": "COM594", "timestamp": "2018-04-23T23:31:32Z", "text": "I'd love to see automatic generation of tag and category archive pages in core (plugins like [jekyll-archives](https://github.com/jekyll/jekyll-archives/) do this, but none are whitelisted in GitHub Pages). I wrote up #6952 with my detailed rationale and a proposal of how it could work.\r\n\r\nHere's the TL;DR:\r\n\r\n> Having vanilla Jekyll auto-generate archive pages for every tag and category is probably a good idea now, and I think I've come up with a good, clean way to do it while staying true to Jekyll's philosophy.\r\n\r\nCode-wise, this snippet gets most of it across:\r\n\r\n```yaml\r\ncollections:\r\n  tags:\r\n    output: true\r\n    permalink: /tags/:name/\r\n  categories:\r\n    output: true\r\n    permalink: /categories/:name/\r\n```\r\n\r\n\r\n", "meta": {"posReactions": "36", "negReactions": "0"}}
{"id": "COM596", "user": "mbrav", "root": "ROOT59", "reply_to": "COM595", "timestamp": "2018-04-24T04:28:25Z", "text": "I know that this is markdown and not necessarily jekyll related, but my life would have been a thousand times easier if jekyll supported inline footnotes like so  `[^Footnote, p. 123]` as apposed to the more tedious:\r\n\r\n```\r\nThis is first reference[^one], this is the second[^two]\r\n\r\n[^one]: Footnote, p.1\r\n[^two]: Footnote, p.2\r\n\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM597", "user": "DirtyF", "root": "ROOT59", "reply_to": "COM596", "timestamp": "2018-04-24T08:58:22Z", "text": "@mbrav This depends on the Markdown engine. Please ask  on [Kramdown](https://github.com/gettalong/kramdown) or [CommonMark](http://commonmark.org/).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM598", "user": "asipple1", "root": "ROOT59", "reply_to": "COM597", "timestamp": "2018-04-25T03:55:37Z", "text": "First would like to say thank you to the Jekyll team for all the great work you all do. Jekyll is one my favorite frameworks to work with and I really do appreciate what you guys do! \r\nOk on to the request it would be great if there was a built-in way to paginate a list Jekyll collection items on a page. I know there is [jekyll-paginate-v2 gem](https://github.com/sverrirs/jekyll-paginate-v2) but it would be nice if there was a built in pagniation that worked for both post and collection items.", "meta": {"posReactions": "21", "negReactions": "0"}}
{"id": "COM599", "user": "nativerez", "root": "ROOT59", "reply_to": "COM598", "timestamp": "2018-04-26T13:08:07Z", "text": "Hello all, my first post so go easy. I want to just say that I love Jekyll, I'm now using it on a lot of my web builds. One thing that has bothered me though, is that I've not been able to take advantage of the latest Jekyll features because a lot of the 3rd party CMS solutions I rely on for my clients use (cloudcannon, siteleaf and forestry) simply don't run the latest versions of Jekyll themselves. This forces me to have my folder structures in a really messy state and not take advantage of the latest features when developing locally. So if anyone at Jekyll could bend a few arms to get them to update that would be fab.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5910", "user": "DirtyF", "root": "ROOT59", "reply_to": "COM599", "timestamp": "2018-04-26T14:00:09Z", "text": "@nativerez It alwyas take some time to update to the latest version for services like GitHub Pages, Forestry, CloudCannon or Siteleaf because they need to run tests and adapt their tools. There's nothing Jekyll's core team can do about it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5911", "user": "rjachuthan", "root": "ROOT59", "reply_to": "COM5910", "timestamp": "2018-04-28T07:21:01Z", "text": "I would like to see Nested Collections. I know there are alternatives to do this. But still if the Jekyll team can make it easier, that would be awesome.!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5912", "user": "hosnas", "root": "ROOT59", "reply_to": "COM5911", "timestamp": "2018-04-30T04:52:45Z", "text": "I would like to see [reading metadata in separate files](https://github.com/jekyll/jekyll/issues/1082). ", "meta": {"posReactions": "8", "negReactions": "0"}}
{"id": "COM5913", "user": "letrastudio", "root": "ROOT59", "reply_to": "COM5912", "timestamp": "2018-04-30T14:02:39Z", "text": "@hosnas Great suggestion. I'll add a use case:\r\n- Create a collection of static image files\r\n- Add metadata (like alt text, captions, dimensions) in sidecar files\r\n- Loop through them to create a rich image gallery\r\n\r\nJekyll CMS services like [Siteleaf](https://siteleaf.com) could make great use of this feature. Siteleaf uploads static assets to an `_uploads` collection. cc @sskylar ", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM5914", "user": "cmhelmer", "root": "ROOT59", "reply_to": "COM5913", "timestamp": "2018-05-02T03:54:51Z", "text": "I would like to see the tags of collections included in site.tags. Thanks!", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM5915", "user": "BerkhanBerkdemir", "root": "ROOT59", "reply_to": "COM5914", "timestamp": "2018-05-03T00:33:39Z", "text": "Please please support for i18n. At least 2 languages. Many plug-ins break or don't work with ghpages.", "meta": {"posReactions": "33", "negReactions": "0"}}
{"id": "COM5916", "user": "shivajivarma", "root": "ROOT59", "reply_to": "COM5915", "timestamp": "2018-05-04T14:39:21Z", "text": "build in support for content blocks and components", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM5917", "user": "ghost", "root": "ROOT59", "reply_to": "COM5916", "timestamp": "2018-05-04T16:22:16Z", "text": "@shivajivarma Can you elaborate? Do you mean something like includes?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5918", "user": "ghost", "root": "ROOT59", "reply_to": "COM5917", "timestamp": "2018-05-04T18:00:44Z", "text": "I'd very much love to have native support for Coffeescript in much the same manner as Sass. Thus, we could define in `_config.yml`\r\n\r\n```\r\n# Support Coffeescript\r\ncoffeescript:\r\n  coffeescript_dir: _coffee\r\n  output: compressed\r\n```\r\n\r\nThis way one could create partials of `.coffee` in well-structured folders with all of them compiling minified to one `.js` file, even same way as you have `css/style.sass` with all the imports of individual Sass files.", "meta": {"posReactions": "4", "negReactions": "2"}}
{"id": "COM5919", "user": "charlesrocket", "root": "ROOT59", "reply_to": "COM5918", "timestamp": "2018-05-05T01:29:38Z", "text": "it would be great to have more interactions with github, like pulling profile information (contributions, avatar, ), releases data - and convert it for proper publication. this would be vital for software website to create team and download pages that would not require multiple code changes. currently working with current available plugins, this solution lacks stability since there's too many plugins that should be constantly updated. would be glad to help if this will go further!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5920", "user": "charlesrocket", "root": "ROOT59", "reply_to": "COM5919", "timestamp": "2018-05-05T04:00:11Z", "text": "also background section could get some improvements - building website that will look good on regular displays and retina quiet challenging. creating multiple backgrounds for could be the solution to decrease loading time. or middle state like `page loading` to comfort browsing", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5921", "user": "DirtyF", "root": "ROOT59", "reply_to": "COM5920", "timestamp": "2018-05-05T09:49:57Z", "text": "@charlesrocket GitHub data should be part of GitHub-metadata plugin not Jekyll-core", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5922", "user": "charlesrocket", "root": "ROOT59", "reply_to": "COM5921", "timestamp": "2018-05-05T11:08:20Z", "text": "@DirtyF sorry, i just started with jekyll a week ago) this repo is on the list. at this time, i guess that this info could be pulled by `metadata`, but shouldn't jekyll convert it for better (more universal) usage?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5923", "user": "DirtyF", "root": "ROOT59", "reply_to": "COM5922", "timestamp": "2018-05-05T11:16:45Z", "text": "@charlesrocket This is off-topic, but FYI GitHub-metadata already provides access to these data through `site.github` namespace.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5924", "user": "charlesrocket", "root": "ROOT59", "reply_to": "COM5923", "timestamp": "2018-05-05T11:23:48Z", "text": "@DirtyF my bad. guess i misfired with backgrounds as well? ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5925", "user": "DirtyF", "root": "ROOT59", "reply_to": "COM5924", "timestamp": "2018-05-05T11:30:02Z", "text": "@charlesrocket It looks like so, as Jekyll is fully agnostic when it comes what's get generated in the front-end, it just transforms files into HTML. You can use plugins like `jekyll-assets` and/or `jekyll-cloudinary` to help you deal with responsive images.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5926", "user": "charlesrocket", "root": "ROOT59", "reply_to": "COM5925", "timestamp": "2018-05-05T11:33:31Z", "text": "@DirtyF thanks for the input! im looking for every jekyll plugin i can find, put majority is out of date and has no support, so it pushed me to propose these functions into core (not counting jekyll-originated plugins) should i delete my comments? don't want to overload the tread since im thinking it will grow and going tho useless comments would add some discomfort", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5927", "user": "ashmaroli", "root": "ROOT59", "reply_to": "COM5926", "timestamp": "2018-05-05T12:01:38Z", "text": "(I) really love this ability to minimize comments on GitHub.. :sparkles:", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM5928", "user": "asipple1", "root": "ROOT59", "reply_to": "COM5927", "timestamp": "2018-05-05T12:56:09Z", "text": "I would like to see an automated tool like Webpack integrated into Jekyll to handle Sass and Javascript. \r\nSome of the biggest reasons are auto-prefixing for Sass and the ability to use ES6 syntax that can automatically be polyfilled with babel. I think having an automated tool handle the sass and javascript bits may speed up the compile time of Jekyll. ", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM5929", "user": "ashmaroli", "root": "ROOT59", "reply_to": "COM5928", "timestamp": "2018-05-05T12:59:41Z", "text": "> I think having an automated tool handle the sass and javascript bits may speed up the compile time of Jekyll\r\n\r\nHow is that..??", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT60", "user": "ghost", "root": "ROOT60", "reply_to": null, "timestamp": "2019-07-11T14:34:28Z", "text": "Norton very unhappy with vcpkgmetricsuploader I just installed the current vcpkg and encountered this as well. I've read through [#6551](https://github.com/microsoft/vcpkg/issues/6551) and [#3345.](https://github.com/microsoft/vcpkg/issues/3345) I see these closed but don't see any resolution.\r \r What I do see is that Norton is very, very unhappy on my system with this tool. I've gotten SONAR reports about the metrics upload (and I'll also put in a vote for making metrics opt-in. I'm surprised that it is opt-out, and not terribly well documented opt-out). Norton is now saying that it needs to restart to finish cleaning out the security risks.\r \r This is not the level of security awareness I expect Microsoft to have. Minimally fix this to be opt-in. Beyond that, work with your security teams to get the uploader qualified by at least the major vendors.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM600", "user": "heydojo", "root": "ROOT60", "reply_to": "ROOT60", "timestamp": "2019-07-15T03:43:34Z", "text": "> This is not the level of security awareness I expect Microsoft\r\n\r\nI don't work for MS. Your tone is derogatory.\r\n\r\nYour software (Norton) has established a false positive in it's threat detection. Please work with the software manufacturer to establish a resolution on their part.\r\n\r\nThere is nothing Microsoft or anyone else can do if a piece of third party software on your machine malfunctions.\r\nOne solution is to use Windows built-in threat detection tools instead of the unreliable Norton software. I am actually quite shocked that Norton are even still in business. Their AV and other \"Security\" products have been malfunctioning and underperforming for well over 20 years.\r\n\r\nBecause vcpkg is open source, you can modify the source code any way that you wish once you have obtained a copy locally, so I'm unsure what else to say other than it would appear that the software Norton have sold you is not providing you value for money and is also causing you frustration instead as well.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM601", "user": "ghost", "root": "ROOT60", "reply_to": "COM600", "timestamp": "2019-07-15T05:02:56Z", "text": "As I pointed out this has been reported repeatedly in the past, and closed with no explanation or correction.  Specifically, #3345 is clear that it is much more widespread.  I'd focus less on Norton, per se, based on these prior reports.\r\n\r\nThe initial issue is the issuance of telemetry without opt-in.  It is, in fact, that telemetry that is causing the image to be considered suspect.\r\n\r\nFurthermore, vcpkg is recommended by Microsoft (e.g. see https://docs.microsoft.com/en-us/cpp/build/vcpkg?view=vs-2019 as an example).  I was, and am, surprised that Microsoft is recommending a solution that performs telemetry by default.  And one that does not have a clear statement that it is taking telemetry, exactly what telemetry it is taking, and does not have a very clear opt-out.\r\n\r\nNow, can I fork the code to do whatever I want?  Sure.  Can I propose a fix?  Sure. Does that change the surprise at the telemetry by default and the lack of visibility, or that this has been reported for over a year?  Not really.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM602", "user": "ghost", "root": "ROOT60", "reply_to": "COM601", "timestamp": "2019-07-19T02:18:29Z", "text": "There are several options you may try to solve the problem:\r\n1. Run the bootstrap process with the \".\\boostrap-vcpkg.bat -disableMetrics\"  option to compile vcpkg without metrics.\r\n2. Tell Norton not to scan the vcpkg.exe executable\r\n3. Tell Norton not to scan the directory/folder containing vcpkg.exe\r\n\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM603", "user": "ghost", "root": "ROOT60", "reply_to": "COM602", "timestamp": "2019-07-20T04:51:25Z", "text": "My workaround was to tell Norton to reverse the quarantine decision and to not scan the metrics upload image.\r\n\r\nMaybe I'm the only person bothered by the opaque decision to have this process upload data from my machine to some remote site.  But I am bothered by it.\r\n\r\nI can surely support a \".\\bootstrap-vcpkg.bat -enableMetrics\" approach.  Or an approach that directly asks at the start of the bootstrap process if I want to upload metrics and either directly disclose, or be able to disclose, what will be uploaded.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM604", "user": "heydojo", "root": "ROOT60", "reply_to": "COM603", "timestamp": "2019-07-22T11:26:20Z", "text": "@JEJ0 \r\n\r\nhttps://github.com/microsoft/vcpkg/blob/7d72108b9a09e92342ff695c074766fb068049df/docs/about/privacy.md\r\n\r\n>  I'd focus less on Norton, per se, based on these prior reports.\r\n\r\nThis is the incorrect approach based upon your issue.\r\n\r\nBecause:\r\n\r\n> Your software (Norton) has established a false positive in it's threat detection.\r\n\r\nAnd one single other bug report:\r\n\r\n> Specifically, #3345 is clear that it is much more widespread.\r\n\r\nDoes not validate your position. Your logic fails to accommodate the fact that AV software (especially badly maintained, poorly coded AV software) is highly prone to false positive detection rates. The simple solution since the false positive problem was identified (decades ago) has been to report the false positive to the manufacturer using (commonly) their automatic reporting tool.\r\nI have already suggested that you do this and yet you persist to assert that your problem is one of Microsoft's making.\r\n\r\n>  I was, and am, surprised that Microsoft is recommending a solution that performs telemetry by default.\r\n\r\nI'm sorry but if you were unaware, telemetry by default is how Windows 10 is shipping too. It is the default position of Microsoft products to do so.\r\nIf you do not like this behaviour (and I personally find it repugnant) then turn it off. The method to do so, as already mentioned is `-disableMetrics`.\r\n\r\n> Now, can I fork the code to do whatever I want? Sure. Can I propose a fix? Sure.\r\n\r\nBoth rhetorical questions.\r\n\r\n> Does that change the surprise at the telemetry by default and the lack of visibility, or that this has been reported for over a year?\r\n\r\nAnd yet according to your report:\r\n\r\n> This is not the level of security awareness I expect Microsoft to have.\r\n\r\nPlease don't attempt to change the topic of this thread. We get it. You don't like metrics.\r\nFalse positive detections by AV products have nothing to do with Microsoft's level of security awareness. You can report false positives to AV product manufacturers. And you can also turn off vcpkg's metrics using a single switch. This in turn should prevent the false positive triggering.\r\n\r\nLet us know how you get on.\r\nThanks.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM605", "user": "Rastaban", "root": "ROOT60", "reply_to": "COM604", "timestamp": "2019-07-23T00:18:56Z", "text": "It is annoying that Norton flags the metrics uploader, but at this time there is no solution that works for the team at this time.  The uploader cannot be qualified by the major anti-virus vendors because it is built on the end users machine and is not signed.  We have discussed fiddling with the implementation of the uploader, but have decided against it because we don't want to obfuscate the code.  Also tricks that may work now could end up backfiring later.  Making the metrics uploader opt-in rather than opt-out does not solve the anti-virus issue either, it only makes it less noticeable.\r\n\r\nIn response to your concerns of the collection of usage metrics, I refer you to the privacy policy: https://github.com/Microsoft/vcpkg/blob/master/docs/about/privacy.md.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT61", "user": "Gibson85", "root": "ROOT61", "reply_to": null, "timestamp": "2018-06-16T20:13:42Z", "text": "Are you serious? Sorry to say, that I am totally pissed off from this worst programmed piece of software/plugin I have ever seen. With every new version something else is not working anymore. I shouldn't complain about software I had nothing to pay for, but have you ever heard something about quality management? You are releasing a version 1.0.0 that is simply not working. How couldn't this be seen? Then a few days later a \"fixed\" version 1.0.1 still not working. And the same with the versions in the past. Fatal errors over errors again. If you have no linux pc please install yourself a virtual machine and have at least a try before releasing such an sh... It's an effort from < 1 hour.\r \r PLEASE improve your testing in future. Thanks.\r \r Debian Stretch 9.4\r cmake version 3.11.3\r \r [fatal] [rollbar] Unhandled exception: Unhandled Promise rejection: build Error: spawn /usr/local/bin/ctest ENOENT {}\r t.log @ /usr/share/code/resources/app/out/vs/workbench/workbench.main.js:268\r /usr/share/code/resources/app/out/vs/workbench/workbench.main.js:268 [Extension Host] Error: spawn /usr/local/bin/ctest ENOENT\r \tat exports._errnoException (util.js:1050:11)\r \tat Process.ChildProcess._handle.onexit (internal/child_process.js:193:32)\r \tat onErrorNT (internal/child_process.js:367:16)\r \tat _combinedTickCallback (internal/process/next_tick.js:80:11)\r \tat process._tickCallback (internal/process/next_tick.js:104:9)\r t.log @ /usr/share/code/resources/app/out/vs/workbench/workbench.main.js:268", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM610", "user": "Randshot", "root": "ROOT61", "reply_to": "ROOT61", "timestamp": "2018-06-16T21:23:16Z", "text": "@Gibson85 Have you looked up what `spawn * ENOENT` means?\r\nIt means that it couldn't find the command/executable in question, so this doesn't really have anything to do with the extension itself.\r\nYou could argue that unhelpful error messages are a kind of bug, but that is another issue.\r\n\r\nSo, instead of ranting here, maybe you should try to find the cause of the problem and/or open a PR that fixes this kind of issue, if necessary.\r\nI don't have anything against bug reports, but the above is really sad...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM611", "user": "neilogd", "root": "ROOT61", "reply_to": "COM610", "timestamp": "2018-06-16T23:02:32Z", "text": "\"Sorry to say, that I am totally pissed off from this worst programmed piece of software/plugin I have ever seen.\"\r\n\r\nThis seems unnecessarily hostile, especially given that, in your own words, - \"I shouldn't complain about software I had nothing to pay for\"\r\n\r\nHave you considered simply reporting the issue, without any of the assholery? Ultimately if you do think it is the \"worst programmed piece of software\", you do have other options. Can write your own, can use something else, or, now this is my preferred approach generally, to help the maintainer improve it without being a douche.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM612", "user": "vector-of-bool", "root": "ROOT61", "reply_to": "COM611", "timestamp": "2018-06-16T23:16:07Z", "text": "> I shouldn't complain about software I had nothing to pay for\r\n\r\nThen don't?\r\n\r\nI develop almost always using a Linux environment. It's *Windows* and *macOS* that receive the most bugs.\r\n\r\nI take pride in my work, even if I only do this in my free time for no payment.\r\n\r\nThe 1.0.0 release was mostly a two-person effort and focused on code health. The 1.0.1 saw only fixes that were pending 1.0.1 since 1.0.0 was hugely behind schedule. I experienced hardware failures that prevented me from working for nearly two weeks. Almost no bugs that were introduced by 1.0.0 were addressed, and I was pleasantly surprised by the lack of an influx of bug reports following 1.0.0 and 1.0.1.\r\n\r\nI feel personally responsible for almost every bug that anyone opens in this issue tracker, and I strive to keep the issue count low and under control.\r\n\r\nI do not feel so keen on this ticket.\r\n\r\nIssue #428 is similar, but I closed it because I believed I had fixed it. That issue was opened by a collaborator, not a general user.\r\n\r\nI have received no automated error reports with a traceback resembling yours. I address issues based on how frequently they appear in my Rollbar account, or how frequently people react using GitHub issue tracker. No one other than a collaborator has ever reported seeing this problem.\r\n\r\nI'm going to close this and lock the conversation.\r\n\r\nIf you would like to re-open another GitHub issue calmly describing your problem with less vitriol and toxicity, I will gladly add it to my next release milestone, I'll add a test case for the situation, and I'll forget that this exchange happened.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT62", "user": "gitstashapply", "root": "ROOT62", "reply_to": null, "timestamp": "2019-12-19T11:46:09Z", "text": "Please rename \"Terminal\" section of menu, because it's offensive to me When I was young, we've traveled with my parents to Russia. \r One time in the Siberian city - \"Novosibirsk\", I got lost at the airport. There was a nightmare. I was cold and scared. The bears and drunk Russians were all that was what I saw.\r And I remember big nameplate \"TERMINAL C\".\r And now when I'm looking at the terminal section in VS code it's offending me.\r ", "meta": {"posReactions": "79", "negReactions": "2"}}
{"id": "COM620", "user": "hugmouse", "root": "ROOT62", "reply_to": "ROOT62", "timestamp": "2019-12-19T12:02:40Z", "text": "I think it is necessary to **remove** this \"Terminal\" word, as it can really offend someone's feelings in some country at some time. Additionally \"Terminal\" has cost millions of Jews their lives over the centuries because the word \"terminal\" could also mean [\"Extermination Camp\"](https://en.wikipedia.org/wiki/Extermination_camp).\r\n\r\n---\r\n\r\nPlease remove it immediately and make it your top priority. ", "meta": {"posReactions": "35", "negReactions": "2"}}
{"id": "COM621", "user": "ivanpopelyshev", "root": "ROOT62", "reply_to": "COM620", "timestamp": "2019-12-19T13:12:51Z", "text": "Rejoice, fellow Terminal C victim!\r\n\r\nThat nightmare was closed, there are only Terminals A and B in airport.", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM622", "user": "hckr", "root": "ROOT62", "reply_to": "COM621", "timestamp": "2019-12-19T13:30:12Z", "text": "\"Terminal\" might also remind someone about a terminal illness they are facing", "meta": {"posReactions": "2", "negReactions": "1"}}
{"id": "COM623", "user": "gitstashapply", "root": "ROOT62", "reply_to": "COM622", "timestamp": "2019-12-19T13:54:20Z", "text": "@ivanpopelyshev Oh my god! Man! It's something that I wish for the years! Christmas miracle literally exists!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM624", "user": "kieferrm", "root": "ROOT62", "reply_to": "COM623", "timestamp": "2019-12-19T22:56:41Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.\r\n\r\nHappy Coding!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT63", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": null, "timestamp": "2019-06-14T14:42:56Z", "text": "Roll third_party/re2 0c95bcce2f1f..848dfb7e1d7b (2 commits)  https://github.com/google/re2.git /compare/0c95bcce2f1f..848dfb7e1d7b  git log 0c95bcce2f1f0f071a786ca2c42384b211b8caba..848dfb7e1d7ba641d598cb66f81590f3999a555a --date=short --no-merges --format=%ad %ae %s 2019-06-13 junyer@google.com Don&#39;t let DFA execution bail when slow for RE2::Set. 2019-06-13 junyer@google.com Expose FilteredRE2::GetRE2() as public.  The AutoRoll server is located here: https://autoroll.skia.org/r/re2-shaderc-autoroll  Documentation for the AutoRoller is here: https://skia.googlesource.com/buildbot/+/master/autoroll/README.md  If the roll is causing failures, please contact the current sheriff (radial-bots&#43;shaderc-roll@google.com), and stop the roller if necessary.  ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM630", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "ROOT63", "timestamp": "2019-06-14T20:00:48Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM631", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM630", "timestamp": "2019-06-14T20:01:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM632", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM631", "timestamp": "2019-06-14T20:03:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM633", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM632", "timestamp": "2019-06-14T20:04:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM634", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM633", "timestamp": "2019-06-14T20:05:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM635", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM634", "timestamp": "2019-06-14T20:06:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM636", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM635", "timestamp": "2019-06-14T20:07:48Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM637", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM636", "timestamp": "2019-06-14T20:08:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM638", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM637", "timestamp": "2019-06-14T20:09:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM639", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM638", "timestamp": "2019-06-14T20:10:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6310", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM639", "timestamp": "2019-06-14T20:11:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6311", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6310", "timestamp": "2019-06-14T20:12:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6312", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6311", "timestamp": "2019-06-14T20:13:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6313", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6312", "timestamp": "2019-06-14T20:14:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6314", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6313", "timestamp": "2019-06-14T20:15:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6315", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6314", "timestamp": "2019-06-14T20:16:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6316", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6315", "timestamp": "2019-06-14T20:17:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6317", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6316", "timestamp": "2019-06-14T20:18:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6318", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6317", "timestamp": "2019-06-14T20:19:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6319", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6318", "timestamp": "2019-06-14T20:20:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6320", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6319", "timestamp": "2019-06-14T20:21:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6321", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6320", "timestamp": "2019-06-14T20:22:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6322", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6321", "timestamp": "2019-06-14T20:23:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6323", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6322", "timestamp": "2019-06-14T20:24:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6324", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6323", "timestamp": "2019-06-14T20:25:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6325", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6324", "timestamp": "2019-06-14T20:26:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6326", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6325", "timestamp": "2019-06-14T20:27:47Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6327", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6326", "timestamp": "2019-06-14T20:28:48Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6328", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6327", "timestamp": "2019-06-14T20:29:48Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6329", "user": "google-shaderc-autoroll", "root": "ROOT63", "reply_to": "COM6328", "timestamp": "2019-06-14T20:30:48Z", "text": "PullRequest is not longer mergeable. Closing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT64", "user": "gregwebs", "root": "ROOT64", "reply_to": null, "timestamp": "2018-09-08T14:38:48Z", "text": "proposal: Go 2: error handling with functions and an error return? # Background (go 2 Process)\r \r go 2 has laid out the [problem of error handling](https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling-overview.md) (Please read before reading this proposal).\r \r I am told that alternative proposals should be raised as git issues here. Please add anyone else you think would like to join the discussion.\r \r \r # Introduction\r \r It is amazing to see the [error handling problem](https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling-overview.md) being properly addressed. The [existing draft proposal](https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling.md) is good, but I think we can iterate to make it better.\r To avoid confusion by comparison to the existing proposal, I will avoid mentioning it in this one.\r However, if you are a supporter of the existing proposal, please separately read my [critique](https://gist.github.com/gregwebs/cdaaaae475ae3012730694598a24e0b9) of it.\r \r It's useful to take a step back and clearly state what we are trying to do with our implementation:\r \r * provide an abstraction that allows for the insertion of a return statement for errors.\r * compose handler functions together before they are used with the error return\r \r In the existing go language, I cannot write a handler function which will create an early return from the function.\r There are a few approaches that use existing languages features for this control flow:\r * Macros (e.g. Rust originally used a `try!` macro).\r * Ruby supports anonymous functions that return from the enclosing function (method)\r * exceptions\r * Sequencing code with short-circuits. Some usage of monads in Haskell are a particularly good example of this.\r \r For sequences with short-circuits, see the errors are values post for how this can be done in go. However, this severely alters how one would write go code.\r \r \r # Proposal: handlers as functions, just a special check\r \r Lets repeat our goals again:\r \r * provide an abstraction that allows for the insertion of a return statement for errors.\r * compose handler functions together before they are used with the error return\r \r Composition can be handled with ordinary functions that take and return an error.\r \r That means we just need a mechanism to insert a `return`.\r For early return in my proposal, I will use a question mark operator `?` rather than a `check` keyword. This is for two reasons\r * the operator can be used postfix, which has readability advantages\r * the original draft proposal used `check`, but it functions differently, so this may help avoid confusion.\r \r See \"Appendix: Operator versus check function\" for a discussion on using `?` or a `check` keyword. \r \r \r ## Implementation as syntactic expansion\r \r ``` go\r v := f() ? handler\r ```\r expands to\r \r ``` go\r v, err := f()\r if err != nil {\r     return Zero, handler(err)\r }\r ```\r \r Where `handler` is a function that takes an `error` and returns one. `Zero` is the zero value for the (success) value returned before the error, assuming the function returns a single success value. A function that returns 4 values, the last one being an error, would have.\r \r ``` go\r     return Zero, Zero, Zero, handler(err)\r ```\r \r This is a simple, easy to understand transformation. It is easy to underestimate the value from being able to [understand the usage site without searching for context](https://github.com/golang/go/issues/27567#issuecomment-421204131). I am trying to avoid comparisons to other proposals, but I want to say that none of the others I have seen can be described this simply.\r \r All of the transformation is performed entirely by `?`. It inserts the nil check, the `return`, and creates the needed zero values. The handler is just a normal function and an argument to `?`.\r \r For some small convenience in writing cleanup handlers, the return section would actually expand to this:\r \r ``` go\r     return Zero, handler.ToModifyError()(err)\r ```\r \r See the section on handler types and the appendix section on `ThenErr` and `ToModifyError`.\r \r \r ## Basic example from the original proposal, re-written\r \r Putting this together, lets re-write SortContents, which wants different handlers in different places.\r \r ``` go\r func SortContents(w io.Writer, files []string) error {\r     handlerAny := func(err error) error {\r \treturn fmt.Errorf(\"process: %v\", err)\r     }\r \r     lines := []strings{}\r     for _, file := range files {\r \thandlerFiles := func(err error) error {\r \t    return fmt.Errorf(\"read %s: %v \", file, err)\r \t}\r \tscan := bufio.NewScanner(os.Open(file) ? handlerFiles)\r \tfor scan.Scan() {\r \t    lines = append(lines, scan.Text())\r \t}\r \tscan.Err() ? handlerFiles\r     }\r     sort.Strings(lines)\r     for _, line := range lines {\r \tio.WriteString(w, line) ? handlerAny\r     }\r }\r ```\r \r Let's show another example from the proposal (slightly simplified) that has handler composition:\r \r ``` go\r func process(user string, files chan string) (n int, err error) {\r     ahandler := func(err error) error { return fmt.Errorf(\"process: %v\", err) }\r     for i := 0; i < 3; i++ {\r \tbhandler := func(err error) error { return fmt.Errorf(\"attempt %d: %v\", i, err) }\r \tdo(something()) ? ahandler.ThenErr(bhandler)\r     }\r     do(somethingElse()) ? ahandler\r }\r ```\r \r It is possible to combine handlers in the same way one would combine functions:\r \r ``` go\r do(something()) ? ahandler.ThenErr(func(err error) error {\r \treturn fmt.Errorf(\"attempt %d: %v\", i, err) }\r )\r ```\r \r Or\r \r ``` go\r do(something()) ? func(err error) { return ahandler(bhandler(err)) }\r ```\r \r The example uses a `.ThenErr` method (see appendix) as a way to compose error handler functions together. \r \r \r ## Results\r \r * This alternative proposal introduces just one special construct, `?`\r * The programmer has control and flexibility in the error handling.\r * Handlers can be naturally composed as functions\r * The code is much more succinct and organized than current go error handling code.\r * errors can be returned from `defer`.\r \r \r ## Checking error returns from deferred calls\r \r This alternative proposal can support returning errors from `defer`:\r \r \tdefer w.Close() ? closeHandler\r \r \r \r ## Notes on error handler function types\r \r To respond to errors we want to do one of two things:\r * cleanup (side-effecting): `(error) -> nil` or `() -> nil`\r * modify the error: `(error) -> error`\r \r An error handler function must always have the type of the modifier, but we may not want the extra noise when writing a purely cleanup handler. The question mark operator can accept all forms. A cleanup function can be automatically converted to return the original error that would have been passed to it.\r \r This is also true of helpers that compose error functions such as `ThenErr`.\r See the Appendix section on `ThenErr` to see how this is implemented.\r \r \r # Appendix\r \r ## Appendix: Handle and anonymous function syntax\r \r This proposal is slightly more verbose than others that introduce a special anonymous function syntax that is lighter-weight and infers types.\r \r ``` go\r handle err { return fmt.Errorf(\"process: %v\", err) }\r ```\r \r Without this syntax, the proposal would read:\r \r ``` go\r handle func(err error) error { return fmt.Errorf(\"process: %v\", err) }\r ```\r \r I think it is worthwhile to explore having anonymous functions that are lighter-weight.\r However, I think this should be usable anywhere rather than just with a single keyword.\r \r But please leave this for another proposal rather than throw it in the mix with error handlers!\r \r \r ## Appendix: unary and binary.\r \r The question mark operator can be used as a unary to just return the exception without any handlers running.\r \r ``` go\r something()?\r ```\r \r This is equivalent to \r \r ``` go\r something() ? func(err error) error { return err }\r ```\r \r I am favoring writing the unary form without any spaces in this case (more similar to Rust), but we should use whatever syntax the community finds best.\r \r \r ## Appendix: Handling errors within the handler itself\r \r A cleanup handler may generate a new error that should be propagated in addition to the current error.\r I believe this should just be handled by a multi-error technique, e.g. [multierr](https://github.com/uber-go/multierr/blob/master/error.go).\r \r \r ## Appendix: custom error types\r \r The existing proposal seems like it would cast a concrete error type to the `error` interface when it is passed to a handler.\r I don't think this proposal is fundamentally different.\r I think this issue should be solved by the generics proposal.\r \r \r ## Appendix: ThenErr and ToModifyErr\r \r An implementation of ThenErr  and ToModifyErr. See the syntax expansion section for how the `?` operator uses `ToModifyError`.\r \r ``` go\r type Cleanup func(error)\r type CleanupNoError func()\r type ModifyError func(error) error\r \r type ToModifyError interface {\r \tToModifyError() ModifyError\r }\r \r func (fn1 ModifyError) ToModifyError() ModifyError {\r \treturn fn1\r }\r \r func (fn1 CleanupNoError) ToModifyError() ModifyError {\r \treturn func(err error) error {\r \t\tfn1()\r \t\treturn err\r \t}\r }\r \r func (fn1 Cleanup) ToModifyError() ModifyError {\r \treturn func(err error) error {\r \t\tfn1(err)\r \t\treturn err\r \t}\r }\r \r // Its easier to write this once as a function\r func CombineErrs(funcs ...ToModifyError) ModifyError {\r \treturn func(err error) error {\r \t\tfor _, fn := range funcs {\r \t\t\terr = fn.ToModifyError()(err)\r \t\t}\r \t\treturn err\r \t}\r }\r \r // But method syntax is convenient\r type ErrorHandlerChain interface {\r \tThenErr(ToModifyError) ModifyError\r }\r \r func (fn1 ModifyError) ThenErr(fn2 ToModifyError) ModifyError {\r \treturn func(err error) error {\r \t\treturn fn1(fn2.ToModifyError()(err))\r \t}\r }\r \r func (fn1 Cleanup) ThenErr(fn2 ToModifyError) ModifyError {\r \treturn func(err error) error {\r \t\tfn1(err)\r \t\treturn fn2.ToModifyError()(err)\r \t}\r }\r \r func (fn1 CleanupNoError) ThenErr(fn2 ToModifyError) ModifyError {\r \treturn func(err error) error {\r \t\tfn1()\r \t\treturn fn2.ToModifyError()(err)\r \t}\r }\r ```\r \r \r ## Appendix: Operator versus check function\r \r The original proposal [rejected the question mark](https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling.md#considered-ideas) and gave some reasons why.\r Some of those points are still valid with this proposal, and others are not.\r \r Here is [another proposal](https://gist.github.com/PeterRK/4f59579c1162cdbc28086f6b5f7b4fa2) that I believe advocates the same solution proposed in this alternative, but with a `check` function. I would be happy with that as a solution, but below I give my preference for `?`.\r \r The original proposal had just one argument given to `check`. This alternative favors the question mark in large part because there are now 2 arguments.\r The original proposal states that there is a large readability difference in these two variants:\r \r ``` go\r check io.Copy(w, check newReader(foo))\r io.Copy(w, newReader(foo)?)?\r ```\r \r However, I think this is a matter of personal preference. Once there is a left-hand-side assignment, the readability opinion may also change.\r \r ``` go\r copied := check io.Copy(w, check newReader(foo))\r copied := io.Copy(w, newReader(foo)?)?\r ```\r \r Now lets add in a handlers and check our preference again.\r \r ``` go\r copied := check(io.Copy(w, check(newReader(foo), ahandler), bhandler)\r copied := io.Copy(w, newReader(foo) ? ahandler) ? bhandler\r ```\r \r I believe `?` will be slightly nicer to use due to\r * fewer parantheses\r * putting error handling solely on the right-hand-side rather than both the left and right.\r \r Note that it is also possible to put all the error handling on the left-hand-side of the error source.\r \r ``` go\r copied := check(bhandler, io.Copy(w, check(ahandler, newReader(foo)))\r ```\r \r But I prefer keeping error handling on the right-hand-side for two reasons\r * a success result is still transferred to the left\r * it is possible to write an anonymous handler rather than being forced to declare it ahead of time\r \r \r ## Appendix: built-in result type\r \r A go programmer that has used Rust, Swift, Haskell, etc will be missing a real result type.\r I would like to see a go 2 proposal for discriminated unions which includes a result type.\r However, I think both the original proposal and this alternative proposal would work fine with the addition of a result type.\r This is because go effectively already has a result type when dealing with errors. It is a tuple where the last member is of type `error`.\r \r A future version of go with discriminated unions should be able to use `?` for dealing with a discriminated union result type.\r \r \r ## Appendix: intermediate bindings for readability\r \r Error handling on the right-hand-side may increase line length undesirably or seem to be easy to miss. Its always possible to use an intermediate binding.\r \r ```\r v, err := f(...) // could be a million lines long\r err ? handler\r ```\r \r ## Appendix: left-hand-side\r \r It is possible to support placing the handler on the left-hand-side.\r \r ```\r v := handler ? f(...)\r ```\r \r This could make more sense for `check`. One of the ideas behind this would be to emphasize the handler, for example in the case where `f(...)` is an enormous expression (see above section on intermediate bindings which is another way to handle this).\r \r ## Appendix: returning the zero value\r \r This proposal does not allow for the defensive practice of returning `-1` as the success value, along with the error. Where `-1` is useful because zero or a positive number are an allowed value in the problem domain, so someone may notice a `-1` propagating. I don't think we need to support this use case for a few reasons:\r \r   * It is not generally applicable anyways (consider a `uint`).\r   * The contract of using the function is already that errors must be checked before looking at success values.\r   * There are standard linters (errcheck) that will warn people about ignoring errors: we should instead ship this ability with `go vet`.\r \r \r ## Appendix: all proposal examples re-written\r \r Below are the rest of the code snippets shown in the original proposal, transformed to this alternative proposal.\r \r ``` go\r func TestFoo(t *testing.T) {\r \thandlerFatal := func(err error) { t.Fatal(err) }\r \tfor _, tc := range testCases {\r \t\tx := Foo(tc.a) ? handlerFatal\r \t\ty := Foo(tc.b) ? handlerFatal\r \t\tif x != y {\r \t\t\tt.Errorf(\"Foo(%v) != Foo(%v)\", tc.a, tc.b)\r \t\t}\r \t}\r }\r \r func printSum(a, b string) error {\r \thandler := func(err error) error { fmt.Errorf(\"printSum(%q + %q): %v\", a, b, err) }\r \tx := strconv.Atoi(a) ? handler\r \ty := strconv.Atoi(b) ? handler\r \tfmt.Println(\"result:\", x + y)\r \treturn nil\r }\r \r func printSum(a, b string) error {\r \tfmt.Println(\"result:\", strconv.Atoi(x)? + strconv.Atoi(y)?)\r \treturn nil\r }\r \r func CopyFile(src, dst string) error {\r \thandlerBase := func(err error) error {\r \t\treturn fmt.Errorf(\"copy %s %s: %v\", src, dst, err)\r \t}\r \r \tr := os.Open(src) ? handlerBase\r \tdefer r.Close()\r \r \tw := os.Create(dst) ? handlerbase\r \thandlerWithCleanup := handlerBase.ThenErr(func(err error) {\r \t\tw.Close()\r \t\tos.Remove(dst) // (only if a check fails)\r \t})\r \r \tcheck io.Copy(w, r) ? handlerWithCleanup\r \tcheck w.Close() ? handlerWithCleanup\r \treturn nil\r }\r \r \r func main() {\r \thandlerAll := func(err error) error {\r \t\tlog.Fatal(err)\r \t}\r \r \thex := check ioutil.ReadAll(os.Stdin) ? handlerAll\r \tdata := check parseHexdump(string(hex)) ? handlerAll\r \tos.Stdout.Write(data)\r }\r ```", "meta": {"posReactions": "3", "negReactions": "2"}}
{"id": "COM640", "user": "PeterRK", "root": "ROOT64", "reply_to": "ROOT64", "timestamp": "2018-09-08T16:11:25Z", "text": "Operator ? looks less noticeable than \"check\".", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM641", "user": "gregwebs", "root": "ROOT64", "reply_to": "COM640", "timestamp": "2018-09-09T00:02:05Z", "text": "@PeterRK you might want to state whether that is a good or a bad thing! I am assuming it is a critique.\r\n\r\nOne advantage of this proposal is that it is not breaking any new ground, but instead following the lead of Rust (but adding a handler component). So we could survey Rust users to see if noticeably of `?` is a problem.\r\n\r\nAlthough I have a preference for `?`, I want to note that I would be perfectly happy with this proposal being accepted but modified to use `check` instead.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM642", "user": "networkimprov", "root": "ROOT64", "reply_to": "COM641", "timestamp": "2018-09-09T00:09:27Z", "text": "https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling.md#considered-ideas", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM643", "user": "PeterRK", "root": "ROOT64", "reply_to": "COM642", "timestamp": "2018-09-09T01:06:39Z", "text": "@gregwebs You are right. Less noticeable may be an advantage.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM644", "user": "gregwebs", "root": "ROOT64", "reply_to": "COM643", "timestamp": "2018-09-09T04:45:24Z", "text": "@networkimprov you are right I should explicitly talk about how the question mark was mentioned in \"considered ideas\". In that, the case is made for `check` rather than `?`. \r\nSome of those points are still valid with this proposal, and others are not. This is reviewed in the section \"Appendix: Operator versus check function\".\r\n\r\nI hope we can move the conversation from comparing `?` to `check` (either of which are acceptable to me) to the bigger picture of using regular functions instead of special stacking.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM645", "user": "networkimprov", "root": "ROOT64", "reply_to": "COM644", "timestamp": "2018-09-09T06:09:47Z", "text": "There is no doubt in my mind that the next proposal draft from the Go team will add named handlers (or a func type) and drop implicit handler chains, given the feedback to date. It might drop `check` altogether.\r\n\r\nHowever, that isn't enough IMO. My detailed critique: [Golang, how dare you handle my checks!](https://medium.com/@mnmnotmail/golang-how-dare-you-handle-my-checks-d5485f991289)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM646", "user": "deanveloper", "root": "ROOT64", "reply_to": "COM645", "timestamp": "2018-09-09T06:35:22Z", "text": "I'll say this a million times - I hate exiting from a function without a return. This should _never_ happen unless there is a catastrophic error (panic). Also, returning an error without adding on to the context should be discouraged. The unary `?` is just a bad idea for Go in general. (Both returning implicitly AND not adding context to the error)\r\n\r\nThe rest of the proposal is interesting, but I'm not sure how much I like the idea of the `?`. I think it means too many things in too many different languages, and it would add to the confusion. (Conditional operator (C), null-safe operation (Kotlin), Coallessing (C#), etc).\r\n\r\nI also feel like the built-in `check` function approach _feels_ more like Go. I like that better than the `?`. You guys discussed it being \"less noticable\" which is \"good\", but I'd say the opposite. It's the potential exit to a function, it _needs_ to be noticable to be maintainable.\r\n\r\nUsing `check(...)` instead of `?` also resolves your \"should we allow `break` and `continue` as the RHS? The answer: no.\r\n\r\nEither way, this shouldn't be about syntax, syntax can be rethought. Let's discuss the idea behind it.\r\n\r\nI think having different function signatures doing different things is an interesting idea, but I don't like it. I think it makes reading code confusing, especially at the call site (\"check site\"?) of the handler function. If I'm reading someone else's code, I don't want to have to scroll back up to the top of the function to see if my code continues or not. The nice thing about the `handle/check` construct is that you _know_ that _if the error is not nil, the function exits_.\r\n\r\nI do like this idea though. Those are my critiques, I like the rest of the proposal. The use of anonymous functions rather than handler blocks is a good idea in my book.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM647", "user": "deanveloper", "root": "ROOT64", "reply_to": "COM646", "timestamp": "2018-09-09T06:44:19Z", "text": "To expand on the whole function signature thing, here's what I mean:\r\n\r\n```go\r\nfunc errorProne() error {\r\n    handler := func(err error) {\r\n        fmt.Println(\"unimportant error occurred:\", err)\r\n    }\r\n\r\n    // 50 lines later\r\n\r\n    // My internal monologue:\r\n    // \"Does this function exit if there's an error,\r\n    // or does it continue execution?\"\r\n    f := check(os.Create(\"Foo\"), handler)\r\n}\r\n```\r\n\r\nAgain, in the `check/handle` made it clear: `if err != nil, the function will exit`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM648", "user": "PeterRK", "root": "ROOT64", "reply_to": "COM647", "timestamp": "2018-09-09T07:38:07Z", "text": "Error handling is a potential control flow changing point, so we care about it.\r\n\r\nThe design in original draft introduces a new control flow changing rule, what we call \"special stacking\" or \"chained handler\". That brings confusion more than convenience.\r\n\r\nSome guys, include me, suggest to use a new control flow changing mark with normal function as error handler. However, how to implement this mark is controversial.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM649", "user": "networkimprov", "root": "ROOT64", "reply_to": "COM648", "timestamp": "2018-09-09T08:14:32Z", "text": "A named catch block after check/?/etc does the trick nicely :-)\r\n```\r\n?outer f1() // or more Go-like: #outer = f()\r\nfor ... {\r\n   ?inner f2()\r\n   catch inner { ?outer fmt.Errorf(\"loop %v\", inner) } // no return\r\n}\r\ncatch outer { return fmt.Errorf(\"context %v\", outer) }\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6410", "user": "PeterRK", "root": "ROOT64", "reply_to": "COM649", "timestamp": "2018-09-09T08:51:50Z", "text": "@deanveloper I agree with that `if err != nil, the function will exit`. I believe exit on error is the common case. We should focus on the common case. If needing continue, just handle it with old style.\r\n\r\n@networkimprov @gregwebs  I know you guys want to figure out a solution covering all cases. I hope it will be a lightweight one. I think heavy solution is against the philosophy of GO. And the design in original draft is already too heavy to me. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6411", "user": "PeterRK", "root": "ROOT64", "reply_to": "COM6410", "timestamp": "2018-09-09T09:38:13Z", "text": "Error handling consists of handler and trigger.\r\nLet me ask some questions.\r\n\r\n1) Should trigger be bound with one or more handlers explicitly?\r\nIn the original draft, \"check\" is the trigger. It cannot be bound with any handler explicitly. So a matching rule is needed.\r\n\r\n2) Should handler be special or just a normal function?\r\n\r\n3) Should trigger be a filter or just a consumer?\r\n In the original draft, \"check\" is the filter. It take return values from child function, and filters out the error. But in code `_, #err := function()`, the trigger `#err` is just a consumer.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6412", "user": "networkimprov", "root": "ROOT64", "reply_to": "COM6411", "timestamp": "2018-09-09T10:06:23Z", "text": "In #27519 (#id/catch model), `#err = f()` filters for non-zero, as stated.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6413", "user": "PeterRK", "root": "ROOT64", "reply_to": "COM6412", "timestamp": "2018-09-09T10:19:35Z", "text": "@networkimprov I mean that filter can work with pipe.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6414", "user": "networkimprov", "root": "ROOT64", "reply_to": "COM6413", "timestamp": "2018-09-09T11:27:37Z", "text": "See link I posted above re \"critique\" for perspective on nesting calls that return error. (A \"pipe\" is an IPC or stream mechanism btw.)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6415", "user": "PeterRK", "root": "ROOT64", "reply_to": "COM6414", "timestamp": "2018-09-09T11:47:56Z", "text": "Good luck! @networkimprov ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6416", "user": "gregwebs", "root": "ROOT64", "reply_to": "COM6415", "timestamp": "2018-09-09T14:20:17Z", "text": "@deanveloper it seems you have misread the proposal. Perhaps I wrote too much, let me know how I can make the section on handler function types more clear. Currently it does state:\r\n\"A cleanup function will automatically be converted to return the original error that would have been passed to it.\"\r\n\r\nIf you write\r\n\r\n``` go\r\n    handler := func(err error) {\r\n        fmt.Println(\"unimportant error occurred:\", err)\r\n    }\r\n```\r\n\r\nWhen used as a handler, the error will still be passed along (see the section on `ThenErr` to show how this can be accomplished).\r\n\r\nIn this proposal, the usage of `check` or `?` always means that the function returns immediately if the error is not nil.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6417", "user": "gregwebs", "root": "ROOT64", "reply_to": "COM6416", "timestamp": "2018-09-09T14:53:54Z", "text": "@deanveloper thanks for critiquing adding `break/continue`. I removed that section now because I don't like the idea either and it seems to distract from the proposal rather than to clarify.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6418", "user": "deanveloper", "root": "ROOT64", "reply_to": "COM6417", "timestamp": "2018-09-09T15:12:46Z", "text": "Ah, I see. You are correct I did misread it, although now there's no explicit exit to the function. (See how that can get confusing to a reader? The function doesn't mark an exit, so I didn't think there was one)\r\n\r\nAnyway, there shouldn't be a special case to allow a developer to return the error which occurred without additional context. If they want to do that, they should do it explicitly with `return err`\r\n\r\nAlso, assuming you want to return the zero value for the other numbers is a dangerous game. For instance, let's say I wanted to write the following function:\r\n\r\n```go\r\n// Returns how many occurrences of find exist in the UTF8 encoded reader r\r\nfunc CountOccurences(r io.Reader, find string) (n int, err error)\r\n```\r\n\r\nIf an error occurs, I don't want to return `n=0` because 0 is a valid return value of my function, I'd want to return `n=-1`.\r\n\r\n`check/handle` does this well because the `return` in it's system actually returns to the function, so there's no assumptions about what you're trying to return.\r\n\r\nPerhaps the handler should always be in the form `(error) -> (parent function's return values)`. This kind-of destroys the idea of reusable handler generators (`ThenErr`), though.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6419", "user": "gregwebs", "root": "ROOT64", "reply_to": "COM6418", "timestamp": "2018-09-09T15:19:17Z", "text": "@bmeh (or anyone else that comes along), it would be great if you left your reason for the thumbs down.  The proposal has received a lot of useful critiques around the edge cases of language interaction. \r\nBut I actually have not yet seen a single critique of the core idea of this proposal, including outside this go 2 process where I have shown it to others.\r\n\r\n@networkimprov similarly, it would be great to see critical comments of the core idea here and leave promotions of your proposal on the github issue that is already open for that.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6420", "user": "networkimprov", "root": "ROOT64", "reply_to": "COM6419", "timestamp": "2018-09-09T18:15:21Z", "text": "I posted a link to a pure critique of check/handle, which largely applies to this proposal. It does not mention #id/catch. I urge you to read it.\r\n\r\nI mentioned a catch block here as a solution to the control flow issue raised above, and used a prefix variation of your `? handler` syntax with it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6421", "user": "gregwebs", "root": "ROOT64", "reply_to": "COM6420", "timestamp": "2018-09-09T21:51:12Z", "text": "@deanveloper zero values: thanks for bringing that up. This proposal is essentially for discriminated unions. That is, the non-error value should not exist. I know that use cases do exist for actually returning a tuple of two meaningful values. However, I believe they are rare enough (I have seen thousands of lines of go code that never do this) that it is a mistake to place them as a design constraint on an error handling system. One can still use one of two approaches:\r\n\r\n* use the existing style of error handling\r\n* use an error type that gives back the value you want\r\n\r\nThe latter looks something like this:\r\n\r\n``` go\r\ntype CountOccurencesError struct {\r\n    Count int\r\n    Err error\r\n}\r\nfunc (e CountOccurencesError) Error() string { return e.Err.Error() }\r\n\r\n// Returns how many occurrences of find exist in the UTF8 encoded reader r\r\nfunc CountOccurences(r io.Reader, find string) (n int, err CountOccurencesError)\r\n```\r\n\r\nI believe you do need generics to be able to return the concrete type through an error check.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6422", "user": "gregwebs", "root": "ROOT64", "reply_to": "COM6421", "timestamp": "2018-09-09T21:58:40Z", "text": "@deanveloper no unary form of the check: I would be okay with always requiring an error handler that adds context. But I thought always requiring a handler was probably too heavy-handed for a go community that is not already consistently doing that.\r\n\r\nIf you define a function `identity`, then you just have to write `? identity` if you don't want to add anything to an error. So keep in mind it is easy to subvert the intent.\r\n\r\nAn additional consideration is that some users may be satisfied enough by using stack traces that they don't feel the need to add context in every passing of an error.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6423", "user": "deanveloper", "root": "ROOT64", "reply_to": "COM6422", "timestamp": "2018-09-09T22:02:03Z", "text": "That's not what I'm trying to say here - what I'm saying is that the zero-value of `int` is meaningful in the `CountOccurences` function, so I would much rather return a `-1` to make it clear that the function doesn't return meaningful information if an error occurs.\r\n\r\nI want to be clear. I don't want the caller to see `0, err`, as it could be mistaken for \"zero occurrences were found before finding the following error\", I want them to see values from the function indicating that the function does not return useful information (other than the error) if an error occurs, which can be done by returning `-1, err`.\r\n\r\nMost of the time `0, err` works, but in my experience, returning `-1, err` is not an uncommon case", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM6424", "user": "gregwebs", "root": "ROOT64", "reply_to": "COM6423", "timestamp": "2018-09-09T22:40:36Z", "text": "@deanveloper sorry for missing your actual concern. I think your level of programming defensiveness is probably appropriate given the lack of discriminated unions in go and the prevalence of zero values. However, it seems not generally applicable (what if I have a `uint`?) and unnecessary. The contract is always that the caller must check the error value before looking at the success value. We shouldn't weaken this proposal because someone is going to ignore errors. There are linters that check for this (errcheck): it would be much more powerful to add that capability to `go vet` or otherwise have this statically checked.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6425", "user": "Azareal", "root": "ROOT64", "reply_to": "COM6424", "timestamp": "2018-09-10T01:37:02Z", "text": "I personally think that handle is sugar for goto rather than an anonymous function.\r\n\r\nIt seems to be doing this:\r\n```go\r\nfunc something() {\r\n    var __reservedVar error\r\n    {\r\n    errHandle:\r\n        return __reservedVar\r\n    }\r\n    blah, err := x()\r\n    if err != nil {\r\n        __reservedVar = err\r\n        goto errHandle\r\n        return\r\n    }\r\n}\r\n```\r\naka\r\n```go\r\nfunc something() {\r\n    handle err {\r\n        return err\r\n    }\r\n    blah := check x()\r\n}\r\n```\r\nIf you read it like that, the return makes perfect sense. Simplified example.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6426", "user": "deanveloper", "root": "ROOT64", "reply_to": "COM6425", "timestamp": "2018-09-10T03:51:23Z", "text": "> The contract is always that the caller must check the error value before looking at the success value\r\n\r\nThis is a very fair point. Although I think that `-1` is still a pretty common thing to return when an error occurs.\r\n\r\nI've said this before, I really like the proposal. It feels very Go-like (at least when using a `check` built-in function), which is hard to come by for proposals not from the Go team themselves.\r\n\r\nI added a +1. Sorry if it seems like I'm nitpicking it pretty hard, just want to make sure everything is considered, this is a really good proposal\r\n\r\n> I personally think that handle is sugar for goto rather than an anonymous function.\r\n\r\nYeah I was the same way. I saw `handle` as more of a goto than a function.\r\n\r\nAlthough both views work and I can see it going both ways. I think it personally makes more sense as a goto (it's how it probably works under the hood, AND just works better in general when it comes to how it returns).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6427", "user": "gregwebs", "root": "ROOT64", "reply_to": "COM6426", "timestamp": "2018-09-13T19:10:34Z", "text": "@deanveloper thanks for the :+1: thorough review, and the good questions!\r\nAlso, please help me promote usage of `errcheck`/`gosec` so that we don't have to bend over backwards with defensive coding practices!\r\n\r\n@ianlancetaylor is there a process to moving this proposal forward with more reviews?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6428", "user": "ianlancetaylor", "root": "ROOT64", "reply_to": "COM6427", "timestamp": "2018-09-13T19:28:45Z", "text": "There is a relatively slow moving Go2 proposal review process.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6429", "user": "ianlancetaylor", "root": "ROOT64", "reply_to": "COM6428", "timestamp": "2018-09-13T19:29:35Z", "text": "Let me expand on that to say that nothing is going to happen in a hurry.  We're going to take the time required to make changes that seem good.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT65", "user": "gubenkovalik", "root": "ROOT65", "reply_to": null, "timestamp": "2018-03-19T09:40:27Z", "text": "This is the worst framework i have ever seen. This is the worst framework i have ever seen.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM650", "user": "gubenkovalik", "root": "ROOT65", "reply_to": "ROOT65", "timestamp": "2018-03-19T09:43:40Z", "text": "I have real project with Angular, and the only thing i get while developing - is the hurting. Tons of hurt i get.\r\nYou need to be a creator of Angular to make a real successful project with Angular,", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM651", "user": "gubenkovalik", "root": "ROOT65", "reply_to": "COM650", "timestamp": "2018-03-19T09:46:21Z", "text": "Yes, Angular is very good if you're developing something not complicated more than \"Hello World\" application. But when you deal with real big scale project - the hurt is the only thing you get.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM652", "user": "zoechi", "root": "ROOT65", "reply_to": "COM651", "timestamp": "2018-03-19T09:47:26Z", "text": "Your issue doesn't contain a single bit of useful information anybody could act on.\r\nAt best the problem is that your expectations are wrong and you blame Angular instead of adjusting yourself,\r\nand the worse case is that you are just spreading spam.\r\nAngular works great for most. If it doesn't for you it's highly likely the problem is on your end.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM653", "user": "gubenkovalik", "root": "ROOT65", "reply_to": "COM652", "timestamp": "2018-03-19T09:53:55Z", "text": "@zoechi , your comment doesn't contain any information, that can help the situation, and from one side, i can understand you, but no one wants to get deep into it. just try to develop big project with angular and without. How many time would take both? Angular with consume at least 5x time more than if without Angular.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM654", "user": "gubenkovalik", "root": "ROOT65", "reply_to": "COM653", "timestamp": "2018-03-19T09:55:26Z", "text": "Angular - is the most perplexing.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM655", "user": "gubenkovalik", "root": "ROOT65", "reply_to": "COM654", "timestamp": "2018-03-19T09:55:49Z", "text": "Unnessesarily perplexed.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM656", "user": "zoechi", "root": "ROOT65", "reply_to": "COM655", "timestamp": "2018-03-19T09:56:12Z", "text": "There is no situation that needs help. \r\nYou need to stop acting like 3-year old.\r\nGrow up, get your sh*t together and stop spamming.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM657", "user": "gubenkovalik", "root": "ROOT65", "reply_to": "COM656", "timestamp": "2018-03-19T10:03:49Z", "text": "@zoechi, don't cry, contributor, you are not blame that you are into that sh*t", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM658", "user": "mlc-mlapis", "root": "ROOT65", "reply_to": "COM657", "timestamp": "2018-03-19T10:06:27Z", "text": "@gubenkovalik ... the reality is just opposite, it is the very suitable framework especially for real big projects. Just to guess, your problem is probably that you see it / try to use it by the same way as from jQuery point of view which is totally wrong way.\r\n\r\n> But when you deal with real big scale project - the hurt is the only thing you get.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM659", "user": "ocombe", "root": "ROOT65", "reply_to": "COM658", "timestamp": "2018-03-19T10:08:10Z", "text": "Hello, this is not the place to post this kind of message @gubenkovalik, I'm closing the topic. Please follow the [contributing](https://github.com/angular/angular/blob/master/CONTRIBUTING.md) guidelines if you want to post anything constructive.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6510", "user": "gubenkovalik", "root": "ROOT65", "reply_to": "COM659", "timestamp": "2018-03-19T10:09:05Z", "text": "Okay, close it, but still Angular remains to be better. Best wishes, contributors, im outtie...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT66", "user": "gunchleoc", "root": "ROOT66", "reply_to": null, "timestamp": "2018-12-26T10:33:26Z", "text": "Please remove Scottish Gaelic from the Google translate block Since my suggestion to remove the Google Translate block was shot down, could you please at least remove Scottish Gaelic (G\u00e0idhlig) from the language list?\r \r In order to produce intelligible results, Google Translate needs a huge bilingual corpus to run their statistic algorithms on. No such corpus exists for Scottish Gaelic, and we can't expect such a corpus to exist in the near future.\r \r I am not only worried about teaching people really really bad Gaelic, but we can expect misunderstandings and accidental NSFW content too.\r \r See https://github.com/LLK/scratch-blocks/issues/1615 for more info about the difficulties that minority languages have with machine translation.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM660", "user": "akerbeltz", "root": "ROOT66", "reply_to": "ROOT66", "timestamp": "2018-12-26T12:32:49Z", "text": "I agree, this is a terrible idea - at best, this should be a per-locale **opt-IN**. For many locales, especially the smaller ones, machine translation produces nothing but gibberish.\r\nMachine translation is intended as a gisting tool, by and large, and for some language combos (mostly large ones with huge corpora) it may function as a translation aid but for most, it's useless at best, an extra time cost at worst.\r\nIt will overall reduce the attractiveness of Scratch to educational establishments. There is no quick fix for localization.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM661", "user": "gunchleoc", "root": "ROOT66", "reply_to": "COM660", "timestamp": "2018-12-29T06:52:58Z", "text": "I think that a disclaimer would also be really helpful for those languages that will keep the translate block - it could act as a teaching opportunity. Something like this:\r\n\r\n> Translating to another language is difficult, and computers haven't quite mastered it yet. Only use this extension when trying to understand a project that was created in another language - you can remix it and add the translate block to your remix. We recommend that you do not publish such remixes. Do not use the translate block inside of _join_ blocks, because it will result in the wrong word order for some languages and you'll sound like Yoda. Please be aware that machine translation can produce offensive content by accident and that it will often contain grammar errors.\r\n\r\nA similar disclaimer could be added to published projects that contain translate blocks, to prevent misunderstandings.\r\n\r\nYou should also be aware that grammar errors in machine translation results can be detrimental to foreign language learning, because the grammar errors will imprint themselves on students' visual memories and these memory imprints are very hard to get rid of. For example, although I have been called \"as fluent as a Bard\" by native speakers, I still have difficulty with vowel length after over a decade of learning Gaelic, because I have seen too many texts where the accents on the vowels were missing.\r\n\r\nHere's a real-life example of machine translation grammar errors from the English -> German language pair. I have left the airport a note and they have now corrected it.\r\n\r\n![nach flugsteig gehen](https://user-images.githubusercontent.com/4095570/50534508-eb4b4500-0b3d-11e9-8d1c-ceb86a285b7d.jpg)\r\n![bitte warten an flugsteig](https://user-images.githubusercontent.com/4095570/50534509-eb4b4500-0b3d-11e9-9eb0-b5424a8fcc74.jpg)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM662", "user": "Kenny2github", "root": "ROOT66", "reply_to": "COM661", "timestamp": "2018-12-29T08:56:32Z", "text": "@gunchleoc I appreciate the sentiment, but you're getting a little extreme. Let's look over your proposed disclaimer:\r\n>Translating to another language is difficult, and computers haven't quite mastered it yet. Only use this extension when trying to understand a project that was created in another language\r\n\r\nRight off the bat, this is already very extreme. Why shouldn't you use the translate extension for a purpose other than this? Computers haven't quite mastered it, sure - but they're already very good, and 99% of the time translation errors are caused by GIGO rather than actual mistranslation.\r\n>you can remix it and add the translate block to your remix. We recommend that you do not publish such remixes.\r\n\r\nWhy not?? What's wrong with sharing your attempt at understanding another language?\r\n>Do not use the translate block inside of join blocks, because it will result in the wrong word order for some languages and you'll sound like Yoda.\r\n\r\nGood recommendation, but the \"you'll sound like Yoda\" is too informal for a disclaimer. And in many languages word order isn't as significant (e.g. Latin) and grammar is mostly determined by word endings, rather than order. Nothing wrong with using join blocks with languages like that. I think this should read something more like \"Pay attention to what language you're translating when putting the translate block inside join blocks. Sentences in some languages may have completely different meanings based on word order.\"\r\n> Please be aware that machine translation can produce offensive content by accident and that it will often contain grammar errors.\r\n\r\nCan produce offensive content by accident: yes. Often contain grammar errors: no. At least for Google Translate (which is, I believe, the API that the translate blocks run on), the grammar errors are few and far between. Most issues with machine translation are with prosidy and not syntax. Better to say that \"machine translation can contain grammar errors or offensive content by accident\".\r\n\r\nAs for your real-life examples: Scratch isn't going to be used in airport displays (if they are, I'd be quite shocked) and the \"an\"/\"am\" problem looks to be a transcription error rather than an error of the machine itself (like somebody said to the person typing, \"am Flugsteig\" but the \"m\" sounded like an \"n\").\r\n\r\nDon't get me wrong - I do agree that some languages should not be in here as there is too little to base machine translations on, and Scottish Gaelic fits that description - I just think your disclaimer is a little too strong, a little too scary, and a little inaccurate.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM663", "user": "gunchleoc", "root": "ROOT66", "reply_to": "COM662", "timestamp": "2018-12-30T09:30:39Z", "text": "The disclaimer is just a first draft collecting some ideas - of course, it can be further refined and rephrased.  I added it as a first basis for discussion and I am not expecting anybody to implementing it just like that verbatim. I do think it is important that we do add some form of disclaimer though ;)\r\n\r\n> Why not?? What's wrong with sharing your attempt at understanding another language?\r\n\r\nBecause other children will assume that it is correct language and learn the mistakes. Such mistakes are very difficult to unlearn. Chances are very high that a child will create a language teaching project using the translate block for languages that the child doesn't speak, just because it's fun. We can't expect the child to understand the implications without any explanation, because in my experience even many adults don't.\r\n\r\nYou're thinking in terms of teaching computing, but we need to look at the bigger picture here and think about the consequences for language teaching too. I just told a language teacher I know about the translate block and she immediately started verbally pulling her hair out before I even had a chance to finish explaining how it's used. She immediately brought up the point that mistakes that have been learned are very hard to unlearn. So, I am not the only person on the planet who is concerned about this.\r\n\r\n> \"Pay attention to what language you're translating when putting the translate block inside join blocks. Sentences in some languages may have completely different meanings based on word order.\"\r\n\r\n+1, a lot better than what I wrote :)\r\n\r\n>  the grammar errors are few and far between\r\n\r\nJudging from the real-life airport example, the grammar error rate there is ~50%. I would not call that \"few and far between\" - and this is for 2 very closely related languages. Of course, your mileage will vary with language pair used and content translated. There will probably be a lot less errors when translating German -> English than translating English -> German because English has less grammar markers. For example, German \"Kopie\" and \"Kopieren\" both translate as \"Copy\" into English.\r\n\r\n> Scratch isn't going to be used in airport displays\r\n\r\nOf course not! But both are using Google Translate, which still produce identical output, no matter whether somebody sticks it on an airport sign or into Scratch.\r\n\r\n>  the \"an\"/\"am\" problem looks to be a transcription error\r\n\r\nIt might look like that for non-German speakers, but it is not. It is a Dative/Accusative case distinction. Any German teacher would mark this as a grammar error and never as a typo.\r\n\r\n> I do agree that some languages should not be in here as there is too little to base machine translations on, and Scottish Gaelic fits that description\r\n\r\nThanks :)\r\n \r\n> I just think your disclaimer is a little too strong, a little too scary, and a little inaccurate.\r\n\r\nIt's just a first draft, and suggestions for improvements like you made are very welcome in my book!\r\n\r\nAnd don't get me wrong, Google Translate itself is a very useful tool, and it will only become harmful if misused. So, I think we do have the responsibility to teach children how to use it properly, since we're offering them the tool directly.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM664", "user": "rprys", "root": "ROOT66", "reply_to": "COM663", "timestamp": "2018-12-31T10:32:56Z", "text": "I support the idea that Google Translate should be an opt-in and have an explicit warning about how correct the translation would be. It could be very embarrassing for a student to get it very wrong!\r\nGoogle Translate is pretty good for English to Welsh from my experience, it's correct about 60-70% of the time. That means that there is plenty of scope for errors, howlers and embarrassment in using machine translation.  Try some of these: https://www.flickr.com/groups/scymraeg/\r\nGoogle Translate, like Microsoft Translate seems to be better with longer sentences and in Welsh because it's based on formal, bureaucratic documents it's in a more formal style than would be appropriate for Scratch.\r\nI would be very cautious about encouraging it's use with students who are not fluent in their use of the translated language.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM665", "user": "Kenny2github", "root": "ROOT66", "reply_to": "COM664", "timestamp": "2019-01-01T08:51:28Z", "text": "Google Translate *is* an opt-in by virtue of the fact that it's an extension! If you don't explicitly include the extension, you can't use the blocks and have therefore not opted in. By including the extension, you are obviously showing that you are opting in to using the extension. A disclaimer is necessary but should not be obtrusive.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM666", "user": "gunchleoc", "root": "ROOT66", "reply_to": "COM665", "timestamp": "2019-01-01T10:17:33Z", "text": "This is a different type of opt-in though. We should not shift the hard decision making to the children, that's not fair on them. The responsibility is ours, not theirs.\r\n\r\nBy all means, keep the block with a disclaimer for those language pairs where the error rate is extremely low. I'd still like to have my locale removed though, because gibberish translations are no use to everybody, and we will be unintentionally teaching this gibberish.\r\n\r\nThe disclaimer should also be short ( a lot shorter than my draft) to make it easy to read. Otherwise, kids will just go tl;dr on it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM667", "user": "akerbeltz", "root": "ROOT66", "reply_to": "COM666", "timestamp": "2019-01-29T23:30:50Z", "text": "> but they're already very good, and 99% of the time translation errors are caused by GIGO rather than actual mistranslation.\r\n\r\nEh, sorry but where are you getting these figures from? Even for a language pair like German <> English for which Google must have a lot of data aren't even close to 99%, that's just a figure you made up to make it sound like a good idea. To begin with, you cannot make a blanket statement about how accurate MT translation is without specifying the language pair you're talking about. I don't know what your language skills are but it's a common mistake by English speakers to assume that because GT does an ok job INTO English, the reverse is also true. It isn't. English happens to be a fairly uninflected language with little morphology, which makes it relatively easy for MT. But try going FROM English to something like German with 4 cases and 3 genders, it gets a whole lot harder straight away.\r\n\r\nSecondly, the quality of MT depends hugely on the domain. For instance, for medical stuff, German <> English is pretty good. Put in a novel, you get vastly different results. If you look at the research, even for something fairly simply as medical texts accuracy has been measured as low as [45-46%](https://cedar.wwu.edu/cgi/viewcontent.cgi?article=1060&context=wwu_honors) (into African and Asian languages). So no, not even close to 99%. Making up figures is not good form.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM668", "user": "thisandagain", "root": "ROOT66", "reply_to": "COM667", "timestamp": "2019-01-29T23:39:33Z", "text": "Thanks for all the feedback on this folks. We are working on developing landing pages for each extension and will add some information that clarifies the accuracy of machine translation on the \"Translate\" extension page based on all of your feedback. Thanks.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT67", "user": "hannahhoward", "root": "ROOT67", "reply_to": null, "timestamp": "2018-08-30T15:02:32Z", "text": "Open an RFC to discuss decision to revert License and remove Jamie While choosing to close https://github.com/lerna/lerna/issues/1635 @TheLarkInn writes:\r \r ```\r Ben I'm going to close this issue, in favor or a more structured, RFC style of a proposal for what decisions you are questioning. Thanks! We don't have a template RFC format, or spec template, but hopefully looking to have one once we catchup and dust settles.\r ```\r \r It's not clear what specifically such an RFC would look like, and what it's format would take. Since then no issue has been opened.\r \r This issue is simply to register there is dissent among a portion of Lerna users about the decision of the core team to revert Jamie's license change and remove him from the project until an RFC can be opened. \r \r It is precisely the time when people are paying attention when discussion is necessary, when a wider group of perspectives can be heard.", "meta": {"posReactions": "29", "negReactions": "6"}}
{"id": "COM670", "user": "shushugah", "root": "ROOT67", "reply_to": "ROOT67", "timestamp": "2018-08-30T15:35:37Z", "text": "My simple question, given the lack of due discussion for the previously MIT license modification, would the maintainers be open to a new PR with legally more robust language along with input from the community?\r\n\r\nI definitely think the previous process was rushed, but the core idea is worth exploring. ", "meta": {"posReactions": "14", "negReactions": "24"}}
{"id": "COM671", "user": "hannahhoward", "root": "ROOT67", "reply_to": "COM670", "timestamp": "2018-08-30T15:53:13Z", "text": "@catcher-in-the-try I disagree. It is relevant for two reasons:\r\n\r\n1. There is significant dissent about the decision to revert the changes in the Licenses and remove Jamie, and an RFC was suggested as a mechanism for discussion, but does not exist. This is a placeholder to simply register there is unaddressed dissent and a promise of a future conversation.\r\n\r\n2. There seems to be a fear of having a discussion while things are \"heated\" -- I would argue that this is a good time to have discussion, as it's the time when there is likely to be the widest set of perspectives and the most voices are likely to be heard.", "meta": {"posReactions": "15", "negReactions": "0"}}
{"id": "COM672", "user": "benwiley4000", "root": "ROOT67", "reply_to": "COM671", "timestamp": "2018-08-30T16:02:48Z", "text": "Calls for \"civility\" and \"cooling down\" are invariably intended to cease discussion, not enhance it. Hannah's right - the time to discuss is now.", "meta": {"posReactions": "17", "negReactions": "5"}}
{"id": "COM673", "user": "nls0", "root": "ROOT67", "reply_to": "COM672", "timestamp": "2018-08-30T16:26:54Z", "text": "If you want to restrict who can use lerna, then lerna can no longer be called free; it will be proprietary. Please let everyone know with advance notice so they can make preparations to move away from it if it's going to become proprietary software.", "meta": {"posReactions": "9", "negReactions": "1"}}
{"id": "COM674", "user": "benwiley4000", "root": "ROOT67", "reply_to": "COM673", "timestamp": "2018-08-30T16:37:13Z", "text": "I don't think anyone's particularly heated, just excited to talk about this. \ud83d\ude42", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM675", "user": "darthtrevino", "root": "ROOT67", "reply_to": "COM674", "timestamp": "2018-08-30T16:46:22Z", "text": "I see these as two separate issues. If the community and the maintainers want to use a modified MIT license, that is fully within their right. However, Jamie's behavior was plainly abusive and in violation of the CoC.", "meta": {"posReactions": "17", "negReactions": "0"}}
{"id": "COM676", "user": "hallister", "root": "ROOT67", "reply_to": "COM675", "timestamp": "2018-08-30T17:37:28Z", "text": "Jamie's removal was a necessity and shouldn't be open for debate. Blocking people from contributing because they disagreed, which eventually lead to him blocking everyone but contributors, attacking companies/individuals, claiming community tools (like Babel) are \"his\" is overwhelming evidence that he violated the CoC.\r\n\r\n@benwiley4000 Calls for civility are perfectly apt after an issue like this. Suggesting that asking people to \"be nice\" is an attempt at ending discussion is one of the strangest stretches I've ever heard. As someone that called maintainers cowards for reverting the changes and removing Jamie, I can get a strong sense of why you'd argue that point, however.\r\n\r\nAs for this issue, @TheLarkInn made it pretty clear that they'd like to wait for the dust to settle prior to a formal RFC. That makes sense. Right now Lerna is a target for people only interested in politics, and once the dust settles they will likely have something new to chase, and the people actually interested in the project can contribute to the suggested RFC.", "meta": {"posReactions": "20", "negReactions": "2"}}
{"id": "COM677", "user": "hannahhoward", "root": "ROOT67", "reply_to": "COM676", "timestamp": "2018-08-30T17:58:48Z", "text": "\"Right now Lerna is a target for people only interested in politics\" -- I am a professional coder. I am interested in code. I am also interested in politics, FWIW. Given the original issue was a political one, it seems particularly important that a wide variety of political perspectives are included. To wait until there is a safe space for those \"only interested in code\" excludes a variety of political views, as the idea that politics and code can and should be separate is itself a political position that many disagree with.\r\n\r\nI am not personally prepared to say Jamie's removal is a settled issue because the announcement he is being removed does not include any accounting or transparency on what specific violations the maintainers feel occurred. But I agree it is a separate question, except in as much the maintainers announced it in the same PR where they reverted the license change, suggesting they consider the two issues intertwined.", "meta": {"posReactions": "10", "negReactions": "1"}}
{"id": "COM678", "user": "hannahhoward", "root": "ROOT67", "reply_to": "COM677", "timestamp": "2018-08-30T18:00:42Z", "text": "@catcher-in-the-try making a fork suggests you are engaging in this discussion in bad faith, and would simply like people who have a different viewpoint to go away.", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM679", "user": "hallister", "root": "ROOT67", "reply_to": "COM678", "timestamp": "2018-08-30T18:13:11Z", "text": "@hannahhoward \r\n> Given the original issue was a political one, it seems particularly important that a wide variety of political perspectives are included. To wait until there is a safe space for those \"only interested in code\" excludes a variety of political views, as the idea that politics and code can and should be separate is itself a political position that many disagree with\r\n\r\nIf the broader open-source community wants to discuss the politics of this, they should do so in a forum that makes sense. The Lerna repo isn't that forum. This repo is intended for end-users and maintainers of the project. As such, decisions about the goals and motivations of the project should be made by the Lerna community.\r\n\r\n> I am not personally prepared to say Jamie's removal is a settled issue because the announcement he is being removed does not include any accounting or transparency on what specific violations the maintainers feel occurred. \r\n\r\nI realize some people feel like open source maintainers need to write books for every decision they make, but I disagree. It was decided by multiple maintainers that he violated the CoC. That's subjective, absolutely, but debating the issue to death isn't suddenly going to give us objectivity. ", "meta": {"posReactions": "2", "negReactions": "1"}}
{"id": "COM6710", "user": "mAAdhaTTah", "root": "ROOT67", "reply_to": "COM679", "timestamp": "2018-08-30T19:42:42Z", "text": "The purpose isn't objectivity, it's transparency.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6711", "user": "benwiley4000", "root": "ROOT67", "reply_to": "COM6710", "timestamp": "2018-08-30T19:58:40Z", "text": "@hallister Justin your implication that commenters have no relation to Lerna is unsubstantiated. I for one am actively involved in the ecosystem surrounding Lerna and have been preparing to add Lerna to a project I maintain, although I am now considering alternative options.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM6712", "user": "hallister", "root": "ROOT67", "reply_to": "COM6711", "timestamp": "2018-08-30T20:07:17Z", "text": "> The purpose isn't objectivity, it's transparency.\r\n\r\nLet's test if that's the actual goal\r\n\r\n> Examples of unacceptable behavior by participants include the use of sexual language or imagery, derogatory comments or *personal attacks*, *trolling*, public or private harassment, *insults*, or other unprofessional conduct.\r\n\r\n(Emphasis added by me)\r\n\r\n> personal attacks... insults\r\n\r\nPer https://github.com/palantir/blueprint/issues/2877\r\n\r\n>> Palantir employees are racist\r\n\r\nI could probably stop here. That's enough for removal. Full stop.\r\n\r\n> trolling\r\n\r\n* Blocking people on the lerna repository that politely called him out.\r\n* Blocking all non-contributors on the repo from posting issues/comments/PR's\r\n\r\nPer https://github.com/lerna/lerna/issues/1628\r\n\r\n* Suggesting he may not do a major version bump\r\n\r\nThis is in addition to his horrible conduct in every issue posted regarding adding his company restrictions to the MIT license. That's pretty transparent. That's pretty objectively trolling, personal attacks and insults. Now the question is, do you really want transparency, or are you looking for a fight?", "meta": {"posReactions": "10", "negReactions": "3"}}
{"id": "COM6713", "user": "hallister", "root": "ROOT67", "reply_to": "COM6712", "timestamp": "2018-08-30T20:13:14Z", "text": "@benwiley4000 \r\n> Justin your implication that commenters have no relation to Lerna is unsubstantiated. \r\n\r\nI made no such implication. I said, quite explicitly, that Lerna is currently a target for those disinterested in the project and overly interested in the politics. By waiting for the dust to settle, we can ensure that any RFC is targeting the actual community. I'm not suggesting that everyone that supported Jamie is a troll, I'm saying that right now Lerna is going to attract them. Wait a few days and they'll be busy trolling someone else so we can get active interest in the discussion, including those that disagree with reverting the change. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6714", "user": "jwietelmann", "root": "ROOT67", "reply_to": "COM6713", "timestamp": "2018-08-30T20:18:13Z", "text": "Re: \"cooling off\" and \"people interested only in politics\"...\r\n\r\nI'm seeing an extremely ill-informed opinion being bandied about that implies the current state of open source is apolitical. FSF was founded on some radically collectivist ideals. OSI on more radically libertarian ones. \"Open source principles\" are what they are because people planted the flag and did the work to make them that way. The reason this project is MIT instead of GPL in the first place is because of decades of ideological debate and changes in community expectations.\r\n\r\nPlanting a different flag and doing a different thing is not more or less political than the status quo. To suggest otherwise is ahistorical nonsense. It's not more political; it's merely more participatory.\r\n\r\nI'm simultaneously intrigued by the effort to change the license and skeptical of what its effects might be. Maybe reverting was a good idea! It would have for sure been _more interesting_ to see the experiment run its course, but I understand the fear to the health of the project that makes someone walk it back.\r\n\r\nOf course this attracted wider attention. Of course people who were otherwise mostly foreign to lerna were intrigued and came running. You were doing something mad and exciting and extremely political. A big project was finally taking an ethical question and putting it front and center and saying \"Yeah, it's time to talk about this.\"\r\n\r\nPost-blowback, you don't wanna be political pioneers anymore. And who does? A) It's hard, and B) that's not how most of us want to spend our OSS time.\r\n\r\nIf you're overwhelmed, frazzled, can't handle being the center of this ethical discussion you started, and just want to be left alone to code now... You could just say so? I mean that completely earnestly. It's okay to get in over your head and ask to be let back out. At least _I_ think so.", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM6715", "user": "hannahhoward", "root": "ROOT67", "reply_to": "COM6714", "timestamp": "2018-08-30T20:20:46Z", "text": "@hallister transparency for a decision comes from the people who made the decision. Right now what we have is:\r\n\r\n```\r\nDespite his numerous (and appreciated) contributions in the past, it has been very clear for quite some time now that he has decided to cease making constructive contributions to the Lerna codebase as well as actively and willfully disregarding the code of conduct that he himself added to the project.\r\n```\r\n\r\nYou and I can quibble indefinitely over whether the things you posted are actually CoC violations. The point is neither of us are maintainers.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM6716", "user": "hannahhoward", "root": "ROOT67", "reply_to": "COM6715", "timestamp": "2018-08-30T20:23:53Z", "text": "@jwietelmann really amazing point.\r\n\r\nthe fear seems to be if we open ourselves to political discussions how will we get our important professional work done.... but the very idea that open source/FSF is the domain where important money making professional work gets done, not where academic and politically radical weirdos hang out in their spare time, is pretty darn new. And that we're at this point it's the work of fairly intense political advocacy and organizing.", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM6717", "user": "evocateur", "root": "ROOT67", "reply_to": "COM6716", "timestamp": "2018-08-30T20:39:23Z", "text": "Please have patience with me. I don't have a lot of spoons right now, between dealing with an unprecedented (for me) deluge of Twitter notifications and staving off suicidal ideation.", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM6718", "user": "shushugah", "root": "ROOT67", "reply_to": "COM6717", "timestamp": "2018-08-30T20:42:46Z", "text": "FWIW @jwietelmann is right that Lerna is getting much attention, eg see this Vice motherboard news article. I did not know about this project myself till I saw the debate. \r\nhttps://motherboard.vice.com/en_us/article/8xbynx/major-open-source-project-revokes-access-to-companies-that-work-with-ice", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6719", "user": "TheLarkInn", "root": "ROOT67", "reply_to": "COM6718", "timestamp": "2018-08-30T20:46:30Z", "text": "@hannahhoward \r\n\r\n> This issue is simply to register there is dissent among a portion of Lerna users about the decision of the core team to revert Jamie's license change and remove him from the project until an RFC can be opened.\r\n\r\nThank you for speaking up and registering your dissent and representing the dissent of like-minded Lerna users. \r\n\r\nAs an open source project we have every right to provide no reason for his removal. \r\n\r\nHowever, as stewards of transparency, trust, and care for our users and the lerna ecosystem, we will provide clarity.\r\n\r\nAccording to the current Lerna Code of Conduct:\r\n\r\n> Examples of unacceptable behavior by participants include the use of sexual language or imagery, derogatory comments or personal attacks, trolling, public or private harassment, insults, or other unprofessional conduct.\r\n\r\nAdditionally our rights as Org Members of the project for handling unacceptable behavior which do not align with the current Code of Conduct.\r\n\r\n> Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct. Project maintainers who do not follow the Code of Conduct may be removed from the project team. \r\n\r\nThese are the segments of the current lerna Code of Conduct that justify our decisions made to revoke all of James involvement and ownership privileges over this GitHub Organization. \r\n\r\nIn multiple GitHub issues (if you need me to cite them, I will do so but in additional comments or edits from this response), on Twitter [important to note he claims ownership of lerna in this context making him profesionally represented and in the capacity of a maintainer] acts in a very unprofessional, rude, and harassing manner.\r\n\r\nThese also have been occurring since July which @evocateur official states in our license change PR #1633 that we made a mistake in this regard to not address earlier violations in a swift and timely manner. \r\n\r\nAs a core team, going forward, we want to not only protect the interest of the project itself, but also the transparency of the project. And that means we need to adopt a much less vague, less interpretive, and more structured Code of Conduct. For that we have open up #1636 per request (I on twitter officially asked Coraline to create this issue).\r\n\r\nOn behalf of the core team who is all actively monitoring this issue, I hope it provides the clarity that you are seeking. Thank you for sticking up for a transparent and responsible process. \r\n\r\n_Note: @hannahhoward once you have your clarifications received (even if you don't explicitly request them), would you confirm your question has been answered? That way I can prevent thread abuse by locking and maintainers can add cited incidents in the issue._", "meta": {"posReactions": "10", "negReactions": "0"}}
{"id": "COM6720", "user": "benwiley4000", "root": "ROOT67", "reply_to": "COM6719", "timestamp": "2018-08-30T20:51:42Z", "text": "Cannot speak for @hannahhoward or others but @TheLarkInn I think where I need additional clarity is:\r\n* Why did you decide to revert the license change despite maintainers having originally been involved in approving it?\r\n* Why did you choose to link Jamie's dismissal with the license change?\r\n* Why did you open a pull request to remove your own employer (Microsoft) from the restricted list?", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM6721", "user": "nls0", "root": "ROOT67", "reply_to": "COM6720", "timestamp": "2018-08-30T20:55:50Z", "text": "https://github.com/palantir/tslint/issues/4132\r\nhttps://github.com/palantir/tslint/issues/4141\r\nhttps://github.com/palantir/blueprint/issues/2870\r\nhttps://github.com/palantir/blueprint/issues/2876\r\nhttps://github.com/palantir/blueprint/issues/2877\r\n\r\nWhy did he keep opening so many issues, harassing other people and why did he repeatedly refer to these free software projects that many people have contributed to as \"my tools\"? Is all the code his property? Are all the contributions by everyone else worthless?\r\n\r\n\"I kinda hope they do try to keep using **my** tools though\" - From the motherboard article, emphasis added\r\n\"Also, stop using my tools (such as Babel)\" - from /palantir/tslint/issues/4132\r\n\r\nBabel is his property as well? Can someone help my understand why these are his property? Thanks.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM6722", "user": "mAAdhaTTah", "root": "ROOT67", "reply_to": "COM6721", "timestamp": "2018-08-30T21:12:19Z", "text": "@nls0 Those questions aren't relevant to the thread. You'd have to ask Jamie himself.", "meta": {"posReactions": "4", "negReactions": "5"}}
{"id": "COM6723", "user": "TheLarkInn", "root": "ROOT67", "reply_to": "COM6722", "timestamp": "2018-08-30T21:22:19Z", "text": "> Why did you decide to revert the license change despite maintainers having originally been involved in approving it? \r\n\r\nI did not decide to revert the license change, I approved it. This decision was made by @evocateur and his resoning is very clear in #1633. \r\n\r\n> Why did you choose to link Jamie's dismissal with the license change?\r\n\r\nI did not link Jamie's dismissal. @evocateur explained his reasoning in #1633\r\n\r\n> Why did you open a pull request to remove your own employer (Microsoft) from the restricted list?\r\n \r\nI thought Microsoft was being treated unfairly and wanted to set the story straight. ", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM6724", "user": "nls0", "root": "ROOT67", "reply_to": "COM6723", "timestamp": "2018-08-30T21:42:02Z", "text": "@mAAdhaTTah Those questions are relevant to the thread. Read the title of the thread.\r\n\r\nEdit: Since some people like @mAAdhaTTah don't seem to understand the relevance of the questions, here is the relevant part of the title: \"Open an RFC to discuss decision to ... remove Jamie\"\r\n\r\nIf you can't answer the questions, that's answer enough for this thread.", "meta": {"posReactions": "1", "negReactions": "3"}}
{"id": "COM6725", "user": "benwiley4000", "root": "ROOT67", "reply_to": "COM6724", "timestamp": "2018-08-30T21:43:06Z", "text": "@TheLarkInn:\r\n\r\n> This decision was made by @evocateur and his resoning is very clear in #1633.\r\n\r\nI disagree that this is very clear:\r\n\r\n\"the impact of this change was almost 100% negative, with no appreciable progress toward the ostensible goal aside from rancorous sniping and harmful drama.\"\r\n\r\nThe claims made here are not supported by evidence or arguments.\r\n\r\n> I did not link Jamie's dismissal. @evocateur explained his reasoning in #1633\r\n\r\nThis was the plural \"you\" here, as in \"you, the maintainers.\" In any case, I still don't understand why Jamie's dismissal was linked as part of the same announcement, clearly implying that his dismissal had to do with his introduction of the modified MIT license.\r\n\r\n> I thought Microsoft was being treated unfairly and wanted to set the story straight.\r\n\r\nRespectfully, given the conflict of interest between your role as a maintainer and your role as a Microsoft employee, I think you should have sat out of that decision. It certainly appears to many as though your loyalty to your employer influenced the revert back to the old license.", "meta": {"posReactions": "5", "negReactions": "8"}}
{"id": "COM6726", "user": "evocateur", "root": "ROOT67", "reply_to": "COM6725", "timestamp": "2018-08-30T21:51:13Z", "text": "> It certainly appears to many as though your loyalty to your employer influenced the revert back to the old license.\r\n\r\nIt did not. Please stop repeating this baseless canard.", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM6727", "user": "benwiley4000", "root": "ROOT67", "reply_to": "COM6726", "timestamp": "2018-08-30T21:53:27Z", "text": "@evocateur this is transparently absurd. You can't just say \"I'm not influenced by the company who pays me\" and thus make it so. I sometimes laugh at the Twitter refrain of \"tech workers need to be trained in ethics,\" but perhaps it's true.", "meta": {"posReactions": "1", "negReactions": "2"}}
{"id": "COM6728", "user": "evocateur", "root": "ROOT67", "reply_to": "COM6727", "timestamp": "2018-08-30T21:53:29Z", "text": "@benwiley4000 If you're looking for \"rancorous sniping and harmful drama\" you might try using a mirror.", "meta": {"posReactions": "13", "negReactions": "2"}}
{"id": "COM6729", "user": "evocateur", "root": "ROOT67", "reply_to": "COM6728", "timestamp": "2018-08-30T21:55:02Z", "text": "Explain how me, the person who made the decision, not employed by Microsoft, was secretly paid by Microsoft to ruin open source. Should be an amusing story.", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "ROOT68", "user": "Hixie", "root": "ROOT68", "reply_to": null, "timestamp": "2021-01-27T19:48:17Z", "text": "My app is slow or missing frames (metabug) This is a meta-issue to track reproducible reports of jank in Flutter apps.\r \r If you are experiencing jank in your app:\r \r 1. Try to reproduce the problem in a test app. Either run `flutter create janktest` and recreate the situation you are experiencing in that app, or clone your app and delete code until you have the jank reproducing with a single .dart file.\r \r 2. [File a bug](https://github.com/flutter/flutter/issues/new?assignees=&labels=created+via+performance+template&template=5_performance_speed.md&title=) and include your .dart file demonstrating the problem. If you need more than just a .dart file (for example, assets are needed to reproduce the issue, or plugins/packages are needed to reproduce the issue) then create a GitHub repository and upload the app there.\r    Make sure to include the `flutter doctor -v` output and any logs from `flutter run` and `flutter analyze`.\r \r 3.  Switch flutter to master channel and run this app on a physical device using profile mode with Skia tracing enabled, as follows:\r        `flutter channel master`\r        `flutter run --profile --trace-skia`\r \r      The bleeding edge master channel is encouraged here because Flutter is constantly fixing bugs and improving its performance. Your problem in an older Flutter version may have already been solved in the master channel.\r \r 4.  Record a video of the performance issue using another phone so we can have an intuitive understanding of what happened. Don\u2019t use \"adb screenrecord\", as that affects the performance of the profile run. Attach the video to your bug.\r \r 5.  Open Observatory and save a timeline trace of the performance issue so we know which functions might be causing it. See \"How to Collect and Read Timeline Traces\" on this blog post:\r        https://medium.com/flutter/profiling-flutter-applications-using-the-timeline-a1a434964af3#a499\r     Make sure that the performance overlay is turned OFF while recording the trace.\r     Attach the JSON file containing your trace to your bug. You may also wish to include a screenshot of the part of the trace showing the problem you are seeing, just so that people can see at a glance what kind of performance issue the bug is about.\r \r 6. Mention _this_ bug in your bug, so that GitHub includes a link to it here.\r \r Please avoid commenting on this bug. Keep each issue separate so that we can examine each specific problem individually. Having one issue that contains comments about multiple problems make the issue intractable.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM680", "user": "goderbauer", "root": "ROOT68", "reply_to": "ROOT68", "timestamp": "2021-01-28T22:43:33Z", "text": "May be worthwhile to note that the performance overlay from step 3 should be turned off again when recording the trace in observatory in step 5 as that messes with performance.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM681", "user": "dnfield", "root": "ROOT68", "reply_to": "COM680", "timestamp": "2021-01-29T21:28:21Z", "text": "The performance overlay is probably not the best thing to recommend here - it actually does incur some performance overhead itself, and on some GPUs it's notable how much. It'd be best to just run the tracing and read that.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM682", "user": "kf6gpe", "root": "ROOT68", "reply_to": "COM681", "timestamp": "2021-02-08T18:24:26Z", "text": "Triage: Adding team labels so this doesn't come up on the \"untriaged\" report.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM683", "user": "Hixie", "root": "ROOT68", "reply_to": "COM682", "timestamp": "2022-06-09T02:14:51Z", "text": "Since we created the performance issue template in issue creation, this hasn't ended up finding any use, so I'm going to close it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM684", "user": "maheshmnj", "root": "ROOT68", "reply_to": "COM683", "timestamp": "2022-08-18T13:30:20Z", "text": "This meta issue has been so useful for the triage team. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM685", "user": "Hixie", "root": "ROOT68", "reply_to": "COM684", "timestamp": "2022-08-18T22:03:21Z", "text": "@maheshmnj good to hear! in what way?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM686", "user": "maheshmnj", "root": "ROOT68", "reply_to": "COM685", "timestamp": "2022-08-19T13:22:46Z", "text": "It has helped us when triaging performance issues to attach the timeline trace with the triage response and it also acts as a nice guide to point to authors of the issue and everyone else. \r\n\r\nSome sample comments where it has helped us\r\n\r\nhttps://github.com/flutter/flutter/issues/104709#issuecomment-1139451006\r\n\r\nhttps://github.com/flutter/flutter/issues/87811#issuecomment-900019236 (I got to know about this issue here)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT69", "user": "Humberd", "root": "ROOT69", "reply_to": null, "timestamp": "2019-12-19T10:18:30Z", "text": "Please remove the black theme, because it's offensive to me When I was young our village was invaded and robbed at night and since then I am afraid of going out anywhere when it's getting darker. VS Code dark theme reminds me of this situation, so please remove it immediately, because for me dark theme = death.", "meta": {"posReactions": "164", "negReactions": "7"}}
{"id": "COM690", "user": "shakeyourbunny", "root": "ROOT69", "reply_to": "ROOT69", "timestamp": "2019-12-19T10:27:22Z", "text": "In addition, it reminds me of black people lurking around.\r\n\r\nMicrosoft scares me by forcing people to use this theme.", "meta": {"posReactions": "14", "negReactions": "3"}}
{"id": "COM691", "user": "Humberd", "root": "ROOT69", "reply_to": "COM690", "timestamp": "2019-12-19T10:29:34Z", "text": "Please don't laugh. This is a serious issue for me. I want to force removal of the feature for everyone, because it hurts my feelings. And no, don't make a toggle for it. It would remind me that a death is still there, but not visible.", "meta": {"posReactions": "59", "negReactions": "3"}}
{"id": "COM692", "user": "Humberd", "root": "ROOT69", "reply_to": "COM691", "timestamp": "2019-12-19T10:34:43Z", "text": "Don't you understand? It makes me feel anxious all the time. If you don't do it I'll feel sad and disappointed.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM693", "user": "Humberd", "root": "ROOT69", "reply_to": "COM692", "timestamp": "2019-12-19T10:37:04Z", "text": "I don't know if it makes any difference, but I'm a black Jew living in Uganda.", "meta": {"posReactions": "38", "negReactions": "0"}}
{"id": "COM694", "user": "Danielx64", "root": "ROOT69", "reply_to": "COM693", "timestamp": "2019-12-19T10:39:55Z", "text": "> \r\n> \r\n> I don't know if it makes any difference, but I'm a black Jew living in Uganda.\r\n\r\nTo me? No, it doesn't.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM695", "user": "Shusek", "root": "ROOT69", "reply_to": "COM694", "timestamp": "2019-12-19T10:57:32Z", "text": "I'm sorry they hurt your and other's feelings. I hope they'll remote the dark theme soon.", "meta": {"posReactions": "31", "negReactions": "0"}}
{"id": "COM696", "user": "ludo237", "root": "ROOT69", "reply_to": "COM695", "timestamp": "2019-12-19T11:00:39Z", "text": "It's okay to use white theme", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM697", "user": "Kegelcizer", "root": "ROOT69", "reply_to": "COM696", "timestamp": "2019-12-19T11:52:15Z", "text": "To avoid being offended, please use the ~~transparent~~ ~~perspicuous~~ pellucid theme.", "meta": {"posReactions": "9", "negReactions": "1"}}
{"id": "COM698", "user": "hckr", "root": "ROOT69", "reply_to": "COM697", "timestamp": "2019-12-19T11:54:19Z", "text": "@Kegelcizer Did you just say trans-parent? But it's ok, my conservative belifs can and even should be offended.", "meta": {"posReactions": "9", "negReactions": "1"}}
{"id": "COM699", "user": "Kegelcizer", "root": "ROOT69", "reply_to": "COM698", "timestamp": "2019-12-19T12:00:34Z", "text": "> @Kegelcizer Did you just say trans-parent? But it's ok, my conservative belifs can and even should be offended.\r\n\r\nI'm deeply sorry for my insensitivity. I hope the edit of my original comment will make it more PC.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6910", "user": "wattengard", "root": "ROOT69", "reply_to": "COM699", "timestamp": "2019-12-19T12:08:47Z", "text": "PC?! What if I'm a mac-user?!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6911", "user": "anterokarttunen", "root": "ROOT69", "reply_to": "COM6910", "timestamp": "2019-12-19T13:30:52Z", "text": "LOL ( troll )", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6912", "user": "pokonski", "root": "ROOT69", "reply_to": "COM6911", "timestamp": "2019-12-19T14:03:32Z", "text": "Dark theme is basically a blackface of white editors.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM6913", "user": "chrisdias", "root": "ROOT69", "reply_to": "COM6912", "timestamp": "2019-12-19T19:00:10Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.\r\n\r\nHappy Coding!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT70", "user": "IainNZ", "root": "ROOT70", "reply_to": null, "timestamp": "2018-08-21T03:36:57Z", "text": "Global variable scope rules lead to unintuitive behavior at the REPL/notebook ### Example 1\r \r This came up with a student who upgraded from 0.6 to 1.0 directly, so never even got a chance to see a deprecation warning, let alone find an explanation for new behavior:\r \r ```julia\r julia> beforefor = true\r true\r \r julia> for i in 1:2\r          beforefor = false\r        end\r \r julia> beforefor  # this is surprising bit\r true\r \r julia> beforeif = true\r true\r \r julia> if 1 == 1\r          beforeif = false\r        end\r false\r \r julia> beforeif  # Another surprise!\r false\r \r julia> function foo()\r          infunc = true\r          for i in 1:10\r            infunc = false\r          end\r          @show infunc\r        end\r foo (generic function with 1 method)\r \r julia> foo()  # \"I don't get this\"\r infunc = false \r ```\r \r ### Example 2\r \r ```julia\r julia> total_lines = 0\r 0\r \r julia> list_of_files = [\"a\", \"b\", \"c\"]\r 3-element Array{String,1}:\r  \"a\"\r  \"b\"\r  \"c\"\r \r julia> for file in list_of_files\r          # fake read file\r          lines_in_file = 5\r          total_lines += lines_in_file\r        end\r ERROR: UndefVarError: total_lines not defined\r Stacktrace:\r  [1] top-level scope at ./REPL[3]:4 [inlined]\r  [2] top-level scope at ./none:0\r \r julia> total_lines  # This crushs the students willingness to learn\r 0\r ```\r \r I \"get\" why this happens in the sense that I think I can explain, with sufficient reference to the arcana in the manual about what introduces scopes and what doesn't, but I think that this is problematic for interactive use.\r \r In example one, you get a silent failure. In example two, you get an error message that is very there-is-no-spoon. Thats roughly comparable to some Python code I wrote in a notebook at work today.\r \r I'm not sure what the rules are in Python, but I do know that generally you can't assign to things at the global scope without invoking global. But at the REPL it does work, presumably because at the REPL the rules are different or the same logic as if they were all are in the scope of function is applied.\r \r I can't language-lawyer the rules enough to propose the concrete change I would like, and based on Slack this isn't even necessarily perceived as an issue by some people, so I don't know where to go with this except to flag it.\r \r Cross-refs:\r #19324\r https://discourse.julialang.org/t/repl-and-for-loops-scope-behavior-change/13514\r https://stackoverflow.com/questions/51930537/scope-of-variables-in-julia", "meta": {"posReactions": "15", "negReactions": "0"}}
{"id": "COM700", "user": "IainNZ", "root": "ROOT70", "reply_to": "ROOT70", "timestamp": "2018-08-21T03:39:24Z", "text": "(Per @mlubin, this is the relevant change https://github.com/JuliaLang/julia/pull/19324)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM701", "user": "jekbradbury", "root": "ROOT70", "reply_to": "COM700", "timestamp": "2018-08-21T04:18:59Z", "text": "Stefan suggested [here](https://discourse.julialang.org/t/repl-and-for-loops-scope-behavior-change/13514/9) that one possibility to solve this issue is automatic wrapping of REPL entries in `let` blocks", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM702", "user": "KristofferC", "root": "ROOT70", "reply_to": "COM701", "timestamp": "2018-08-21T09:36:57Z", "text": "But wouldn't that be confusing in that you couldn't do\r\n\r\n```\r\na = 1\r\n```\r\n\r\nand use `a` after that? Unless `global` is inserted for all the toplevel assignments, I guess?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM703", "user": "StefanKarpinski", "root": "ROOT70", "reply_to": "COM702", "timestamp": "2018-08-21T12:57:46Z", "text": "The behavior wouldn't be just to wrap everything in a `let` block\u2014it's more complicated than that. You need to let-bind any global that's assigned inside the expression and then extract the let-bound value to a global at the end of the expression.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM704", "user": "StefanKarpinski", "root": "ROOT70", "reply_to": "COM703", "timestamp": "2018-08-21T13:05:47Z", "text": "So you would turn `a = 1` into something like `a = let a; a = 1; end`. And something like\r\n```jl\r\nfor i in 1:2\r\n    before = false\r\nend\r\n```\r\nwould be turned into this:\r\n```jl\r\nbefore = let before = before\r\n    for i in 1:2\r\n        before = false\r\n    end\r\nend\r\n```\r\nFrankly, I'm pretty annoyed that people are only giving this feedback now. This has change has been on master for ten months.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM705", "user": "piever", "root": "ROOT70", "reply_to": "COM704", "timestamp": "2018-08-21T13:38:14Z", "text": "I'm guilty of not having followed master very closed until recently, so this feedback is indeed a bit late. More than a concern for programmers (most `for` loops will be inside a function in library code) I'm afraid this is a concern for teaching. Often `for` loops are taught before functions or scopes (of course you need to understand scopes to really understand what's going on but in teaching things are often simplified).\r\n\r\nHere it becomes a bit difficult to teach a beginner how to sum numbers from 1 to 10 without explaining functions or global variables.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM706", "user": "mlubin", "root": "ROOT70", "reply_to": "COM705", "timestamp": "2018-08-21T13:46:42Z", "text": "> Frankly, I'm pretty annoyed that people are only giving this feedback now. This has change has been on master for ten months.\r\n\r\nTo be fair, Julia 0.7 was released 13 days ago. This is a new change for most Julia users.", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM707", "user": "IainNZ", "root": "ROOT70", "reply_to": "COM706", "timestamp": "2018-08-21T13:59:17Z", "text": "> Frankly, I'm pretty annoyed that people are only giving this feedback now. This has change has been on master for ten months\r\n\r\nUnfortunately for those of us who can not handle living on the edge, its brand-new from our perspective.", "meta": {"posReactions": "14", "negReactions": "0"}}
{"id": "COM708", "user": "rickhg12hs", "root": "ROOT70", "reply_to": "COM707", "timestamp": "2018-08-21T14:04:29Z", "text": "> Frankly, I'm pretty annoyed that people are only giving this feedback now. This has change has been on master for ten months.\r\n\r\nAnd for those of us who have been encouraged to stay off the development branches, \"it's brand-new from our perspective.\"", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM709", "user": "KristofferC", "root": "ROOT70", "reply_to": "COM708", "timestamp": "2018-08-21T14:21:27Z", "text": "Can we please go back to focus on the issue at hand now, instead of having a meta discussion about how long people have had to test this. It is what it is right now, so let's look forward.", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM7010", "user": "ChrisRackauckas", "root": "ROOT70", "reply_to": "COM709", "timestamp": "2018-08-21T14:25:47Z", "text": ">I'm guilty of not having followed master very closed until recently, so this feedback is indeed a bit late. More than a concern for programmers (most for loops will be inside a function in library code) I'm afraid this is a concern for teaching. Often for loops are taught before functions or scopes (of course you need to understand scopes to really understand what's going on but in teaching things are often simplified).\r\n\r\n>Here it becomes a bit difficult to teach a beginner how to sum numbers from 1 to 10 without explaining functions or global variables.\r\n\r\nThis is a big point. After finding out what the issue really is, it's surprising how little it actually shows up. It is less of an issue with a lot of Julia code in the wild and in tests, and it did reveal a lot of variables which were accidentally global (in both Julia Base's tests according to the original PR, and I noticed this on most of DiffEq's tests). In most cases it seems that the subtly wrong behavior isn't what you get (expecting a change in a loop), but rather expecting to be able to use a variable in a loop is what I've found to be the vast majority of where this shows up in updating test scripts to v1.0. So the good thing is that in most cases the user is presented with an error, and it's not difficult to fix.\r\n\r\nThe bad thing is that it's a little verbose to have to put `global x` inside of the loops, and now your REPL code is also different from the function code. Whether or not it's more intuitive behavior than before is a tough opinion because [there were definitely some edge cases in hard/soft local scoping](http://ucidatascienceinitiative.github.io/IntroToJulia/Html/ScopingExperiment) and so this is clearly easier to explain. But at the same time, while having a much more succinct explanation than the behavior of before, it's now easier to hit the edge cases where understanding scoping rules matters. \ud83e\udd37\u200d\u2642\ufe0f. \r\n\r\nI for one would like to see the experiments with `let` blocking. This would keep the \"you didn't really want so many globals\" aspect of it, along with the simplified scoping explanation, while at the same time make REPL code behave like function interiors (which is seemingly what we've always wanted). Or inversely, making people specify variables they want to act as globals\r\n\r\n```julia\r\nglobal x = 5\r\nfor i = 1:5\r\n  println(x+i)\r\nend\r\n```\r\n\r\ncould be a nice way to keep the explicitness, and would make the \"REPL code is slow because of globals\" be much more obvious. The downside is that once again throwing things into a function would not require the `global` markers. \r\n\r\nBut given how this tends to show up, it's not really gamebreaking or a showstopper. I'd classify it as a wart  that should get a mention in any workshop but it's not like v1.0 is unusable because of it. I hope that changing this behavior isn't classified as breaking and require v2.0 though.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7011", "user": "ExpandingMan", "root": "ROOT70", "reply_to": "COM7010", "timestamp": "2018-08-21T14:58:56Z", "text": "I'm not so sure I like the idea that the REPL should behave like a function interior.  It clearly isn't, so I expect it to behave like global scope.  To me the REPL not behaving like global scope would be potentially even more confusing than the discrepency that causes this issue.\r\n\r\nRegardless, at the very least I think that the documentation should be somewhat more explicit about this issue.  Casually reading the docs I would have assumed that you would need to use the `local` keyword to get the behavior occurs in global scope by default.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7012", "user": "piever", "root": "ROOT70", "reply_to": "COM7011", "timestamp": "2018-08-21T15:06:32Z", "text": "> I for one would like to see the experiments with `let` blocking. This would keep the \"you didn't really want so many globals\" aspect of it, along with the simplified scoping explanation, while at the same time make REPL code behave like function interiors (which is seemingly what we've always wanted)\r\n\r\nIf we're going for \"REPL is the same as the inside of a function\" we should also think about `outer`:\r\n\r\n```julia\r\njulia> i = 1\r\n1\r\n\r\njulia> for outer i = 1:10\r\n       end\r\nERROR: syntax: no outer variable declaration exists for \"for outer\"\r\n```\r\n\r\nversus:\r\n\r\n```julia\r\njulia> function f()\r\n          i = 0\r\n          for outer i = 1:10\r\n          end\r\n          return i\r\n       end\r\nf (generic function with 1 method)\r\n\r\njulia> f()\r\n10\r\n```", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7013", "user": "stevengj", "root": "ROOT70", "reply_to": "COM7012", "timestamp": "2018-08-21T16:29:03Z", "text": "> Frankly, I'm pretty annoyed that people are only giving this feedback now. This has change has been on master for ten months.\r\n\r\nPeople haven't been using master for interactive use or for teaching, they've been using it to upgrade packages, which are only minimally affected by this and are mostly written by experienced programmers.\r\n\r\n(I was one of the few people who did give feedback in #19324, though, where I argued [for the old behavior](https://github.com/JuliaLang/julia/pull/19324#issuecomment-356484761).)\r\n\r\nA non-breaking way out of this would be to change back to the old behavior (ideally not by inserting implicit `let` blocks or anything \u2014 just restore the old code in `julia-syntax.scm` as an option) in the REPL.  Or rather, to make it available in environments like IJulia that might want it, add a `soft_global_scope=false` flag to `include`, `include_string`, and `Core.eval` to restore the old behavior.", "meta": {"posReactions": "10", "negReactions": "0"}}
{"id": "COM7014", "user": "StefanKarpinski", "root": "ROOT70", "reply_to": "COM7013", "timestamp": "2018-08-21T16:52:48Z", "text": "> (I was one of the few people who did give feedback in #19324, though, where I argued for the old behavior.)\r\n\r\nYes, and I greatly appreciate it. It doesn't much matter now since we made the choice, let it bake for ten months and have now released it with a long-term commitment to stability. So the only thing to do now is to focus on what to do going forward.\r\n\r\nHaving an option to choose between the old behavior and the new one is interesting but it feels very hacky. That means we not only sometimes have a scoping behavior that everyone apparently found incredibly confusing, but we don't always have it and whether we have it or not depends on a global flag. That feels pretty unsatisfactory, I'm afraid.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7015", "user": "stevengj", "root": "ROOT70", "reply_to": "COM7014", "timestamp": "2018-08-21T16:56:11Z", "text": "> Having an option to choose between the old behavior and the new one is interesting but it feels very hacky.\r\n\r\nIf someone implements an \"unbreak me\" soft-scope AST transformation, it will be very tempting to use it in IJulia, OhMyREPL, etcetera, at which point you get the even more problematic situation in which the default REPL is seen as broken.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7016", "user": "StefanKarpinski", "root": "ROOT70", "reply_to": "COM7015", "timestamp": "2018-08-21T17:02:31Z", "text": "That's not what I'm saying. Clearly we should use the same solution in all those contexts. But implementing it as two different variations on scoping rules seems less clean than implementing it as a code transformation with one set of scoping rules. But perhaps those are functionally equivalent. However, it seems easier to explain in terms of the new simpler scoping rules + a transformation that takes REPL-style input and transforms it before evaluating it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7017", "user": "StefanKarpinski", "root": "ROOT70", "reply_to": "COM7016", "timestamp": "2018-08-21T17:06:55Z", "text": "That could be done as `Meta.globalize(m::Module, expr::Expr)` that transforms an expression by automatically annotating any globals which exist in the module as global if they are assigned inside of any top-level non-function scope. Of course, I think that's equivalent to what the old parser did, but a bit more transparent since you can call `Meta.globalize` yourself and see what the REPL will evaluate.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7018", "user": "stevengj", "root": "ROOT70", "reply_to": "COM7017", "timestamp": "2018-08-21T17:07:36Z", "text": "> That could be done as `Meta.globalize(m::Module, expr::Expr)` that transforms an expression by automatically annotating any globals which exist in the module as global if they are assigned inside of any top-level non-function scope.\r\n\r\nI actually started looking into implementing something like this a few minutes ago.  However, it looks like it would be *much* easier to implement as an option in `julia-syntax.jl`:\r\n\r\n* Writing an external AST transformation is possible, but it seems like there are lots of tricky corner cases \u2014 you basically have to re-implement the scoping rules\u00a0\u2014 whereas we already had the code to get it right in `julia-syntax.scm`.\r\n* It's even more tricky for something like IJulia that currently uses `include_string` to evaluate a whole block of code and get the value of the last expression.  Not only would we have to switch to parsing expression by expression, but some hackery may be needed in order to preserve the original line numbers (for error messages etcetera).  (Though I found a [hack for ChangePrecision.jl for this sort of thing](https://github.com/stevengj/ChangePrecision.jl/blob/master/src/ChangePrecision.jl#L105-L111) that may work here also.)\r\n* Not to mention of the case of people that `include` external files, which would not be caught by your AST transformation.\r\n\r\n> However, it seems easier to explain in terms of the new simpler scoping rules + a transformation that takes REPL-style input and transforms it before evaluating it.\r\n\r\nI seriously doubt this would be easier to explain to new users than just saying that the rules are less picky for interactive use or for `include` with a certain flag.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7019", "user": "stevengj", "root": "ROOT70", "reply_to": "COM7018", "timestamp": "2018-08-21T17:54:27Z", "text": "Here is a rough draft of a `globalize(::Module, ast)` implementation: https://gist.github.com/stevengj/255cb778efcc72a84dbf97ecbbf221fe", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7020", "user": "stevengj", "root": "ROOT70", "reply_to": "COM7019", "timestamp": "2018-08-21T19:48:16Z", "text": "Okay, I've figured out how to implement a `globalize_include_string` function that preserves line-number information, and have added it to [my gist](https://gist.github.com/stevengj/255cb778efcc72a84dbf97ecbbf221fe).\r\n\r\nA possible (non-breaking) way forward, if people like this approach:\r\n\r\n1. Release a SoftGlobalScope.jl package with the `globalize` etc. functions.\r\n2. Use SoftGlobalScope in IJulia (and possibly Juno, vscode, and OhMyREPL).\r\n3. Fold the SoftGlobalScope functions into a future release of the REPL stdlib package and use it in the REPL.\r\n\r\nOr is it practical to roll it into REPL.jl immediately?  I'm not completely clear on how stdlib updates work in 1.0.\r\n\r\nPlease take a look at my implementation, in case I'm missing something that will cause it to be fragile.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7021", "user": "KristofferC", "root": "ROOT70", "reply_to": "COM7020", "timestamp": "2018-08-21T21:26:09Z", "text": "Can't we have it as a non-default feature of the REPL in 1.1?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7022", "user": "JeffBezanson", "root": "ROOT70", "reply_to": "COM7021", "timestamp": "2018-08-21T21:50:05Z", "text": "Duplicate of #28523 and #28750. To those saying they don't want to teach people about global variables, I suggest teaching functions first, before `for` loops. Functions are more fundamental anyway, and this will help set the expectation that code should be written in functions. While I understand the inconvenience, this scoping behavior can be turned into a pedagogical advantage: \"In fact, global variables are such a bad idea, particularly using them in loops, that the language makes you bend over backwards to use them.\"\r\n\r\nAdding a non-default feature to the REPL for this seems ok to me though.", "meta": {"posReactions": "5", "negReactions": "5"}}
{"id": "COM7023", "user": "stevengj", "root": "ROOT70", "reply_to": "COM7022", "timestamp": "2018-08-21T23:11:58Z", "text": "@JeffBezanson, remember that many of us would like to use Julia as a substitute for Matlab etcetera in technical courses like linear algebra and statistics.  These are *not* programming courses and the students often have no programming background.   We never do structured programming \u2014 it's almost *all* interactive with short snippets and global variables.\r\n\r\nFurthermore, the reason I'm using a dynamic language in the first place is to switch fluidly between interactive exploration and more disciplined programming.   The inability to use the same code in a global and a function context is a hindrance to that end, even for someone who is used to scoping concepts, and it is much worse for students from non-CS backgrounds.", "meta": {"posReactions": "31", "negReactions": "0"}}
{"id": "COM7024", "user": "ExpandingMan", "root": "ROOT70", "reply_to": "COM7023", "timestamp": "2018-08-21T23:34:20Z", "text": "> remember that many of us would like to use Julia as a substitute for Matlab etcetera in technical courses like linear algebra and statistics. These are not programming courses and the students often have no programming background. We never do structured programming \u2014 it's almost all interactive with short snippets and global variables.\r\n\r\nMany of us Julia users have absolutely 0 CS background (including myself), but it seems to me that the proper attitude (*especially* for students) is a willingness to learn rather than demanding things be changed for the worse to accommodate our naivete.\r\n\r\nNow, I'm not necessarily implying that this particular change would be for the worse as I only have a limited understanding of what's going on here, but if it *is* the case that this is a significant complication or makes it excessively easy to write needlessly badly performing code it does not seem worth it to make a change in order to have a better lecture example.  You can't change the laws of physics so that the electrostatics examples you show to freshman are more applicable to real life.\r\n\r\nSo my question as a non-CS user who also cares about performance is how would I be likely to screw up if this were made the default behavior.  Is it literally just the sorts of examples we are seeing here that are a problem (which I was already aware of), or are we likely to often screw this up badly in more subtle ways?\r\n\r\nFor what it's worth, I do agree that having code behave differently depending on its enclosing scope is a generally undesirable feature.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7025", "user": "stevengj", "root": "ROOT70", "reply_to": "COM7024", "timestamp": "2018-08-22T00:57:15Z", "text": "Making code harder to write interactively, forcing beginners writing their first loops to understand obscure scoping rules, and making code pasted from functions not work in global scopes does not help programmers write fast code in functions. It just makes it harder to use Julia interactively and harder for beginners. ", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM7026", "user": "stevengj", "root": "ROOT70", "reply_to": "COM7025", "timestamp": "2018-08-22T01:10:43Z", "text": "> Can't we have it as a non-default feature of the REPL in 1.1?\r\n\r\nMaking an \"unbreak me\" option the default seems wiser, especially an option that is aimed squarely at beginning users.   If it is a non-default option, then precisely those people who need it most will be those who don't have it enabled (and don't know it exists).", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM7027", "user": "mauro3", "root": "ROOT70", "reply_to": "COM7026", "timestamp": "2018-08-22T06:51:02Z", "text": "What would the proposed REPL-mode do to `include`ed scripts?  Would the evaluation of global statements depend on whether the REPL mode is activated?  If so, IMO this would be at odds with the 1.0 stability promise.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7028", "user": "StefanKarpinski", "root": "ROOT70", "reply_to": "COM7027", "timestamp": "2018-08-22T07:21:58Z", "text": "If we did something like this it seems like it might make sense for the module to determine how it works. So `Main` would be a \"soft scope\" module while by default other modules would be \"hard scope\" modules.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7029", "user": "dawbarton", "root": "ROOT70", "reply_to": "COM7028", "timestamp": "2018-08-22T15:00:15Z", "text": "I was interested to see if it was possible to monkey patch the REPL to use @stevengj's `globalize` function and it appears it is without too much effort (though quite hacky). See the [gist](https://gist.github.com/dawbarton/0388715fb56fb5cd05e0e4b12c322815). This doesn't work with Juno (or anything else that calls `Core.eval` directly).\r\n\r\nI'm **not** going to be recommending this to people, but it's quite useful to me when doing quick-and-dirty data analysis. I would very much like to see a (better thought out) solution since it really is quite confusing for inexperienced and often reluctant coders (i.e., my students) when you can't copy and paste in code from a function into the REPL to see what it does and vice-versa.\r\n\r\n```julia\r\njulia> a = 0                                                                \r\n0                                                                           \r\n                                                                            \r\njulia> for i = 1:10                                                         \r\n         a += i                                                             \r\n       end                                                                  \r\nERROR: UndefVarError: a not defined                                         \r\nStacktrace:                                                                 \r\n [1] top-level scope at .\\REPL[2]:2 [inlined]                               \r\n [2] top-level scope at .\\none:0                                            \r\n                                                                            \r\njulia> using SoftGlobalScope                                                \r\n[ Info: Precompiling SoftGlobalScope [363c7d7e-a618-11e8-01c4-4f22c151e122] \r\n                                                                            \r\njulia> for i = 1:10                                                         \r\n         a += i                                                             \r\n       end                                                                  \r\n                                                                            \r\njulia> a                                                                    \r\n55                                                                          \r\n```\r\n(BTW: the above is about as much testing as it has had!)", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "ROOT71", "user": "IdanCo", "root": "ROOT71", "reply_to": null, "timestamp": "2017-03-15T13:20:54Z", "text": "Bootstrap 4 with npm and webpack I've been spending WAY too much time on adding bootstrap 4 with npm to a webpack project. In hope to save others the time, I thought i'll share the final recipe -\r \r start by installing bootstrap in your project -\r ```\r npm install bootstrap@4.0.0-alpha.6 --save\r ```\r (notice bootstrap has two dependencies - jquery and tether. If you would rather have explicit versions of those two, you should install them as well)\r \r import bootstrap's javascript through index.js -\r ```javascript\r import 'bootstrap';\r ```\r (i'm assuming you're using es6, in case of es5, use `require('bootstrap')`)\r \r The previous line will only import the js part of bootstrap. for the styling part you have two options -\r \r ### 1. Precompiled SASS\r Inside one of your sass files (index.scss for example) add this line -\r ```SASS\r @import \"~bootstrap/scss/bootstrap.scss\";\r ```\r (notice the ~ (tilde) which points to the node modules folder)\r This mehtod is beneficial if you plan on using your own version of the wonderful __variables_ file bootstrap comes with. just make sure you import __variables_ before _bootstrap_. Also, now you can use all the cool mixins bootstrap has.\r \r ### 2. Compiled CSS only\r If you're not planning on using the variables or the mixins, and prefer the precooked css file, simply add this line to index.js or any other js file -\r ```javascript\r import 'bootstrap/dist/css/bootstrap.css';\r ```\r (btw - you can also import this way the sass file, but it's nicer to import it via another sass file as shown in pervious mehtod)\r \r now comes the webpack part. for _jquery_ and _tether_ to be available as a global variable throughout the project, you'll have to add this to your webpack plugins sections -\r ```javascript\r new webpack.ProvidePlugin({ // inject ES5 modules as global vars\r   $: 'jquery',\r   jQuery: 'jquery',\r   'window.jQuery': 'jquery',\r   Tether: 'tether'\r })\r ```\r The different jquery definition are meant to answer requirements of different libraries (for example angular looks for 'window.jQuery'). I'm assuming your webpack.config already has rules for scss and/or css.\r \r And that's it! now you have bootstrap in your webpack project.\r Let me know if any further explanation is needed, and if anyone knows of a better way, please share.", "meta": {"posReactions": "64", "negReactions": "0"}}
{"id": "COM710", "user": "cr101", "root": "ROOT71", "reply_to": "ROOT71", "timestamp": "2017-03-16T07:59:37Z", "text": "> `@import \"~bootstrap/scss/bootstrap.scss\";`\r\n> (notice the ~ (tilde) which points to the node modules folder)\r\n\r\n@IdanCo Do you need to install a dependency to be able to use `~` instead of the `node_modules` folder?\r\nI tried it but it didn't work.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM711", "user": "IdanCo", "root": "ROOT71", "reply_to": "COM710", "timestamp": "2017-03-16T14:09:34Z", "text": "@Olivia101 good question. [I took this convention from sass-loader](https://github.com/webpack-contrib/sass-loader#imports), but if in addition to sass-loader you're also using postcss than this could be related -\r\nhttps://github.com/postcss/postcss-import/issues/209\r\n\r\nAnyway you can try without the tilde, or worst case use '../../node_modules'.\r\n\r\nlet me know how it goes.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM712", "user": "mselerin", "root": "ROOT71", "reply_to": "COM711", "timestamp": "2017-03-22T07:41:57Z", "text": "Really nice explanations @IdanCo :+1: \r\n\r\nI'm also using Bootstrap w/ Webpack but I have a slightly different configuration regarding the \"Jquery & Tether\" part.\r\n\r\nInstead of using this :\r\n```javascript\r\nnew webpack.ProvidePlugin({ // inject ES5 modules as global vars\r\n  $: 'jquery',\r\n  jQuery: 'jquery',\r\n  'window.jQuery': 'jquery',\r\n  Tether: 'tether'\r\n})\r\n```\r\nwhich does not inject $ as a global variable but 'auto-require' it when encountered in a dependency, I use the \"expose-loader\" (which, actually, expose global variables ;-) ).\r\n\r\nYou could use it directly in the webpack config but, personnaly, I prefer using it in my entry file like this : \r\n```javascript\r\nrequire('expose-loader?$!expose-loader?jQuery!jquery');\r\nrequire(\"expose-loader?Tether!tether\");\r\n```\r\n(yeah, the syntax looks like some sort of incantations or something ;-))\r\n\r\nBut if you prefer the webpack config way, it looks like this : \r\n```javascript\r\nmodule: {\r\n  rules: [\r\n    {\r\n      test: require.resolve('jquery'),\r\n      use: [\r\n        { loader: 'expose-loader', options: 'jQuery' },\r\n        { loader: 'expose-loader', options: '$' }\r\n      ]\r\n    },\r\n    \r\n    {\r\n      test: require.resolve('tether'),\r\n      use: [\r\n        { loader: 'expose-loader', options: 'Tether' }\r\n      ]\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nMy 2 cents...", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM713", "user": "Mioleris", "root": "ROOT71", "reply_to": "COM712", "timestamp": "2017-03-27T13:41:09Z", "text": "O u can use bootstrap-loader https://github.com/shakacode/bootstrap-loader", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM714", "user": "mdo", "root": "ROOT71", "reply_to": "COM713", "timestamp": "2017-04-08T21:35:34Z", "text": "Is there something here we need to update in our docs or JS?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM715", "user": "IdanCo", "root": "ROOT71", "reply_to": "COM714", "timestamp": "2017-04-09T18:17:09Z", "text": "@mdo I think a webpack configuration is something that many developers might find useful. I'll wrap it as a PR and leave it for you to decide.", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM716", "user": "IdanCo", "root": "ROOT71", "reply_to": "COM715", "timestamp": "2017-05-07T12:15:00Z", "text": "thanks for reporting @bbottema , a few questions to better diagnose the issue -\r\n1. when importing scss, you do it directly from the js or from a secondary scss file?\r\n2. If you use a secondary scss file, do rules before/after the import **are working** in the browser?\r\n3. what version of style-loader are you using?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM717", "user": "IdanCo", "root": "ROOT71", "reply_to": "COM716", "timestamp": "2017-05-07T12:31:52Z", "text": "Smells to me like could be related to [this issue](https://github.com/webpack-contrib/css-loader/issues/484), try a couple of things for me -\r\n\r\n1. use a secondary scss, and add this code **before** importing bootstrap -\r\n```sass\r\n$navbar-inverse-color: #FFF;\r\n$navbar-light-color: #FFF; \r\n```\r\n2. upgrade style-loader to 0.17.0\r\n3. take a look at a [demo project implementing bootstrap](https://github.com/IdanCo/webpack-modular/tree/bootstrap4)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM718", "user": "bbottema", "root": "ROOT71", "reply_to": "COM717", "timestamp": "2017-05-07T15:42:29Z", "text": "@IdanCo Sorry, nevermind. I made a mess out of it :D. My config was not in order, ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM719", "user": "bparanj", "root": "ROOT71", "reply_to": "COM718", "timestamp": "2017-05-26T21:24:52Z", "text": "@Mioleris bootstrap-loader currently does not support Bootstrap 4.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7110", "user": "mdo", "root": "ROOT71", "reply_to": "COM719", "timestamp": "2017-05-27T04:09:23Z", "text": "Closing since #22423 was merged.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7111", "user": "petrpacas", "root": "ROOT71", "reply_to": "COM7110", "timestamp": "2017-07-13T14:14:29Z", "text": "For consideration:\r\nhttps://github.com/twbs/bootstrap/pull/22423#issuecomment-315081413", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7112", "user": "ajthinking", "root": "ROOT71", "reply_to": "COM7111", "timestamp": "2018-01-18T13:37:27Z", "text": "This thread helped me. But dont forget to install dependencies. Im surprised this is not mentioned more explicit in https://getbootstrap.com/ npm installation section.\r\n```\r\nnpm install --save jquery popper.js\r\nnpm install bootstrap@4.0.0-beta.3 --save\r\n```\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7113", "user": "Johann-S", "root": "ROOT71", "reply_to": "COM7112", "timestamp": "2018-01-18T13:43:22Z", "text": "@ajthinking it's written here : https://getbootstrap.com/docs/4.0/getting-started/webpack/#importing-javascript\r\n\r\n>Bootstrap is dependent on jQuery and Popper, these are defined as peerDependencies, this means that you will have to make sure to add both of them to your package.json using npm install --save jquery popper.js.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7114", "user": "ajthinking", "root": "ROOT71", "reply_to": "COM7113", "timestamp": "2018-01-18T13:52:17Z", "text": "@Johann-S yes that page is great! But on https://getbootstrap.com no dependencies are mentioned in the npm section thats what caught me. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7115", "user": "petrpacas", "root": "ROOT71", "reply_to": "COM7114", "timestamp": "2018-01-18T20:09:10Z", "text": "Feel free to check out https://github.com/petrpacas/webpack-bootstrap-4-setup to see how I tackled this...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7116", "user": "cebartling", "root": "ROOT71", "reply_to": "COM7115", "timestamp": "2018-02-12T15:53:44Z", "text": "I would stay far away from `bootstrap-loader`. We are using it on a React project and it's been a pain in the butt to update to Bootstrap 4.0 beta. I ultimately want to go to Bootstrap 4 GA and I think I'm going to have to ditch `bootstrap-loader` to do it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7117", "user": "Alex1sz", "root": "ROOT71", "reply_to": "COM7116", "timestamp": "2018-02-16T02:57:08Z", "text": "^^ +1 on the staying away from bootstrap-loader you will regret using it I had to rip it out after it randomly broke compilation due to buggy path resolve & bootstrap version code. After forking bootstrap-loader in an attempt to fix their code I quickly realized my mistake in adding it in the first place.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7118", "user": "mdo", "root": "ROOT71", "reply_to": "COM7117", "timestamp": "2018-02-16T02:58:09Z", "text": "Seeing all the follow-up comments, do we need more docs updates here?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7119", "user": "connelhooley", "root": "ROOT71", "reply_to": "COM7118", "timestamp": "2018-03-21T16:19:19Z", "text": "I'm very new to webpack, but I have just set up a project and I have TypeScript and SCSS compiling correctly. I asm using webpack version `4.1.1`. When I import bootstrap like this:\r\n\r\n`import 'bootstrap';`\r\n\r\nThe TypeScript compiles, but I am given the following error on page load:\r\n\r\n```\r\nmain.ts:3 Uncaught Error: Cannot find module \"bootstrap\"\r\n    at webpackMissingModule (main.ts:3)\r\n    at Object../ts/main.ts (main.ts:3)\r\n    at __webpack_require__ (bootstrap:19)\r\n    at bootstrap:68\r\n    at bootstrap:68\r\n```\r\n\r\nI have the following packages installed in my package.config:\r\n\r\n```\r\n  \"@fortawesome/fontawesome-free-webfonts\": \"^1.0.4\",\r\n  \"@types/bootstrap\": \"^4.0.1\",\r\n  \"@types/jquery\": \"^3.3.1\",\r\n  \"bootstrap\": \"^4.0.0\",\r\n  \"jquery\": \"^3.3.1\",\r\n  \"popper.js\": \"^1.14.1\"\r\n```\r\n\r\nThis is the typescript code:\r\n\r\n```\r\nimport \"../scss/main.scss\";\r\nimport * as $ from \"jquery\";\r\nimport 'bootstrap';\r\n\r\n$(() => {\r\n    $('[data-toggle=\"tooltip\"]').tooltip();\r\n    alert(sayHello(\"TypeScript\"));\r\n});\r\n```\r\n\r\nI imagine I also have to declare the `$` sign globally somewhere but this isn't documented in the bootstrap docs, but for me I can't seem to import the bootstrap js at all.\r\n\r\nIs there something missing from the docs that I need to do?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7120", "user": "connelhooley", "root": "ROOT71", "reply_to": "COM7119", "timestamp": "2018-03-21T16:55:33Z", "text": "Update: I fixed my issue by using:\r\n`import \"bootstrap/dist/js/bootstrap.js`\r\n\r\nApart from that the docs were enough for me to get going personally.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7121", "user": "petrpacas", "root": "ROOT71", "reply_to": "COM7120", "timestamp": "2018-03-21T19:07:04Z", "text": "Well, I\u2019m not a Webpack guru myself, and I\u2019m glad you sorted it out, but just gonna mention that my setup is importing the individual bootstrap.js pieces (so that you can select only the necessary ones), and you are importing the whole package. Which might ofc be fine for you\u2026\n\nJust sayin\u2019\n\nTake care,\nPetr\n\nOn 21. 3. 2018 16:58 +0000, Connel Hooley <notifications@github.com>, wrote:\n> Update: I fixed my issue by using:\n> import \"bootstrap/dist/js/bootstrap.js\n> Apart from that the docs were enough for me to get going personally.\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7122", "user": "marcosleonel", "root": "ROOT71", "reply_to": "COM7121", "timestamp": "2018-03-30T20:16:10Z", "text": "Well done, @IdanCo ! It worked nicely for me. Thanks!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7123", "user": "Ruud-cb", "root": "ROOT71", "reply_to": "COM7122", "timestamp": "2018-04-06T10:23:51Z", "text": "So many different solutions, so many different workable options, yet none of them helped me in the past 3 hours getting bootstrap up and running... The webpack documentation page looks so simple but it is not that simple, apparently. Please include some more documentation on how to test if it is working and if there are any differences when using typescript. I just installed, included, imported and my app just runs fine, no errors, but yet no col-md or container styling working.. meh, i'll just return to CDN's...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7124", "user": "Johann-S", "root": "ROOT71", "reply_to": "COM7123", "timestamp": "2018-04-06T11:05:23Z", "text": "Feel free @Ruud-cb to improve our docs if you found something, we cannot covered every use case", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7125", "user": "Johann-S", "root": "ROOT71", "reply_to": "COM7124", "timestamp": "2018-04-06T11:07:26Z", "text": "I lock this issue everything is here: https://getbootstrap.com/docs/4.0/getting-started/webpack/\r\n\r\nIf someone want to improve our docs feel free to do it, or you can open an issue which point what is missing in our docs", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT72", "user": "InfoLibre", "root": "ROOT72", "reply_to": null, "timestamp": "2019-03-07T09:00:06Z", "text": "Telemetry This project collects usage data and sends it to Microsoft. Please stop collecting MY data and remove telemetry from all your f**g Windows products.", "meta": {"posReactions": "24", "negReactions": "22"}}
{"id": "COM720", "user": "lard", "root": "ROOT72", "reply_to": "ROOT72", "timestamp": "2019-03-07T09:18:41Z", "text": "See #80 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM721", "user": "JAremko", "root": "ROOT72", "reply_to": "COM720", "timestamp": "2019-03-07T09:23:21Z", "text": "@Petrouchka Be thankful. Microsoft uses the data to improve your calculating experience. :smile: ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM722", "user": "jdschuitemaker", "root": "ROOT72", "reply_to": "COM721", "timestamp": "2019-03-07T09:42:43Z", "text": "The Microsoft Store version does collect data, in this project it is disabled by default (per the read me):\r\n\r\n>Data / Telemetry\r\n> ...Telemetry is disabled in development builds by default, and can be enabled with the \r\n> SEND_TELEMETRY build flag.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM723", "user": "mozo78", "root": "ROOT72", "reply_to": "COM722", "timestamp": "2019-03-07T09:50:42Z", "text": "Just use Linux - simple as that ;)", "meta": {"posReactions": "8", "negReactions": "5"}}
{"id": "COM724", "user": "InfoLibre", "root": "ROOT72", "reply_to": "COM723", "timestamp": "2019-03-07T09:56:28Z", "text": "Yes, that's what I'm doing since 2000. Just hoping Microsoft will not put backdoor, telemetry, obfuscation and all its shit in all Github projects, like others did in SourceForge.\r\nUse https://about.gitlab.com, https://framagit.org...", "meta": {"posReactions": "4", "negReactions": "12"}}
{"id": "COM725", "user": "jonkoops", "root": "ROOT72", "reply_to": "COM724", "timestamp": "2019-03-07T11:31:49Z", "text": "> This project collects usage data and sends it to Microsoft. Please stop collecting MY data and remove telemetry from all your f**g Windows products.\r\n\r\nJust because a product is open-sourced doesn't mean you can go around making demands in this manner. Please try to keep your conversation to the point and polite, this benefits nobody.", "meta": {"posReactions": "23", "negReactions": "1"}}
{"id": "COM726", "user": "InfoLibre", "root": "ROOT72", "reply_to": "COM725", "timestamp": "2019-03-07T11:43:47Z", "text": "The subject isn't the Open Source. I don't respect people who want to collect my PRIVATE data with software. If you don't like my demand, delete it. If you want better software, delete all these malwares.", "meta": {"posReactions": "2", "negReactions": "8"}}
{"id": "COM727", "user": "Injazz", "root": "ROOT72", "reply_to": "COM726", "timestamp": "2019-03-07T11:46:20Z", "text": "_FSF wants to know your location_", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM728", "user": "wattengard", "root": "ROOT72", "reply_to": "COM727", "timestamp": "2019-03-07T11:49:22Z", "text": "Why are you even here?", "meta": {"posReactions": "3", "negReactions": "1"}}
{"id": "COM729", "user": "InfoLibre", "root": "ROOT72", "reply_to": "COM728", "timestamp": "2019-03-07T11:54:46Z", "text": "> Why are you even here?\r\n\r\nBecause everybody today is speaking on the Net about a Windows Calculator with telemetry inside. I didn't believe even that was possible and... yes.", "meta": {"posReactions": "1", "negReactions": "3"}}
{"id": "COM7210", "user": "JAremko", "root": "ROOT72", "reply_to": "COM729", "timestamp": "2019-03-07T12:08:53Z", "text": "> Why are you even here?\r\n\r\nBig questions time :roll_eyes: \r\n\r\n@wattengard Let's all be respectful.", "meta": {"posReactions": "2", "negReactions": "2"}}
{"id": "COM7211", "user": "wattengard", "root": "ROOT72", "reply_to": "COM7210", "timestamp": "2019-03-07T12:23:05Z", "text": "How was I not respectful? I just asked a simple question. What isn't respectful is polluting the issue-catalog with useless rants, poorly hidden profanity and shouting. I am, however, done with this issue now.", "meta": {"posReactions": "4", "negReactions": "2"}}
{"id": "COM7212", "user": "glouw", "root": "ROOT72", "reply_to": "COM7211", "timestamp": "2019-03-07T14:53:48Z", "text": "you guys are worried about what data the calculator is collecting? what about the rest of windows lol", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7213", "user": "techtheory", "root": "ROOT72", "reply_to": "COM7212", "timestamp": "2019-03-07T14:54:43Z", "text": "Take your foul mouthed trolling to Twitter. That's what it's there for. There are countless calculator apps. Find one that you are satisfied with and use it. This one is obviously for people with different concerns than you. They get to have their applications too. You are not Calculator King of the Internet. Grow up and move along.", "meta": {"posReactions": "1", "negReactions": "1"}}
{"id": "COM7214", "user": "MicrosoftIssueBot", "root": "ROOT72", "reply_to": "COM7213", "timestamp": "2019-03-07T15:02:23Z", "text": "This is your friendly Microsoft Issue Bot. I've seen this issue come in and have gone to tell a human about it.\r\n<!--METADATA:418196403:{\r\n    \"id\":  20764000\r\n}-->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7215", "user": "InfoLibre", "root": "ROOT72", "reply_to": "COM7214", "timestamp": "2019-03-07T15:05:44Z", "text": "Twitter collects and sells our data too. It's as bad as Microsoft.\r\nUse [Mastodon](https://joinmastodon.org/) instead.\r\nhttps://en.wikipedia.org/wiki/Fediverse", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7216", "user": "mcooley", "root": "ROOT72", "reply_to": "COM7215", "timestamp": "2019-03-07T15:44:31Z", "text": "Our [Code of Conduct](https://github.com/Microsoft/calculator/blob/master/CODE_OF_CONDUCT.md) requires everyone to *be respectful* to each other, and we should do better than what's in this thread. If you have specific questions about our telemetry system for Calculator we can try to answer them separately.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "ROOT73", "user": "insidewhy", "root": "ROOT73", "reply_to": null, "timestamp": "2019-07-21T14:52:51Z", "text": "[Shallow] Implement callEffects option to call effects from shallow renderer (#15275) Fixes the effects related part of #15275 by allowing the user to tell the shallow renderer to call effect hooks.\r \r ~It could do with a couple more tests but I wanted to get feedback on the approach and was also worried about putting any more time into it given that the maintainers have not responded to the corresponding issue in the months it's been open.~\r \r Added a full set of tests.", "meta": {"posReactions": "105", "negReactions": "0"}}
{"id": "COM730", "user": "sizebot", "root": "ROOT73", "reply_to": "ROOT73", "timestamp": "2019-07-21T14:55:58Z", "text": "\n<!--\n  0 failure: \n  0 warning: \n  \n  1 markdown notices\n  DangerID: danger-id-default;\n-->\n\n\n\n\n  <details>\n  <summary>Details of bundled changes.</summary>\n\n  <p>Comparing: 606f76b6e4763581ecf742144ee82756902674ff...9e6ad0ac077fc7f72a4ec17ade583c5826b054bc</p>\n\n\n  \n## react-test-renderer\nFile | Filesize Diff | Gzip Diff | Prev Size | Current Size | Prev Gzip | Current Gzip | ENV\n ---  |  ---  |  ---  |  ---  |  ---  |  ---  |  ---  |  --- \nReactTestRenderer-dev.js | 0.0% | -0.0% | 602.38 KB | 602.38 KB | 125.73 KB | 125.72 KB | FB_WWW_DEV\nreact-test-renderer-shallow.development.js | +5.4% | +3.7% | 39.51 KB | 41.64 KB | 9.95 KB | 10.32 KB | UMD_DEV\n**react-test-renderer-shallow.production.min.js** | **:small_red_triangle:+8.2%** | **:small_red_triangle:+6.2%** | **11.66 KB** | **12.62 KB** | **3.56 KB** | **3.78 KB** | **UMD_PROD**\nreact-test-renderer-shallow.development.js | +6.3% | +4.3% | 33.64 KB | 35.78 KB | 8.54 KB | 8.91 KB | NODE_DEV\n**react-test-renderer-shallow.production.min.js** | **:small_red_triangle:+8.1%** | **:small_red_triangle:+6.3%** | **11.81 KB** | **12.76 KB** | **3.69 KB** | **3.92 KB** | **NODE_PROD**\nreact-test-renderer.development.js | 0.0% | -0.0% | 590.1 KB | 590.1 KB | 126.25 KB | 126.24 KB | UMD_DEV\n**react-test-renderer.production.min.js** | **0.0%** | **-0.0%** | **69.05 KB** | **69.05 KB** | **21.15 KB** | **21.15 KB** | **UMD_PROD**\nReactShallowRenderer-dev.js | +6.7% | +4.7% | 33.63 KB | 35.87 KB | 8.38 KB | 8.78 KB | FB_WWW_DEV\nreact-test-renderer.development.js | 0.0% | -0.0% | 585.64 KB | 585.64 KB | 125.15 KB | 125.15 KB | NODE_DEV\n**react-test-renderer.production.min.js** | **0.0%** | **-0.0%** | **68.78 KB** | **68.78 KB** | **20.93 KB** | **20.93 KB** | **NODE_PROD**\n\n  </details>\n  \n<p align=\"right\">\n  Generated by :no_entry_sign: <a href=\"http://github.com/danger/danger-js/\">dangerJS</a>\n</p>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM731", "user": "bdwain", "root": "ROOT73", "reply_to": "COM730", "timestamp": "2019-07-23T10:26:11Z", "text": "thanks for figuring this out! If you want to copy the logic for componentDidMount and componentDidUpdate, you can see it at #15589", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM732", "user": "insidewhy", "root": "ROOT73", "reply_to": "COM731", "timestamp": "2019-07-24T09:21:56Z", "text": "@bdwain I thought it would be good to handle the life-cycle events in a different PR. Since all my code is using hooks now, I'm not so interested in them. Plus it's easy to call them from outside if you need them, I see that enzyme already does that.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM733", "user": "euroclydon37", "root": "ROOT73", "reply_to": "COM732", "timestamp": "2019-07-25T21:17:19Z", "text": "Lol. I need this in my testing life.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM734", "user": "insidewhy", "root": "ROOT73", "reply_to": "COM733", "timestamp": "2019-07-26T21:32:39Z", "text": "Closed by accident, sorry.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM735", "user": "ssunday", "root": "ROOT73", "reply_to": "COM734", "timestamp": "2019-07-29T20:49:41Z", "text": "@ohjames Thank you so much for doing this! I'm not as familiar with the react code base (clearly from my comments) but if there's anything you need help on to get this going let me know \ud83d\ude2cSo eager to have this functionality in place. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM736", "user": "insidewhy", "root": "ROOT73", "reply_to": "COM735", "timestamp": "2019-07-29T21:01:42Z", "text": "@ssunday Nothing more we can really do for this until the maintainers have a look. They haven't commented on any of the related issues and they've been open for months. It's possible to get this working in your own extension of this library by hooking into one private method on ReactShallowRenderer, that's what I'm doing for now. Enzyme could possibly do the same.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM737", "user": "ssunday", "root": "ROOT73", "reply_to": "COM736", "timestamp": "2019-07-29T21:13:42Z", "text": "@ohjames Yeah, it'll take a while. With a draftjs change I was following, took a decent amount of time. But it happened!\r\n\r\nFor the hooking into private methods, could you link a gist or some examples of how to do that you could add to your PR comment? I think that helped with this [draftjs](https://github.com/facebook/draft-js/pull/2035) PR\u2014 provide a way for people to rest in the wild and confirm? Or post to the Enzyme issue related to this. If it's not too difficult?", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM738", "user": "nommuna", "root": "ROOT73", "reply_to": "COM737", "timestamp": "2019-07-29T21:14:58Z", "text": "This addition would help immensely when testing hooks with enzyme. Hopefully this gets added soon. \r\n\r\n@ohjames what do you mean by \u201chooking into private methods\u201d?  Right now I am trying to find a good way to test private functions under a functional component and I\u2019m not having any luck with it. ", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM739", "user": "ljharb", "root": "ROOT73", "reply_to": "COM738", "timestamp": "2019-07-29T21:49:45Z", "text": "Functional components can't have \"methods\"; that's a term that applies only to classes. If you mean, functions created inside the function, or only accessible via closure, you can't and shouldn't directly test those.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM7310", "user": "bdwain", "root": "ROOT73", "reply_to": "COM739", "timestamp": "2019-07-29T21:59:42Z", "text": "yea i think @ohjames was referring to private methods on the shallow renderer itself", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM7311", "user": "insidewhy", "root": "ROOT73", "reply_to": "COM7310", "timestamp": "2019-07-30T00:35:41Z", "text": "@ljharb I mean you can make the react test renderer support effects if you override one of its \"private\" (underscore prefixed) methods and then flush the hooks after each call to render.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM7312", "user": "ljharb", "root": "ROOT73", "reply_to": "COM7311", "timestamp": "2019-07-30T01:10:08Z", "text": "ah, sure, if hooking into fully public methods can be a reliable mechanism for enzyme, that would suffice pending the proper PRs being merged and released :-)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7313", "user": "insidewhy", "root": "ROOT73", "reply_to": "COM7312", "timestamp": "2019-07-30T08:41:03Z", "text": "@ljharb I wouldn't call an underscore prefixed method \"fully\" public because the intention is private. But... well they didn't use a symbol or # to make it completely private ;)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7314", "user": "ljharb", "root": "ROOT73", "reply_to": "COM7313", "timestamp": "2019-08-01T06:35:54Z", "text": "@ohjames a symbol is also fully public, because it's also accessible from the outside :-) only closed-over variables and private fields are actually \"private\" in javascript.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7315", "user": "insidewhy", "root": "ROOT73", "reply_to": "COM7314", "timestamp": "2019-08-05T08:19:18Z", "text": "@ljharb It can be done by overriding `_createDispatcher` so if that method would be acceptable to enzyme I can hook it in. Is there someone I should be @-ing from the react team to get some \ud83d\udc40 on this? Seems to be quite a lot of interest, but not a single issue on this topic has received a comment from a maintainer in 5 months. Maybe they would have dropped in to tell us it won't be accepted and not to waste any effort on it?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7316", "user": "Joonpark13", "root": "ROOT73", "reply_to": "COM7315", "timestamp": "2019-08-05T15:15:10Z", "text": "> Is there someone I should be @-ing from the react team to get some \ud83d\udc40 on this? Seems to be quite a lot of interest, but not a single issue on this topic has received a comment from a maintainer in 5 months. Maybe they would have dropped in to tell us it won't be accepted and not to waste any effort on it?\r\n\r\nJust wanted to chime in and say I strongly feel the same way - it would be at least good to get a \"hey we won't be considering this\".", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM7317", "user": "gaearon", "root": "ROOT73", "reply_to": "COM7316", "timestamp": "2019-08-05T18:24:06Z", "text": "Sorry I haven't replied earlier!\r\n\r\nGenerally we've been using shallow renderer less and less at Facebook because it encourages brittle tests that verify implementation detail. So components that relied on it a lot introduced a lot of refactoring friction, and didn't catch valuable regressions anyway for us. (Your experience might differ.)\r\n\r\nThe main value proposition of shallow rendering is that you mock out the inner components. We see the value in this, but in our experience doing this at the module system level gives you more leeway when refactoring. For example, you can always `jest.mock('Button', () => 'button')` to replace a child `Button` component with a mock. We've mostly been happy with this approach and found it more flexible.\r\n\r\nSince we don't use the shallow renderer much anymore, we don't feel like we would be good stewards of its API, or even can recommend it. Additionally, Enzyme has been adding different behavior to it (such as calling class commit phase lifecycles) that we didn't originally plan. At least some of it was due to a misunderstanding (for example, React intends to guarantee refs are resolved in the commit phase, but running code with shallow renderer forces you to handle null gracefully). But there is also some mismatch between how Enzyme uses it internally, and how we initially thought it would be used.\r\n\r\n**At this point I think it would be better if we could move out the shallow renderer out of this repository.** It's stagnating here, getting fixes very late, and causes frustration like in this PR. By design, it doesn't use almost any of the React code, so it should be easy to move. On the other hand, Enzyme is in active development and might as well want to take ownership of this piece.\r\n\r\nIf @davidmarkclements were kind to offer the `react-shallow-renderer` package name, we could externalize it there, and maybe it could be maintained in the Enzyme repository or elsewhere instead.\r\n\r\nWould anyone like to propose a plan? Thanks.", "meta": {"posReactions": "11", "negReactions": "0"}}
{"id": "COM7318", "user": "ljharb", "root": "ROOT73", "reply_to": "COM7317", "timestamp": "2019-08-05T23:11:30Z", "text": "That sounds like a great plan, as long as the react team can provide some kind of commitment to expose API as needed, and ideally include tests as part of core - so that enzyme (and the shallow renderer) doesn\u2019t unintentionally break with every release.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7319", "user": "gaearon", "root": "ROOT73", "reply_to": "COM7318", "timestamp": "2019-08-06T11:43:01Z", "text": "What API do you expect to need? Shallow renderer doesn't depend on any other code so I don't expect it to need private APIs. The only one I can think of is the way Hooks Dispatcher is exposed from the `react` package \u2014 but that isn't Enzyme-specific.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7320", "user": "gaearon", "root": "ROOT73", "reply_to": "COM7319", "timestamp": "2019-08-06T11:44:13Z", "text": "We'd be happy to run some tests against a separate package fwiw. Similar to how we have integration tests with `create-react-class`.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7321", "user": "insidewhy", "root": "ROOT73", "reply_to": "COM7320", "timestamp": "2019-08-06T14:11:21Z", "text": "The shallow renderer uses the following modules from \"shared\" that I don't think are externally reachable:\r\n\r\n```js\r\nimport describeComponentFrame from 'shared/describeComponentFrame';\r\nimport getComponentName from 'shared/getComponentName';\r\nimport shallowEqual from 'shared/shallowEqual';\r\nimport invariant from 'shared/invariant';\r\nimport ReactSharedInternals from 'shared/ReactSharedInternals';\r\nimport warning from 'shared/warning';\r\nimport is from 'shared/objectIs';\r\nimport type { ReactContext, ReactEventResponderListener } from 'shared/ReactTypes';\r\nimport type {ReactElement} from 'shared/ReactElementType';\r\n```", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7322", "user": "ljharb", "root": "ROOT73", "reply_to": "COM7321", "timestamp": "2019-08-07T03:36:47Z", "text": "Note that I've previously manually extracted `shallowEqual` as https://www.npmjs.com/package/enzyme-shallow-equal, and `getComponentName` as https://unpkg.com/browse/airbnb-prop-types@2.14.0/build/helpers/getComponentName.js - but it'd be *much* better if I could deprecate both of those to use official React packages, or alternatively, if React could use those instead of its current implementation.\r\n\r\nAlso, `is` exists as https://npmjs.com/object-is (same thing tho, it'd be ideal if React just used that package).", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7323", "user": "roy-law", "root": "ROOT73", "reply_to": "COM7322", "timestamp": "2019-08-11T19:59:10Z", "text": "> Sorry I haven't replied earlier!\r\n> \r\n> Generally we've been using shallow renderer less and less at Facebook because it encourages brittle tests that verify implementation detail. So components that relied on it a lot introduced a lot of refactoring friction, and didn't catch valuable regressions anyway for us. (Your experience might differ.)\r\n> \r\n> The main value proposition of shallow rendering is that you mock out the inner components. We see the value in this, but in our experience doing this at the module system level gives you more leeway when refactoring. For example, you can always `jest.mock('Button', () => 'button')` to replace a child `Button` component with a mock. We've mostly been happy with this approach and found it more flexible.\r\n> \r\n> Since we don't use the shallow renderer much anymore, we don't feel like we would be good stewards of its API, or even can recommend it. Additionally, Enzyme has been adding different behavior to it (such as calling class commit phase lifecycles) that we didn't originally plan. At least some of it was due to a misunderstanding (for example, React intends to guarantee refs are resolved in the commit phase, but running code with shallow renderer forces you to handle null gracefully). But there is also some mismatch between how Enzyme uses it internally, and how we initially thought it would be used.\r\n> \r\n> **At this point I think it would be better if we could move out the shallow renderer out of this repository.** It's stagnating here, getting fixes very late, and causes frustration like in this PR. By design, it doesn't use almost any of the React code, so it should be easy to move. On the other hand, Enzyme is in active development and might as well want to take ownership of this piece.\r\n> \r\n> If @davidmarkclements were kind to offer the `react-shallow-renderer` package name, we could externalize it there, and maybe it could be maintained in the Enzyme repository or elsewhere instead.\r\n> \r\n> Would anyone like to propose a plan? Thanks.\r\n\r\nWhat do you recommend using instead? ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7324", "user": "ljharb", "root": "ROOT73", "reply_to": "COM7323", "timestamp": "2019-08-11T21:10:11Z", "text": "I believe part of the mismatch here is that Facebook largely/historically doesn't do serverside rendering, which is where enzyme (and the shallow renderer) is critical. I'm not aware of any scalable alternatives.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7325", "user": "insidewhy", "root": "ROOT73", "reply_to": "COM7324", "timestamp": "2019-08-16T10:24:28Z", "text": "@ljharb @gaearon How about just renaming `_createDispatcher` to `createDispatcher`. By making it part of the public interface of the class, we can hook into it and implement whatever effects we want from outside?\r\n\r\nIn the long term, to extract the shallow renderer, couldn't the `shared` package just be published?\r\n\r\nBut please consider implementing my first proposal. In the react-native world the shallow renderer is very popular, not being able to use (test) hooks makes us very sad.", "meta": {"posReactions": "10", "negReactions": "0"}}
{"id": "COM7326", "user": "davidmfoley", "root": "ROOT73", "reply_to": "COM7325", "timestamp": "2019-09-17T15:44:52Z", "text": "This would be quite useful to me and to other experienced TDD practitioners who work with react.\r\n\r\nIn addition to being on the order of 100x faster to run as compared to tests that require a stubbed DOM (i.e. JSDOM), shallow rendering allows for test-driving the designs of components much more efficiently/directly than the equivalent virtual DOM tests. Certain classes of components (for example: Providers that encapsulate state machines and provide to their children via context) are much, much easier to test-drive with shallow approaches. \r\n\r\nPlease consider merging this or otherwise exposing hooks to easily integrate effects into shallow test tools like enzyme in a way that is reliable and relatively future-proof.", "meta": {"posReactions": "16", "negReactions": "0"}}
{"id": "COM7327", "user": "kumar303", "root": "ROOT73", "reply_to": "COM7326", "timestamp": "2019-10-11T18:32:51Z", "text": "> Generally we've been using shallow renderer less and less at Facebook because it encourages brittle tests \r\n\r\n@gaearon just curious, is that because those specific components don't have static typing (like Flow) to enforce that nested components get instantiated correctly? Even with Flow, it's sometimes tricky to truly enforce component signatures, e.g. when using poorly typed HOCs.\r\n\r\nIt's true that shallow rendering won't expose problems like passing invalid props but static typing *can* solve this when done correctly.\r\n\r\n> The main value proposition of shallow rendering is that you mock out the inner components. We see the value in this, but in our experience doing this at the module system level gives you more leeway when refactoring. For example, you can always `jest.mock('Button', () => 'button')` to replace a child `Button` component with a mock. We've mostly been happy with this approach and found it more flexible.\r\n\r\nHuh. To me, it seems way more flexible to rely on shallow rendering for this because the test doesn't have to *know* which dependencies to mock. This is important for refactoring; a test should not break when you add/remove nested components since they are not relevant to the main component under test -- nested components already have their own responsibilities.\r\n\r\nI also like how shallow rendering encourages the test author to *only* consider functionality that the component under test is responsible for.\r\n\r\n\r\n> Since we don't use the shallow renderer much anymore, we don't feel like we would be good stewards of its API, or even can recommend it. \r\n\r\nThat makes sense, I was just curious to understand why, in case I'm missing some flaws in shallow rendering.\r\n", "meta": {"posReactions": "14", "negReactions": "0"}}
{"id": "COM7328", "user": "thedanchez", "root": "ROOT73", "reply_to": "COM7327", "timestamp": "2019-10-14T16:17:06Z", "text": "Any updates on this idea of creating a `react-shallow-renderer` package (and merging this PR into it) that can be maintained in isolation or within Enzyme?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7329", "user": "davidmarkclements", "root": "ROOT73", "reply_to": "COM7328", "timestamp": "2019-10-15T10:54:24Z", "text": "@gaearon btw I'm happy to donate the package name when you guys are ready.\r\nI'd also like to talk to someone about contributing https://github.com/esxjs/esx to the project in some way - any pointers?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT74", "user": "Jackarunda", "root": "ROOT74", "reply_to": null, "timestamp": "2019-12-19T10:06:01Z", "text": "Holiday Festivities \r Issue Type: <b>Bug</b>\r \r I saw a red clothing item earlier in the bottom left corner of the window. It reminded me of when my parents were still alive, and brought me such indescribeable joy to see it while coding. When I updated my VSCode, it was gone. I have to assume this was a bug. Where did it go? The last thread I made on this topic was locked by accident. I posted it on my tumblr and sent it to several news outlets but it was locked, and so unusable, so I made a new one to hopefully get some resolution to this issue. This time I'll be taking screenshots to ensure that the Github Issue record doesn't become unuseable.\r \r VS Code version: Code 1.41.0 (9579eda04fdb3a9bba2750f15193e5fafe16b959, 2019-12-11T18:37:42.077Z)\r OS version: Windows_NT x64 10.0.17134\r \r <details>\r <summary>System Info</summary>\r \r |Item|Value|\r |---|---|\r |CPUs|AMD Ryzen 3 1300X Quad-Core Processor           (4 x 3793)|\r |GPU Status|2d_canvas: enabled<br>flash_3d: enabled<br>flash_stage3d: enabled<br>flash_stage3d_baseline: enabled<br>gpu_compositing: enabled<br>metal: disabled_off<br>multiple_raster_threads: enabled_on<br>oop_rasterization: disabled_off<br>protected_video_decode: unavailable_off<br>rasterization: enabled<br>skia_renderer: disabled_off<br>surface_control: disabled_off<br>surface_synchronization: enabled_on<br>video_decode: enabled<br>viz_display_compositor: enabled_on<br>viz_hit_test_surface_layer: disabled_off<br>webgl: enabled<br>webgl2: enabled|\r |Load (avg)|undefined|\r |Memory (System)|7.94GB (3.46GB free)|\r |Process Argv||\r |Screen Reader|no|\r |VM|0%|\r </details><details><summary>Extensions (1)</summary>\r \r Extension|Author (truncated)|Version\r ---|---|---\r csharp|ms-|1.21.9\r \r \r </details>\r <!-- generated by issue reporter -->", "meta": {"posReactions": "31", "negReactions": "1"}}
{"id": "COM740", "user": "Danielx64", "root": "ROOT74", "reply_to": "ROOT74", "timestamp": "2019-12-19T10:27:26Z", "text": "It was removed all because of this one guy: https://github.com/microsoft/vscode/issues/87268 and he prob think that what he did is funny.", "meta": {"posReactions": "4", "negReactions": "1"}}
{"id": "COM741", "user": "PierreRambaud", "root": "ROOT74", "reply_to": "COM740", "timestamp": "2019-12-19T11:25:49Z", "text": "Same, I lost all my family in a car accident. Santa hat reminds me old good memories :sob: :sob: :sob:  ", "meta": {"posReactions": "2", "negReactions": "1"}}
{"id": "COM742", "user": "Piorys", "root": "ROOT74", "reply_to": "COM741", "timestamp": "2019-12-19T11:40:12Z", "text": "I was able to reproduce the issue on my side as well", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM743", "user": "galimba", "root": "ROOT74", "reply_to": "COM742", "timestamp": "2019-12-19T13:20:32Z", "text": "I was attempting to reproduce the issue. Got as far as to feel the joy of my parents being alive, but then a snowflake got in the way and I got offended.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM744", "user": "chrisdias", "root": "ROOT74", "reply_to": "COM743", "timestamp": "2019-12-19T20:05:15Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.\r\n\r\nHappy Coding!\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT75", "user": "jackbond", "root": "ROOT75", "reply_to": null, "timestamp": "2019-06-17T22:14:53Z", "text": "In Which Jack Is Angry An experiment to see whether ANYONE on the SF team actually receives GitHub notifications.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM750", "user": "masnider", "root": "ROOT75", "reply_to": "ROOT75", "timestamp": "2019-06-17T23:03:49Z", "text": "@jackbond Please try to be more constructive. Of course we do. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM751", "user": "jackbond", "root": "ROOT75", "reply_to": "COM750", "timestamp": "2019-06-17T23:06:24Z", "text": "Oh, so you monitor them, but completely ignore them. Much better.\r\n\r\nIs it acceptable that two core Microsoft offerings DevOps and Service Fabric are currently out of sync?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM752", "user": "masnider", "root": "ROOT75", "reply_to": "COM751", "timestamp": "2019-06-17T23:17:52Z", "text": "You are making toxic and unhelpful statements. Please refrain from doing so. Sarcasm and profanity will not help you get your issues resolved. \r\n\r\nI have replied in your [main question](https://github.com/microsoft/service-fabric/issues/333). If you would like to engage in constructive discussion, go there. If you want to continue to make mean and unhelpful assumptions and remarks, go ahead, but then we can just close down this whole thread as well. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT76", "user": "jamescassell", "root": "ROOT76", "reply_to": null, "timestamp": "2019-03-07T00:44:41Z", "text": "spurious CONDITIONAL_BARE_VARS warnings <!--- Verify first that your issue is not already reported on GitHub -->\r <!--- Also test if the latest release and devel branch are affected too -->\r <!--- Complete *all* sections as described, this form is processed automatically -->\r \r ##### SUMMARY\r <!--- Explain the problem briefly below -->\r \r Suprrious Deprecation warning and regular (non-deprecation) warnings when using boolean vars.\r \r ##### ISSUE TYPE\r - Bug Report\r \r ##### COMPONENT NAME\r <!--- Write the short name of the module, plugin, task or feature below, use your best guess if unsure -->\r core\r \r ##### ANSIBLE VERSION\r <!--- Paste verbatim output from \"ansible --version\" between quotes -->\r ```paste below\r ansible 2.8.0.dev0\r   config file = /etc/ansible/ansible.cfg\r   configured module search path = [u'/home/user/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\r   ansible python module location = /home/user/ansible-ansible/lib/ansible\r   executable location = /home/user/ansible-ansible/bin/ansible\r   python version = 2.7.5 (default, Oct 30 2018, 23:45:53) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]\r ```\r \r ##### CONFIGURATION\r <!--- Paste verbatim output from \"ansible-config dump --only-changed\" between quotes -->\r ```paste below\r DEFAULT_STDOUT_CALLBACK(env: ANSIBLE_STDOUT_CALLBACK) = debug\r ```\r \r ##### OS / ENVIRONMENT\r <!--- Provide all relevant information below, e.g. target OS versions, network device firmware, etc. -->\r CentOS/RHEL 7, Fedora 29\r \r ##### STEPS TO REPRODUCE\r <!--- Describe exactly how to reproduce the problem, using a minimal test-case -->\r \r <!--- Paste example playbooks or commands between quotes below -->\r ```yaml\r ---\r - hosts: localhost\r   gather_facts: no\r   vars:\r     mybare: true\r     myfalse: false\r     mycomplex: \"{{ mybare or myfalse }}\"\r   tasks:\r   - debug:\r       msg: bare\r     when: mybare\r   - debug:\r       msg: complex\r     when: mycomplex\r ```\r \r <!--- HINT: You can paste gist.github.com links for larger files -->\r \r ##### EXPECTED RESULTS\r <!--- Describe what you expected to happen when running the steps above -->\r \r Results on ansible 2.7:\r ```\r PLAY [localhost] ****************************************************************************************************************************************************************************************************************************\r \r TASK [debug] ********************************************************************************************************************************************************************************************************************************\r ok: [localhost] => {}\r \r MSG:\r \r bare\r \r \r TASK [debug] ********************************************************************************************************************************************************************************************************************************\r ok: [localhost] => {}\r \r MSG:\r \r complex\r \r \r PLAY RECAP **********************************************************************************************************************************************************************************************************************************\r localhost                  : ok=2    changed=0    unreachable=0    failed=0\r ```\r \r ##### ACTUAL RESULTS\r <!--- Describe what actually happened. If possible run with extra verbosity (-vvvv) -->\r \r Results on devel/2.8\r <!--- Paste verbatim command output between quotes -->\r ```paste below\r PLAY [localhost] ****************************************************************************************************************************************************************************************************************************\r \r TASK [debug] ********************************************************************************************************************************************************************************************************************************\r [DEPRECATION WARNING]: evaluating mybare as a bare variable, this behaviour will go away and you might need to add |bool to the expression in the future. Also see CONDITIONAL_BARE_VARS configuration toggle.. This feature will be removed\r  in version 2.12. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.\r ok: [localhost] => {}\r \r MSG:\r \r bare\r \r \r TASK [debug] ********************************************************************************************************************************************************************************************************************************\r [DEPRECATION WARNING]: evaluating mycomplex as a bare variable, this behaviour will go away and you might need to add |bool to the expression in the future. Also see CONDITIONAL_BARE_VARS configuration toggle.. This feature will be\r removed in version 2.12. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.\r  [WARNING]: conditional statements should not include jinja2 templating delimiters such as {{ }} or {% %}. Found: {{ mybare or myfalse }}\r \r ok: [localhost] => {}\r \r MSG:\r \r complex\r \r \r PLAY RECAP **********************************************************************************************************************************************************************************************************************************\r localhost                  : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0\r ```\r ", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM760", "user": "mz0", "root": "ROOT76", "reply_to": "ROOT76", "timestamp": "2019-03-07T15:07:47Z", "text": "same here:\r\n```\r\n- name: Flag swap LV found (skip otherwise).\r\n  set_fact: swap_lv=yes\r\n  when: res.stdout == \"vg-lv_swap\"\r\n\r\n- name: Flag swap LV not found (skip otherwise).\r\n  set_fact: swap_lv=no\r\n  when: res.stdout != \"vg-lv_swap\"\r\n\r\n- block:\r\n  - ... (5 tasks omitted)\r\n  when: swap_lv|bool\r\n```\r\n(shown with silencing workaround, without this '|bool' each task in block shows that warning)\r\n\r\n```\r\n[DEPRECATION WARNING]: evaluating swap_lv as a bare variable, this behaviour will go away and you\r\nmight need to add |bool to the expression in the future. Also see CONDITIONAL_BARE_VARS \r\nconfiguration toggle.. This feature will be removed in version 2.12. Deprecation warnings can be \r\ndisabled by setting deprecation_warnings=False in ansible.cfg.\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM761", "user": "sivel", "root": "ROOT76", "reply_to": "COM760", "timestamp": "2019-03-07T15:19:35Z", "text": "This is a purposeful warning for this situation.\r\n\r\nThe behavior that it is warning about, relates to how a single bare variable is handled in conditionals.\r\n\r\nWe have a piece of logic, that can perform unexpected actions that we are deprecating in 2.12.\r\n\r\nThat logic would enable the following bad behavior:\r\n\r\n```\r\n- debug:\r\n    msg: \"This should run with 'thing' is the string 'false'\"\r\n  when: thing\r\n  vars:\r\n    thing: \"false\"\r\n```\r\n\r\nThis task actually gets skipped, instead of run.  A string should be a truthy value, but is unwound in a way that makes it falsy.\r\n\r\nInstead of treating that as:\r\n\r\n```\r\n{% if thing %}True{% else %}False{% endif %}\r\n```\r\n\r\nIt instead get's treated as:\r\n\r\n```\r\n{% if false %}True{% else %}False{% endif %}\r\n```", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM762", "user": "jamescassell", "root": "ROOT76", "reply_to": "COM761", "timestamp": "2019-03-07T15:35:57Z", "text": "I assume my reproducer playbook will work identically as it does today (2.7) once the deprecation message is gone.  Can an option to be added to squash only this warning?  There is nothing wrong w/ the playbook I described above.\r\n\r\nThe second warning in the \"complex\" task for certain seems like a recurrence of a bug that happened a few releases ago.\r\n\r\nEdit: it would be most useful to only show the warning for cases where a string is converted implicitly to a bool.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM763", "user": "sivel", "root": "ROOT76", "reply_to": "COM762", "timestamp": "2019-03-07T15:40:04Z", "text": "It should work the same.  You can try to silence it by setting `CONDITIONAL_BARE_VARS` to `False` (https://docs.ansible.com/ansible/devel/reference_appendices/config.html#conditinal-bare-vars)\r\n\r\nThere are issues aside from bool conversion as well.\r\n\r\nIn the case of `thing: \"foo\"`, it would be changed to `{% if foo %}` which would give an undefined var error, if `foo` did not exist, or if it existed, it could also give an unexpected outcome.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM764", "user": "jamescassell", "root": "ROOT76", "reply_to": "COM763", "timestamp": "2019-03-07T15:48:53Z", "text": "So this feature is opt-in for now?  And if I opt-in, it will squash the warning?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM765", "user": "sivel", "root": "ROOT76", "reply_to": "COM764", "timestamp": "2019-03-07T15:55:48Z", "text": "It is opt-in, and if you opt-in, the warning will disappear.  Once 2.12 lands, the default will swap to `False`, the current default is `True`", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM766", "user": "ChristianCiach", "root": "ROOT76", "reply_to": "COM765", "timestamp": "2019-05-23T11:12:49Z", "text": "Does it really make sense to show the warning even if the variable in question is undoubtedly a boolean? There is no difference in this case (as far as I understand this). It doesn't make sense to pipe a boolean variable through the `|bool` filter.\r\n\r\nAlso, I think the warning itself is misleading. It says `evaluating x as a bare variable, this \r\nbehaviour will go away`. This sounds like bare variables won't be supported at all in the future, but in reality they will just be interpreted differently in cases where the variable is of type String.", "meta": {"posReactions": "8", "negReactions": "0"}}
{"id": "COM767", "user": "dbilling", "root": "ROOT76", "reply_to": "COM766", "timestamp": "2019-05-28T21:16:39Z", "text": "Completely agree with @ChristianCiach -- shouldn't this warning be only issued when a bare **string** variable is used in a conditional?  That would be deserving of a warning. However, this deprecation warning also seems to be issued when a bare **boolean** variable is being used in a conditional. \r\n\r\nLet's look at an example included in ansible's own documentation:  https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html#the-when-statement\r\n```\r\nvars:\r\n  epic: true\r\ntasks:\r\n    - shell: echo \"This certainly is epic!\"\r\n       when: epic\r\n```\r\n\r\nWhy is this triggering the deprecation warning?   This warning will cause a tremendous amount of work for the ansible community... that is, tons of playbooks will need to be rewritten that have conditionals checking bare booleans.  (for example, adding the | bool filter to make the warning go away)  Wouldn't it make sense to only have the deprecation warning pop out when it's a naked string variable is being evaluated, and not have the warning for a naked boolean variable?", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM768", "user": "ChristianCiach", "root": "ROOT76", "reply_to": "COM767", "timestamp": "2019-05-29T08:56:16Z", "text": "It should also be mentioned that ansible-lint rule E602 explicitly encourages the use of bare-variable conditionals that trigger deprecation warnings now. https://docs.ansible.com/ansible-lint/rules/default_rules.html", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM769", "user": "jamescassell", "root": "ROOT76", "reply_to": "COM768", "timestamp": "2019-05-29T10:40:40Z", "text": "> It should also be mentioned that ansible-lint rule E602 explicitly encourages the use of bare-variable conditionals that trigger deprecation warnings now. https://docs.ansible.com/ansible-lint/rules/default_rules.html\r\n\r\nNothing is really being deprecated for those using true booleans, only a default changed.  I agree that it should not be triggered in this case. You can squash these warnings by opting in to the new behavior, which is what everyone wanted anyway from the start.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7610", "user": "dbilling", "root": "ROOT76", "reply_to": "COM769", "timestamp": "2019-05-29T17:00:57Z", "text": "Opting into the new/future behavior  (i.e. setting conditional_bare_variables to false in ansible.cfg) is only a resonable solution for an end user.  For those that write and maintain roles consumed by others, these spurious warnings create a horrible choice: they will either need to continuously tell all their users to ignore the copious warnings/reconfigure their ansible.cfg file, or, alternatively, make silly changes to the role to make the spurious warnings go away.    Most role maintainers will simply give in, and add a \" | bool\" filter, even though using the | bool filter on a boolean is just silly.   This is really a sad situation, and I'm really surprised to see Ansible miss so badly.  Ansible's own examples cause this spurious warning, yet there have been no changes to the examples!\r\n\r\n\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7611", "user": "sivel", "root": "ROOT76", "reply_to": "COM7610", "timestamp": "2019-05-30T15:53:26Z", "text": "After a discussion in our recent IRC meeting (https://meetbot.fedoraproject.org/ansible-meeting/2019-05-30/ansible_public_core_irc_meeting.2019-05-30-15.01.log.html#l-116) we would entertain a PR that tries to further clarify the warning, or restrict it to a smaller subset of conditions.\r\n\r\nAccepting the PR would be dependent on the implications of the change and specific implementation, ensuring that we do not cause performance regressions or cause other problems.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7612", "user": "s-hertel", "root": "ROOT76", "reply_to": "COM7611", "timestamp": "2019-05-30T16:38:20Z", "text": "I have opened a tentative solution [here](https://github.com/ansible/ansible/pull/57190) to restrict it to a smaller subset of warnings and would appreciate any feedback.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT77", "user": "jamiebuilds", "root": "ROOT77", "reply_to": null, "timestamp": "2018-08-28T23:07:06Z", "text": "\u274c(REVERTED): Add text to MIT License banning ICE collaborators ## The Lerna Core team has reverted this PR and revert information and response can be found in https://github.com/lerna/lerna/pull/1633\r \r ============================================\r \r In this PR, the following text has been added to the existing MIT license:\r \r ```\r The following license shall not be granted to the following entities or any\r subsidiary thereof due to their collaboration with US Immigration and Customs\r Enforcement (\"ICE\"):\r \r - \"Microsoft Corporation\"\r - \"Palantir Technologies\"\r - \"Amazon.com, Inc.\"\r - \"Northeastern University\"\r - \"Ernst & Young\"\r - \"Thomson Reuters\"\r - \"Motorola Solutions\"\r - \"Deloitte Consulting LLP\"\r - \"Johns Hopkins University\"\r - \"Dell Inc\"\r - \"Xerox Corporation\"\r - \"Canon Inc\"\r - \"Vermont State Colleges\"\r - \"Charter Communications\"\r - \"LinkedIn Corporation\"\r - \"United Parcel Service Co\"\r ```\r \r I have already spoken to @kittens and @evocateur about this privately, but I do need @kittens to give us permission to make this change.\r \r # Explanation\r \r Over the last year I've been really disturbed to see what ICE has done to American immigrants, to an extreme with what has happened to children.\r \r The other day I saw this video from the ACLU about a toddler who after being separated from his family for several months could no longer look his mother in the face:\r \r [<img width=\"1312\" alt=\"screen shot 2018-08-28 at 3 53 53 pm\" src=\"https://user-images.githubusercontent.com/952783/44755388-cdf86280-aada-11e8-8749-3ec6fd27fdcc.png\">\r ](https://twitter.com/ACLU/status/1033084026893070338)\r \r <p align=\"center\"><a href=\"https://twitter.com/ACLU/status/1033084026893070338\">twitter.com/ACLU/status/1033084026893070338</a></p>\r \r Those with a background in early childhood development can tell you that severe cases of neglect at an early age can and will cause severe developmental delays and disabilities. They will grow up feeling detached, they will have deep rooted trust issues, and they will have an inability to feel empathy. The actions of ICE have had a lasting lifelong impact on these children, and many of them won't even remember it happening.\r \r I have trouble expressing how angry this makes me feel.\r \r And the worst part is that I feel helpless to improve the situation. I vote, I campaign, I phone bank, I donate, I protest, I write to officials, I try to inform others... and yet things just keep getting worse and worse.\r \r There is one thing I have control over, and that's open source. Open source has always been a way that I try to make the world a better place. Bringing new contributions to the community helps drives innovation and competition.\r \r Lerna is a perfect example of that. Historically monorepos required a lot of infrastructure and only large teams and companies could afford to set it up and maintain it. They had a very expensive cost to them. Lerna made it available to everyone and the community has flourished around it.\r \r Tool after tool, this is what we accomplish with open source. This is what we contribute back to the world. But today I want to do something more.\r \r As we've learned over the last few years with Facebook, Uber, Google, and others. Tech companies do a lot of shady things behind the scenes.\r \r Recently it's come out that a lot of big tech companies are supporting ICE by providing them with infrastructure and in some cases doing significant development work for them. They all have their excuses, but the fact is that these companies care only about the millions of dollars that ICE is paying them and are willing to ignore all the horrible things that ICE does.\r \r Recently it has come to my attention that many of these companies which are being paid millions of dollars by ICE are also using some of the open source software that I helped build.\r \r Now, it's not news to me that people can use open source for evil. That's part of the whole deal.\r \r But it's really hard for me to sit back and ignore what these companies are doing with my code. It doesn't feel like there are enough steps in between me and the horrible things ICE is doing.\r \r So my plan now is to start licensing my software differently.\r \r I have spoken to Sebastian and Daniel about this and we all want Lerna to do the same.\r \r For the companies that are known supporters of ICE: Lerna will no longer be licensed as MIT for you. You will receive no licensing rights and any use of Lerna will be considered theft. You will not be able to pay for a license, the only way that it is going to change is by you publicly tearing your contracts with ICE.\r ", "meta": {"posReactions": "18", "negReactions": "9"}}
{"id": "COM770", "user": "nitrohorse", "root": "ROOT77", "reply_to": "ROOT77", "timestamp": "2018-08-29T02:04:08Z", "text": "Lerna team, thank you for taking a stand \ud83d\udc4f\ud83c\udffc\ud83d\udc4f\ud83c\udffc\ud83d\udc4f\ud83c\udffc", "meta": {"posReactions": "4", "negReactions": "5"}}
{"id": "COM771", "user": "jepler", "root": "ROOT77", "reply_to": "COM770", "timestamp": "2018-08-29T03:04:04Z", "text": "Please make sure that you amend your page on npmjs.org so that it does not state that the license of the project is \"MIT\".", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM772", "user": "akatechis", "root": "ROOT77", "reply_to": "COM771", "timestamp": "2018-08-29T03:09:47Z", "text": "Curious: Do \"parents\" who drag their children across the desert with the express intent of illegally entering the United States have no share of blame for what happens to these children?", "meta": {"posReactions": "0", "negReactions": "17"}}
{"id": "COM773", "user": "leibwiht", "root": "ROOT77", "reply_to": "COM772", "timestamp": "2018-08-29T03:24:41Z", "text": "Are you protesting the right of the United States to choose who to allow to immigrate by deporting illegal aliens, or are you protesting the specific treatment of these illegal aliens in the context of their removal? If it's the former, then there's no point in bringing up their specific treatment as a point for why ICE should be protested (because it would be the case regardless of the treatment of any particular alien), and if it's the latter, then why not specify that, and protest by listing what exactly you would like changed about the treatment of aliens during their deportation? That would make what exactly you are protesting much clearer.", "meta": {"posReactions": "3", "negReactions": "1"}}
{"id": "COM774", "user": "tjdownes", "root": "ROOT77", "reply_to": "COM773", "timestamp": "2018-08-29T03:40:14Z", "text": "I'm adding it to all my repos to prevent the lerna project from being used in any of those projects, both open source and commercial. Just as a matter of principal. Adding your political beliefs to your licensing is petty. The irony is that this very project is hosted on a resource owned by Microsoft...", "meta": {"posReactions": "2", "negReactions": "1"}}
{"id": "COM775", "user": "benbrittain", "root": "ROOT77", "reply_to": "COM774", "timestamp": "2018-08-29T03:44:57Z", "text": "While I too abhor ICE, this isn't actually a valid license change. In order to re-license a project without a CLA, the consent of all contributors needs to be sought. There are a variety of scripts out there that accomplish this, the one I am most familiar with is the [Rust Relicense assistant](https://github.com/cmr/relicense-assistant). I'd suggest using similar tooling to avoid potential legal issues.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM776", "user": "jwcrawley", "root": "ROOT77", "reply_to": "COM775", "timestamp": "2018-08-29T03:48:33Z", "text": "Yep, noted that is is no longer Open Source Software, by definition of https://opensource.org/osd .\r\n\r\nThe way this tirefire of a license can be interpreted, is that since a company uses Windows and pays Microsoft, they are complicit. Or Github for that matter, which is owned by Microsoft. Are the Lerna repo maintainers profiting on ICE, in direct opposition to their license? Github free accounts didn't come from nothingness.", "meta": {"posReactions": "2", "negReactions": "3"}}
{"id": "COM777", "user": "exogen", "root": "ROOT77", "reply_to": "COM776", "timestamp": "2018-08-29T03:56:32Z", "text": "@jwcrawley: So what? Maximal open source permissiveness is not automatically correct and just. It's just one option.\r\n\r\nAnd no, the terms are pretty clear, I suggest you read more carefully: \"The following license shall not be granted to the following entities or any subsidiary thereof.\" It says nothing about people giving money to e.g. Microsoft or using Microsoft products.", "meta": {"posReactions": "2", "negReactions": "1"}}
{"id": "COM778", "user": "zeusk", "root": "ROOT77", "reply_to": "COM777", "timestamp": "2018-08-29T04:21:19Z", "text": "I'm not sure how disallowing corporations that deal with ICE from using lerna would affect ICE's behavior - which I assume is the intent behind this PR.\r\n\r\nShoving politics into code will not help anyone.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM779", "user": "sebmck", "root": "ROOT77", "reply_to": "COM778", "timestamp": "2018-08-29T04:28:52Z", "text": "**Edit:** Just to clarify, I would not have personally made this change. I do however respect the existing maintainers of the projects decision to do so. I do not consider this project to be mine.\r\n\r\nLocking this issue.\r\n\r\nIf you disagree with the license then you're welcome to use one of the alternatives or write your own.\r\n\r\nIf you're employed by a subsidiary listed, direct any questions about the usage of Lerna to your company lawyer. This license only applies to future versions, you're free to use old versions that do not contain this clause.\r\n\r\nIf you have concerns over the legality of relicensing. The MIT license allows sublicensing, which this falls under. Even still, all contributors implicitly agreed to the existing license, of which I am the original license holder, when they submitted code meaning we are within our rights to relicense.\r\n\r\nIf you're a contributor with active code in Lerna, and disagree with the relicense, feel free to privately message @jamiebuilds, @evocateur, or myself and we'll ensure that your contributions are either removed or rewritten to remove attribution.\r\n\r\nThanks everyone for your comments thus far.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT78", "user": "jan-johansson-mr", "root": "ROOT78", "reply_to": null, "timestamp": "2016-05-23T15:05:43Z", "text": "Server side WCF  Hi,  I'd like to start a thread to have a dialog about server side WCF on .NET Core. For me the WCF stack is quite impressive, and support for server side WCF on .NET Core would be fantastic. Please feel free to add your opinions to the thread.  Here is a list of some of the WCF features (that comes to my mind): - Throttling - Reliability - Ordered Messages - Bindings - Instance Management - Behaviors - Transactions - Security - Discovery - Metadata Exchange - Extensibility  These features and more are for me very desirable, but some might be harder to support (e.g. WCF transactions relies on MS DTC (as fas as I know), but transactions enabled communication on a server side is a very important feature).  I hope you're as excited as I am about WCF, and even more so for a server side WCF on .NET Core. ", "meta": {"posReactions": "131", "negReactions": "8"}}
{"id": "COM780", "user": "guybar", "root": "ROOT78", "reply_to": "ROOT78", "timestamp": "2016-05-25T10:53:57Z", "text": "Hi,\n\nI too appreciate WCF, and use it a lot.\nFor me the most important features are:\n- Security\n- Extensibllity\n- Behaviors\n- Bindings (Especially TCP.Net)\n- Metadata Exchange\n- Instance Management\n- Reliability\n\nI think this could really be a showstopper for .Net core, if it will not have WCF server side support.\n\nGuy\n", "meta": {"posReactions": "21", "negReactions": "0"}}
{"id": "COM781", "user": "menaheme", "root": "ROOT78", "reply_to": "COM780", "timestamp": "2016-05-25T11:33:08Z", "text": "Helllo, \n\nWe also use WCF extensively in our applications. \nTo add to the lists above we also use:\n- queued services\n\nMenahem\n", "meta": {"posReactions": "15", "negReactions": "0"}}
{"id": "COM782", "user": "reifnir", "root": "ROOT78", "reply_to": "COM781", "timestamp": "2016-05-25T13:12:57Z", "text": "WCF applications on Core would be a huge boon.\n\nThe only thing I would explicitly like to add to the OP's features are all of the behavior types (not just the ones available in Service Fabric)\n- Operation Behaviors\n- Service Behaviors\n- Contract Behaviors\n- Endpoint Behaviors\n\nI distributed transactions are a prohibitive factor, they can be thrown out the window though.\n", "meta": {"posReactions": "14", "negReactions": "0"}}
{"id": "COM783", "user": "dotnetchris", "root": "ROOT78", "reply_to": "COM782", "timestamp": "2016-05-25T14:33:40Z", "text": "Service Bus binding of WCF is absolutely amazing for building push based reactive applications\n", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM784", "user": "kscelfo", "root": "ROOT78", "reply_to": "COM783", "timestamp": "2016-05-26T02:16:15Z", "text": "I do consider a full WCF implementation to be a prerequisite for moving to .NET core. Without it, it will remain a variation of the .NET Framework that cannot be utilized behind the firewall of major enterprise applications that employ Service Orientation. The major features I rely on that haven't been mentioned are:\n- Net.TCP Binding\n- Net.Pipe Binding\n- Interception-based Pipeline\n- Context \n- Headers\n- Contract-based Coding Model\n\nThe two bindings are required to enable the efficiency of communication that Service Oriented systems require behind the firewall. \n\nThe interception is critical to allow architects to provide the necessary aspects of the system in a way that does not require the developers to do anything except code as they normally would. \n\nContexts and Headers are required to propagate information that is ubiquitous through the application\u2019s stack from the client layer all the way down to the data layer and back up again without affecting the call contracts. Here, I\u2019m thinking about identity information as a universal example. \n\nThe contract-based coding model is really necessary to avoid going back to the string-parsing voodoo that had us living in a type-uncertain, data-validity-in-question wild-west back when Microsoft thought passing hash tables to and from SOAP web services was a good idea. \n", "meta": {"posReactions": "15", "negReactions": "0"}}
{"id": "COM785", "user": "jan-johansson-mr", "root": "ROOT78", "reply_to": "COM784", "timestamp": "2016-05-28T02:43:50Z", "text": "Thanks for input. The implementation of back-end systems needs a mature communication stack, such as WCF. As you pointed out in the thread, a .NET Core positioned on the client side is in my mind taking away the potential of what .NET Core can be.\n\nI'm sure we all can wire basic communication (TCP, HTTP, ...) and then get bogged down into details about message parsing, to get some implementation of back-end on .NET Core. I'll stick my neck out and  claim that WCF takes a lot of plumbing away from development (reduces waste and error prone code), letting us focus on business value. That is the reason why I enjoy WCF so much, and really would love to see support for server side WCF in .NET Core, rather sooner than later.\n", "meta": {"posReactions": "10", "negReactions": "0"}}
{"id": "COM786", "user": "EricaMo", "root": "ROOT78", "reply_to": "COM785", "timestamp": "2016-06-01T00:05:42Z", "text": "Thanks for all the feedback on WCF Server top features! Keep it coming!\n\nProviding WCF Server support for .NET Core is on the radar.\n\nAs you know, our current POR is to provide the WCF client-side libraries in .NET Core to enable UWP/ ASP.NET Core/.NET Core applications to call .NET Framework based WCF Services.\n\nWe are very interested to better understand your scenarios where WCF server side functionality is required.\nIs this blocking your adoption .NET Core? \nDo you have active projects on .NET Core for WCF Server scenarios? (We would like to partner closely with you)\nWould you plan to port over your existing services or is this for needed new development? \n", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM787", "user": "olilanz", "root": "ROOT78", "reply_to": "COM786", "timestamp": "2016-06-01T07:00:07Z", "text": "A specific business case I have is that we have an investment management system with several million lines of code for which the server side is currently hosted on premise on MS Windows Servers at about 200 insurance companies and banks world wide. We have about 100+ service types, of which in the largest installations there are 700 to 800 concurrent service instances at play. Our product is driving important parts of the core businesses.\n\nThe expenditure on IT is huge for our customers. This is also the place where we are looking to make major improvements over the coming years. A part of that is to find alternative hosting environments. A favorable choice would be Windows Nano, or the .NET Core on Linux. For being able to adopt .NET Core (or Windows Nano) we are missing the WCF server side.\n\nSince we are very happy with WCF as a programming model, there is no incentive to rewrite our applications other than that WCF server side is unavailable in our future hosting environments. Particular features that we use is long. But to start .NET Core adoption are, these are the important ones:\n- Self-hosting using ServiceModel.ServiceHost\n- NetTcp (half-duplex)\n- Message inspectors for instrumentation and access to SOAP headers\n- Behaviours\n- OperationContext\n- Contract based programming model\n\nYes. We would continue building WCF services also on .NET Core.\n", "meta": {"posReactions": "18", "negReactions": "0"}}
{"id": "COM788", "user": "jan-johansson-mr", "root": "ROOT78", "reply_to": "COM787", "timestamp": "2016-06-01T18:53:39Z", "text": "In my case it is needed for new solutions, where WCF services can be agnostic deployed (Windows, Linux, OSX, cloud) on .NET Core.\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM789", "user": "niplar", "root": "ROOT78", "reply_to": "COM788", "timestamp": "2016-06-02T06:38:35Z", "text": "Over the past 6 years, in the solutions I have been involved in (in the .net area), we have always relied on WCF to handle the service layer (behind the firewall & intranet) of the solutions. Nothing out there gives us the same level of flexibility and support for different communication channels like WCF does.\n\nI have been holding back moving to .net core for production environments for the lack of WCF support specifically. Not supporting WCF server on .net core creates a need to rewrite a lot of infrastructure code; which will probably end up mimicking the WCF programming model anyway.\n\nThe biggest solution I worked on was used by over 300 health care institutes, rewriting the server layers and functionalities is a big investment to say the least, not to mention high risk. \nIn fact, in that same solution we were looking at a way to unify the programming model between server and embeded devices (linux) for new products. Supporting WCF services on .net core (not just clients) could've been a really big help and cost saver as there would be no need to have 2 development teams; but in stead have a larger singularly focused team.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7810", "user": "fefedimoraes", "root": "ROOT78", "reply_to": "COM789", "timestamp": "2016-06-02T20:32:52Z", "text": "My scenario is pretty much similar to @olilanz's, except that my business case is Point of Sales. Like him, we have our application deployed to numerous stores world wide. We are also looking for alternate ways of hosting our application in order to reduce infrastructure costs. As @jan-johansson-mr said, agnostic deploying WCF services would be great and would give us a huge flexibility.\n\nWCF plays a major role in our application: it is based on a plug-in architecture where which plug-in is basically a WCF Service, so communication between plug-ins are actually WCF calls. Changing this aspect would mean have to rewrite/rethink a lot of infrastructure code.\n\nIn our case, self hosting using instances of _ServiceHost_ and the Contract based programming model is crucial. Our plan is not only migrate existing services, but also create new services.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7811", "user": "Suriman", "root": "ROOT78", "reply_to": "COM7810", "timestamp": "2016-06-07T15:21:12Z", "text": "Hi,\n\nFor us the most important features are:\n- Behaviors.\n- Bindings.\n- Transactions.\n- Headers.\n- Self-hosting.\n- Integration with WF.\n- Queued Services.\n- MEX.\n- Binary Serialization (intranet communications).\n- Callback operations.\n\nResponding to Erica:\n1) Yes, at least it is delaying.\n2) Yes, we are migrating our application that also uses WF.\n3)  For both scenarios.\n\nThanks!\n", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM7812", "user": "websitewill", "root": "ROOT78", "reply_to": "COM7811", "timestamp": "2016-06-09T14:11:05Z", "text": "I have done a lot of projects that leverage the many aspects of WCF. Most of what I leverage in WCF (pretty much everything) is currently missing from .NET Core. Much of this missing capability  would require various 3rd party libraries (or extensive custom code) to fill in the gaps and it's just not worth that level of investment when WCF already works, brilliantly. WCF is, above all else, a great productivity enhancer for my teams.\n\nThe biggest piece missing for me, currently, is the extensibility model that WCF provides. \nMost of my projects leverage the capability to completely decouple cross-cutting concerns from my other components (which are light-weight WCF services). WCF provides a fantastic mechanism for doing this without the need of 3rd party Aspect Oriented Programming libraries. Developers don't know (or even care) and can focus solely on delivering the business value of the features they are concerned with.\n\nWe also leverage many other aspects of WCF such as: \nnamed pipes, transactional queuing programming model, enforcement (not encouragement) of interface-based design, security capabilities, process isolation, error masking, I could go on.\n\nWithout WCF (or equivalent capabilities) in .NET core I would lose way too much productivity and cannot justify the switch. It would be great to have all of these powerful capabilities in a platform that can be used in any type of environment. Imagine, productivity of WCF plus cost-savings of cheaper hosting environments. That is a tremendous business value.\n\nThanks for tracking this issue,\nWill\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7813", "user": "kscelfo", "root": "ROOT78", "reply_to": "COM7812", "timestamp": "2016-06-09T14:27:37Z", "text": "I agree with @websitewill as I am in that exact situation. I'd also like to point out that WCF in the full .NET Framework is done, finished, complete. If that spec were implemented to the letter in .NET Core I'd be very content and would be able to start transitioning projects. \n\nThanks,\nKenny\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7814", "user": "tpkurilla", "root": "ROOT78", "reply_to": "COM7813", "timestamp": "2016-06-09T14:44:00Z", "text": "I have to throw my support for WCF in .NET Core as well.\n\nMy primary client is a fairly large, heterogeneous WAN with intermittent connectivity.\n\nI have dreamed for years of having WCF across their entire network so that I can finally (!) have reliable transactions and durable services spanning their various generations of Linux and Windows.\n\nThe thought of bringing all of WCF's many capabilities (as enumerated in this thread) to my client's entire infrastructure would literally be a dream come true. We can spend the vast efforts we've previously put toward plumbing into the services that can streamline everything we do, and take us to the next level.\n\nPlease, please make this happen.\n\n-Thomas\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7815", "user": "paulharker", "root": "ROOT78", "reply_to": "COM7814", "timestamp": "2016-06-09T16:30:47Z", "text": "Let me also mention the value of WCF in .NET core.\n\nWCF gives the best capabailities across all my services. (Perhaps we need a sexier name for it) but in general, I use and wish to continue to use:\n- **System.Transactions**\n- **Durable services**\n- **Named pipes**\n- **An extensibility model**\n- **Transactional Queuing**\n- **MEX framework (and MEX endpoint)**\n\nAnd when we can run these services on Linux (and eventually IOS), it allows the most solid framework\n\nPaul\n", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM7816", "user": "escherrer", "root": "ROOT78", "reply_to": "COM7815", "timestamp": "2016-06-09T17:57:17Z", "text": "Having WCF on .Net core is not only desirable, it is essential. At it's current state WCF is THE most universal and mature framework to communicate between devices, and within devices using Named Pipes. Over the wire, it adheres to common standards allowing other platforms to communicate as well. But with WCF running in .Net core, the choice will be easy to make.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7817", "user": "holthopkins", "root": "ROOT78", "reply_to": "COM7816", "timestamp": "2016-06-09T18:23:32Z", "text": "We have a strong need to run .NET/WCF on Linux, so please add this to the road map!  We have invested heavily in WCF over the past decade and would hate to give up all the WCF benefits others have listed so well just because this was passed over by .NET Core.  We use most features and benefit greatly from being able to customize/extend the framework to suit our needs, such as custom message broker support (alternatives to MSMQ).\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7818", "user": "mjpandian", "root": "ROOT78", "reply_to": "COM7817", "timestamp": "2016-06-09T21:45:09Z", "text": "Having WCF supported in .NET Core is a great idea and my list of key features are:\n\nSecurity \nBehaviors\nBindings \nInstance Management\nThrottling\nMetadata Exchange.\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7819", "user": "billyweisberg", "root": "ROOT78", "reply_to": "COM7818", "timestamp": "2016-06-10T00:24:46Z", "text": "Our team used WCF to build an entire SOA platform. Each service is hosted in it's own app domain that provides complete isolation for every service. This allowed us to monitor resources, per service, and unload a service and swap it out with the app hot. I know app domains are gone, but what could possibly replace wcf?\n\nService Bus + Net Messaging Binding\nNet Pipe binding \nstrongly typed headers and contexts\nBehaviors and interception\nMEX\n\nyou have a super reliable, and extendable set of tools. wcf provides the best tools for building enterprise applications. Without it, you simply end up rebuilding it.\n\nBringing the power of wcf to other platforms would be huge.\n\nLinux + sql + wcf + service bus + .net core looks good to me.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7820", "user": "websitewill", "root": "ROOT78", "reply_to": "COM7819", "timestamp": "2016-06-10T00:41:04Z", "text": "I'm curious. From what I understand, Azure itself is written, in large part,  usIng WCF (or at least something that provides all the capabilities of WCF) behind the firewall. That being the case, why would it be excluded from .NET Core in the first place? \n\nSeems odd to exclude such a powerful and foundational toolset.\n\nSent from my iPhone\n\n> On Jun 9, 2016, at 8:24 PM, Billy notifications@github.com wrote:\n> \n> Our team used WCF to build an entire SOA platform. Each service is hosted in it's own app domain that provides complete isolation for every service. This allowed us to monitor resources, per service, and unload a service and swap it out with the app hot. I know app domains are gone, but what could possibly replace wcf?\n> \n> Service Bus + Net Messaging Binding\n> Net Pipe binding \n> strongly typed headers and contexts\n> Behaviors and interception\n> MEX\n> \n> you have a super reliable, and extendable set of tools. wcf provides the best tools for building enterprise applications. Without it, you simply end up rebuilding it.\n> \n> Bringing the power of wcf to other platforms would be huge.\n> \n> Linux + sql + wcf + service bus + .net core looks good to me.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7821", "user": "vercruysb", "root": "ROOT78", "reply_to": "COM7820", "timestamp": "2016-06-10T07:59:59Z", "text": "Another use case could be, using WCF on a gateway like device for example in home automation using linux based controllers with an ARM CPU and 512MB memory is not that uncommon. Being able to use .NET core on those types of devices and using WCF to allow creating a SOA like programming model, making use of named pipes and allowing to move around context and create reliable communication could create a whole other way of working than the current C daemons, dbus communicating way of doing things. \n\nUsing WCF could also than be used to for example let your app communicate with your WCF service in your house, for offline controlling. It would provide better integration with service bus allowing efficient communication to and from cloud based services.\n\nBjorn \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7822", "user": "davojc", "root": "ROOT78", "reply_to": "COM7821", "timestamp": "2016-06-10T13:43:06Z", "text": "We have quants writing server side code in Mono (they need cross platform) who were almost jumping up and down in glee with the introduction of .Net Core ... until I told them that it wouldn't support AppDomains, which they currently rely on heavily.\n\nThe look on their faces was one of despair. I have showed them a viable alternative using WCF and named pipes (to give them the isolation they desire without compromising performance). They were even more interested when I showed them that they could then scale these services across machines and across platform (if WCF services were supported on Linux)\n\nSo, this is blocking adoption of .NET Core in this scenario and we would be looking to port existing processes/services to .NET Core as well as developing new services using .NET Core.\n\nDavid\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7823", "user": "joychak", "root": "ROOT78", "reply_to": "COM7822", "timestamp": "2016-06-10T15:28:15Z", "text": "My company (one of the largest financial product company) has huge investment in Linux/Ubuntu. The windows infrastructure is relatively tiny but has tons of WCF services running for business critical applications. Running WCF on .NET Core running in Linux environment is a huge benefit in integrating with other (non-windows) services and platform consolidation point of view.\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7824", "user": "roncain", "root": "ROOT78", "reply_to": "COM7823", "timestamp": "2016-06-10T16:09:56Z", "text": "Thank you -- this is really great feedback and much appreciated.  We hear you and are collating this feedback as well as reaching out to other known WCF customers.  Especially useful are the specific features called out (e.g. queuing, transaction, etc.) because it allows us to prioritize and do targeted investigations.\n\nFor the record, the \"missing\" features of the full .NET framework's WCF were not deliberately excluded from .NET Core WCF. Rather, the initial goal was to support all the existing Windows Store WCF API's on NET Core (which are all client-facing) before tackling other mission-critical features of WCF.  It might help to know that much of the work of porting WCF features involves re-implementing OS-level libraries that WCF depends on (e.g. socket layer, cryptography, etc.) to allow it to work cross-platform. So lighting up WCF features usually involves replacing OS-level libraries for each platform first.  It might help to think that the \"W\" in WCF is no longer a given in NET Core.\n\nThis is one reason why it is so valuable to hear from you which features matter most, because it lets us investigate more deeply questions like \"Which libraries are required to do feature X on Linux? OS X?, etc.\".  Please keep those suggestions and specific scenarios coming!\n", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM7825", "user": "SergeyZa", "root": "ROOT78", "reply_to": "COM7824", "timestamp": "2016-06-10T17:29:24Z", "text": "1.      Named pipes\n2.      System.Transactions\n3.      A transactional queuing programming model\n4.      Durable services\n5.       Extensibility model\n6.       MEX endpoint and MEX framework\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7826", "user": "willblackie", "root": "ROOT78", "reply_to": "COM7825", "timestamp": "2016-06-13T14:23:07Z", "text": "+1 please provide a way for me to build on WCF and host on linux\n\nHaving moved away from windows (an subsequently WCF) here are the things I miss the most and would love to have back.\n\n#1 bindings > named pipes in particular, then tcp\n#2 security > though i understand this will be difficult without a windows domain\n#3 extensibility model > I like a number of others out there have done a decent amount with this to make working with WCF easier for engineers in my teams\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7827", "user": "oldkord", "root": "ROOT78", "reply_to": "COM7826", "timestamp": "2016-06-13T20:46:33Z", "text": "All the bindings\nSecurity\nextensibility\nMex\n\nI just agree with whatever one else is saying.\n\nWCF is amazing\n\nRework the config to leverage the new config system. Json config > xml\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7828", "user": "scotthurlbert", "root": "ROOT78", "reply_to": "COM7827", "timestamp": "2016-06-14T18:37:32Z", "text": "I do a lot of work on the IoT.  It would greatly facilitate creating cross platform systems if my lightweight WCF services could be hosted anywhere that .NET core could be hosted.  As you can imagine, in IoT (and other systems) discovery is important so MEX and an extensible model.  The ability to debug locally and to support named pipes between services is valuable.  Really, in a nut shell as much of the WCF stack as possible - tranactions, bindings, durability, interoperability with azure and cloud based services (which often requires proper security and metadata).\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7829", "user": "joerglang", "root": "ROOT78", "reply_to": "COM7828", "timestamp": "2016-06-15T10:59:11Z", "text": "Messaging between services is important and when doing enterprise backends, REST is not going to work. It lacks too many things like others have mentioned. So certainly Transactions, Queues Messaging, Named Pipes, Extensibility should be supported by .Net Core\n\nSo .NET Core has to provide those things in one way or another. If it is called WCF I don't care. Maybe it would be the opportunity to fix some of the weaknesses of WCF like the overy complicated configuration story and replace it with a convention based approach.\n\nAlso you should/must support other Messaging frameworks beside MSMQ or Service Bus. In general support of AMQP would be nice, including the various messaging patterns.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT79", "user": "jbgraug", "root": "ROOT79", "reply_to": null, "timestamp": "2017-02-16T16:01:43Z", "text": "Typescript should follow semantic versioning   I guess this can be considered as a bug as it is breaking my apps.\r If version 2.1.0 has breaking changes, why don't set it to 3.0.0?  Semantic versioning, right?\r Typescript lives and has important role in the nodejs ecosystem, therefore should follow some basic rules.\r We can not use the npm's semver features to block only major changes.\r \r **TypeScript Version:**  2.1.1 / nightly (2.2.0-dev.201xxxxx)\r > 2.1.0\r **Code**\r ```ts\r // A *self-contained* demonstration of the problem follows...\r No need\r ```\r **Expected behavior:**\r Follow semantic versioning rules\r **Actual behavior:**\r Just follows marketing versioning rules\r can be related to https://github.com/Microsoft/TypeScript/issues/6520 created a year ago and closed without being solved", "meta": {"posReactions": "32", "negReactions": "2"}}
{"id": "COM790", "user": "mhegazy", "root": "ROOT79", "reply_to": "ROOT79", "timestamp": "2017-02-16T18:08:50Z", "text": "TypeScript never claimed to follow semantic versioning, in the sense that breaking changes imply major versions.\r\n\r\nTypeScript, however, promises no breaking changes after a stable release. so no breaking changes between `2.1.5` and `2.1.6`, `2.1.*`.\r\n\r\nMy recommendation is fix your version of typescript to `major.minor` instead of just major. e.g. `^2.1` and not `^2`", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM791", "user": "jbgraug", "root": "ROOT79", "reply_to": "COM790", "timestamp": "2017-02-17T06:44:46Z", "text": "Thanks for the early response @mhegazy .\r\nAs you mentioned, blocking the versions is easy to fix in my projects (I was being a bit ironic.). \r\nHowever, as a developer i don't feel comfortable having to memorise a different set of rules for each package as the number of packages used grows very quickly.\r\nI guess having typescript follow semantic versioning would be a nice to have feature.", "meta": {"posReactions": "19", "negReactions": "0"}}
{"id": "COM792", "user": "RyanCavanaugh", "root": "ROOT79", "reply_to": "COM791", "timestamp": "2017-02-17T08:55:24Z", "text": "The trade-off for getting millions of dollars of engineering investment in the TypeScript project is that marketing gets to control version numbers to a certain extent.\r\n\r\nIt's not really an unalloyed good anyway. If we followed semver rules exactly, literally every single release would be a major version bump. Any time we produced the wrong type or emitted the wrong code or failed to issue a correct error, that's a breaking change, and we fix dozens of bugs like that in every release. The middle digit just isn't useful for TypeScript in a strict semver interpretation.", "meta": {"posReactions": "18", "negReactions": "24"}}
{"id": "COM793", "user": "niieani", "root": "ROOT79", "reply_to": "COM792", "timestamp": "2017-02-19T12:18:39Z", "text": "NPM should simply allow for descriptive marketing versions as a forth group. Then we'd have the best of both worlds, i.e.\r\n\r\n```json\r\n       marketing\r\n           \u2228\r\nTypeScript 2.34.2.1 \r\n             \u2227\u2227 \u2227 \u2227\r\n          major \u2227 patch\r\n                \u2227\r\n              minor\r\n```\r\n\r\nYou would simply skip the marketing version while installing, i.e. `npm install typescript@^34` since it would hold no semantic meaning, i.e. bumping marketing wouldn't reset the `major` counter.", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM794", "user": "BenSayers", "root": "ROOT79", "reply_to": "COM793", "timestamp": "2017-04-07T01:15:07Z", "text": "I'm concerned that not following semver is creating unnecessary friction for TypeScript consumers who are opted in to having their builds broken whenever TypeScript releases a minor version as npm locks down to only major versions by default. The Microsoft Edge team has figured out how to do their marketing despite bumping the major version a few times a month (currently up to v38), I think TypeScript should give serious consideration to doing the same for the good of its consumers.", "meta": {"posReactions": "2", "negReactions": "1"}}
{"id": "COM795", "user": "aluanhaddad", "root": "ROOT79", "reply_to": "COM794", "timestamp": "2017-04-07T02:32:02Z", "text": "Personally, I think it is a good idea to always specify exact versions of critical stack components such as compilers, loaders, bundlers, and of course frameworks.\r\n\r\nThere are not that many of these tools in a single project and they do not tend to release more than once a week or so. This makes explicitly upgrading a relatively straightforward process.\r\n\r\nAlso, reading the changelogs for updates to such key dependencies is almost certainly something that one should be doing.\r\n\r\nThat said, I think it's fine to version more liberally. Each project is different in this regard.\r\n\r\n> The trade-off for getting millions of dollars of engineering investment in the TypeScript project is that marketing gets to control version numbers to a certain extent.\r\n\r\nThat _is_ a trade well worth making.\r\n\r\nFurthermore, TypeScript is by no means the only project that does this.\r\n\r\nI think any project that is high profile enough is likely subject to this, at least to some extent.\r\n\r\nEven if it is not the marketing department, it may be the maintainers' own self-consciousness that leads to such versioning.\r\n\r\n> Any time we produced the wrong type or emitted the wrong code or failed to issue a correct error, that's a breaking change, and we fix dozens of bugs like that in every release.\r\n\r\nTypeScript really releases at a blisteringly unprecedented pace for a programming language so I think this is somewhat inevitable. I also think it's common across almost all software. Minor versions of most software contain breaking changes, but they often go unnoticed. The more high-profile the project, the more users that has,  the more likely it is that this will be noticed.\r\n\r\nThe TypeScript team do an incredible job and they ship a wonderfully high quality product.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM796", "user": "gcnew", "root": "ROOT79", "reply_to": "COM795", "timestamp": "2017-04-07T08:14:07Z", "text": "I can't agree with @aluanhaddad more. Personally, I think using language version 81 and browser version 127 is terrible. It looks ugly and these high numbers quickly become meaningless. In the browser case that's the intention - forcing consumers to update to the latest version. However, for a language it's out of place and makes following new features and important changes extremely hard. Every version, no matter how big or small, looks the same way as every other. Flow has fallen in that trap and it doesn't seem to reap many benefits out of it.\r\n\r\nFor TypeScript, if you still want automatic updates without worrying too much, just lock the minor version in and everything will fall into place.", "meta": {"posReactions": "3", "negReactions": "3"}}
{"id": "COM797", "user": "RyanCavanaugh", "root": "ROOT79", "reply_to": "COM796", "timestamp": "2017-04-07T16:15:30Z", "text": "I mean, even semver's *own definition* of \"breaking change\" is arguably wrong. Minor updates can add new functionality under new properties, and new properties can break existing codepaths because JS is full of do-x-if-y-property-is-present patterns. Fixing a performance bug, which would in theory be a bugfix version update, could cause two async operations which previously always resolved in one order to instead always resolve in another order.\r\n\r\nIt is simply not the case that you can safely upgrade code, with semver *as used* today by normal package maintainers, from 34.1 of some library to 34.9 and be guaranteed that your program will still behave the same way.\r\n\r\nWhat semver means *in practice* is that the major version bump is \"You will probably need to update your code in a lot of places\", and the minor version bump is \"You should always be OK for the most part\". *TypeScript never makes updates of the first kind*. We only make compat-breaking changes where we believe you should always be OK modulo a small number of fixes we think you'll be happy making (because we found new bugs).\r\n\r\nWe're not going to take a major version bump because there was a bug in the compiler where it failed to identify early errors, even though that's technically a breaking change - we think you should be \"along for the ride\" on that one if you didn't shrinkwrap. That's how semver is used *in practice* by everyone anyway.", "meta": {"posReactions": "14", "negReactions": "10"}}
{"id": "COM798", "user": "eddieajau", "root": "ROOT79", "reply_to": "COM797", "timestamp": "2017-06-15T04:14:36Z", "text": "Can we at least get a section on \"TypeScript and Semver\" added to the docs? The fundamental problem is that `npm install --save typescript` will add `\"typescript\":\"^2.4.0\" by default. Consumers need to be aware that this is dangerous and you need to change it to \"~2.4.0\" (tilde, not carat). I'm happy to do the PR if you can advise on where you want such information.\r\n\r\nBut for what it's worth:\r\n\r\n> \"You will probably need to update your code in a lot of places\" ... TypeScript never makes updates of the first kind.\r\n\r\nThe Promise changes in 2.4 **is** resulting in lots of little changes all over the place. I'm not saying I don't agree with the changes, but they are there nonetheless. I've been caught only because I've [wrongly] assumed that TypeScript was following Semver.\r\n", "meta": {"posReactions": "14", "negReactions": "0"}}
{"id": "COM799", "user": "daprahamian", "root": "ROOT79", "reply_to": "COM798", "timestamp": "2017-06-21T16:16:17Z", "text": "I'd like to add a related question: should type definition files be compatible across all of 2.x.x? Can someone compile their library in 2.2, and have it work when someone pulls it in and compiles with 2.1?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7910", "user": "DynConcepts", "root": "ROOT79", "reply_to": "COM799", "timestamp": "2017-07-10T14:03:34Z", "text": "I too would prefer SemVer, and yes I know the majority of publishers are not \"doing it right\"...But lets look at an earlier comment:\r\n\r\n\"If we followed semver rules exactly, literally every single release would be a major version bump. Any time we produced the wrong type or emitted the wrong code or failed to issue a correct error, that's a breaking change, and we fix dozens of bugs like that in every release. \"\r\n\r\nWriting quality software is hard and requires investment. The above can be mitigated with improved testing and documentation.\r\n\r\nRemember the Agile principle: \"the art of maximizing the amount of work not done--is essential. \". This should *not* mean the amount of work done by a team to get something out the door. Rather it should be a global optimization to minimize the work required by all stakeholders globally and across type - the TOTAL work.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7911", "user": "daprahamian", "root": "ROOT79", "reply_to": "COM7910", "timestamp": "2017-07-11T04:38:47Z", "text": "If it is not possible to follow semver, could we come up with some sort of way to enable backwards compatibility / legacy behavior in our code? I am currently dealing with two major issues that I view as breaking changes:\r\n\r\n# Consuming a library where the `.d.ts` files are compiled in TS version higher than my project.\r\n\r\nExample: Using TS 2.0, consuming a project that exports an interface with a member that is of type `object`.\r\n\r\nA few ideas on how to fix this:\r\n+ Allow TypeScript to compile to a previous version's output.\r\n+ Allow TypeScript to compile to multiple versions of types output, and then include a root file that routes the consuming compiler to the right definition using some sort of markup (comments, conditional compilation, etc.)\r\n\r\n# Consuming a library where the `.d.ts` files are compiled in a TS version lower than my project.\r\n\r\nSome examples include:\r\n\r\n+ https://github.com/Microsoft/TypeScript/issues/16536\r\n+ https://github.com/DefinitelyTyped/DefinitelyTyped/issues/17925\r\n+ https://github.com/ReactiveX/rxjs/pull/2722\r\n\r\nAll of these issues stem from stricter type checking introduced in a later version of TS. This could probably be mitigated by doing the following:\r\n1. Having `.d.ts` files contian the compiler version via comments\r\n2. Having the compiler check the imported code's compiler version, and only apply new/stricter rules if they existed in the compiled version.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7912", "user": "jsamr", "root": "ROOT79", "reply_to": "COM7911", "timestamp": "2017-11-23T16:13:17Z", "text": "And what about a new `package.json` property : `\"breaking\"` which values can be `\"MAJOR\"` (default), `\"MINOR\"` ?\r\nSee npm/npm#19231", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7913", "user": "FranklinYu", "root": "ROOT79", "reply_to": "COM7912", "timestamp": "2018-06-08T13:42:13Z", "text": "> Fixing a performance bug, which would in theory be a bugfix version update, could cause two async operations which previously always resolved in one order to instead always resolve in another order.\r\n\r\nIf the resolution order is *documented*, then indeed it is breaking change and should bump major version; otherwise it is *implementation details* and user is responsible for depending on this.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM7914", "user": "calidion", "root": "ROOT79", "reply_to": "COM7913", "timestamp": "2019-02-06T16:38:32Z", "text": "@mhegazy You have my full support. Semver is evil. And should be rejected everywhere. Typescript is a very good example.", "meta": {"posReactions": "0", "negReactions": "11"}}
{"id": "COM7915", "user": "eps1lon", "root": "ROOT79", "reply_to": "COM7914", "timestamp": "2019-02-06T17:24:52Z", "text": ">  Fixing a performance bug, which would in theory be a bugfix version update, could cause two async operations which previously always resolved in one order to instead always resolve in another order.\r\n\r\nThis is one of the go to arguments against SemVer and it's a classic strawman. The very first point of the SemVer spec invalidates the argument here that \"semvers own definition is wrong. here's why:\"\r\n\r\n> 1. Software using Semantic Versioning MUST declare a public API. This API could be declared in the code itself or exist strictly in documentation. However it is done, it should be precise and comprehensive.\r\n\r\nIf your public API declared that two operations resolve in a given order then, yes, a performance fix is probably a breaking change. However I don't know any library that declares two public functions **and** declares that one is always fast than the other.\r\n\r\nI agree if you don't have a public API then the SemVer is meaningless. However most of the issues with SemVer are a result of a problematic public API. Also https://xkcd.com/1172/: Just because a change breaks a workflow does not mean it is a SemVer breaking change if the public API never documented that workflow.", "meta": {"posReactions": "8", "negReactions": "1"}}
{"id": "COM7916", "user": "calidion", "root": "ROOT79", "reply_to": "COM7915", "timestamp": "2019-02-07T02:45:51Z", "text": "Even with public apis, semver should never be applied.\r\nVersion update is a way to note software changes, not software compatibility.\r\nMain versions for architectural or big updates. Minor versions for small changes and new feature additions. Patch versions for bug fixes. Either one can break compatibility.\r\n\r\nSemver is stupid focusing on compatibility, which is nothing to do with versions.\r\n\r\nCompatibility should be maintained by developers and test cases.\r\n\r\nnpm is stupid in auto version updates which cause security issues and instability. The false assumption is originated from the idea semver bearing where versions should to be compatible within main version.", "meta": {"posReactions": "0", "negReactions": "8"}}
{"id": "COM7917", "user": "calidion", "root": "ROOT79", "reply_to": "COM7916", "timestamp": "2019-02-07T02:47:50Z", "text": "Another principal should be never update until updates are fully tested.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7918", "user": "jsamr", "root": "ROOT79", "reply_to": "COM7917", "timestamp": "2019-02-07T07:22:10Z", "text": "> Compatibility should be maintained by developers and test cases.\r\n\r\nSo developers should test all the API surface they consume ? That is a big field.\r\nIn my opinion, they should test all the undocumented **assumptions** they are making on third party APIs. And of course, unexposed callpoints (classes and methods) they might use or inherit.\r\n\r\n> Fixing a performance bug, which would in theory be a bugfix version update, could cause two async operations which previously always resolved in one order to instead always resolve in another order.\r\n\r\nIf you are assuming the order in which those async tasks resolve, you are *Programming by Coincidence* (The Pragmatic Programmer, Ch. 6). This is a major flaw in your development process.\r\n**Breaking** in SemVer means **breaking the contract**, not your program. If your program doesn't fulfil its contract with an API, minor changes might well break it (*Design by Contract*). ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7919", "user": "calidion", "root": "ROOT79", "reply_to": "COM7918", "timestamp": "2019-02-07T08:00:15Z", "text": "@jsamr No one can do that. \r\n\r\nNo one can 100% predict the process of the software development.\r\n\r\nSoftware development is more of a way of exploring than a process of promise keeping.\r\nIt is good to bear *Design by Contract* in mind and not to *Programming by Coincidence*.\r\nBut the real life is not functioning that way.\r\nYou even can't promise that your code is 100% correct. \r\nWhy you dear to say your updates are 100% compatible when you released a version?\r\n\r\nWe should respect *Design by Contract* and *Pragmatic Programmers*.\r\nAnd we should also know that we are human beings, who make mistakes and break promises. \r\nIt is the fact and reality. \r\nWe lives in reality not in illusion or theory.\r\n\r\nThe promise semver wants to keep breaks everyday and you still not wake up.\r\nWhy?\r\n\r\nDo you really know the difference between angular 2, 3, 4 and 5?\r\nDo you really care?\r\nWhy you care about the compatibility ? or you are simply driven by those people who propagating semver?\r\nWhy should update be compatible while you even don't write test cases?\r\nWhy should you update when no test is made ? Is that a pragmatic way?\r\n\r\nNever lie to yourself.\r\n\r\nTo keep compatibility is a very good practice, but to assume compatibility is a very stupid thought.\r\n\r\nFor major, minor, patch, all versions should try to keep compatibility.\r\nFor developers, should never trust compatibility.\r\n \r\n", "meta": {"posReactions": "0", "negReactions": "9"}}
{"id": "COM7920", "user": "jsamr", "root": "ROOT79", "reply_to": "COM7919", "timestamp": "2019-02-07T09:02:59Z", "text": "@calidion I think we are misunderstanding each other.\r\n\r\nI have never claimed that *I can promise code is 100% correct*. However, a library author can aim at testing all the features exposed to consumers.\r\n\r\nHowever, it doesn't mean *there is 0 chance a minor upgrade will break the contract entitled by its authors*.\r\nSemantic versioning is, from a producer perspective, about expressing the contract and its retro-compatibility. Patches are here to correct a mismatch between the contract and its implementation.\r\n\r\nIt's **not**, from a consumer perspective, about neutralizing the risk of upgrading. I agree with you about testing upgrades, of course. Even better : put those tests in a pull request to library authors. If a test fails, they'll fix it and upgrade their patch version.\r\n\r\nYour argument is similar to refuting the utility of *Laws* because we can't promise it will be applied fairly to everybody. Do you have in mind a better system to address, **from a producer perspective**, the contract and retro-compatibility issues in library development? I don't, and that is why I find compliance with semantic versioning great.\r\n\r\nThe flaw in npm use of semantic versioning has been addressed with lockfiles. ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM7921", "user": "DynConcepts", "root": "ROOT79", "reply_to": "COM7920", "timestamp": "2019-02-07T14:42:49Z", "text": "If SemVer is to be of value only to the producer [i.e. the consumer can not base their actions reliability upon it] then what is the value of it even being exposed to the consumer????\r\n\r\nYes, I agree it is about contracts, but this leads to the discussion of what exactly is a contract that provides the value necessary to truly be useful to the consumer....  In my experience there are multiple orders of magnitude between what is typically produced as a contract [by the publisher] and what is needed by the consumer to determine the impact on their usage.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7922", "user": "calidion", "root": "ROOT79", "reply_to": "COM7921", "timestamp": "2019-02-08T05:45:55Z", "text": "@jsamr \r\n\r\nSoftware won't get matured by merely contracts.\r\nIt is a much more complicated way.\r\n\r\nLike humans constantly violating laws,  software development will surely break contracts.\r\n\r\nSo it is stupid to believe in contracts.\r\n\r\nThere are police stations and courts for law violations.\r\nThere are no such things for software development and publishing.\r\n\r\nNo one wants to breaks compatibility, but it is inevitable even when semver is applied.\r\n\r\nIt's in fact not about contracts, It is about evolution which cannot be predicted precisely.\r\n\r\n\r\nAnother wrong believe is that updated should always be executed after software updates.\r\n\r\nNodejs has a service called green keeper which strengthens that wrong believe.\r\n\r\nSoftware quality is nothing to do with updates, newer updates maybe worse and mass things up.\r\n \r\nso updates should be applied when they are tested extensively not because they are newer.\r\n\r\nprogrammers should be selective to one stable version.\r\n\r\nFor example Ubuntu 16.04 is more stable than 17.04, 16.10, and even 18.04.\r\n\r\nWin 7 is more popular than win 8, win 10.\r\n\r\nThere are in fact no contracts, there are just releases.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "12"}}
{"id": "COM7923", "user": "jsamr", "root": "ROOT79", "reply_to": "COM7922", "timestamp": "2019-02-08T07:37:15Z", "text": "@calidion It would be appreciable and civilized if you stopped calling the other's point of view &mdash; or the point of view you think they hold &mdash; \"stupid\". Just be decent and follow the community's rules. Even worse, you don't seem to try to understand the other side point of view, and rush to your own conclusions.\r\n\r\n@DynConcepts \r\n\r\n> [If] the consumer cannot base their actions reliability upon [semantic versioning], then what is the value of it even being exposed to the consumer?\r\n\r\nVery easy. Just imagine a version signature which has majors only, which would be equivalent to a standardless version signature (i.e., not semantic).\r\n\r\nYou need to upgrade a library from version `234 503` to `244 503` because this last version gives compatibility to a set of target platforms you need to integrate.\r\n\r\nBut you have no idea of the **intended** breaking changes by just looking at the signature. So you have to read the changelog from `234 503` to `244 503`, have fun!\r\n\r\nQuoting from the original specification:\r\n\r\n> Without compliance to some sort of formal specification, version numbers are essentially useless for dependency management. By giving a name and clear definition to the above ideas, **it becomes easy to communicate your intentions to the users of your software**.\r\n\r\nSemantic versioning is about **communicating**, nothing more.\r\n\r\n> Yes, I agree it is about contracts, but this leads to the discussion of what exactly is a contract that provides the value necessary to truly be useful to the consumer.... In my experience there are multiple orders of magnitude between what is typically produced as a contract [by the publisher] and what is needed by the consumer to determine the impact on their usage.\r\n\r\nI am certain this is an area of improvements, and this is why semantic versioning is only at [version 2.0.0](https://semver.org/) right now! To do so, we could explore different canonical unintended breaking changes between minors that happened in software history, where the interpretation of the contract was at stake. And from there, extrapolate a taxonomy of contracts and library purity.\r\n\r\nWhat I mean by library purity is close to purity in functional programming: if you only expose functions with no side effects, the library is *pure*. If your library instantiates a singleton in the global namespace, it is *unpure*. If it rely on non-javascript, environment-specific binaries, it is *environment-coupled*. But I am sure we could go way further in describing what could be called the **library footprint**.\r\n \r\nFrom that library footprint exposed to public knowledge, leveraging the impact of a library update would be easier.\r\n", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM7924", "user": "calidion", "root": "ROOT79", "reply_to": "COM7923", "timestamp": "2019-02-08T08:21:48Z", "text": "@jsamr \r\n\r\nYou move from **assumptions**,  **contracts** to **communicating**.\r\nBut you still don't realize the fact.\r\n\r\nScience and technologies draw principals from facts not from thinking, from what it is instead of what it should be.\r\n\r\nI think computer should based on decimal but it is binary.\r\n\r\nI think programs should be bug free but it will never be.\r\n\r\nIf the fact is ignored,  what is the value of finding communicating methods?\r\n\r\nSemver bears a good will, but it will never be a realistic one.\r\n\r\nA false good will always lead to a bad result. \r\n\r\nNpm's auto update has shown the downside and now lock fill has be introduced for remedy.\r\n\r\nI don't know why you still insist on use semver, what benefits do you gain on applying semver?\r\n\r\nGet sky high version number?\r\nMake versions meaningless?\r\nUpgrade major version on every small change that breaks?\r\nAuto updates that makes software unstable?\r\n\r\nI think there must be a list of gains if semver should be adopted.\r\n\r\n> I apologize for using `stupid` if it is offensive.\r\n\r\nSoftware quality will not be improve by merely defining very strict rules.\r\n\r\n\r\n\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "11"}}
{"id": "COM7925", "user": "jsamr", "root": "ROOT79", "reply_to": "COM7924", "timestamp": "2019-02-08T08:34:56Z", "text": "@calidion Perhaps the language barrier has an incidence, but I don't think you really grasp what I am attempting to express... If you want to continue this discussion, please drop a mail (see my profile to get the address).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7926", "user": "justinfagnani", "root": "ROOT79", "reply_to": "COM7925", "timestamp": "2020-03-19T17:22:18Z", "text": "TypeScript not following semver has some serious negative implications in an ecosystem that builds a lot of features around the assumption that packages _do_ follow semver.\r\n\r\nSince npm installs libraries with a default version range that allows for newer minor versions, the command `npm i typescript` _will_ install an unstable and occaisionally breaking version of TypeScript. Collaborators on a project may get different versions when they install, and may get different sets of compiler errors. Fixing them for one developer may break things for another. Yes, projects should override the npm default, but they have to understand TypeScript's unusual versioning scheme in order to know to do so.\r\n\r\nEven worse, an upgrade to a new minor version of TypeScript may break users of a project. We don't have any indication through version numbers of which .d.ts files are compatible with which versions of TypeScript. A project that implicitly upgrades TypeScript to a breaking version due to breaks occurring at minor releases, builds, and publishes a new version with newer declaration files, will break consumers using an older version of TypeScript. Some users can't even choose their version due to the compiler being integrated into their build system / runtime (Angular, Storybook, TS-Node).\r\n\r\nBy adopting semver TypeScript would be a much better citizen in the npm ecosystem and reduce unintended breaks.", "meta": {"posReactions": "20", "negReactions": "1"}}
{"id": "COM7927", "user": "calidion", "root": "ROOT79", "reply_to": "COM7926", "timestamp": "2020-03-19T17:49:11Z", "text": "It is semver's problem not typescript.\r\n\r\nsemver is the most misleading rule set ever.\r\n\r\nnpm's default rules make things worse.\r\n\r\nas now npm Inc. is sold to Microsoft, maybe we can see further advance in npm.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "14"}}
{"id": "COM7928", "user": "treshugart", "root": "ROOT79", "reply_to": "COM7927", "timestamp": "2020-03-20T04:32:03Z", "text": "How is semver misleading?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM7929", "user": "calidion", "root": "ROOT79", "reply_to": "COM7928", "timestamp": "2020-03-20T07:13:59Z", "text": "Semver is like some idiots claim that all human are straight,  never know of LGBT.", "meta": {"posReactions": "0", "negReactions": "9"}}
{"id": "ROOT80", "user": "jermowery", "root": "ROOT80", "reply_to": null, "timestamp": "2020-07-08T01:25:12Z", "text": "Rename the \"master\" branch to avoid problematic terminology Similar to the reasoning behind GitHub's recent statement that the default branch on new repos will be changed to not use \"master\" can we change the name of the default branch on this repo to something else? Perhaps \"main\"?", "meta": {"posReactions": "0", "negReactions": "8"}}
{"id": "COM800", "user": "spock123", "root": "ROOT80", "reply_to": "ROOT80", "timestamp": "2020-07-08T07:33:33Z", "text": "Master is not a problematic word. ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM801", "user": "CodeLiam", "root": "ROOT80", "reply_to": "COM800", "timestamp": "2020-07-08T11:01:47Z", "text": "This crap has gotten way out of control, give em an inch and they'll try to take a mile.  Enough is enough already, rather than people getting offended by a word that is not offensive in this context, grow some thicker skin and calm down.  I agree with @spock123 above, here the word Master is not a problematic word", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM802", "user": "spock123", "root": "ROOT80", "reply_to": "COM801", "timestamp": "2020-07-08T11:10:12Z", "text": "@CodeLiam  I guess my `Masters Degree` now has to renamed to `Main Degree` as well..  \r\n\r\nWhat people don't grasp is that in this context, the Master is like the Master in an audio recording. It's THE version. That's the context and the only context. I can't believe the insanity that's going on. ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM803", "user": "CodeLiam", "root": "ROOT80", "reply_to": "COM802", "timestamp": "2020-07-08T11:24:34Z", "text": "I concur @spock123 I am of the opinion that this is not even an issue with regards to Angular, it's functionality, and if it works properly and should therefore simply be closed.  Regardless I hope you are well and have an awesome day!!!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM804", "user": "ericmartinezr", "root": "ROOT80", "reply_to": "COM803", "timestamp": "2020-07-08T14:07:34Z", "text": "Simply stupid. There's no other way to put it. Stupid, like all this progressive shit destroying everything it touches.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM805", "user": "mgechev", "root": "ROOT80", "reply_to": "COM804", "timestamp": "2020-07-08T16:45:57Z", "text": "Hey @jermowery, thanks for starting the discussion. This is something we've been talking about. As you mentioned GitHub will be likely [taking actions](https://twitter.com/natfriedman/status/1271253144442253312?lang=en) in the future and we'd want to coordinate the efforts.\r\n\r\nI'll lock this thread for now. If you're interested in further reading on the motivation for such a change, I recently got pointed to a [similar discussion](https://lkml.org/lkml/2020/7/4/229) in the Linux community.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM806", "user": "JoostK", "root": "ROOT80", "reply_to": "COM805", "timestamp": "2022-05-27T12:19:42Z", "text": "The framework, CLI and components repo have recently switched to using `main` as default branch.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT81", "user": "jhkrischel", "root": "ROOT81", "reply_to": null, "timestamp": "2017-06-28T16:50:58Z", "text": "Allow decrypting of files with vaulted variables ##### ISSUE TYPE\r  - Feature Idea\r \r ##### COMPONENT NAME\r ansible-vault\r \r ##### ANSIBLE VERSION\r ```\r ansible 2.3.1.0\r   config file = \r   configured module search path = Default w/o overrides\r   python version = 2.7.13 (default, Apr 23 2017, 16:50:35) [GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)]\r ```\r \r ##### CONFIGURATION\r n/a\r \r ##### OS / ENVIRONMENT\r n/a\r \r ##### SUMMARY\r ansible-vault decrypt allows the decryption of completely encrypted yaml files, but it will not decrypt vaulted variables in an unencrypted yaml file with encrypted variables.\r \r It would be nice, for CLI purposes, to have decrypt take a partially encrypted file, and give us the decrypted text.\r \r ##### STEPS TO REPRODUCE\r * create `test.yml` file with single encrypted variable encrypted by `~/.vault_pass.txt`\r * ansible-vault decrypt file\r \r ```\r ansible-vault decrypt test.yml --vault-password-file ~/.vault_pass.txt\r ```\r \r ##### EXPECTED RESULTS\r * Expected plain text output with encrypted variable decrypted.\r \r ##### ACTUAL RESULTS\r ```\r ERROR! input is not vault encrypted data for test.yml\r ```\r ", "meta": {"posReactions": "100", "negReactions": "0"}}
{"id": "COM810", "user": "gundalow", "root": "ROOT81", "reply_to": "ROOT81", "timestamp": "2017-06-29T08:55:23Z", "text": "@alikins I believe you look after vault", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM811", "user": "krzysztof-magosa", "root": "ROOT81", "reply_to": "COM810", "timestamp": "2017-07-06T19:14:57Z", "text": "Would be also good if 'ansible-vault view' worked for such files.", "meta": {"posReactions": "22", "negReactions": "0"}}
{"id": "COM812", "user": "alikins", "root": "ROOT81", "reply_to": "COM811", "timestamp": "2017-07-24T14:53:42Z", "text": "This might be something that will get covered in https://github.com/ansible/ansible/blob/devel/docs/docsite/rst/roadmap/ROADMAP_2_4.rst#id25\r\n\r\nAs a user, what would you expect the decrypted file to look like?\r\n\r\nFirst thought is just to replace the !vault yaml scalar with the decrypted text. That probably makes the most sense for 'view'.\r\n\r\nFor 'decrypt' and especially 'edit', I'm not sure that will be sufficient. For 'edit', the re-encrypt phrase is going to need to be able to figure out which variable values originally came from a vaulted value. Especially if the file is edited significantly (reordering lines for example, or changing the variable name). \r\n\r\nSo the file presented for editing would need to include some markers indicating the text that was decrypted/should be re-encrypted. A couple of ways to do that:\r\n\r\n   1) Add comments to mark the text, and doing some text manipulation/regexes to replace it with encrypted text in place. Something like:\r\n\r\n``` yaml\r\n# START VAULT PLAINTEXT - my_var\r\nmy_var: my text goes here\r\n# END VAULT PLAINTEXT - my_var\r\nsome_plain_var: blippy\r\n```\r\n\r\n  2) Add a new yaml type indicating text to be encrypted. Something like:\r\n\r\n``` yaml\r\nmy_var: !vault-plaintext |\r\n    my text goes here\r\nsome_plain_var: blippy\r\n```\r\n\r\nIt would be best if we could yaml parse the input, decrypt the value, serialize the yaml to a file for editing, let user edit it, then yaml parse the results, encrypt the value, and serialize to yaml and save.\r\n\r\nBut... doing that with the available yaml parser would lose comments and ordering of maps.\r\n\r\nSo likely some in place string/text manipulations will be required.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM813", "user": "alikins", "root": "ROOT81", "reply_to": "COM812", "timestamp": "2017-09-14T14:14:22Z", "text": "Not going to happen for 2.4, so bumped to 2.5.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM814", "user": "ansibot", "root": "ROOT81", "reply_to": "COM813", "timestamp": "2018-01-31T15:47:45Z", "text": "@jhkrischel This issue is waiting for your response. Please respond or the issue will be closed.\n\n[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)\n<!--- boilerplate: needs_info_base --->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM815", "user": "andrunah", "root": "ROOT81", "reply_to": "COM814", "timestamp": "2018-01-31T18:57:34Z", "text": "Any news when this is planned to be implemented in ansible?\r\nWe have lots of passwords as vaulted variables, hence updating\\viewing them is troublesome.\r\nI did some script (based on solution, from alikins last post) to at least parse such yml and decrypt every variable to stdout\\file to see a decrypted file at once, but this is just a script that is not a complete solution (and it is decrypting only).\r\nUPD: I ended up going thru ansible code to understand how it works with encrypted variables and wrote some tiny script that I can use in my automation jobs with Jenkins. I hope it would be useful for anyone who is waiting for this issue to be fixed.\r\nhttps://github.com/andrunah/ansible-vault-variable-updater\r\nIt would be nice to have this functionality in ansible out of the box.", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM816", "user": "csillab", "root": "ROOT81", "reply_to": "COM815", "timestamp": "2018-03-05T14:27:09Z", "text": "I do see this in 2.5.\r\n\r\n```\r\nroot@ubuntu-xenial:~# ansible  --version\r\nansible 2.5.0rc1 (stable-2.5 36566e62a7) last updated 2018/03/05 13:46:00 (GMT +000)\r\n  config file = /etc/ansible/ansible.cfg\r\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\r\n  ansible python module location = /root/git/ansible/lib/ansible\r\n  executable location = /root/git/ansible/bin/ansible\r\n  python version = 2.7.12 (default, Nov 20 2017, 18:23:56) [GCC 5.4.0 20160609]\r\n\r\nroot@ubuntu-xenial:~# cat vars.yaml\r\nansible_ssh_pass: !vault |\r\n          $ANSIBLE_VAULT;1.2;AES256;my_user\r\n          31313064366365626535323066613234626234336664333266663161366233396365633063303539\r\n          3066363333666236666335656631666663373037643338630a303763363031373337663733326134\r\n          38336566366535373561373830386638663635363438333633313536333731646331366138383961\r\n          3331346163623661340a663862323337313562376338386539326438323562383136383832376266\r\n          31306663393532323761353761353435373432633632626365633734303335633436\r\nnonpass: pass\r\nroot@ubuntu-xenial:~# ansible-vault view vars.yaml\r\nVault password:\r\nERROR! input is not vault encrypted datavars.yaml is not a vault encrypted file for vars.yaml\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM817", "user": "ansibot", "root": "ROOT81", "reply_to": "COM816", "timestamp": "2018-03-05T14:37:12Z", "text": "@jhkrischel This issue is waiting for your response. Please respond or the issue will be closed.\n\n[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)\n<!--- boilerplate: needs_info_base --->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM818", "user": "alikins", "root": "ROOT81", "reply_to": "COM817", "timestamp": "2018-03-09T18:13:35Z", "text": "I poked at this a little yesterday and braindumped some thoughts in code comments at https://github.com/alikins/ansible/commit/603cac4a041a10ec8186617c95ef539a9ece787a\r\n\r\n(copied/paraphrased here for discussion)\r\n\r\n>         Open a file, figure out if it is all vault or yaml with vault strings, edit.\r\n> \r\n>         if yaml with vault strings, parse the yaml with AnsibleYaml \r\n>         and secret. Replace with '!vault-plaintext vault-id' and plaintext. \r\n>         Save, open editor. \r\n>         On save/reencrypt, reparse the file with AnsibleYaml, get the\r\n>         plaintext of the to be reencrypted vaulted string, encrypt it\r\n>         (!vault-plaintext -> !vault,\r\n>          AnsibleVaultUnencryptedUnicode -> AnsibleVaultEncryptedUnicode).\r\n> \r\n>         And then, things get complicated... we can't just AnsibleYaml.dumps()\r\n>        the data structure out:\r\n>             1. Comments and comment placement is not preserved which \r\n>                 is kind of annoying\r\n>             2. AnsibleYaml can loads things into data structures\r\n>                 that it can not `dumps()` out.\r\n>                 Ie, we can't serialize a bunch of stuff we can deserialize.\r\n> \r\n>             So just AnsibleYaml.dumps'ing the datastructure back\r\n>             to a file will usually either fail or do the wrong thing.\r\n> \r\n>             #2 above is unlikely to get fixed soon if ever.\r\n>             #1 is mostly a limitiation of the PyYaml yaml module ansible uses. \r\n>                Other implementation like Rueyaml can do this, but it is unlikely for \r\n>                ansible to change this any time soon.\r\n> \r\n>         So, since we can't just serialize to yaml, we likely need to do some \r\n>         string manipulation to replace the '!vault ' blob.\r\n> \r\n>         We would need to know exactly what the before string looked like\r\n>         and where in the file it is, and what the new !vault will look like.\r\n>         But we don't really know what the new  !vault-plaintext \r\n>         string will look like.\r\n> \r\n>         For that  matter, we don't know if it will be in the same place,\r\n>         or if it will exist at all, or if it will be at the same path in the \r\n>         datastructure after the edit. \r\n> \r\n>         We could limit edit to only try to work in cases where\r\n>         those aren't changed. We also have no idea what the\r\n>         plaintext will look like.\r\n>         \r\n>        ideas:\r\n>            - !vault-plaintext is a compound yaml type, with fields for\r\n>               the vault id to use, and for the plaintext. Could also\r\n>              possibly include some identifying info for what the !vault\r\n>              it replaced looked like. An example:\r\n> \r\n>         some_var: !vault-plaintext:\r\n>                     vault_id: 'dev'\r\n>                     decrypted_from: |\r\n>                                     $ANSIBLE_VAULT;1.1;AES256\r\n>                                     66393964663765613335633461643334393234346231666665306635323635333137306339356232\r\n>                     plaintext: |\r\n>                                 The new plaintext to replace decrypted_from with\r\n> \r\n>         That would give vault-edit enough info to do a reliable job \r\n>         of replacing the previous content.\r\n> \r\n\r\n       \r\n\r\nThe downside to that approach is that it points out the limitations of the current !vault format. It may also be useful to extend !vault to support getting a data structure with info in it instead of just the plain text scalar. At the moment, I'm not sure if it could do both but it seems possible.\r\n\r\nOr could just call the extended info version of !vault  !vault-extended or similar.  At that point it might be possible to make !vault-extended the default vault blob format for vaulted files as well. ie, instead of\r\na vaulted file being:\r\n\r\n```\r\n$ANSIBLE_VAULT;1.1;AES256\r\n66393964663765613335633461643334393234346231666665306635323635333137306339356232\r\n3533306631646431663239623762366365663137383435380a393139303161383561303336623962\r\n35373663663036333863373666326634616532376335333133326163376136353636633763623739\r\n3736343064326662390a306438356239386665306437646665323836393032393565666136643362\r\n3663\r\n```\r\n\r\nIt would be yaml something like\r\n\r\n``` yaml\r\n--- \r\n- !vault-extended:\r\n    vault_id: 'dev'\r\n    cipher: AES256\r\n    encrypted_on: 2018-03-14\r\n    ciphertext: |\r\n        $ANSIBLE_VAULT;1.2;AES256;dev\r\n        66393964663765613335633461643334393234346231666665306635323635333137306339356232\r\n                  \r\n```\r\n\r\nie, more or less like https://github.com/voxpupuli/hiera-eyaml", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM819", "user": "gail-b-stewart", "root": "ROOT81", "reply_to": "COM818", "timestamp": "2018-03-14T14:39:50Z", "text": "Would it be possible for the user to tell you which scalars to decrypt - not try to do the whole file?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8110", "user": "MarkusTeufelberger", "root": "ROOT81", "reply_to": "COM819", "timestamp": "2018-04-12T14:21:15Z", "text": "Right now the usability of encrypted variables compared to whole encrypted files is rather poor unfortunately. Especially in cases where I quickly need to access an encrypted variable (e.g. a password) I really don't want to google for solutions like https://stackoverflow.com/questions/43467180/how-to-decrypt-string-with-ansible-vault-2-3-0.\r\n\r\nIt is also a problem for `git diff` use cases (https://stackoverflow.com/questions/29937195/how-to-diff-ansible-vault-changes). Is improving this state still on the roadmap? I didn't find it neither for 2.5 nor 2.6...", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM8111", "user": "ghost", "root": "ROOT81", "reply_to": "COM8110", "timestamp": "2018-05-17T02:20:56Z", "text": "Hi, so I've figured out a way to do this for checking individual values, using a yaml parser, **yq** https://github.com/mikefarah/yq (there's more than one yq project, but I used this). This works with ansible 2.5.2\r\n\r\nI have a vars file, with encrypted and unencrypted values, `all.yml`\r\n\r\n```\r\nunencrypted_value: 1234\r\nencrypted_value: !vault |\r\n          $ANSIBLE_VAULT;1.1;AES256\r\n          37316535353565313063353530353539666634363834626664366263666538346131653332353932\r\n          3637363030613037316336306466656432353463383230370a396530323164353563363434663238\r\n          30336436396264656663663837346162323762333063376631326633356533376566633563386637\r\n          6531383261396366640a363339616164333630373730613564646434386364396534653063666238\r\n          6131\r\n```\r\n\r\nI have a password file, `vault-password`\r\n```\r\npassword\r\n```\r\n\r\nUsing `yq`, I'm able to decrypt the value pretty easily, by selecting the encrypted value and passing it to the decrypt function\r\n\r\n```\r\n$ yq read all.yml encrypted_value | ansible-vault --vault-id vault-password decrypt\r\nDecryption successful\r\nsecretsecret\r\n```\r\n\r\nHope this helps!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8112", "user": "MarkusTeufelberger", "root": "ROOT81", "reply_to": "COM8111", "timestamp": "2018-05-17T11:24:52Z", "text": "Thanks, this helps if it is possible to install additional software. I would argue that ansible-vault should also have this functionality built-in.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8113", "user": "ghost", "root": "ROOT81", "reply_to": "COM8112", "timestamp": "2018-05-17T23:48:43Z", "text": "Yeah definitely that'd be the best option :)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8114", "user": "brianguy", "root": "ROOT81", "reply_to": "COM8113", "timestamp": "2018-08-08T22:04:22Z", "text": "Also related, let rekey work on all encrypted variables in a file. There doesn't seem to be a good way to rekey all the encrypted variables, which makes encrypted variables super cumbersome now that we have to rekey (will end up having script this). Even if it just spits it back out to stdout that'd be a huge help instead of modifying the variables in the file directly.", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM8115", "user": "varac", "root": "ROOT81", "reply_to": "COM8114", "timestamp": "2018-08-23T07:55:52Z", "text": "Why is this issue still assigned to the `2.5 milestone` when `ansible 2.5` is already release a long time ago ? See #44556 for outdated milestones.\r\n\r\nPlease reassign to a current milestone, this is a really missing feature imo (especially the lack of rekeying functionality).", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM8116", "user": "Goobaroo", "root": "ROOT81", "reply_to": "COM8115", "timestamp": "2018-09-28T21:25:28Z", "text": "It would be nice if rekey worked this way as well.  Updating only the encrypted values in a mixed variable file.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM8117", "user": "geerlingguy", "root": "ROOT81", "reply_to": "COM8116", "timestamp": "2019-01-15T17:21:38Z", "text": "Just giving another thumbs up on this; something like the `yq` solution above works okay and can be scripted, but having the functionality be part of `ansible-vault` itself would make management and re-keys so much simpler, and require one fewer dependency.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8118", "user": "boormat", "root": "ROOT81", "reply_to": "COM8117", "timestamp": "2019-03-25T22:21:46Z", "text": "A simple but effective solution would be to keep the existing symantecs of ansible vault encrypt, decrypt and view commands, to detect and encrypt and decrypt values of complete files.\r\n\r\nFor existing users of encrypted files, it would be trivial to convert to the enrypted values.  It could even be considered best practice is to keep encrypted values in files named such as secrets.yml, to make it easier to spot accidently unencrypted secrets.\r\n\r\nDuring the encrypt phase, it would convert any unencrypted values to encrypted values.  This would allow users to very simply add new values just by editing the \"secrets.yml\", test as required, then run the encypt command.   Users would be able to enforce or check encryption by git hooks or similar.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8119", "user": "MarkusTeufelberger", "root": "ROOT81", "reply_to": "COM8118", "timestamp": "2019-03-25T22:44:19Z", "text": "That solution would be simple, but likely not enough. For example every variable can be encrypted with a different secret/vault identifier. Also encrypted and unencrypted variables can be mixed.\r\n\r\nI'd still like to have a way at least to decrypt all variables belonging to a vault ID transparently using `ansible-vault`. Seriously, this is a usability problem since Ansible 2.3! This makes it nearly impossible for me to use vaulted variables, since being able to run `git diff` on changes is important.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8120", "user": "steffann", "root": "ROOT81", "reply_to": "COM8119", "timestamp": "2019-06-05T10:42:20Z", "text": "This is still a problem with Ansible 2.8... A solution would be really appreciated!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8121", "user": "steffann", "root": "ROOT81", "reply_to": "COM8120", "timestamp": "2019-06-05T12:33:33Z", "text": "For others looking for a quick solution I created this script: https://gist.github.com/steffann/240d4170e45aa3cf7cf0df5e9beaf0ba\r\n\r\nIt uses [ruamel.yaml](https://yaml.readthedocs.io/), which preserves ordering, comments etc in the YAML file. Great when depending on decent git diffs etc :)", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM8122", "user": "varac", "root": "ROOT81", "reply_to": "COM8121", "timestamp": "2019-06-05T14:01:47Z", "text": "maybe a bit unrelated but I like how [sops](https://github.com/mozilla/sops) does it.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM8123", "user": "fzink", "root": "ROOT81", "reply_to": "COM8122", "timestamp": "2019-06-11T18:36:23Z", "text": "Running into this issue again and it sucks. Please guys, this issue has been open for almost 2 years now and for people who really use ansible-vault, this is a major pain the butt.", "meta": {"posReactions": "16", "negReactions": "0"}}
{"id": "COM8124", "user": "joeto0", "root": "ROOT81", "reply_to": "COM8123", "timestamp": "2019-11-19T01:04:53Z", "text": "same issue here, we need to unencrypt all values and it is a nightmare, this must be common function", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8125", "user": "tom0010", "root": "ROOT81", "reply_to": "COM8124", "timestamp": "2019-12-05T11:25:00Z", "text": "+1 for this functionality.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8126", "user": "martincermak", "root": "ROOT81", "reply_to": "COM8125", "timestamp": "2019-12-05T14:13:48Z", "text": "+1, really need it!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8127", "user": "whirlwin", "root": "ROOT81", "reply_to": "COM8126", "timestamp": "2020-01-07T11:51:24Z", "text": "I solved this using debug mode. E.g.\r\n\r\n`ansible localhost -m debug -a var='myVariable' -e \"@myFile.yml\" --ask-vault-pass`", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM8128", "user": "romulo-dbts", "root": "ROOT81", "reply_to": "COM8127", "timestamp": "2020-02-04T12:45:01Z", "text": "+1 it would be very handy!!!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8129", "user": "drewhemm", "root": "ROOT81", "reply_to": "COM8128", "timestamp": "2020-02-06T11:39:12Z", "text": "> I solved this using debug mode. E.g.\r\n> \r\n> `ansible localhost -m debug -a var='myVariable' -e \"@myFile.yml\" --ask-vault-pass`\r\n\r\nWorks beautifully! No need for `--ask-vault-pass` if you have the password in a file identified by the `ANSIBLE_VAULT_PASSWORD_FILE` environment variable:\r\n\r\nhttps://docs.ansible.com/ansible/latest/reference_appendices/config.html#envvar-ANSIBLE_VAULT_PASSWORD_FILE", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "ROOT82", "user": "jKittyj", "root": "ROOT82", "reply_to": null, "timestamp": "2019-03-09T17:04:35Z", "text": "Make wording in the directives more inclusive # \ud83d\ude80 feature request\r \r ### Description\r I led a workshop on web development for the youth. A girl asked me a question what a certain line on an angular template meant. She was unusually shy and had trouble pointing at the line. Later she said in private that she didn't know how to read ng-repeat out loud. Spelling it reminded her of an ugly racial slur. I understand that it is just an unfortunate abbreviation, but it limits the pool of the talented folks who could learn angular.\r \r ### Describe the solution you'd like\r Replacing the ng with ang or something similar would be awesome. It will make the project more inclusive. It also matches the library name better, so it's easier to remember. There is evidence that it is a confusing name https://stackoverflow.com/questions/14669322/what-does-the-ng-stand-for-in-angular-js-directives\r \r ### Describe alternatives you've considered\r This is a big change. We could start it by improving documentation and accepting two prefixes by default.\r ", "meta": {"posReactions": "0", "negReactions": "15"}}
{"id": "COM820", "user": "lazarljubenovic", "root": "ROOT82", "reply_to": "ROOT82", "timestamp": "2019-03-10T16:55:51Z", "text": "I disagree with this feature request.\r\n\r\nFirstly, I tilted my head in confusion when I read \"ugly racial slur\", because none came to mind. Took me a couple of seconds of staring at `ng-repeat` to understand what you mean. I think that the girl was in a vast minority of people who would interpret `ng-repeat` as [the word I assume you're referring to](https://en.wikipedia.org/wiki/Nigger). In fact, I find it fascinating that someone at an Angular workshop was confused. Did the girl really not notice the pattern of `ng-app`-`ng-init`-`ng-model`-`ng-if` leading to `ng-repeat`? Furthermore, I am amazed by how you, as the teacher, managed to avoiding pronouncing _any_ of the directives as \"en-gee\" during the whole workshop.\r\n\r\nFurthermore, a question on StackOverflow asking for the etymology of the `ng-` prefix is by no means \"evidence that it is a confusing name\". Being curious about an official origin doesn't mean you're confused.\r\n\r\nReplacing the directive would not make the project more \"inclusive\". There are several definitions for this word, but I will assume that you meant this one: \"not excluding any section of society or any party involved in something\" (please correct me if my assumption was incorrect). The project is already as inclusive as it gets: _everyone_ is welcome to use it and participate in its evolution by contributing, pointing out bugs, asking questions and helping others. Changing `ng-` to `ang-` would not affect this fact, positively or negatively. \r\n\r\nAlso, it would certainly not be \"easier to remember\" because that would mean changing every existing material online. It would be a huge breaking change and I'm sure that a huge portion of developers would be outraged. Angular already had one issue with renaming few years ago, which brings me to the following point: `ng-repeat` is not an Angular directive. It comes from a different framework called AngularJS, so this issue is opened in a wrong place. Angular uses `ngFor`.", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM821", "user": "Airblader", "root": "ROOT82", "reply_to": "COM820", "timestamp": "2019-03-10T22:21:11Z", "text": "By this logic ang- is a terrible choice as it could stand for anything from negative words like ang-ry to religious words like ang-el.\r\n\r\nTrying to find two or three letters that are universally innocent in every language in a way that you cannot somehow turn them into something negative is probably an impossible task. ", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM822", "user": "Splaktar", "root": "ROOT82", "reply_to": "COM821", "timestamp": "2019-03-11T18:05:51Z", "text": "@lazarljubenovic did you mean \"vast minority\"?\r\n\r\nAs mentioned, [`ng-repeat`](https://docs.angularjs.org/api/ng/directive/ngRepeat) is from [AngularJS](https://github.com/angular/angular.js), not Angular (this repo) where `*ngFor` is used. \r\n\r\nAlso please note that [AngularJS has reached LTS](https://blog.angular.io/stable-angularjs-and-long-term-support-7e077635ee9c) and is no longer being modified other than for security issues or major breaking changes to browser or jQuery support.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM823", "user": "jorroll", "root": "ROOT82", "reply_to": "COM822", "timestamp": "2019-06-12T19:49:49Z", "text": "> The project is already as inclusive as it gets: everyone is welcome to use it and participate in its evolution by contributing, pointing out bugs, asking questions and helping others.\r\n\r\n@lazarljubenovic I believe that, in this case, \"inclusive\" means ~\"how welcome someone ***feels*** in the angular community.\" The poster is _telling us_ that, in at least one case, someone doesn't feel like the angular community is inclusive. Responding to that feeling by saying, basically, \"you are wrong\" is practically providing proof that the angular community is not that welcoming.\r\n\r\n> In fact, I find it fascinating that someone at an Angular workshop was confused. Did the girl really not notice\r\n\r\nThat sentence reads as a euphemism for \"that girl is stupid\". Again: Not. Welcoming.\r\n\r\nA better response would be something along the lines of, ~\"You raise a valid concern. At the moment I think that this issue is not a generally applicable because...\".\r\n\r\nIgnoring the fact that this issue is concerning angularjs and not angular, this seems to boil down to \"what percentage of the community/potential community might interpret `ng` as a slur.\" Personally, I also fall on the side of \"this sounds like an isolated experience that isn't generally applicable.\" However, responding this way also provides a clear avenue for @jKittyj, or someone else, to bolster their suggestion by providing more examples or reasons why the interpretation the girl had is actually generally applicable.\r\n\r\nIt also makes clear that, as a community, we do care about how welcome people feel and our issue is not with the _intent_ of the original post (to be more inclusive and thoughtful), but rather the execution.\r\n\r\nRegarding \r\n\r\n> I tilted my head in confusion when I read \"ugly racial slur\", because none came to mind\r\n\r\nThis strikes me as equivalent to someone commenting on a feature request by saying \"FYI, I don't need this feature.\" Great, I'm glad you don't interpret `ng-repeat` negatively. If I were evaluating this issue, I wouldn't care how many people interpret `ng-repeat` the way I intended, I'm interested in how many people interpret `ng-repeat` the way I *didn't* intend.\r\n\r\nBecause of this, this issue strikes me as providing valuable feedback and I would encourage people to surface similar experiences that they may have had.", "meta": {"posReactions": "0", "negReactions": "7"}}
{"id": "COM824", "user": "IgorMinar", "root": "ROOT82", "reply_to": "COM823", "timestamp": "2020-02-29T20:52:08Z", "text": "Hi @jKittyj, I'm sorry to hear about your experience and I understand the sensitivity of your concern. Let us take some time to consider your request and respond in a mindful way.\r\n\r\nGiven our past experience with these kinds of issue discussions getting out of hand due to comments from people outside of our team, I'm going to lock this thread until we have a chance to respond. Thanks for understanding.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM825", "user": "IgorMinar", "root": "ROOT82", "reply_to": "COM824", "timestamp": "2020-11-06T19:26:36Z", "text": "We've discussed this issue quite a bit. We the Angular team, strongly believe in building an inclusive community where everyone feels welcome, and we see how especially ng-repeat could be problematic in certain scenarios. It was never our intention. \r\n\r\n\"ng\" simply stands for a*NG*ular - the two characters in the middle of the name. And the name Angular has its roots in angle brackets that are the key part of HTML syntax that Angular uses.\r\n\r\nAfter reviewing the current names of APIs that are prefixed with ng we concluded that ng-repeat was the only one that stood out as potentially problematic. Fortunately, the latest versions of Angular use [ngFor](https://angular.io/api/common/NgForOf) instead of  ng-repeat. ng-repeat is no longer used by Angular and was deprecated along with AngularJS a few years ago, so this api is no longer used in new development.\r\n\r\nFor these reasons, we will not make any changes in our current APIs, but we will be very mindful of this problem when creating future APIs. Thank you for bringing it to our attention.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT83", "user": "jknapp25", "root": "ROOT83", "reply_to": null, "timestamp": "2021-05-07T19:17:06Z", "text": "Indicator of module progress As a user, I constantly return to the module level (multiple courses) to see how far I have progressed in relation to the entire module. It would be nice if I didn't have to go back to this view and scroll up and down it to get an indication of how much I have left.\r \r For me, I think a feature like this would keep me more engaged and therefore reduce the likelihood of me not finishing a module.\r \r **Describe the solution you'd like**\r ![image](https://user-images.githubusercontent.com/3934326/117497796-c9dc9e00-af2d-11eb-9baf-7097a372b657.png)\r \r **Describe alternatives you've considered**\r I think there are many ways this could be done, here a few I could think of:\r - Percentage of completion\r - Ratio\r - Approximation of remaining time. Given FCC has data on average time to completion on each challenge. _Just curious, where does the 300hr estimation come from?_\r \r **Additional context**\r There is some useful discussion that has already happened on the FCC forum [here](https://forum.freecodecamp.org/t/new-feature-indicator-of-module-level-progress/459290).\r \r I think it's fair to say that this is a simple feature to experiment with. If users say it's helpful, and it increases engagement, I say keep it. If not, then toss it. I remember being surprised it wasn't included when I first started though.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM830", "user": "jeremylt", "root": "ROOT83", "reply_to": "ROOT83", "timestamp": "2021-05-07T19:30:37Z", "text": "See additional discussion here: https://forum.freecodecamp.org/t/new-feature-indicator-of-module-level-progress/459290\r\n\r\nPersonally, given the wide range of difficulty between challenges, I think this would be a bad statistic that makes it easy for users to infer incorrect information about their progress, as percent of challenges completed in a certification module is not related to amount of effort or time remaining in such a simple manner.\r\n\r\nThis would especially be a bad piece of information to display next to the *very* rough estimate of 300 hours, and it would be worse to 'estimate' the time remaining for a user. The variance in time to competition between users is already pretty high and we already have to tell a decent number of users that its ok if they go 'too fast' or 'too slow' wrt the 300 hours.\r\n\r\nIt is really tempting to provide numbers because of the assumption that more numbers = more information = more better. But aggregating data that is too dissimilar is a common statistical sin that we shouldn't be showing our users.\r\n\r\nAlso, I think this would add clutter to the simpler UX.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM831", "user": "jknapp25", "root": "ROOT83", "reply_to": "COM830", "timestamp": "2021-05-07T19:40:44Z", "text": "Luckily, this is software, it's always changing. If we try it, and it doesn't work, atleast then we have data to re-inforce that the feature doesn't improve the app.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM832", "user": "jeremylt", "root": "ROOT83", "reply_to": "COM831", "timestamp": "2021-05-07T19:44:43Z", "text": "\"Because we can undo it\" is not a good reason to present bad statistics. Data should not only be technically accurate, but meaningful and not lead readers to incorrect assumptions. fCC should strive to follow sound statistical principals and not teach bad habits by example.\r\n\r\nI think we understand each other's opinions on the matter. Let's let others chime in.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM833", "user": "jknapp25", "root": "ROOT83", "reply_to": "COM832", "timestamp": "2021-05-07T19:49:05Z", "text": "52/130 (40%) is not inacurrate. That is 100% accurate as _a gauge of percentage of challenges completed_. \r\n\r\nMaybe it's important to clarify that this feature is not an estimate of time remaining, but simply progress through a module.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM834", "user": "jeremylt", "root": "ROOT83", "reply_to": "COM833", "timestamp": "2021-05-07T19:55:52Z", "text": "All the percentage or ratio reveals is the percent/ratio of challenges completed. As I said, the data is *technically accurate* but not *meaningful* and *may lead readers to incorrect assumptions*.\r\n\r\nThe percent of challenges completed is, at best, only roughly correlated with the total time remaining for the user. Given the wide range of learning styles, processes, challenge difficulty, etc, this statistic provides zero *actionable information* to the user. It is just clutter, and possibly demotivating clutter to users that do not understand the limited and misleading statistic we'd be putting on the front page.\r\n\r\nReporting statistics that distill information and strip contextual factors is a statistical bad practice, and we should not show statistical bad practices.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM835", "user": "jsdisco", "root": "ROOT83", "reply_to": "COM834", "timestamp": "2021-05-07T20:01:49Z", "text": "I'm not super passionate about it but I agree that this would be a useful feature, as long as it's in the format \"number_completed/number_total\". It'll be obvious to everyone who goes through the curriculum that the difficulty and the time you need to invest into a challenge increases. Just like it's obvious to everyone who's ever played a video game that the boss level won't be as easy as level 1-10. ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM836", "user": "jknapp25", "root": "ROOT83", "reply_to": "COM835", "timestamp": "2021-05-07T20:04:25Z", "text": "To be fair, @jeremylt, the 300hrs estimate was quite demotivating for me when I started.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM837", "user": "jeremylt", "root": "ROOT83", "reply_to": "COM836", "timestamp": "2021-05-07T20:06:50Z", "text": "Adding UX clutter should have a purpose. What is the *actionable information* this would give the user? Why is it worth adding the clutter? Reported statistics must help the recipient make better decisions. That's the purpose of statistics. If we 'all know' (bad assumption) this statistic is not useful, then why add it?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM838", "user": "jknapp25", "root": "ROOT83", "reply_to": "COM837", "timestamp": "2021-05-07T20:08:18Z", "text": "@jeremylt, @jsdisco just said \"I agree that this would be a useful feature\"", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM839", "user": "raisedadead", "root": "ROOT83", "reply_to": "COM838", "timestamp": "2021-05-07T20:09:25Z", "text": "Hi @jeremylt \r\n\r\nThanks for your candid and honest feedback. We have been thinking about this and in fact we are not against the idea considering it does exist in a form here:\r\n\r\n![image](https://user-images.githubusercontent.com/1884376/117502529-42c70e80-af9d-11eb-916a-cc5cbcf3ca12.png)\r\n\r\nOne of the ways, that users of the curriculum keep coming back is gamification. Does it keep users motivated? Yes - The #100DaysOfCode challenge is one of those initiatives. \r\n\r\nI am 100% in agreement with you that we can never design a program that will give exact report of where a learner stands in terms of knowledge gained. An 80% completion does not mean a user has 80% mastery on the topic. \r\n\r\n@jknapp25 @jeremylt \r\n\r\nLet's keep this thread constructive towards an actual implementation. You should continue to deliberate on the forum thread for pros-cons. Deliberation is a good thing to vet out a feature.\r\n\r\nMeanwhile let me check with the team and get back to you, after discussing this more objectively.\r\n\r\nThanks for your patience and comments everyone.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM8310", "user": "jeremylt", "root": "ROOT83", "reply_to": "COM839", "timestamp": "2021-05-07T20:17:27Z", "text": "I am fine with the fact that we have progress bars for each course. The variance in task difficulty is closer in the individual courses than it is across the entire module, so the statistic is not as bad as an aggregation across all courses in a module. The user can gain actionable information from the percentage of challenges completed in a course - specifically, a reasonable estimate of the time and effort required to complete the course.\r\n\r\nA challenge from Basic JavaScript and one from Intermediate Algorithm Scripting are not remotely comparable. Mixing disparate objects and obscuring differences is bad statistics, and we shouldn't show bad statistics. The user cannot derive actionable information from this statistic.\r\n\r\nI understand that the *feature* feels useful, but we all seem to be in agreement that the *statistic* is meaningless. I'm trying to use specific words with intentionality to be clear. Please ask for clarification as needed. I really am reading and responding to what others write here.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8311", "user": "raisedadead", "root": "ROOT83", "reply_to": "COM8310", "timestamp": "2021-05-07T20:24:56Z", "text": "I understand the goal should be able to make the UX more actionable, and like I said:\r\n\r\n> Let's keep this thread constructive towards an actual implementation.\r\n\r\nWe are not inclined in anyway right now.\r\n\r\nThat could either be proceed with some form of the proposal by the OP or an objective rejection. I would urge to continue the deliberation on the forum thread instead. \r\n\r\nThanks for your understanding.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8312", "user": "jknapp25", "root": "ROOT83", "reply_to": "COM8311", "timestamp": "2021-05-07T20:26:24Z", "text": "Thank you all for taking time out of your day to discuss this. Especially, @jeremylt. This _has_ been pretty constructive in my opinion. \r\n\r\nMaybe it would be helpful to step back and discuss the role that metrics play within the app, because I don't necessarily agree that a ratio of completed modules is meaningless.\r\n\r\nAs a user, from the start I'm assuming variance of time-to-completion within challenges. But maybe the value in a metric like this is that it simply re-inforces that progress is being made. Re-orienting the learner in a way. And maybe, like video games, it's safe to assume users are expecting challenges to get harder or take longer as they go?\r\n\r\nAnyways, I'll let the pro's take it from here \ud83d\ude0a", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8313", "user": "jknapp25", "root": "ROOT83", "reply_to": "COM8312", "timestamp": "2021-05-07T20:42:04Z", "text": "I think @jeremylt has made good points! It feels like we're at a bit of a stalemate though. \r\n\r\nFrom experience, when stalemates like this are reached on an idea, the \"[Fail fast](https://innolution.com/resources/glossary/fail-fast)\" approach can provide value. By trying something, then, at least we can say with greater confidence (and data) if it provided value or not.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8314", "user": "ShaunSHamilton", "root": "ROOT83", "reply_to": "COM8313", "timestamp": "2021-05-07T20:51:12Z", "text": "@jknapp25 Thank you, for opening this feature request. We have spent a lot of time going back-and-forth between ideas. One of the main discussions occurred here: https://github.com/freeCodeCamp/freeCodeCamp/pull/39265\r\n\r\nUltimately, the decision was:\r\n> It looks cool, but there are a few things that prevent visual representation from working well here:\r\n\r\n>For each certification, the lessons only constitute about 16% of the cert. The other 84% is the certification projects. This means that on the first certification, a camper could make it through a hundred or more lessons and only be 5 or 6% of the way done with the certification. So all they would see would be a tiny slice of the pie for their first 50 hours of coding.\r\n\r\n>This is why I recommended using the (300 hours - 1.03% complete) text. Because we really need that level of granularity in the numbers. Otherwise progress would be virtually invisible from one coding session to the next.\r\n\r\n>Also, people may wonder \"what is this thing over on the right hand margin\"? The \"X.XX% complete\" text is unambiguous.\r\n\r\n>Thus, if you want to implement a text-based version of this, we would be very interested in this.\r\n\r\n\r\n---\r\n\r\nSo, there is still scope to implement such a feature, but keeping in mind the discussion had in this issue, and the linked PR.\r\n\r\nWe welcome PoCs (proof of concepts) - as you have done, or more; visual communication is appreciated. However, it is in your and our best interest to read through the current/past discussion so as to not end up spending hours on something which ultimately might not be used.\r\n\r\nHope this adds to the discussion.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8315", "user": "jsdisco", "root": "ROOT83", "reply_to": "COM8314", "timestamp": "2021-05-07T20:57:30Z", "text": "The estimate of \"300 hours\" is already very nebulous statistics, so I see little harm in adding much more descriptive information that only shows the number of challenges completed vs. total challenges.\r\n\r\nI'm thumbs up for the feature because it saves the user the effort of having to click on each section to get that information. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8316", "user": "naomi-lgbt", "root": "ROOT83", "reply_to": "COM8315", "timestamp": "2021-05-07T20:58:02Z", "text": "> Luckily, this is software, it's always changing. If we try it, and it doesn't work, atleast then we have data to re-inforce that the feature doesn't improve the app.\r\n\r\nThe one thing I really want to touch on is that freeCodeCamp operates on a budget of limited funds from our generous donors. As such, our approach does not allow for a \"try it and see if it works\" mindset - every feature we implement needs to be deliberate, planned, and well thought out to avoid sinking our finite development resources into something that does not pan out.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8317", "user": "raisedadead", "root": "ROOT83", "reply_to": "COM8316", "timestamp": "2021-05-07T21:03:09Z", "text": "Hi everyone, \r\n\r\nI am going ahead and closing this thread for now. Please continue on the forum here: https://forum.freecodecamp.org/t/new-feature-indicator-of-module-level-progress/459290/12\r\n\r\nThe staff and the contributors are very much active on the forum and will be happy to answer open-ended queries there. \r\n\r\nWe really want to limit the GitHub tracker for dev work. Please do not take this  as a rejection or endorsement of anything.\r\n\r\nThanks for your understanding again.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT84", "user": "joaomoreno", "root": "ROOT84", "reply_to": null, "timestamp": "2021-02-10T15:51:57Z", "text": "\u26a0\ufe0f\ud83d\udea7\ud83d\udc77 Scheduled rename `master` branch to `main` On **Feb 14, 2021, 8PM UTC** the `microsoft/vscode` repository will rename its `master` branch to `main`.\r \r cc @microsoft/vscode\r \r ---\r \r \u26a0\ufe0f **Call to Action** \u26a0\ufe0f\r \r If you have a clone of `microsoft/vscode` locally, you'll need to run the following commands **_after_** the rename happens:\r \r ```\r git branch -m master main\r git fetch origin\r git branch -u origin/main main\r git fetch --prune\r ```", "meta": {"posReactions": "16", "negReactions": "0"}}
{"id": "COM840", "user": "baslr", "root": "ROOT84", "reply_to": "ROOT84", "timestamp": "2021-02-11T08:39:57Z", "text": "Women can also be a construction worker \ud83d\udc77\u200d\u2640\ufe0f \ud83e\udd26\u200d\u2640\ufe0f ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM841", "user": "joaomoreno", "root": "ROOT84", "reply_to": "COM840", "timestamp": "2021-02-11T09:11:01Z", "text": "> Women can also be a construction worker \ud83d\udc77\u200d\u2640\ufe0f \ud83e\udd26\u200d\u2640\ufe0f\r\n\r\n@baslr Absolutely, why would you even think otherwise?\r\n\r\nIn this case, I am the one doing the construction work and I happen to be a man... I think. \ud83e\udd14 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM842", "user": "solarblueberry", "root": "ROOT84", "reply_to": "COM841", "timestamp": "2021-02-11T10:24:18Z", "text": "May I ask why is this necessary? Did I miss something? ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM843", "user": "foreignmeloman", "root": "ROOT84", "reply_to": "COM842", "timestamp": "2021-02-11T12:22:46Z", "text": "> May I ask why is this necessary? Did I miss something?\r\n\r\nI guess the same reason why GitHub defaults to 'main' master branch name now. Good old PC BS. Apparently word 'master' has a bad stigma attached to it now \ud83e\udd26\u200d\u2642\ufe0f", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM844", "user": "joaomoreno", "root": "ROOT84", "reply_to": "COM843", "timestamp": "2021-02-11T13:04:58Z", "text": "Guys & gals, I'm sorry. Nothing bad happened here, but I'm just going to lock this thread right now before it does.\r\n\r\nAs a team, we've decided to go ahead with this rename, because reasons. This issue isn't the place to discuss the merits and drawbacks of the rename. If you feel like venting, I recommend you do so through your own personal mechanisms. Mine is running 10k out in the cold. \ud83c\udfc3 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT85", "user": "joaomoreno", "root": "ROOT85", "reply_to": null, "timestamp": "2019-12-03T11:49:28Z", "text": "Remote Containers using SSH doesn't work in Windows Related to microsoft/vscode-remote-release#1935\r \r - I confirmed that I can successfully connect to the remote machine using SSH via command line\r - There is no error in the entire UI, just loading progress bars when opening the Docker viewlet\r - When running `Attach to Running Container`, nothing happens\r - When I open devtools, this is what I see:\r \r ![image](https://user-images.githubusercontent.com/22350/70048648-14d0e400-15cb-11ea-946e-3ef839e581b1.png)\r ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM850", "user": "chrmarti", "root": "ROOT85", "reply_to": "ROOT85", "timestamp": "2019-12-03T13:36:46Z", "text": "This is the Docker extension's viewlet. That should support ssh:// with the current release (https://github.com/microsoft/vscode-docker/issues/646). Moving there.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM851", "user": "philliphoff", "root": "ROOT85", "reply_to": "COM850", "timestamp": "2019-12-03T17:47:46Z", "text": "@joaomoreno Can you provide repro steps and what version of VS Code and vscode-docker you're using?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM852", "user": "joaomoreno", "root": "ROOT85", "reply_to": "COM851", "timestamp": "2019-12-09T07:19:43Z", "text": "This was the latest VS Code Insider and latest vscode-docker from 6 days ago. I don't have access to the machine right now. I tested it on a fresh VM: install VS Code, Docker extension, Docker for Windows, Git for Windows, create SSH key, make sure you can `ssh` from Command Prompt solely using the key. Once all of that is done, simply configure the remote docker setting to the `ssh://` format.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM853", "user": "zifik", "root": "ROOT85", "reply_to": "COM852", "timestamp": "2020-01-03T03:22:04Z", "text": "I am experiencing the exact same thing as @diablodale.\r\n\r\nI was able to eliminate the \"openssh-ssh-agent\" error messages by starting the \"ssh-agent\" service in Windows 10: I found this helpful: https://stackoverflow.com/questions/52113738/starting-ssh-agent-on-windows-10-fails-unable-to-start-ssh-agent-service-erro\r\n\r\nI am perplexed by this as I am able to run `docker -H ssh://user@ip ps` from Powershell and WSL just fine.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM854", "user": "zifik", "root": "ROOT85", "reply_to": "COM853", "timestamp": "2020-01-03T03:48:15Z", "text": "Additionally, I see theses messages if I open the vscode developer tools from Help:\r\n`mainThreadExtensionService.ts:66 Error: All configured authentication methods failed`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM855", "user": "zifik", "root": "ROOT85", "reply_to": "COM854", "timestamp": "2020-01-03T18:23:06Z", "text": "Ok, so I figured it out for my purposes -- finally.\r\n\r\nMy situation was practically identical to what @diablodale describes. \r\n\r\n**SOLUTION**\r\n\r\nEven though you have your keys setup and you can do example commands like `docker -H ssh://user@ip ps`, you can still run into auth issues because this extension is specifically making using of the \"ssh-agent\" under the hood.\r\n\r\n_**IMPORTANT**: Don't get these steps confused with similar things that can be done in WSL. Things done in WSL do not affect the outcome. This extension does not use WSL under the hood even if you have your terminal configured to use WSL. You must have it setup through the means the Windows OS uses._\r\n1. Follow directions [here](https://code.visualstudio.com/docs/remote/troubleshooting#_setting-up-the-ssh-agent) to enable the Windows SSH-Agent.  This addresses the errors with the ` \\\\.\\pipe\\openssh-ssh-agent` in the message.\r\n2. Ensure that you have your SSH keys inside of `<windows user folder>/.ssh/`. \r\n3. Run `ssh-add` from powershell. This was the last part that I was missing and why I would get `All configured authentication methods failed`\r\n\r\nIn the end, would be nice if these errors were caught and the users were notified of the GUI of what actions might be needed.\r\n", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM856", "user": "bwateratmsft", "root": "ROOT85", "reply_to": "COM855", "timestamp": "2020-02-11T18:09:57Z", "text": "I agree with @zifik. There's nothing we can realistically do about the fact that our dependencies (`dockerode`, `ssh2` Node packages) require an auth agent, at least not in the short term, but we can warn the user if they have an SSH DOCKER_HOST but no agent set up. A Learn More link to the [Wiki page on SSH setup](https://github.com/microsoft/vscode-docker/wiki/SSH) would probably also help.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM857", "user": "bwateratmsft", "root": "ROOT85", "reply_to": "COM856", "timestamp": "2020-03-09T17:01:39Z", "text": "We have improved the warnings for this in [Docker extension version 1.0.0](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-docker).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT86", "user": "Joebeazelman", "root": "ROOT86", "reply_to": null, "timestamp": "2019-12-18T20:25:31Z", "text": "Is Microsoft capable of writing software that doesn't turn into a nightmare? I just wasted several hours trying to figure out why my site wasn't working. First, I got a 500.32 \"ANCM Failed to Load dll\" server error code. This wasted several hours of my time trying to work through the suggested troubleshooting tips (https://docs.microsoft.com/en-us/aspnet/core/test/troubleshoot-azure-iis?view=aspnetcore-3.1).  The doc said it was most likely due to binary incompatibility so I tried to use the **dotnet** command to find out what's installed. When I typed  **dotnet --list-sdks** or  **dotnet --version** I got the following error message:\r \r > The specified SDK version [3.1.100] from global.json [D:\\****] not found; install specified SDK version\r > Did you mean to run dotnet SDK commands? Please install dotnet SDK from:\r >   http://go.microsoft.com/fwlink/?LinkID=798306&clcid=0x409\r \r I reinstalled the SDK and received the same error.  Why is **dotnet** giving me this error for no apparent reason?  This was getting me no closer to the solving the problem until I realized that I should restart the web server and perhaps my app will work again.  Lo and behold it was a simple restart!  This is the second or third time I've been screwed over by Microsoft's shitty installation practices. You guys suck at everything!\r \r WTF Microsoft!  Can't you guys get anything done without turning it into a nightmare?  You force the user to restart the computer when they uninstall a server bundle, but you don't require them to restart IIS when they install a server bundle?  I would be tempted to blame legalization for this kind of mishap, but you guys have always sucked at software!  Everything you guys put your hands on sucks!  Windows sucks and now you even made .NET, your crown jewels, suck!  Microsoft should grow turnips instead of writing software!", "meta": {"posReactions": "0", "negReactions": "9"}}
{"id": "COM860", "user": "hirre", "root": "ROOT86", "reply_to": "ROOT86", "timestamp": "2019-12-18T21:18:08Z", "text": "Relax and take your medication. The grass isn't greener on the other side... \r\n\r\n// +10 year Java master & former frequent linux user", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM861", "user": "snickler", "root": "ROOT86", "reply_to": "COM860", "timestamp": "2019-12-18T21:28:13Z", "text": "Take a deep breath and try the following:\r\n\r\nIF USING AZURE APP SERVICE:\r\n\r\n1) Remove any older ASP.NET Core Runtime Extensions from your App Service (especially any preview extensions), then install the ASP.NET Core 3.1 Runtime x64 Extension. \r\n2) Restart your app service\r\n3) a) If you see more errors, republish your project.\r\n b) Make sure the deployment Mode is `Framework-Dependent`. \r\n\r\nIF ON PREM:\r\n\r\n1) Make sure you have the ASP.NET Core 3.1 Hosting Bundle installed (Installs the RUNTIME and IIS hosting support. Does NOT install the SDK).\r\nhttps://dotnet.microsoft.com/download/dotnet-core/thank-you/runtime-aspnetcore-3.1.0-windows-hosting-bundle-installer\r\n2) Run the `dotnet --info` commands outside of the current directory location you tried. You have a global.json file somewhere that's locking .NET Core SDK to 3.1.100. You likely don't have the 3.1 SDK installed, which would be why you're encountering that error. \r\n3) IISReset\r\n4) Check the Application Event Logs. Usually more details about why the IIS Hosting Module blew up will appear in there.\r\n", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM862", "user": "Joebeazelman", "root": "ROOT86", "reply_to": "COM861", "timestamp": "2019-12-19T22:00:48Z", "text": "> Relax and take your medication. The grass isn't greener on the other side...\r\n> \r\n> // +10 year Java master & former frequent linux user\r\n\r\nIf you're comparing the development products of one of the largest corporations in the world to those developed by volunteers, then you've made my point better than I have. I have over 25 years of development experience from 80x86 to C++ on many different platforms and the grass has always been greener! During the 1990s, we had Think C and Metrowerks CodeWarrior on the Macintosh which were far more productive and pleasant than what we even have today. Microsoft was at least smart enough to incorporate those features into VB and Visual Studio.\r\n\r\nMicrosoft's development tools have never been great, but just \"good enough.\" The trend over the past years, however, has been a downward spiral. Visual Studio has become unbearably slow no matter how much computing resources you throw at it.  The documentation is a labyrinth of dead ends full of outdated information and broken links. Microsoft is no longer vested in providing useful and productive GUI-based development tools. They're leaving it to the open source \"community\" who believe in UNIX's user-hostile CLIs and configuration files are the only way to go, hence VS Code.\r\n\r\nMicrosoft has never had much of a vision. It's like a fat, old Elvis who still rides on its monopolistic past. As the PC fades as the primary computing platform, so will Microsoft. Apple, a company left for dead back in the late 1990s, has leapfrogged Microsoft through product excellence. Apple dominates the mobile platform, while Microsoft failed spectacularly in the mobile market and the internet.  Even Microsoft's own top developers, including Miguel de Icaza, are shamelessly seen using MacBook Pros. That speaks volumes about Microsoft's quality.\r\n\r\nSo I guess I need to be smoking the same grass you're smoking in order to medicate my way out of seeing Microsoft's mediocrity?  No thanks! ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT87", "user": "JoeGruffins", "root": "ROOT87", "reply_to": null, "timestamp": "2020-06-25T05:37:19Z", "text": "website/docs: Please remove political banner. I think that the docs are for documenting golang. I do not think they are the place for political rhetoric. I do not open a Webster dictionary and see an ad asking for donations to a political party. I see definitions. Furthermore, it is illegal for foreigners to donate to political parties. AT LEAST remove the banner for people that are not in the US.\r \r The banner:\r ![banner](https://user-images.githubusercontent.com/34998433/85660680-e0508100-b6f0-11ea-9587-dc42d3ed6b96.png)\r \r If this is not the right forum to discuss this issue, please direct me to it.\r \r ", "meta": {"posReactions": "5", "negReactions": "8"}}
{"id": "COM870", "user": "mvdan", "root": "ROOT87", "reply_to": "ROOT87", "timestamp": "2020-06-25T14:00:39Z", "text": "You should see https://groups.google.com/forum/#!topic/golang-nuts/YzN4LkMHs7k, where the same point was made. I don't think any new point is being made here, so I'm closing this issue as we only use the tracker for bugs.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM871", "user": "JoeGruffins", "root": "ROOT87", "reply_to": "COM870", "timestamp": "2020-06-26T00:18:24Z", "text": "The thread you directed me to is locked. This banner is on my docs too. Docs that I wrote, that my organization relies on. Am I powerless here?", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM872", "user": "ianlancetaylor", "root": "ROOT87", "reply_to": "COM871", "timestamp": "2020-06-26T01:00:13Z", "text": "That thread is locked because it got too contentious, as you can see by reading it.  Although it is locked, it has the answers to your questions.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM873", "user": "JoeGruffins", "root": "ROOT87", "reply_to": "COM872", "timestamp": "2020-06-26T01:31:45Z", "text": "Indeed.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM874", "user": "cybercrypt13", "root": "ROOT87", "reply_to": "COM873", "timestamp": "2020-09-27T13:35:23Z", "text": "No, it got locked because people disagree with your ignorant stance.  I am now learning RUST even though I absolutely loved golang strictly because of not just your ignorant stance of adding this banner but also because of your even more ignorant inability to have an adult conversation about it.  I will not participate in a dictatorship as you're too dumb on the matter to be my leader.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM875", "user": "mvdan", "root": "ROOT87", "reply_to": "COM874", "timestamp": "2020-09-27T13:56:12Z", "text": "This is getting too heated, so I'm locking the thread for now. You can reply to that golang-nuts thread if you wish to voice your opinion. Thanks!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT88", "user": "JohnMH", "root": "ROOT88", "reply_to": null, "timestamp": "2019-12-19T09:12:44Z", "text": "Removal of the Santa hat and kowtowing to a single fake user is offensive to me The removal of the santa hat, and kowtowing to a fake user, is incredibly offensive to me. Please reinstate the santa hat icon.", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM880", "user": "vscodebot[bot]", "root": "ROOT88", "reply_to": "ROOT88", "timestamp": "2019-12-19T09:12:50Z", "text": "(Experimental duplicate detection)\nThanks for submitting this issue. Please also check if it is already covered by an existing one, like:\n- [Removal of the Santa Hat and kowtowing to SJWs (#87314)](https://www.github.com/microsoft/vscode/issues/87314) <!-- score: 0.786 -->\n- [Santa Hat Removal (#87318)](https://www.github.com/microsoft/vscode/issues/87318) <!-- score: 0.519 -->\n- [Removal of the Santa Hat on vscode insiders is very offensive to me (#87296)](https://www.github.com/microsoft/vscode/issues/87296) <!-- score: 0.513 -->\n- [Santa Hat removal on vscode insiders and bending to one jew is very offensive to me (#87291)](https://www.github.com/microsoft/vscode/issues/87291) <!-- score: 0.479 -->\n<!-- potential_duplicates_comment -->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM881", "user": "MaurogDark", "root": "ROOT88", "reply_to": "COM880", "timestamp": "2019-12-19T09:28:01Z", "text": "...Dissenter detected\r\n...Stifling discussion\r\n...Summoning egamma\r\n...Issue closed in 3... 2... 1...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM882", "user": "egamma", "root": "ROOT88", "reply_to": "COM881", "timestamp": "2019-12-19T19:25:16Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.\r\n\r\nHappy Coding!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT89", "user": "jsalado", "root": "ROOT89", "reply_to": null, "timestamp": "2018-02-16T08:22:13Z", "text": "Add the ability to author cross platform tasks in powershell core Hi there,\r \r @bryanmacfarlane to open this possible enhancement.\r \r Now PS based task won't even try to run on Linux/MacOS agent because of the missing handler. However, PowerShell is installed on those agents and you have the PowerShell task available for them and works...\r \r As Bryan pointed out, custom PS task may have windows assumptions, but that's okay, developers will just have to make those scripts OS aware to avoid those pitfalls. With the handler in place they can see where there scripts fail when running on Linux/MacOS PowerSHell implementation and fix them.\r \r I think this will open more options to PS developers.\r Thanks,\r J.", "meta": {"posReactions": "11", "negReactions": "0"}}
{"id": "COM890", "user": "DerGary", "root": "ROOT89", "reply_to": "ROOT89", "timestamp": "2018-04-25T08:30:32Z", "text": "Is something done in this field? We would like to run powershell tasks on Linux as well because a lot of the VSTS Extensions are Powershell based.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM891", "user": "bryanmacfarlane", "root": "ROOT89", "reply_to": "COM890", "timestamp": "2018-04-25T11:37:08Z", "text": "We have an item on the backlog to support writing tasks in powershell core.  The powershell handlers ( and the tasks written using that ) is for full windows powershell.  We can\u2019t just redirect all the existing windows powershell tasks to Linux - beyond catching all those existing tasks by surprise, the task authors that intentionally wrote windows specific tasks would start routing to Linux boxes in a heterogeneous pool.  We need a powershell core capability for routing and s powershell core handler in the agent.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM892", "user": "bryanmacfarlane", "root": "ROOT89", "reply_to": "COM891", "timestamp": "2018-04-25T11:37:53Z", "text": "Opening as enhancement", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM893", "user": "DerGary", "root": "ROOT89", "reply_to": "COM892", "timestamp": "2018-04-25T18:01:44Z", "text": "I don't really know how this works in the background but a powershell task that does not use the vsts-tasks-lib should be executable or? because it does not depend on anything OS Specific? I wrote some tasks that do not use vsts-tasks-lib they are just pure powershell script and they also don't run on Linux by the agent. I haven't tried running them natively without vsts on the linux machine.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM894", "user": "bryanmacfarlane", "root": "ROOT89", "reply_to": "COM893", "timestamp": "2018-04-25T19:44:02Z", "text": "@DerGary - the agent has a handler in it that basically knows how to run the script that's in the task.  So the node handler runs node against the script that's declared in the execution section of the task.json.  The task is run out of proc and communication and status is communicated via an RPC stdout protocol (hash hash vso statements in output).  The task lib is simply libraries with functions that emit that protocol over stdout.  It's a convenience.\r\n\r\nIf you just have an arbitrary powershell script that you need run as part of your build / release, then you can use the powershell task (2.x version) to run.  A formalized task is the way to share your unit of work with others on the market place.  \r\n\r\nSee the step by step walk throughs in this repo.  You can also look at our tasks in the vsts-tasks repo as reference examples.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM895", "user": "ChrisLGardner", "root": "ROOT89", "reply_to": "COM894", "timestamp": "2018-06-11T22:08:24Z", "text": "Is it possible to update the current PowerShell handler to work similarly to the v2 task? Use pwsh if it's there and fall back to Windows PowerShell if it's not? Or add a an extra property to the handler definition in the task.json file to say if it should try pwsh at all, defaulting to false to maintain legacy support?\r\n\r\nHopefully the task authors will know if their task will run in pwsh and by not requiring pwsh there should be no change to the agents. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM896", "user": "bryanmacfarlane", "root": "ROOT89", "reply_to": "COM895", "timestamp": "2018-06-11T22:12:42Z", "text": "It's possible but it's going to be explicit.  Yes, authors will know whether their task will run on powershell core and more importantly, not windows only and they should mark the task.json appropriately.  That marking will be \"powershellcore\".  Existing powershell3 tasks were written and distributed with an assumption of windows only so it needs to be explicit.\r\n\r\nNote that the v2 task is about running end use ad-hoc scripts which they explicitly know the limitations and explicitly pick where it will run (queue).  The handlers is all about task authors releasing tasks to a market place where end users consume the task having no idea (and shouldn't) how it was written.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM897", "user": "ChrisLGardner", "root": "ROOT89", "reply_to": "COM896", "timestamp": "2018-06-11T22:25:15Z", "text": "So is the intention that a task marked as requiring the powershellcore handler will fall back to Windows PowerShell if pwsh isn't available? Or do we have to maintain two versions with the same functionality?\r\n\r\nI've got at least one task I'd love to make available on nix and Mac but don't want to maintain multiple versions or have some funky build process to copy the files around and then package it up. \r\n\r\nI'd also not seen anything about a PowerShell3 handler, is it documented anywhere how it differs from the PowerShell handler? Or is it just a name change? Or are they the same handler and the engine just passes one to the other (presumably powershell to powershell3)?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM898", "user": "bryanmacfarlane", "root": "ROOT89", "reply_to": "COM897", "timestamp": "2018-06-11T22:34:59Z", "text": "powershellcore handler should be able to handle all platforms and all scenarios.  The powershell3 implementation has it's current restrictions.  You will be able to write one.  It's not documented on how they differ because it's not designed/implemented yet.  It's an outstanding enhancement request.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM899", "user": "ChrisLGardner", "root": "ROOT89", "reply_to": "COM898", "timestamp": "2018-06-11T22:43:03Z", "text": "I might have a look at implementing a powershellcore handler then.\r\n\r\nI'm the powershell3 question, I work on this pester task and it uses the powershell handler, that's what I was curious about the differences between it and the powershell3 one. If there are no real differences then I'll leave it as it is, everything seems to work fine so I assume it's not a problem. \r\n\r\nhttps://github.com/rfennell/vNextBuild/blob/35cb26cd0619f6e9711f62b1d7d0e28affbdd287/Extensions/Pester/task/task.json#L105", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8910", "user": "bryanmacfarlane", "root": "ROOT89", "reply_to": "COM899", "timestamp": "2018-06-12T00:28:47Z", "text": "If you take a stab at it, make sure you write up a proposal / design in the vsts-agent repo in the form of a forked branch in the docs / preview folder as markdown.  We want to avoid a large PR only to be rejected.\r\n\r\nTL;DR;\r\nAs an FYI, here's what we're struggling with internally (and the concepts get confusing so I'll try my best to be concise :) )\r\n\r\nWe have a major shift and feature set around yaml and containers:\r\nhttps://github.com/Microsoft/vsts-agent/blob/master/docs/preview/yamlgettingstarted-phase.md#container-applies-to-queue\r\n\r\nThe scenario isn't building / deploying your app container (a prime scenario however) - this one is build and test in a container to seal the dev tools and configs (dev == dev == ci).\r\n\r\nIn the current implementation coming to preview, the agent runs on the host and we exec steps in a container we start up with work dir mapped in.  So single use, incremental source, clean config / machine every time.  The agent can still update forward if demanded, etc...\r\n\r\nThe agent carries everything it needs to to run \"any container you bring\" - outside / in.  It carries node internal as a script engine (mapped in) and stdin/out is the protocol.  Everything is golden with what we support.  Powershell3 is hand wavy but it's ubiquitous and win only right now.\r\n\r\nEnter powershell core and dotnet core (maybe carries dlls).  You need powershell core in the container - OK, that makes sense for a task like pester, azure powershell, etc... - anything that's powershell tech related.  Hey, I add the pester task to my def, say run in my container it makes sense that I need powershell in it.\r\n\r\nNow, write a general task like config file variable substitutions (generic task).  I install from the market place, drag it on, pick my container.  When I run it (if we do it right) we inform you powershell core is not in the container.  The user who added the task from the market place had no idea how you implemented the generic task.  \r\n\r\nSo at this point the only option is to say all containers must contain powershell core or we inject it into the container if missing (not quite immutable :) ).\r\n\r\nNext problem is versions - which version of powershell core to prereq in container?  There isn't one since whatever you pick it to be, what happens when you write a task using capabilities in a later powershellcore?  All the builds with containers that took our prereq advice of installing pscore into the container will break when they add your task from the marketplace that needs a later one.  It's a forward compat problem.\r\n\r\nPotential solution there is to have a handler per maj version channel of pscore but it still has the odd experience of adding a task from the marketplace and having to realize how it was coded.  As pointed out above, the agent currently carries node.  The other option is to explore ways to do the same with powershell core and we're meeting with the ps core team.\r\n\r\nFor those reasons we can't prereq certain versions.  It's also why the agent is built as a self contained net core app - it updates itself as demanded and moves to new net core versions so we can't pre-req one at config time.  \r\n\r\nEverything right now in the agent and the task model is self contained.  OS dependencies of net core is the exception but those are generally going down with new versions of net core.\r\n\r\nSo it's not the implementation time that we're struggling with - it's all the versions and back and forward compat of a service, the agent and tasks on different versions with containers.\r\n\r\nLong winded but hopefully it makes sense.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8911", "user": "ChrisLGardner", "root": "ROOT89", "reply_to": "COM8910", "timestamp": "2018-06-12T13:09:55Z", "text": "Is the PowerShell Core prereq something that can be presented to the user in a similar way to Demands/Requirements for normal agents? That will need to be used anyway for users not using containers as part of their build process. I'm not sure how well those requirements are currently presented to a user when using YAML definitions but I assume it is still done in some way since those requirements will still be there. I'm not sure being in a container has a big impact on the way it should handle this, there will be plenty of times when a user has a definition which doesn't use containers or even YAML defs and so will just be running a def defined in the web UI and we just need to surface the requirements of the various tasks to them in a sensible way.\r\n\r\nSome work would have to be done by extension authors as well to include those requirements in their readme files on the marketplace to ensure that the requirement is known ahead of time. \r\n\r\nAs for versions of PS Core to handle with this, I'd go with the latest minor version of the current major version and the previous one, so currently that's just 6.0.2 but will soon be 6.1.x and eventually will be 7.0.x and 6.x.x . I don't think the PS Team has plans to release major versions too often so that shouldn't mean updating things too often and supporting the current and 1 previous major versions feels like a reasonable amount. From a user perspective if a task changes major versions because it's supporting things in PSCore 8.0 and I want those things then I can just update my dockerfile (or whatever is building my container) to use that newer version, if I don't want/need those new things then I can keep using the old version of the task and my existing container.\r\n\r\nI'm not sure how best to handle that from the agent side, a single powershellcore execution handler with some config settings coming from the task.json about what versions it requires/supports, which then lets it swap between the two supported versions of core or full PowerShell if they aren't available.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8912", "user": "bryanmacfarlane", "root": "ROOT89", "reply_to": "COM8911", "timestamp": "2018-06-12T14:47:01Z", "text": "No, generic tasks from the market place don't have pre-reqs.  The requirement is you install the task from the marketplace and it works.\r\n\r\nEven if you entertained communicating pre-reqs, the problem is shifting pre-reqs.  If you pre-req 1.0 and everyone puts that in their container, when can your task start using capabilities of 1.1?  never.  If they heeded your pre-req at install time and their build works on the container they put your pre-req in, it will blow up when you change your task to code against 1.1 capabilities.  \r\n\r\nThe fundamental problem is you have multiple layers from the agent, tasks and system that float on different lifetimes. That's why the agent and tasks are self contained.  You also have to be crisp between what's a dependency (node) and a tool (what the task is calling - msbuild, etc...).\r\n\r\nNothing is preventing you from creating a task in typescript that calls powershell / pester right now until and if we add this.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8913", "user": "ChrisLGardner", "root": "ROOT89", "reply_to": "COM8912", "timestamp": "2018-06-12T15:36:48Z", "text": "That's a fair point about separating dependencies for the task from the tool, I always think of Java as a dependency for the SonarQube task but it's actually a dependency for the SonarQube tool that is presented to the user as requirement for the build agent to have installed. \r\n\r\nThe only clean way of handling making use of new functionality in newer versions of a dependency that I can see is to increment the major version number of your task, so it becomes a choice for the users to make use of it and the need to install a new version of the dependency. The other approach requires adding checks for that version in your code before trying to use it, which grants more compatability but takes more time and effort on the part of the task author. \r\n\r\nI still think updating for new prereqs is less of a problem for people using containers due to their nature but I know there will be a large number who don't want to change their working container because a task updated a bit. It's also still a bigger problem for people not using containers as that takes more time and effort to roll out new versions of prereqs.\r\n\r\nI'll certainly give some thought to writing a typescript wrapper for the pester task I already have and see how that performs. Hopefully some of these more interesting and difficult design questions can be worked out to enable a PS Core handler.\r\n\r\nThanks for taking the time to explain this stuff Bryan, it's given me a much better idea of how it all hangs together and the things you have to think about when working on the agents.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8914", "user": "bryanmacfarlane", "root": "ROOT89", "reply_to": "COM8913", "timestamp": "2018-06-12T16:03:35Z", "text": "@ChrisLGardner - Cool.  Thanks for listening :) ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8915", "user": "dmitryserbin", "root": "ROOT89", "reply_to": "COM8914", "timestamp": "2019-04-21T04:15:04Z", "text": "We also really need a native PowerShell Core task execution support (for Windows-based agents at least).\r\n\r\nAs far as I understand you guys (@bryanmacfarlane) already have a backlog item for this, however I want to understand when you're planning to implement/release it?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8916", "user": "damccorm", "root": "ROOT89", "reply_to": "COM8915", "timestamp": "2019-05-16T03:12:58Z", "text": "@dmitryserbin I think while this is something we're interested in, its not high priority for us right now so we don't have an immediate eta. There's a lot of challenges associated with this (see above) and if we do decide to move forward it will take a concerted push/thought that we don't have the bandwidth to invest right now.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8917", "user": "samswork", "root": "ROOT89", "reply_to": "COM8916", "timestamp": "2019-06-06T17:15:39Z", "text": "I spent a couple days trying to force existing PS module to work on Linux. I got very close, but the things I had to do made it clear that while it's possible, it's a bad idea.\r\n\r\nMy approach was to invoke my existing PS script in pscore from a \"trivial\" JS script; importing the PS Module using Import-Module, of course. This feel apart because of the \"Vaulting\" behavior: the variables were inaccessible to my PS script because they'd been \"vaulted\" by JS (see internal.js:645,656 and a couple other places). \r\n\r\nJust \"for science\", I hacked the scripts to not delete the environment variables post vault. This works. However, it's clearly a case of \"because you can doesn't mean you should\".\r\n\r\nI'm currently re-writing these PS scripts in JS.\r\n\r\nI'd love to see PS Core support! If you pick this up, send me a ping and I'll share my experiences.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8918", "user": "sandersaares", "root": "ROOT89", "reply_to": "COM8917", "timestamp": "2019-06-12T05:58:32Z", "text": "Oh wow, I thought for sure PowerShell Core was a v1 feature. I am very disappointed that I cannot author tasks via PowerShell Core. This is currently a complete blocker for me when it comes to authoring pipelines tasks. Going with TypeScript is a complete non-starter.\r\n\r\nFrom a user perspective, all this prerequisite talk is besides the point. To run JavaScript it also needs a JavaScript runtime - there is no difference with a PowerShell runtime. If you are afraid of the risk, tell the user to install it manually via some Install PowerShell Core task.\r\n\r\nYour users want to get stuff done, not wait for the perfect solution.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8919", "user": "bryanmacfarlane", "root": "ROOT89", "reply_to": "COM8918", "timestamp": "2019-06-12T12:41:20Z", "text": "@sandersaares - as noted above, it's not about the user installing pre-reqs.  The consumer (user) of task simply goes to the market place and uses it.  They shouldn't have to inspect the tasks code and figure out what it's pre-reqs are.  The requirements are, choose task, use, works.  So market place tasks cannot have pre-reqs.\r\n\r\nFor those reasons, the agent carries the javascript runtime (node).  It's a self contained executable.\r\n\r\nWe also need to make it work in containers since [jobs can run in containers](https://docs.microsoft.com/en-us/azure/devops/pipelines/process/container-phases?view=azure-devops&tabs=yaml).   That includes alpine and we're tracking.  For typescript tasks, we map it into the container (user can pick any container) and at that point it's about the OS pre-reqs which is almost zero for typescript/node.  netcore has been reducing OS dependencies with 2.x and 3.x so we're evaluating.\r\n\r\nAll of this is possible since we could potentially package ps core in the agent but it will take quite a bit of work, docs etc. and we need ps to address the alpine (wasn't there when we last looked).  This is why we've left the issue open.  We're still considering and looking at the work involved.\r\n\r\nNote that you can use the typescript task-lib to exec powershell core against a powershell core your task carries.  That will have the issue mentioned above of a task having a pre-req though.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8920", "user": "ChrisLGardner", "root": "ROOT89", "reply_to": "COM8919", "timestamp": "2019-06-12T12:59:38Z", "text": "I believe PS Core now supports Alpine, might be worth checking in with @SteveL-MSFT as I know a few people asked him about Azure Pipelines supporting PS Core when we were at PSConfEU. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8921", "user": "bryanmacfarlane", "root": "ROOT89", "reply_to": "COM8920", "timestamp": "2019-06-12T13:06:03Z", "text": "@ChrisLGardner - yep.  Last status I heard was a [personal / experimental container](https://github.com/PowerShell/PowerShell/issues/4605).  Following up.  ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8922", "user": "gogbg", "root": "ROOT89", "reply_to": "COM8921", "timestamp": "2019-06-12T13:31:23Z", "text": "Not having Handler that supports natively PS6 is blocker!\r\nIt`s not only cross-platform related problem, PS5 is no longer supported! We have ton of PS5 related bugs to which MS replied: \"We cannot do anything in ps5, they are already fixed in ps6, go use ps6\".\r\n\r\nAlso I cannot understand why the \"ProcessHandler\" is calling cmd.exe to start the desired executable. If that wasn`t the case, we could have used it to call pwsh.exe from it.\r\n\r\nI don`t like the typescript approach because of:\r\n- My understanding is that in order to use typescript, we will end up as an with extra dependency of node.\r\n- chaining lots of processes will cause a lot of environment variables propagation issues, and Env variables are essential for pipelines.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8923", "user": "sandersaares", "root": "ROOT89", "reply_to": "COM8922", "timestamp": "2019-06-12T13:52:00Z", "text": "> They shouldn't have to inspect the tasks code and figure out what it's pre-reqs are.\r\n\r\nNonsense. For NuGet tasks, I have to spray \"NuGet Installer\" tasks all over the place and this is far from the only one. Make a PowerShell Installer task, along the same lines, and you would make a lot of people very happy.\r\n\r\nWhat you claim there is an unreasonable ideal that is holding back progress.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8924", "user": "bryanmacfarlane", "root": "ROOT89", "reply_to": "COM8923", "timestamp": "2019-06-12T14:32:38Z", "text": "> My understanding is that in order to use typescript, we will end up as an with extra dependency of node\r\n\r\nThat is not correct.  The agent carries node as the task runtime.  It's completely self contained so adding a task from the market place works.  And that's the work that this enhancement needs.\r\n\r\n> a PowerShell Installer task\r\n\r\nThat won't work in container jobs as pointed out above.  Note that a task dependency is different than installing tools in an environment.  The user and consumer of tasks brings tools they use\r\n\r\nNote that we have not said we're not doing this which is why enhancement is still open.   The work is known and it's on our backlog.  The requirements, patterns and expectations have been set for how the type script tasks work.  When we add powershell core support, the requirements are the same and it will need to work for all of our features. \r\n\r\nI would kindly ask that we keep the conversation friendly and respectful.  Please refer to our code of conduct: https://opensource.microsoft.com/codeofconduct/\r\n\r\nWe are keeping this issue open and will address it on our backlog. Thanks for all of your feedback -  All the details and considerations are captured in this issue.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM8925", "user": "damccorm", "root": "ROOT89", "reply_to": "COM8924", "timestamp": "2019-10-29T21:10:23Z", "text": "Hi, per #537 we've decided not to add this at this time", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT90", "user": "Kasea", "root": "ROOT90", "reply_to": null, "timestamp": "2019-12-19T09:00:30Z", "text": "Snow Flake on vscode insiders and pushing death is very offensive to me The Snow Flake on vscode insiders and pushing it as a \"cozy\"/\"wintery\" thing is very offensive to me. I come from Norway and people who glorify snow is equivalent to the people who glorified hitler during WW2. The amount of deaths caused by winter is massive, not to mention the depression the season brings and you want to bring that into my work space as well? This is unacceptable, everytime I leave my house I see snow and I want to escape into Visual Studio Code and get some work done and what do I see? More snow... To me this is equally offensive as a swastika.\r \r This isn't just me either, think about the people who cannot even get snow, think about how you're making them feel, making them see what they cannot get, although personally I don't understand that. Snow is terrifying.\r \r Version: 1.42.0-insider (user setup)\r Commit: 26f5dfc\r Date: 2019-12-19T05:31:04.916Z\r Electron: 6.1.6\r Chrome: 76.0.3809.146\r Node.js: 12.4.0\r V8: 7.6.303.31-electron.0\r OS: Windows_NT x64 10.0.18362\r \r Steps to Reproduce:\r \r 1. Install latest build of insiders.\r \r Does this issue occur when all extensions are disabled?: Yes\r \r Additional reading on the issue that most certainly needs to be considered.\r [https://thoughtcatalog.com/jim-goad/2015/12/death-by-snow-14-ways-that-winter-weather-can-kill-you/](https://thoughtcatalog.com/jim-goad/2015/12/death-by-snow-14-ways-that-winter-weather-can-kill-you/)\r [https://www.nrdc.org/stories/global-warming-101](https://www.nrdc.org/stories/global-warming-101)\r [https://www.recoveryranch.com/addiction-blog/snow-depression/](https://www.recoveryranch.com/addiction-blog/snow-depression/)\r \r ", "meta": {"posReactions": "100", "negReactions": "6"}}
{"id": "COM900", "user": "bhack", "root": "ROOT90", "reply_to": "ROOT90", "timestamp": "2019-12-19T09:10:39Z", "text": "This is really offending for people that are suffering for global warming and desertfication areas. \r\nAlso is that a natural snow icon or a fake snow icon?\r\nPlease think about how much water Is wasted to create artificial snow just for games:\r\nhttps://news.bloombergenvironment.com/environment-and-energy/fake-snow-for-china-olympics-needs-49-million-gallons-of-water", "meta": {"posReactions": "31", "negReactions": "1"}}
{"id": "COM901", "user": "braindigitalis", "root": "ROOT90", "reply_to": "COM900", "timestamp": "2019-12-19T09:18:17Z", "text": "Perhaps this is not the correct platform for trolling?", "meta": {"posReactions": "6", "negReactions": "58"}}
{"id": "COM902", "user": "bhack", "root": "ROOT90", "reply_to": "COM901", "timestamp": "2019-12-19T09:27:31Z", "text": "@braindigitalis It Is not trolling Is that when MS applies too extreme \"politically correct\" reactions it Is healty if the community react with a little bit of satire.", "meta": {"posReactions": "31", "negReactions": "1"}}
{"id": "COM903", "user": "SaltyMonkey", "root": "ROOT90", "reply_to": "COM902", "timestamp": "2019-12-19T09:28:38Z", "text": "Also, seems, censoring everything just keep self \"clean\"", "meta": {"posReactions": "13", "negReactions": "1"}}
{"id": "COM904", "user": "bhack", "root": "ROOT90", "reply_to": "COM903", "timestamp": "2019-12-19T09:44:39Z", "text": "We could make the snowflake toggable https://github.com/microsoft/vscode/issues/87333 :smile:", "meta": {"posReactions": "6", "negReactions": "1"}}
{"id": "COM905", "user": "MaurogDark", "root": "ROOT90", "reply_to": "COM904", "timestamp": "2019-12-19T09:59:06Z", "text": "> We could make the snowflake toggable #87333\r\n\r\nIf it was possible to just turn the slowflake off, this whole debacle wouldn't happen :thinking: ", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM906", "user": "shakeyourbunny", "root": "ROOT90", "reply_to": "COM905", "timestamp": "2019-12-19T10:01:19Z", "text": "It is really offending me because I am very snow sensitive and get hurt by snowflakes when it is snowing.\r\n\r\nIf I see that on the VS code I feel physically hurt.\r\n\r\nSo remove it immediately like you did the other thing.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM907", "user": "ChronoTempus", "root": "ROOT90", "reply_to": "COM906", "timestamp": "2019-12-19T10:07:59Z", "text": "On the other hand snowflake is the best symbol for spineless corporations bowing down to any random activist complain.", "meta": {"posReactions": "22", "negReactions": "1"}}
{"id": "COM908", "user": "bhack", "root": "ROOT90", "reply_to": "COM907", "timestamp": "2019-12-19T10:09:15Z", "text": "Also there was some recent effort to associate snowflake and Santa with its red hat to drug consumption so please don't talk about Its red hat and snow symbol in the same thread. :smile_cat: \r\nhttps://www.vice.com/en_us/article/jgee9k/amazon-is-still-selling-festive-christmas-sweaters-showing-santa-doing-cocaine", "meta": {"posReactions": "7", "negReactions": "2"}}
{"id": "COM909", "user": "MaKiPL", "root": "ROOT90", "reply_to": "COM908", "timestamp": "2019-12-19T10:52:50Z", "text": "I am with you guys- the one **TROLL** that offended many, many people got his wish fulfilled. Only ONE person wanted this ridiculous change and you are just ignoring so many requests to bring back what was deleted. Shame on you, shame. ", "meta": {"posReactions": "20", "negReactions": "2"}}
{"id": "COM9010", "user": "PierreRambaud", "root": "ROOT90", "reply_to": "COM909", "timestamp": "2019-12-19T11:27:43Z", "text": "@daniel1302 Please stop offended me! You're not my dad, I can use everything I like / dislike!", "meta": {"posReactions": "5", "negReactions": "3"}}
{"id": "COM9011", "user": "MaKiPL", "root": "ROOT90", "reply_to": "COM9010", "timestamp": "2019-12-19T11:33:00Z", "text": "@daniel1302 Please stop offending other users. @Christian-Schiffer created enough havoc already.", "meta": {"posReactions": "5", "negReactions": "2"}}
{"id": "COM9012", "user": "ludo237", "root": "ROOT90", "reply_to": "COM9011", "timestamp": "2019-12-19T11:33:06Z", "text": "@daniel1302 ok boomer", "meta": {"posReactions": "4", "negReactions": "2"}}
{"id": "COM9013", "user": "shakeyourbunny", "root": "ROOT90", "reply_to": "COM9012", "timestamp": "2019-12-19T11:38:23Z", "text": "So, interesting to see that this issue is actively watched but the only thing what happens, is that two posts were deleted instead of instapromptu removing the hurtful snowflake from the application, like the other thing.\r\n\r\nI'd be really  grateful if that the correct reaction will be delivered like the other one, snowflakes do hurt and sting in the eyes, I won't be able to sleep if I see all day this hurtful symbol of pain and climate oppression in my IDE.\r\n", "meta": {"posReactions": "1", "negReactions": "1"}}
{"id": "COM9014", "user": "SimonGrn", "root": "ROOT90", "reply_to": "COM9013", "timestamp": "2019-12-19T11:40:44Z", "text": "Some guy in Microsoft HQ is sweating right now.\r\n\r\nAlthough this is 100% deserved.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9015", "user": "matthieu-rolland", "root": "ROOT90", "reply_to": "COM9014", "timestamp": "2019-12-19T11:41:36Z", "text": "His name is **Christian**, that must be a troll account, too good to be true :D", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM9016", "user": "shakeyourbunny", "root": "ROOT90", "reply_to": "COM9015", "timestamp": "2019-12-19T11:42:48Z", "text": "If you need further reference why snowflakes remind me of cold, pain and hurt see:\r\nhttps://www.aao.org/eye-health/diseases/photokeratitis-snow-blindness\r\nhttps://www.webmd.com/a-to-z-guides/news/20110120/snow-shoveling-injures-thousands-each-year#1\r\n", "meta": {"posReactions": "1", "negReactions": "1"}}
{"id": "COM9017", "user": "ioquatix", "root": "ROOT90", "reply_to": "COM9016", "timestamp": "2019-12-19T12:02:02Z", "text": "I'm from New Zealand, and in the Southern Hemisphere, it's not cold, but hot during the holiday season. I suggest you geo-locate the user's position and prompt them for the icon of their choice, e.g. snow, ice, fire, sun shine.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9018", "user": "pgawlowski", "root": "ROOT90", "reply_to": "COM9017", "timestamp": "2019-12-19T12:18:49Z", "text": "BTW. To original author of this storm - @Christian-Schiffer. I wonder if his name not offending him? \r\nhttps://en.m.wikipedia.org/wiki/Christian_(given_name)\r\nMaybe he should change it...", "meta": {"posReactions": "7", "negReactions": "1"}}
{"id": "COM9019", "user": "cy6erGn0m", "root": "ROOT90", "reply_to": "COM9018", "timestamp": "2019-12-19T12:24:38Z", "text": "Every Christian should be renamed immediately to eliminate possible offence. The name should be strictly prohibited for future use.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM9020", "user": "cristaloleg", "root": "ROOT90", "reply_to": "COM9019", "timestamp": "2019-12-19T12:28:27Z", "text": "https://en.wikipedia.org/wiki/Snowflake_(slang)", "meta": {"posReactions": "7", "negReactions": "1"}}
{"id": "COM9021", "user": "Kasea", "root": "ROOT90", "reply_to": "COM9020", "timestamp": "2019-12-19T12:52:37Z", "text": "Can you people stick on topic? This is a serious discussion about the terror that is snow flakes and how it terrorises a lot of people everyday, even more now with the new VS Code update.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM9022", "user": "Yobilat", "root": "ROOT90", "reply_to": "COM9021", "timestamp": "2019-12-19T12:56:29Z", "text": "I would also like to point out that snow(flake) is _white_ and is commonly used as a white supremacy symbol to oppress and marginalize whole ethnicities, which due to systemic geographic discrimination couldn't historically experience, first-hand, full range of weather phenomena.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM9023", "user": "ivanpopelyshev", "root": "ROOT90", "reply_to": "COM9022", "timestamp": "2019-12-19T13:00:09Z", "text": "Winter is one good buff against invaders in Russia. Praise the winter! Let it snow!\r\n\r\nAlso I think climate calculations are wrong and new ice age is nearby. There will be more snow. Thank you global warming fighters, for helping to make even more snow!", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM9024", "user": "chrisdias", "root": "ROOT90", "reply_to": "COM9023", "timestamp": "2019-12-19T19:02:45Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.\r\n\r\nHappy Coding!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT91", "user": "kenyon", "root": "ROOT91", "reply_to": null, "timestamp": "2020-04-08T07:45:58Z", "text": "v2.9.6 templating performance regression due to caching change in #67429 ##### SUMMARY\r #67429 (included in Ansible v2.9.6) causes a massive performance penalty compared to Ansible v2.9.5. I have a project making heavy use of Ansible's `template` module. With v2.9.5 it takes about 15 seconds to render a file. With v2.9.6, it takes about 9 minutes. Reverting the change in #67429 (just changing `if cache and only_one:` back to `if cache:`) restores the v2.9.5 performance.\r \r ##### ISSUE TYPE\r - Bug Report\r \r ##### COMPONENT NAME\r `lib/ansible/template/__init__.py`\r \r ##### ANSIBLE VERSION\r <!--- Paste verbatim output from \"ansible --version\" between quotes -->\r ```paste below\r ansible 2.9.6\r   config file = /users/kenyon/git/tni4/ansible.cfg\r   configured module search path = ['/users/kenyon/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']\r   ansible python module location = /users/kenyon/.local/share/virtualenvs/tni4-I44CyCAv/lib/python3.6/site-packages/ansible\r   executable location = /users/kenyon/.local/share/virtualenvs/tni4-I44CyCAv/bin/ansible\r   python version = 3.6.8 (default, Apr 25 2019, 21:02:35) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]\r ```\r \r ##### CONFIGURATION\r <!--- Paste verbatim output from \"ansible-config dump --only-changed\" between quotes -->\r ```paste below\r DEFAULT_HOST_LIST(/users/kenyon/git/tni4/ansible.cfg) = ['/users/kenyon/git/tni4/hosts']\r ```\r \r ##### OS / ENVIRONMENT\r <!--- Provide all relevant information below, e.g. target OS versions, network device firmware, etc. -->\r CentOS 7\r \r ##### STEPS TO REPRODUCE\r <!--- Describe exactly how to reproduce the problem, using a minimal test-case -->\r Use large templates with lots of Jinja code. I am rendering configuration files for network devices, so the end resulting rendered files are around 2000 lines or less, but the templates use a lot of Jinja features.\r \r ##### EXPECTED RESULTS\r <!--- Describe what you expected to happen when running the steps above -->\r No performance regression.\r \r ##### ACTUAL RESULTS\r <!--- Describe what actually happened. If possible run with extra verbosity (-vvvv) -->\r Performance regression.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM910", "user": "ansibot", "root": "ROOT91", "reply_to": "ROOT91", "timestamp": "2020-04-08T07:53:18Z", "text": "Files identified in the description:\n* [`lib/ansible/modules/files/template.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/files/template.py)\n* [`lib/ansible/plugins/action/template.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/plugins/action/template.py)\n* [`lib/ansible/plugins/lookup/template.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/plugins/lookup/template.py)\n* [`lib/ansible/template/__init__.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/template/__init__.py)\n* [`lib/ansible/template/native_helpers.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/template/native_helpers.py)\n* [`lib/ansible/template/safe_eval.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/template/safe_eval.py)\n* [`lib/ansible/template/template.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/template/template.py)\n* [`lib/ansible/template/vars.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/template/vars.py)\n\nIf these files are incorrect, please update the `component name` section of the description or use the `!component` bot command.\n\n[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)\n<!--- boilerplate: components_banner --->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM911", "user": "sivel", "root": "ROOT91", "reply_to": "COM910", "timestamp": "2020-04-09T18:20:28Z", "text": "After reviewing the change, we believe this to be a correct change. However, since you are seeing a performance degradation, I'm going to assume that you have some variable assigned to a `lookup`, that is being repeatedly re-evaluated now.\r\n\r\nCan you confirm whether this is the case, and how that variable is being used in these templates?\r\n\r\nIn order to more effectively help you, we ultimately need a reproducer that we can run that replicates the behavior you describe.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM912", "user": "sivel", "root": "ROOT91", "reply_to": "COM911", "timestamp": "2020-04-09T19:01:09Z", "text": "needs_info", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM913", "user": "kenyon", "root": "ROOT91", "reply_to": "COM912", "timestamp": "2020-04-10T07:14:06Z", "text": "I'm only using `lookup` as in `somevar: '{{ lookup(\"vars\", ...) }}'`, and only in two places out of thousands of lines, and the performance is degraded even when templating files that don't include those `lookup` calls, so those aren't the problem (not sure if that's what you meant by \"some variable assigned to a `lookup`\").\r\n\r\nI'll try to come up with a minimal reproducer soon.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM914", "user": "Oloremo", "root": "ROOT91", "reply_to": "COM913", "timestamp": "2020-04-17T13:04:20Z", "text": "We use a lot of lookup in variables too and observing a 26% performance degradation in our case on 2.9.6+", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM915", "user": "kenyon", "root": "ROOT91", "reply_to": "COM914", "timestamp": "2020-04-19T23:57:19Z", "text": "Well I'm having trouble making a reproducer for this. Unfortunately I can't easily attempt to reproduce this on the same hardware where I first experienced the problem because my company network heavily restricts Internet access from my development environment. So I've been trying to reproduce on my home computer, but am only getting essentially identical results between 2.9.5 and 2.9.6. One difference between my work and home environments is that the work env has $HOME mounted over NFS, so I wonder if that has something to do with it. Otherwise, I'm not sure.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM916", "user": "timflannagan", "root": "ROOT91", "reply_to": "COM915", "timestamp": "2020-05-01T15:57:47Z", "text": "I can also confirm that I'm seeing this templating caching change have pretty significant performance degradation issues. Before 2.9.6, role execution took anywhere from 3-7 minutes, and when we bump the Ansible minor version to 2.9.6+, it typically takes 45+ minutes to deploy all of our resources and this is always reproducible. When I deploy with more verbose logs, I can see that a task given a [jinja2 expression](https://github.com/kube-reporting/metering-operator/blob/master/images/metering-ansible-operator/roles/meteringconfig/tasks/configure_root_ca.yml#L13) makes a file lookup call many, many times:\r\n\r\n```yaml\r\nTASK [meteringconfig : Check if Root CA secret already exists] *****************\r\ntask path: /opt/ansible/roles/meteringconfig/tasks/configure_root_ca.yml:9\r\nFriday 01 May 2020  15:43:09 +0000 (0:00:00.054)       0:00:20.668 ************\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\nFile lookup using /opt/ansible/charts/openshift-metering/values.yaml as file\r\n\r\n...\r\n```\r\n\r\nIn comparison to 2.9.5, this file lookup call was made one or two times, and if I revert the change to `if cache and only_one`, I see the performance issues resolved.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM917", "user": "geerlingguy", "root": "ROOT91", "reply_to": "COM916", "timestamp": "2020-05-01T16:32:33Z", "text": "> One difference between my work and home environments is that the work env has $HOME mounted over NFS, so I wonder if that has something to do with it.\r\n\r\n@kenyon - That would definitely have an impact, if something is doing a filesystem lookup X times, on NFS it might be a 20-30ms delay, whereas on a local SSD it's like 0.01ms... if it's running 100 lookups, that's an extra 3 seconds per task. I've run into similar issues when pulling data from EFS on AWS (not reproducible outside of that environment).", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM918", "user": "sivel", "root": "ROOT91", "reply_to": "COM917", "timestamp": "2020-05-01T16:54:53Z", "text": "@timflannagan1 yes, so in your case, because templating is lazy evaluated, every time `meteringconfig_default_values` is used, it's re-evaluated.  The `only_one` var used in templating is described as:\r\n\r\n```\r\n                    # Check to see if the string we are trying to render is just referencing a single\r\n                    # var.\r\n```\r\n\r\nBecause `meteringconfig_default_values` has a value using `lookup` it is not just a single var.\r\n\r\nRight now, to improve performance, you would need to have a `set_fact` task towards the start of the role that \"finalizes\" the variable, so that the result is stored.\r\n\r\n```\r\n- set_fact:\r\n    meteringconfig_default_values: \"{{ meteringconfig_default_values }}\"\r\n```\r\n\r\nWe've been talking about someway to tell ansible to finalize a variable immediately on definition, like:\r\n\r\n```\r\nmeteringconfig_default_values: !finalize \"{{ lookup('file', meteringconfig_default_values_file) | from_yaml }}\"\r\n```\r\n\r\nBut that feature does not exist yet.\r\n\r\nAnother potential future feature, is a way to instruct `lookup` to cache the value.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM919", "user": "Oloremo", "root": "ROOT91", "reply_to": "COM918", "timestamp": "2020-05-01T17:44:38Z", "text": "I'm puzzled why this caching was removed without an optional fallback. lookup() could have dynamic data! Ok, mine don't. Could we have an optional and disabled by default argument \"enable lookup cache\"?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9110", "user": "sivel", "root": "ROOT91", "reply_to": "COM919", "timestamp": "2020-05-01T17:56:35Z", "text": "@Oloremo We fixed valid bugs by making this change.  The change in question is a correct change. However, it exposes that some people were relying on buggy behavior, without realizing it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9111", "user": "Oloremo", "root": "ROOT91", "reply_to": "COM9110", "timestamp": "2020-05-01T18:07:24Z", "text": "It's a correct change in 90% of the cases, I agree. Yet there is cases where lookups work with static data and adding an argument to the lookup function would solve 100% of cases.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9112", "user": "thaumos", "root": "ROOT91", "reply_to": "COM9111", "timestamp": "2020-05-01T18:22:10Z", "text": "I think what @sivel is saying that while we fixed buggy behaviour as a result, it's not as easy for us  to implement the expected caching behaviour as suggested or previously worked.  \r\n\r\nFor now, there is a work-around, using set_fact.  Let's use that for now.\r\n\r\nWe are going to introduce a feature in a future release, after 2.10, to re-implement the expected caching behaviour.  That behaviour being, to allow for performance improvement to exist, by having an explicit decision made by the content creator to do the caching.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9113", "user": "Oloremo", "root": "ROOT91", "reply_to": "COM9112", "timestamp": "2020-05-01T19:35:43Z", "text": "No chance to introduce it in 2.9? It seems like a single argument and an `if`.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9114", "user": "zem", "root": "ROOT91", "reply_to": "COM9113", "timestamp": "2020-05-13T21:01:38Z", "text": "+1 \r\n\r\nThe bug happens here too. Steps are taking up to 20 Minutes with 2.9.7 when they access a software version/location lookup structure that maps a current variable multiple times. \r\n\r\nFor now we have installed an older version (2.9.3) as workaround. \r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9115", "user": "sivel", "root": "ROOT91", "reply_to": "COM9114", "timestamp": "2020-05-13T21:08:43Z", "text": "As an update to this issue, we will not revert the fix, as the original bug has been reclassified as a CVE and documented at https://access.redhat.com/security/cve/CVE-2020-10729\r\n\r\nThe 2.9.x series will not see any resolution of this performance degradation, as it will require a new feature to implement. It is also unlikely that such a feature will make it into the 2.10 release.\r\n\r\nIn the meantime, as indicated above, I recommend using an intermediate `set_fact` task to \"finalize\" the value.  If you are experiencing this issue during template file generation due to looping, you can also take advantage of Jinja2 [assignments](https://jinja.palletsprojects.com/en/master/templates/#assignments) to create an intermediate cached variable.\r\n\r\nFor the time being I am locking this issue to further activity.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9116", "user": "ansibot", "root": "ROOT91", "reply_to": "COM9115", "timestamp": "2020-05-21T21:27:20Z", "text": "Files identified in the description:\n* [`lib/ansible/modules/template.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/template.py)\n* [`lib/ansible/plugins/action/template.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/plugins/action/template.py)\n* [`lib/ansible/plugins/lookup/template.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/plugins/lookup/template.py)\n* [`lib/ansible/template/__init__.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/template/__init__.py)\n* [`lib/ansible/template/native_helpers.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/template/native_helpers.py)\n* [`lib/ansible/template/safe_eval.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/template/safe_eval.py)\n* [`lib/ansible/template/template.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/template/template.py)\n* [`lib/ansible/template/vars.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/template/vars.py)\n\nIf these files are incorrect, please update the `component name` section of the description or use the `!component` bot command.\n\n[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)\n<!--- boilerplate: components_banner --->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9117", "user": "ansibot", "root": "ROOT91", "reply_to": "COM9116", "timestamp": "2020-08-25T22:53:37Z", "text": "Files identified in the description:\n* [`lib/ansible/template/__init__.py`](https://github.com/ansible/ansible/blob/devel/lib/ansible/template/__init__.py)\n\nIf these files are incorrect, please update the `component name` section of the description or use the `!component` bot command.\n\n[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)\n<!--- boilerplate: components_banner --->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT92", "user": "kevinburke", "root": "ROOT92", "reply_to": null, "timestamp": "2018-08-30T18:06:50Z", "text": "fmt: add examples Let's add examples. I think it would be good to add examples to each function (if possible?) as well as to illustrate some points - not every example should make every point but it would be good to cover these.\r \r - how do %d, %s, %q, %v differ\r \r - how do you do left/right padding\r \r - decimal formatting\r \r - how does \"ln\" ending vary from \"f\" ending\r \r When you open a change, put this at the bottom of the commit message:\r \r ```\r Updates golang/go#27376.\r ```\r \r That way gopherbot will post a comment here with a link to your CL.\r \r Add a comment if you want to fix one and I'll put your name next to the func in question.\r \r - [x] `func Errorf(format string, a ...interface{}) error`: @ianzapolsky\r \r - [x] func Fprint(w io.Writer, a ...interface{}) (n int, err error)\r \r - [ ] `func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error)`: @MaerF0x0\r \r - [x] `func Fprintln(w io.Writer, a ...interface{}) (n int, err error)`: @waits \r \r - [ ] `func Fscan(r io.Reader, a ...interface{}) (n int, err error)`: @andriisoldatenko\r \r - [ ] func Fscanf(r io.Reader, format string, a ...interface{}) (n int, err error)\r \r - [x] `func Fscanln(r io.Reader, a ...interface{}) (n int, err error)`: @mfrw\r \r - [x] func Print(a ...interface{}) (n int, err error)\r \r - [ ] `func Printf(format string, a ...interface{}) (n int, err error)`: @mooreds \r \r - [x] `func Println(a ...interface{}) (n int, err error)`: @techmexdev\r \r - [ ] func Scan(a ...interface{}) (n int, err error)\r \r - [ ] func Scanf(format string, a ...interface{}) (n int, err error)\r \r - [ ] func Scanln(a ...interface{}) (n int, err error)\r \r - [x] func Sprint(a ...interface{}) string\r \r - [x] `func Sprintf(format string, a ...interface{}) string`: @venilnoronha\r \r - [x] `func Sprintln(a ...interface{}) string`: @drewvanstone\r \r - [ ] func Sscan(str string, a ...interface{}) (n int, err error)\r \r - [ ] func Sscanf(str string, format string, a ...interface{}) (n int, err error)\r \r - [ ] func Sscanln(str string, a ...interface{}) (n int, err error)\r \r - [ ] type Formatter\r \r - [x] type GoStringer\r \r - [ ] type ScanState\r \r - [ ] type Scanner\r \r - [ ] type State\r \r - [x] type Stringer\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM920", "user": "venilnoronha", "root": "ROOT92", "reply_to": "ROOT92", "timestamp": "2018-08-30T18:13:28Z", "text": "`Sprintf(format string, a ...interface{}) string`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM921", "user": "techmexdev", "root": "ROOT92", "reply_to": "COM920", "timestamp": "2018-08-30T18:13:33Z", "text": "I can do  `func Println(a ...interface{}) (n int, err error)`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM922", "user": "ianzapolsky", "root": "ROOT92", "reply_to": "COM921", "timestamp": "2018-08-30T18:13:56Z", "text": "I'll do `func Errorf(format string, a ...interface{}) error`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM923", "user": "drewvanstone", "root": "ROOT92", "reply_to": "COM922", "timestamp": "2018-08-30T18:19:56Z", "text": "I'll do `func Sprintln(a ...interface{}) string`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM924", "user": "waits", "root": "ROOT92", "reply_to": "COM923", "timestamp": "2018-08-30T18:26:04Z", "text": "I'll do `func Printf(format string, a ...interface{}) (n int, err error)`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM925", "user": "kevinburke", "root": "ROOT92", "reply_to": "COM924", "timestamp": "2018-08-30T18:31:50Z", "text": "@waits there is actually a CL open for that one at the moment from @mooreds https://github.com/golang/go/issues/27349 - I should have added it to the sheet. how about Fprintf?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM926", "user": "MaerF0x0", "root": "ROOT92", "reply_to": "COM925", "timestamp": "2018-08-30T18:37:04Z", "text": "I'll do `func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error)`\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM927", "user": "waits", "root": "ROOT92", "reply_to": "COM926", "timestamp": "2018-08-30T18:39:19Z", "text": "Fprintf was taken also, I'll take `Fprintln`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM928", "user": "ianzapolsky", "root": "ROOT92", "reply_to": "COM927", "timestamp": "2018-08-30T19:44:54Z", "text": "Anyone know how often the official go documentation is updated? i.e. how long our commits should take to show up here: https://golang.org/pkg/fmt/", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM929", "user": "kevinburke", "root": "ROOT92", "reply_to": "COM928", "timestamp": "2018-08-30T19:47:40Z", "text": "They should appear at tip.golang.org almost immediately, as I believe that project fetches from HEAD every 15 minutes.\r\n\r\nThe docs on golang.org will update the next time there's a new Go release, or earlier if the patches are backported from master (which targets Go 1.12) to the Go 1.11.1 point release.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9210", "user": "kevinburke", "root": "ROOT92", "reply_to": "COM929", "timestamp": "2018-08-30T19:53:21Z", "text": "The problem with updating golang.org is if we add some new API for Go 1.12 (like strings.Builder) it would not be good if it showed up in the docs before most people were able to use it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9211", "user": "MaerF0x0", "root": "ROOT92", "reply_to": "COM9210", "timestamp": "2018-08-30T20:33:26Z", "text": "Is there a way we can run our new ExampleFunc locally to ensure it works? Else I can copy it to play.golang.org\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9212", "user": "kevinburke", "root": "ROOT92", "reply_to": "COM9211", "timestamp": "2018-08-30T20:36:34Z", "text": "Yes, run `go get golang.org/x/tools/cmd/godoc` and then start godoc:\r\n\r\n```\r\nGOROOT=/path/to/your/contribution-repo godoc -http=:6060\r\n```\r\n\r\nOpen localhost:6060/fmt in your browser and your changes should be there.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM9213", "user": "kevinburke", "root": "ROOT92", "reply_to": "COM9212", "timestamp": "2018-08-30T20:37:19Z", "text": "Alternatively you can create a new `fmt` repo on Github, copy the source files, push your changes there, then go to e.g. godoc.org/github.com/yourname/fmt to see the docs.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9214", "user": "gopherbot", "root": "ROOT92", "reply_to": "COM9213", "timestamp": "2018-08-30T21:33:28Z", "text": "Change https://golang.org/cl/132375 mentions this issue: `fmt: add doc example for Fprintf`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9215", "user": "kevinburke", "root": "ROOT92", "reply_to": "COM9214", "timestamp": "2018-08-30T21:35:03Z", "text": "Looking great! https://tip.golang.org/pkg/fmt/", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9216", "user": "mfrw", "root": "ROOT92", "reply_to": "COM9215", "timestamp": "2018-08-31T06:17:35Z", "text": "I'll  do `func Fscanln(r io.Reader, a ...interface{}) (n int, err error)`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9217", "user": "andriisoldatenko", "root": "ROOT92", "reply_to": "COM9216", "timestamp": "2018-08-31T12:28:59Z", "text": "@kevinburke I can create example for `Fscan`.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9218", "user": "drewvanstone", "root": "ROOT92", "reply_to": "COM9217", "timestamp": "2018-08-31T16:37:46Z", "text": "`Sprintln` is done", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9219", "user": "gopherbot", "root": "ROOT92", "reply_to": "COM9218", "timestamp": "2018-08-31T18:28:50Z", "text": "Change https://golang.org/cl/132675 mentions this issue: `fmt: add example for Fscanln`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9220", "user": "wfernandes", "root": "ROOT92", "reply_to": "COM9219", "timestamp": "2018-09-03T18:12:04Z", "text": "I'll do `GoStringer`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9221", "user": "gopherbot", "root": "ROOT92", "reply_to": "COM9220", "timestamp": "2018-09-03T18:48:29Z", "text": "Change https://golang.org/cl/133075 mentions this issue: `fmt: add example for GoStringer interface`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9222", "user": "gopherbot", "root": "ROOT92", "reply_to": "COM9221", "timestamp": "2018-09-05T06:42:26Z", "text": "Change https://golang.org/cl/133455 mentions this issue: `fmt: add example for Fprint`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9223", "user": "gopherbot", "root": "ROOT92", "reply_to": "COM9222", "timestamp": "2018-09-07T11:53:38Z", "text": "Change https://golang.org/cl/134035 mentions this issue: `fmt: add example for Print`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9224", "user": "gopherbot", "root": "ROOT92", "reply_to": "COM9223", "timestamp": "2018-09-07T12:04:03Z", "text": "Change https://golang.org/cl/134036 mentions this issue: `fmt: add example for Sprint`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9225", "user": "robpike", "root": "ROOT92", "reply_to": "COM9224", "timestamp": "2018-09-07T12:44:59Z", "text": "Replacing with issue https://github.com/golang/go/issues/27554.\r\n\r\nPlease stop adding examples to the package for now.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM9226", "user": "bmeh", "root": "ROOT92", "reply_to": "COM9225", "timestamp": "2018-09-08T21:05:33Z", "text": "> The problem with updating golang.org is if we add some new API for Go 1.12 (like strings.Builder) it would not be good if it showed up in the docs before most people were able to use it.\r\n\r\nFirst off, I don't see how this could be an issue if you are having docs per version (docs for 1.11, docs for 1.12, and so on), and secondly, what is `strings.Builder` and do we really need it? Are we going to have `strings.Factory`, too? For a moment I thought go is finally taking a better route, but it makes me reconsider that thought.\r\n\r\nOn another note, yes, I agree with Rob here. Inconsistency has been a problem for go, it just seems like people come and write completely different and random examples to similar, related functions. That's not how it should be done. Apparently Rob had to assign it to himself, and tell others to stop posting examples for this reason. Thanks Rob, this chaotic madness needs to stop.\r\n\r\nGo linters complain when exported variables or constants are not documented (despite them being obvious in many cases), yet when core developers make major changes to go, they keep the old documentation, and don't even bother making it up-to-date.\r\n\r\nExcuse me for my tone, but it irks me a bit, anyways: thanks for putting an end to it, for the time being.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9227", "user": "ianlancetaylor", "root": "ROOT92", "reply_to": "COM9226", "timestamp": "2018-09-09T12:23:03Z", "text": "Please do keep a polite tone.  Thanks.\r\n\r\nThe comment about updating golang.org was in the context of somebody asking how they could see the current docs.  The answer was: use tip.golang.org, with an explanation for why golang.org is not updated.\r\n\r\nFor `strings.Builder` see https://golang.org/pkg/strings/#Builder .", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9228", "user": "bmeh", "root": "ROOT92", "reply_to": "COM9227", "timestamp": "2018-09-09T13:08:57Z", "text": "Is there any particular reason for why it's not called `strings.Buffer`, next to `bytes.Buffer` (which exists)?\r\n\r\nIt was a neutral-tone, you might have never actually attached or imagined negative connotations to it if it weren't for me saying \"excuse me for my tone\", which I have only said because I know how often people imagine hostility where there is none. :relaxed: ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9229", "user": "ianlancetaylor", "root": "ROOT92", "reply_to": "COM9228", "timestamp": "2018-09-09T13:47:32Z", "text": "`bytes.Buffer` is also an `io.Reader`, `strings.Builder` is not.\r\n\r\nI disagree about the tone; phrases like \"this chaotic madness\" and statements that the core developers do not keep documentation up to date, without giving any examples, are not helpful.  Please see https://golang.org/conduct; search for \"Avoid destructive behavior\".  Thanks.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "ROOT93", "user": "kgignatyev-inspur", "root": "ROOT93", "reply_to": null, "timestamp": "2018-06-16T06:44:05Z", "text": "gatling stuck when project has other dependencies \r [gatling-stuck.zip](https://github.com/gatling/gatling/files/2107919/gatling-stuck.zip)\r \r Basically when project includes \r <dependency>\r             <groupId>io.kubernetes</groupId>\r             <artifactId>client-java</artifactId>\r             <version>1.0.0</version>\r         </dependency>\r \r gatling does not start execution of scenario. Repro case is attached\r \r mvn  clean gatling:execute\r \r and gatling is stuck doing nothing, last message\r  \r     14:34:15.070 [main] INFO  io.gatling.http.ahc.HttpEngine - Start warm up\r     \r     \r now comment out kubernetes client in pom.xml and all will be well  \r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM930", "user": "slandelle", "root": "ROOT93", "reply_to": "ROOT93", "timestamp": "2018-06-16T08:03:59Z", "text": "You've messed up the \"writers\" option in gatling.conf.\r\nWorks just fine for me.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM931", "user": "kgignatyev-inspur", "root": "ROOT93", "reply_to": "COM930", "timestamp": "2018-06-18T23:13:29Z", "text": "Hmm @slandelle , do not you think that simply stating that I 'messed up \"writers\" ' without explaining why is rude?\r\n\r\nAs far as I know I did not mess them, if I do not put writers in square braces and leave as in default config then Gattling would not even start with this exception:\r\n\r\n/src/test/resources/gatling.conf: 118: gatling.data.writers has type STRING rather than LIST\r\n\r\njava.lang.reflect.InvocationTargetException\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat io.gatling.mojo.MainWithArgsInFile.runMain(MainWithArgsInFile.java:50)\r\n\tat io.gatling.mojo.MainWithArgsInFile.main(MainWithArgsInFile.java:33)\r\nCaused by: com.typesafe.config.ConfigException$WrongType: gatling.conf @ file:/Users/kgignatyev/dev/reprocases/gatling-stuck/src/test/resources/gatling.conf: 118: gatling.data.writers has type STRING rather than LIST\r\n\tat com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:159)\r\n\tat com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170)\r\n\tat com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176)\r\n\tat com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176)\r\n\tat com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184)\r\n\tat com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189)\r\n\tat com.typesafe.config.impl.SimpleConfig.getList(SimpleConfig.java:258)\r\n\tat com.typesafe.config.impl.SimpleConfig.getHomogeneousUnwrappedList(SimpleConfig.java:329)\r\n\tat com.typesafe.config.impl.SimpleConfig.getStringList(SimpleConfig.java:387)\r\n\tat io.gatling.core.config.GatlingConfiguration$.mapToGatlingConfig(GatlingConfiguration.scala:215)\r\n\tat io.gatling.core.config.GatlingConfiguration$.load(GatlingConfiguration.scala:98)\r\n\tat io.gatling.app.Gatling$.start(Gatling.scala:54)\r\n\tat io.gatling.app.Gatling$.fromArgs(Gatling.scala:45)\r\n\tat io.gatling.app.Gatling$.main(Gatling.scala:37)\r\n\tat io.gatling.app.Gatling.main(Gatling.scala)\r\n\t... 6 more\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM932", "user": "slandelle", "root": "ROOT93", "reply_to": "COM931", "timestamp": "2018-06-19T04:51:04Z", "text": "> Hmm @slandelle , do not you think that simply stating that I 'messed up \"writers\" ' without explaining why is rude?\r\n\r\nNo, I don't think spending some personal time investigating a problem you have with a software you got from me for free is \"rude\".\r\n\r\nI've pointed out your mistake and you are perfectly capable of spotting the difference between the original configuration that was working and you've commented out and the one you've changed and that don't.\r\n\r\nFrom the `gatling.conf` in the sample you've provided (L217):\r\n\r\n```\r\n    #writers = [\"graphite\", \"console\", \"file\"]\r\n    writers = [\"console, file\"]\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM933", "user": "kgignatyev-inspur", "root": "ROOT93", "reply_to": "COM932", "timestamp": "2018-06-19T05:10:55Z", "text": "Too bad that you do not consider this rude, @slandelle . If you are not willing to spend your time it is your right.  I let Gatling community know that Gatling exhibits strange behavior in the presence of other libraries, and you @slandelle do not care.\r\n\r\nIt is OK too, it just not helpful to make false statements like: 'works for me' and 'you messed up writers' because you did not bother to run the repro-case following very simple instructions.  ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM934", "user": "slandelle", "root": "ROOT93", "reply_to": "COM933", "timestamp": "2018-06-19T05:58:57Z", "text": "> It is OK too, it just not helpful to make false statements like: 'works for me' and 'you messed up writers' because you did not bother to run the repro-case following very simple instructions.\r\n\r\nIf I state that your sample \"works for me\", it of course means that I did bother running it on my side and didn't get to reproduce the issue you're mentioning.\r\n\r\n>  I let Gatling community know that Gatling exhibits strange behavior in the presence of other libraries\r\n\r\nThat's mostly likely an invalid statement, as:\r\n\r\n1) your sample works, at least on my side\r\n2) the library you're mentioning, `io.kubernetes:client-java`, is built on top of Square's okhttp and doesn't share any dependency with Gatling which is built on top of Netty.\r\n\r\n> and you @slandelle do not care.\r\n\r\nLet's agree that we disagree and that nothing good will come from this discussion.\r\n\r\n```\r\nMacBook-Pro-de-slandelle:gatling-stuck slandelle$ mvn clean gatling:execute\r\n[INFO] Scanning for projects...\r\n[WARNING] The project com.inspur.k8s.testing:gatling--testing:jar:1.0-SNAPSHOT uses prerequisites which is only intended for maven-plugin projects but not for non maven-plugin projects. For such purposes you should use the maven-enforcer-plugin. See https://maven.apache.org/enforcer/enforcer-rules/requireMavenVersion.html\r\n[INFO]\r\n[INFO] --------------< com.inspur.k8s.testing:gatling--testing >---------------\r\n[INFO] Building gatling--testing 1.0-SNAPSHOT\r\n[INFO] --------------------------------[ jar ]---------------------------------\r\n[INFO]\r\n[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ gatling--testing ---\r\n[INFO] Deleting /Users/slandelle/Downloads/gatling-stuck/target\r\n[INFO]\r\n[INFO] --- gatling-maven-plugin:2.2.4:execute (default-cli) @ gatling--testing ---\r\n06:20:02.536 [main][WARN ][ZincCompiler.scala:141] i.g.c.ZincCompiler$ - Pruning sources from previous analysis, due to incompatible CompileSetup.\r\n06:20:07,571 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]\r\n06:20:07,571 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.groovy]\r\n06:20:07,572 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Found resource [logback.xml] at [jar:file:/Users/slandelle/.m2/repository/io/kubernetes/client-java/1.0.0/client-java-1.0.0.jar!/logback.xml]\r\n06:20:07,572 |-WARN in ch.qos.logback.classic.LoggerContext[default] - Resource [logback.xml] occurs multiple times on the classpath.\r\n06:20:07,572 |-WARN in ch.qos.logback.classic.LoggerContext[default] - Resource [logback.xml] occurs at [jar:file:/Users/slandelle/.m2/repository/io/kubernetes/client-java/1.0.0/client-java-1.0.0.jar!/logback.xml]\r\n06:20:07,572 |-WARN in ch.qos.logback.classic.LoggerContext[default] - Resource [logback.xml] occurs at [jar:file:/Users/slandelle/.m2/repository/io/gatling/gatling-maven-plugin/2.2.4/gatling-maven-plugin-2.2.4.jar!/logback.xml]\r\n06:20:07,586 |-INFO in ch.qos.logback.core.joran.spi.ConfigurationWatchList@61dc03ce - URL [jar:file:/Users/slandelle/.m2/repository/io/kubernetes/client-java/1.0.0/client-java-1.0.0.jar!/logback.xml] is not of type file\r\n06:20:07,636 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - debug attribute not set\r\n06:20:07,637 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]\r\n06:20:07,644 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - Naming appender as [console]\r\n06:20:07,649 |-INFO in ch.qos.logback.core.joran.action.NestedComplexPropertyIA - Assuming default type [ch.qos.logback.classic.encoder.PatternLayoutEncoder] for [encoder] property\r\n06:20:07,700 |-INFO in ch.qos.logback.classic.joran.action.RootLoggerAction - Setting level of ROOT logger to INFO\r\n06:20:07,700 |-INFO in ch.qos.logback.core.joran.action.AppenderRefAction - Attaching appender named [console] to Logger[ROOT]\r\n06:20:07,700 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - End of configuration.\r\n06:20:07,701 |-INFO in ch.qos.logback.classic.joran.JoranConfigurator@50f8360d - Registering current configuration as safe fallback point\r\n\r\n06:20:08.648 [GatlingSystem-akka.actor.default-dispatcher-2] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started\r\n06:20:08.934 [GatlingSystem-akka.actor.default-dispatcher-3] INFO  i.g.c.stats.writer.LogFileDataWriter - Initializing\r\n06:20:08.934 [GatlingSystem-akka.actor.default-dispatcher-2] INFO  i.g.c.stats.writer.ConsoleDataWriter - Initializing\r\n06:20:08.941 [GatlingSystem-akka.actor.default-dispatcher-2] INFO  i.g.c.stats.writer.ConsoleDataWriter - Initialized\r\n06:20:08.953 [GatlingSystem-akka.actor.default-dispatcher-3] INFO  i.g.c.stats.writer.LogFileDataWriter - Initialized\r\n06:20:09.316 [main] INFO  io.gatling.http.ahc.HttpEngine - Start warm up\r\n06:20:09.697 [main] INFO  io.gatling.http.ahc.HttpEngine - Warm up done\r\nSimulation com.inspur.k8s.perf_tests.BasicSimulation started...\r\n06:20:09.906 [GatlingSystem-akka.actor.default-dispatcher-4] INFO  i.gatling.core.controller.Controller - InjectionStopped expectedCount=1\r\n06:20:10.054 [gatling-http-thread-1-2] INFO  io.gatling.core.action.Pause - Pausing for 7000ms (real=6988ms)\r\n\r\n================================================================================\r\n2018-06-19 06:20:13                                           5s elapsed\r\n---- Requests ------------------------------------------------------------------\r\n> Global                                                   (OK=2      KO=0     )\r\n> request_1                                                (OK=1      KO=0     )\r\n> request_1 Redirect 1                                     (OK=1      KO=0     )\r\n\r\n---- Scenario Name -------------------------------------------------------------\r\n[--------------------------------------------------------------------------]  0%\r\n          waiting: 0      / active: 1      / done:0\r\n================================================================================\r\n\r\n06:20:17.063 [GatlingSystem-akka.actor.default-dispatcher-5] INFO  i.gatling.core.controller.Controller - All users are stopped\r\n\r\n================================================================================\r\n2018-06-19 06:20:17                                           8s elapsed\r\n---- Requests ------------------------------------------------------------------\r\n> Global                                                   (OK=2      KO=0     )\r\n> request_1                                                (OK=1      KO=0     )\r\n> request_1 Redirect 1                                     (OK=1      KO=0     )\r\n\r\n---- Scenario Name -------------------------------------------------------------\r\n[##########################################################################]100%\r\n          waiting: 0      / active: 0      / done:1\r\n================================================================================\r\n\r\n06:20:17.073 [GatlingSystem-akka.actor.default-dispatcher-6] INFO  i.gatling.core.controller.Controller - StatsEngineStopped\r\nSimulation com.inspur.k8s.perf_tests.BasicSimulation completed in 7 seconds\r\nParsing log file(s)...\r\n06:20:17.134 [main] INFO  i.gatling.charts.stats.LogFileReader - Collected ArrayBuffer(/Users/slandelle/Downloads/gatling-stuck/target/gatling/basicsimulation-1529382008914/simulation.log) from basicsimulation-1529382008914\r\n06:20:17.142 [main] INFO  i.gatling.charts.stats.LogFileReader - First pass\r\n06:20:17.151 [main] INFO  i.gatling.charts.stats.LogFileReader - First pass done: read 5 lines\r\n06:20:17.161 [main] INFO  i.gatling.charts.stats.LogFileReader - Second pass\r\n06:20:17.203 [main] INFO  i.gatling.charts.stats.LogFileReader - Second pass: read 5 lines\r\nParsing log file(s) done\r\nGenerating reports...\r\n\r\n================================================================================\r\n---- Global Information --------------------------------------------------------\r\n> request count                                          2 (OK=2      KO=0     )\r\n> min response time                                     50 (OK=50     KO=-     )\r\n> max response time                                     86 (OK=86     KO=-     )\r\n> mean response time                                    68 (OK=68     KO=-     )\r\n> std deviation                                         18 (OK=18     KO=-     )\r\n> response time 50th percentile                         68 (OK=68     KO=-     )\r\n> response time 75th percentile                         77 (OK=77     KO=-     )\r\n> response time 95th percentile                         84 (OK=84     KO=-     )\r\n> response time 99th percentile                         86 (OK=86     KO=-     )\r\n> mean requests/sec                                   0.25 (OK=0.25   KO=-     )\r\n---- Response Time Distribution ------------------------------------------------\r\n> t < 800 ms                                             2 (100%)\r\n> 800 ms < t < 1200 ms                                   0 (  0%)\r\n> t > 1200 ms                                            0 (  0%)\r\n> failed                                                 0 (  0%)\r\n================================================================================\r\n\r\nReports generated in 0s.\r\nPlease open the following file: /Users/slandelle/Downloads/gatling-stuck/target/gatling/basicsimulation-1529382008914/index.html\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD SUCCESS\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 16.852 s\r\n[INFO] Finished at: 2018-06-19T06:20:17+02:00\r\n[INFO] ------------------------------------------------------------------------\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT94", "user": "kieferrm", "root": "ROOT94", "reply_to": null, "timestamp": "2020-07-14T17:01:02Z", "text": "Security Fix Details in https://portal.msrc.microsoft.com/en-us/security-guidance/advisory/CVE-2020-1416", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM940", "user": "MLefebvreICO", "root": "ROOT94", "reply_to": "ROOT94", "timestamp": "2020-07-14T18:21:45Z", "text": "Just received update `1.47.1` linking to this issue, but it doesn't have details \ud83d\ude10 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM941", "user": "kieferrm", "root": "ROOT94", "reply_to": "COM940", "timestamp": "2020-07-14T18:22:40Z", "text": "I updated the link. The MITRE copy is not yet updated.", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM942", "user": "aaomidi", "root": "ROOT94", "reply_to": "COM941", "timestamp": "2020-07-14T22:14:30Z", "text": "The link currently just goes to this milestone (https://github.com/microsoft/vscode/milestone/128), is that expected?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM943", "user": "vp2177", "root": "ROOT94", "reply_to": "COM942", "timestamp": "2020-07-14T22:26:39Z", "text": "\r\n\r\n\r\n> Details in https://portal.msrc.microsoft.com/en-us/security-guidance/advisory/CVE-2020-1416\r\n\r\nThat page is currently empty, so is https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1416\r\n\r\nHowever, if anyone is wondering, just google (_bing_?) the CVE number.\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM944", "user": "jlk", "root": "ROOT94", "reply_to": "COM943", "timestamp": "2020-07-15T00:18:34Z", "text": "The milestone page is \"empty,\" but if you click \"closed\" you'll see it. Probably should tweak the link to show closed issues.", "meta": {"posReactions": "15", "negReactions": "0"}}
{"id": "COM945", "user": "wwahammy", "root": "ROOT94", "reply_to": "COM944", "timestamp": "2020-07-15T16:40:19Z", "text": "Is there a commit/PR we can see fixing this bug? It's not super helpful to know a CVE existed if we can't verify that it was fixed properly.", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM946", "user": "ExE-Boss", "root": "ROOT94", "reply_to": "COM945", "timestamp": "2020-07-15T20:04:35Z", "text": "@wwahammy It\u00a0seems\u00a0like the\u00a0bug\u00a0was [in\u00a0the\u00a0closed\u00a0source `vscode\u2011distro`\u00a0component](https://github.com/microsoft/vscode/wiki/Differences-between-the-repository-and-Visual-Studio-Code): https://github.com/microsoft/vscode/compare/1.47.0...1.47.1.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM947", "user": "wwahammy", "root": "ROOT94", "reply_to": "COM946", "timestamp": "2020-07-15T20:26:55Z", "text": "Ah, so there's some proprietary software that VSCode uses that apparently does something which can lead to a security hole. We don't know what it does or how risky it is to run.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM948", "user": "mahen23", "root": "ROOT94", "reply_to": "COM947", "timestamp": "2020-07-16T10:22:05Z", "text": "This is the kind of coding quality we get when corporations prioritizes employee diversity over code quality ", "meta": {"posReactions": "0", "negReactions": "21"}}
{"id": "COM949", "user": "jlk", "root": "ROOT94", "reply_to": "COM948", "timestamp": "2020-07-16T13:59:45Z", "text": "A thumbs down isn't enough on this one. There's zero tolerance for backwater attitude @mahen23. Reporting.", "meta": {"posReactions": "8", "negReactions": "0"}}
{"id": "ROOT95", "user": "kpetrow", "root": "ROOT95", "reply_to": null, "timestamp": "2019-11-06T21:36:20Z", "text": "BUG: MeshPhongMaterial flicker with flatShading: false Updated from v92 to v110 and have flicker on the edges.  I use PlaneBufferGeometry with null z values to represent unknown elevations(holes).  The sparse grid shows a flicker where the nulls' edges are.  Was not seen with flatShading: true or v92:\r \r ![image](https://user-images.githubusercontent.com/18248938/68339808-812af700-00a2-11ea-8f01-ec761d009580.png)\r \r I know you are going to say NaN are not supported in geometries, but any chance you could fix this or point me in proper direction?\r \r \r ##### Three.js version\r \r - [ ] Dev\r - [x ] r110\r - [ ] ...\r \r ##### Browser\r \r - [x] All of them\r - [ ] Chrome\r - [ ] Firefox\r - [ ] Internet Explorer\r \r ##### OS\r \r - [ ] All of them\r - [x] Windows\r - [ ] macOS\r - [ ] Linux\r - [ ] Android\r - [ ] iOS\r \r ##### Hardware Requirements (graphics card, VR Device, ...)\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM950", "user": "kpetrow", "root": "ROOT95", "reply_to": "ROOT95", "timestamp": "2019-11-06T21:59:27Z", "text": "Its something that occurred between 103 and 104.  103 works, 104 flickers.... Looking at change log", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM951", "user": "Mugen87", "root": "ROOT95", "reply_to": "COM950", "timestamp": "2019-11-07T11:06:42Z", "text": "I'm afraid a screenshot is not sufficient to debug this issue. Please always provide live examples when reporting such problems.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM952", "user": "kpetrow", "root": "ROOT95", "reply_to": "COM951", "timestamp": "2019-11-07T14:28:39Z", "text": "thank you for your help;  Flicker is seen when not moving.\r\n\r\nhttps://jsfiddle.net/b4xzmqcr/\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM953", "user": "kpetrow", "root": "ROOT95", "reply_to": "COM952", "timestamp": "2019-11-07T15:00:14Z", "text": "The issue gets worse when multiple 3js windows are open and active(open the fiddle in 2 windows).  Also noticeably when \"lightShot\" screen capture was opened.  Also noticed when whats app message received.  I have a dev team of 4 guys finding inconsistencies of producing on different graphics cards with different results, but all see a flicker at different times", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM954", "user": "Mugen87", "root": "ROOT95", "reply_to": "COM953", "timestamp": "2019-11-07T15:30:56Z", "text": "Sorry, but I can't see any flickering on my system. Tested with Chrome 78.0.3904.97, FF 70.0.1 and macOS 0.14.6. Are you on Windows?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM955", "user": "kpetrow", "root": "ROOT95", "reply_to": "COM954", "timestamp": "2019-11-07T16:00:01Z", "text": "video: Multiple instances of the window seem to be the issue, even with duplicate fiddles it appears.\r\n\r\n[here](https://drive.google.com/open?id=1zgscsAoXE1DNdWyIW1qORhXgatCRhKL1)\r\n\r\nwindows version 1809 OS Build 17763.805\r\nNVIDIA GeForce RTX 2080 SUPER\r\n\r\nI have also tested on msi lapiop with NVIDIA GeForce GTX 980M and the problem is probably worse.\r\n\r\nAll other devs have windows machines, but we could check on a mac if that helps\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM956", "user": "arpu", "root": "ROOT95", "reply_to": "COM955", "timestamp": "2019-11-07T16:27:41Z", "text": "looks like a Problem with the nvideo driver?  i tested this on two Systems, with amd driver (linux) without any problem \r\n\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM957", "user": "kpetrow", "root": "ROOT95", "reply_to": "COM956", "timestamp": "2019-11-07T16:47:40Z", "text": "I haven't gone through the diff of 103-104, but ideas on where to look that would make this happen?\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM958", "user": "sciecode", "root": "ROOT95", "reply_to": "COM957", "timestamp": "2019-11-07T17:18:08Z", "text": "Was able to replicate on Windows with NVidia GPU, but not on Mac with intel integrated GPU. \r\n\r\nCouldn't find anything on the change logs from `r103 -> r104` that would explain that. \r\n\r\nBut, then again, you are making use of unsupported behavior, as you said it yourself.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM959", "user": "kpetrow", "root": "ROOT95", "reply_to": "COM958", "timestamp": "2019-11-07T17:35:41Z", "text": "Seems very odd that separate instances of three are causing it.  Even though unsupported seems like it could be a canary for a scoping issue?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9510", "user": "makc", "root": "ROOT95", "reply_to": "COM959", "timestamp": "2019-11-08T06:02:51Z", "text": "why not just map NaNs to some big but finite values to move the triangles out of the view. that would mean removing the index attribute as well, however (rough idea: https://jsfiddle.net/uxwqyjvm/ )", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9511", "user": "Mugen87", "root": "ROOT95", "reply_to": "COM9510", "timestamp": "2019-11-08T11:25:20Z", "text": "In any event, I don't see a `three.js` bug here. I suppose this happens also with pure WebGL and with any other 3D engine so I think it's more correct to close the issue and move the dicussion to stackoverflow or the forum.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9512", "user": "kpetrow", "root": "ROOT95", "reply_to": "COM9511", "timestamp": "2019-11-08T13:08:08Z", "text": "@makc We are constantly updating the surface with new known position.  Might be worth testing but would take a considerable amount of work.  If anything this would double the overhead(two geometries needed) of multi-million point grid geometries.  Do you have any docs for ExplodeModifier?  Also we have to have bufferGeometry.  These are very large surface models.\r\n\r\n@Mugen87 I do not think that is true because the issue is not seen in r103.  There was a change in the code base that introduced this bug.  If it never worked, then i would agree it is a  webGL/GPU issue, but it was working up to r103 and we have it in production at r92 for a pretty long time(since r92 release)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9513", "user": "kpetrow", "root": "ROOT95", "reply_to": "COM9512", "timestamp": "2019-11-08T14:37:30Z", "text": "So there were two shader changes in the revision in the build.  \r\nEDIT\r\n\r\nsingle change then adding that change in so this is messing it up.\r\nsorry my github skills suck , we are svn:\r\n\r\nit is here in light_pars_begin lines 1-40:\r\n```\r\n\r\nexport default /* glsl */`\r\nuniform vec3 ambientLightColor;\r\nuniform vec3 lightProbe[ 9 ];\r\n// get the irradiance (radiance convolved with cosine lobe) at the point 'normal' on the unit sphere\r\n// source: https://graphics.stanford.edu/papers/envmap/envmap.pdf\r\nvec3 shGetIrradianceAt( in vec3 normal, in vec3 shCoefficients[ 9 ] ) {\r\n\t// normal is assumed to have unit length\r\n\tfloat x = normal.x, y = normal.y, z = normal.z;\r\n\t// band 0\r\n\tvec3 result = shCoefficients[ 0 ] * 0.886227;\r\n\t// band 1\r\n\tresult += shCoefficients[ 1 ] * 2.0 * 0.511664 * y;\r\n\tresult += shCoefficients[ 2 ] * 2.0 * 0.511664 * z;\r\n\tresult += shCoefficients[ 3 ] * 2.0 * 0.511664 * x;\r\n\t// band 2\r\n\tresult += shCoefficients[ 4 ] * 2.0 * 0.429043 * x * y;\r\n\tresult += shCoefficients[ 5 ] * 2.0 * 0.429043 * y * z;\r\n\tresult += shCoefficients[ 6 ] * ( 0.743125 * z * z - 0.247708 );\r\n\tresult += shCoefficients[ 7 ] * 2.0 * 0.429043 * x * z;\r\n\tresult += shCoefficients[ 8 ] * 0.429043 * ( x * x - y * y );\r\n\treturn result;\r\n}\r\nvec3 getLightProbeIrradiance( const in vec3 lightProbe[ 9 ], const in GeometricContext geometry ) {\r\n\tvec3 worldNormal = inverseTransformDirection( geometry.normal, viewMatrix );\r\n\tvec3 irradiance = shGetIrradianceAt( worldNormal, lightProbe );\r\n\treturn irradiance;\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9514", "user": "kpetrow", "root": "ROOT95", "reply_to": "COM9513", "timestamp": "2019-11-08T14:56:42Z", "text": "looks like probe light is causing this issue @WestLangley  @sciecode :\r\n\r\nAdded support for light probes. [#16223](https://github.com/mrdoob/three.js/pull/16223)\r\n\r\nEdit as i walk through for future refrence:\r\n1.  Light probe is part of ambient light so removing ambient light fixes the issue. \r\n2. light probe is a measure of ambient light not a child.  So no ambient light no light probe?\r\n3. Hemisphere lighting does not show flicker\r\n4. Hemisphere white light is super flickery\r\n5.  Looks like the more white the light the worse the flicker, equally bad on hemisphere and ambient.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9515", "user": "kpetrow", "root": "ROOT95", "reply_to": "COM9514", "timestamp": "2019-11-08T15:57:19Z", "text": "updated fiddle with super flicker:\r\nhttps://jsfiddle.net/sxjemofg/1/\r\n\r\nturn off ambient light for no flicker", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9516", "user": "kpetrow", "root": "ROOT95", "reply_to": "COM9515", "timestamp": "2019-11-08T16:51:14Z", "text": "RESOLVED\r\n\r\nfixed it.  Is this worth committing?  Someone who knows get and three should commit this \ud83d\udc4d @WestLangley \r\n@Mugen87 \r\n\r\n\r\n```\r\nvec3 shGetIrradianceAt( in vec3 normal, in vec3 shCoefficients[ 9 ] ) {\r\n\t// normal is assumed to have unit length\r\n\tfloat x = normal.x, y = normal.y, z = normal.z;\r\n\t// band 0\r\n\tvec3 result = shCoefficients[ 0 ] * 0.886227;\r\n\r\n      //FIX\r\n      // in webgl 2.0 this could be replaced with  isnan(val)\r\n      if(\r\n              (! ( x < 0.0 || x > 0.0 || x == 0.0 )) || \r\n              (! ( y < 0.0 || y > 0.0 || y == 0.0 )) || \r\n              (! ( z < 0.0 || z > 0.0 || z == 0.0 ))\r\n        ){ return result; };\r\n      // response from dev who helped fix this:\r\n      // \"it is a bug because they should always account for NaN \r\n      // whether it is intended or not ;)\"\r\n      //END FIX\r\n\r\n\t// band 1\r\n\tresult += shCoefficients[ 1 ] * 2.0 * 0.511664 * y;\r\n\tresult += shCoefficients[ 2 ] * 2.0 * 0.511664 * z;\r\n\tresult += shCoefficients[ 3 ] * 2.0 * 0.511664 * x;\r\n\t// band 2\r\n\tresult += shCoefficients[ 4 ] * 2.0 * 0.429043 * x * y;\r\n\tresult += shCoefficients[ 5 ] * 2.0 * 0.429043 * y * z;\r\n\tresult += shCoefficients[ 6 ] * ( 0.743125 * z * z - 0.247708 );\r\n\tresult += shCoefficients[ 7 ] * 2.0 * 0.429043 * x * z;\r\n\tresult += shCoefficients[ 8 ] * 0.429043 * ( x * x - y * y );\r\n\treturn result;\r\n}\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9517", "user": "WestLangley", "root": "ROOT95", "reply_to": "COM9516", "timestamp": "2019-11-08T17:09:10Z", "text": "> I use PlaneBufferGeometry with null z values to represent unknown elevations(holes). \r\n\r\nYou have NaN's in your position data.\r\n\r\nYou also have NaN's in your vertex normals. Hence their length is undefined.\r\n\r\nthree.js does not support NaNs in data pushed to the GPU.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9518", "user": "kpetrow", "root": "ROOT95", "reply_to": "COM9517", "timestamp": "2019-11-08T17:13:23Z", "text": "one should always account for NaN whether it is intended or not.  And its a simple fix.  We need this to work for our production and it doesnt harm anything having a check in.   Could we please add, is there any harm?  @WestLangley ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9519", "user": "WestLangley", "root": "ROOT95", "reply_to": "COM9518", "timestamp": "2019-11-08T17:25:42Z", "text": ">one should always account for NaN whether it is intended or not.\r\n\r\nNo, YOU need to account for it in your app and pass valid data.\r\n\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM9520", "user": "Mugen87", "root": "ROOT95", "reply_to": "COM9519", "timestamp": "2019-11-08T17:37:44Z", "text": "Yes, this is something that needs to be fixed on app level.\r\n\r\n> three.js does not support NaNs in data pushed to the GPU.\r\n\r\nNaN geometry data also corrupt operations on the CPU like intersection tests or the computation of bounding volumes. So again, this is no library bug.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9521", "user": "kpetrow", "root": "ROOT95", "reply_to": "COM9520", "timestamp": "2019-11-08T17:48:06Z", "text": "We have a valid use case for putting NaN's in our data set that as far as I can tell can not be done in any other way, efficiently.  In any real world application dealing with NaN's is just a fact of life .\r\n\r\n@Mugen87 Bounding Volumes was actually my last post.  It all stems from not handling NaN's properly.  Just a simple test for isNaN would resolve most these.  Why is there such push back and not a desire to resolve this issue?\r\n\r\nAre there any suggestions for dealing with real world data that has NaN's?  We have bandied around alpha mapping, but then we increase overhead with the map and need to access the alpha map and the vertex positions.  \r\n\r\nAlso what if the numbers are very large and overflows?  Will that cause a NaN that might need to be dealt with.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9522", "user": "Mugen87", "root": "ROOT95", "reply_to": "COM9521", "timestamp": "2019-11-08T17:58:42Z", "text": "> Why is there such push back and not a desire to resolve this issue?\r\n\r\n`NaN` values is an app level problem from our point of view since the user is in some sense the data producer. Geometric data like position, normal or color data are meant to be numerical. `NaN` data are no numerical data.\r\n\r\nHandling `NaN` values is use case specific since proper default values depend on what the application actually does.\r\n\r\nThis is not only an issue in graphics. When you process huge data in context of KDD and machine learning, data cleanup is one important preparation step before you execute the actual algorithm (which is not responsible for handling missing, undefined or corrupt values).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9523", "user": "kpetrow", "root": "ROOT95", "reply_to": "COM9522", "timestamp": "2019-11-08T18:13:55Z", "text": "so this is a \"no\" on resolving?  Is there a reason not to other than \"we don't support this\"?  Its a one line PR.\r\n\r\nI guess we will be patching every update from here out.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9524", "user": "WestLangley", "root": "ROOT95", "reply_to": "COM9523", "timestamp": "2019-11-08T18:17:37Z", "text": "three.js does not validate data -- much less accommodate invalid data. That is the app's responsibility.\r\n\r\nAlso, your patch accommodates your use case, but it does not accommodate an arbitrary use case with invalid data. So, your patch is not a \"fix\".", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9525", "user": "WestLangley", "root": "ROOT95", "reply_to": "COM9524", "timestamp": "2019-11-08T18:20:48Z", "text": ">I guess we will be patching every update from here out.\r\n\r\nOne way to handle your examples is to add an \"invalid\" attribute: 0 if valid; 1 if invalid. Then discard fragments for which the interpolated attribute value is non-zero.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM9526", "user": "kpetrow", "root": "ROOT95", "reply_to": "COM9525", "timestamp": "2019-11-08T18:28:52Z", "text": "> Also, your patch accommodates your use case, but it does not accommodate an arbitrary use case with invalid data. So, your patch is not a \"fix\".\r\n\r\n what case would it not fix?  It fixes unknowns in position array from flickering. Could I add a switch to turn off probe lighting?\r\n\r\n> One way to handle your examples is to add an \"invalid\" attribute: 0 if valid; 1 if invalid. Then discard fragments for which the interpolated attribute value is non-zero.\r\n\r\nWhere woudl you implement this.  Seems alot like an alpha map but culling vertices else where?\r\n\r\nEdit: thanks for the help.  \r\n\r\n> three.js does not validate data -- much less accommodate invalid data. That is the app's responsibility.\r\n\r\nits semantics(and not my project)  but in my mind \"unknown\" != \"invalid\". ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9527", "user": "WestLangley", "root": "ROOT95", "reply_to": "COM9526", "timestamp": "2019-11-08T18:57:12Z", "text": "My [suggestion](https://github.com/mrdoob/three.js/issues/17882#issuecomment-551936446) is similar to alpha-testing and would require injecting code into the fragment shader. Without knowing the details of your use case, I can only offer it as a suggestion.\r\n\r\nPlease use the three.js forum if you need additional help.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9528", "user": "mrdoob", "root": "ROOT95", "reply_to": "COM9527", "timestamp": "2019-11-08T21:21:42Z", "text": "@kpetrow \r\n\r\n> Just a simple test for isNaN would resolve most these. Why is there such push back and not a desire to resolve this issue?\r\n\r\nYou may have more luck by doing a PR with that \"simple test\" rather than asking us to do it for you.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9529", "user": "makc", "root": "ROOT95", "reply_to": "COM9528", "timestamp": "2019-11-09T01:17:21Z", "text": "@kpetrow,\r\n> two geometries needed... ExplodeModifier\r\n\r\nof course you could just create un-indexed buffer geometry to begin with, and not use ExplodeModifier or convert geometries otherwise.\r\n\r\n> RESOLVED... Is this worth committing?\r\n\r\nwell, you know, a bunch of IF-s in the shader that almost noone would need any way... so, probably not.\r\n\r\n> updated fiddle with super flicker\r\n\r\nno flicker here at all", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "ROOT96", "user": "kzu", "root": "ROOT96", "reply_to": null, "timestamp": "2019-10-04T15:02:23Z", "text": "Include Ctrl+C, Ctrl+V keybindings by default I've read the other \"copy not working\" bugs and the universal suggestion seems to be \"just create your own keybinding\".\r \r It's quite puzzling for a *Windows* terminal to not come with the most commonly used *Windows* shortcuts ever. \r \r I'd suggest these two are added to the product, and people can instead *change* (or remove them) if they wish. I guess that's a much more intuitive default.\r \r For others wondering why they are missing, just add these two to your keybindings:\r \r ```\r { \"command\": \"copy\", \"keys\": [\"ctrl+c\"] },\r { \"command\": \"paste\", \"keys\": [\"ctrl+v\"] },\r ```\r \r Just to add to the discussion: the built-in Terminal in VS Code supports this out of the box too, which is awesome. ", "meta": {"posReactions": "39", "negReactions": "12"}}
{"id": "COM960", "user": "KirillOsenkov", "root": "ROOT96", "reply_to": "ROOT96", "timestamp": "2019-10-04T17:58:28Z", "text": "cmd.exe didn't support these for years and finally added them quite recently. Even more puzzling to have these missing in the new one.", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM961", "user": "ealsur", "root": "ROOT96", "reply_to": "COM960", "timestamp": "2019-10-04T18:50:50Z", "text": "Copy and Paste was added in 0.3, if you installed 0.3 (or later), they were there by default. If you upgraded to 0.3, you needed to add them manually: https://devblogs.microsoft.com/commandline/windows-terminal-preview-v0-3-release/\r\n\r\n![image](https://user-images.githubusercontent.com/1633401/66232216-34b45c00-e69d-11e9-83b1-7ed2e467b6c5.png)\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM962", "user": "pedroreys", "root": "ROOT96", "reply_to": "COM961", "timestamp": "2019-10-04T19:05:41Z", "text": "For the curious,  [here is the PR](https://github.com/microsoft/terminal/pull/1093) where they added the default keybindings for copy and paste and they discuss the challenges of using `Ctrl+C` by default.\r\n\r\nThere is also #2285 that has extensive discussion about using Ctrl+C for copy vs emitting SIGINT.\r\n", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM963", "user": "bradwilson", "root": "ROOT96", "reply_to": "COM962", "timestamp": "2019-10-04T20:57:15Z", "text": "Please don't do this. Ctrl+C already has meaning inside terminals that long outdates copy/paste.", "meta": {"posReactions": "19", "negReactions": "1"}}
{"id": "COM964", "user": "DHowett-MSFT", "root": "ROOT96", "reply_to": "COM963", "timestamp": "2019-10-04T20:59:42Z", "text": "> Even more puzzling to have these missing in the new one.\r\n\r\n> Please don't do this. Ctrl+C already has meaning inside terminals that long outdates copy/paste.\r\n\r\nThis is a delightful vignette about why we have rebindable key actions, and why we don't want to be prescriptive with user experience where \"terminal input\" is concerned.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM965", "user": "DHowett-MSFT", "root": "ROOT96", "reply_to": "COM964", "timestamp": "2019-10-07T23:20:24Z", "text": "We can 100% bind <kbd>Ctrl+C</kbd> by default, now that we have support for passing through bindings that didn't trigger an action. We can **100% not** bind <kbd>Ctrl+V</kbd> by default.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM966", "user": "KirillOsenkov", "root": "ROOT96", "reply_to": "COM965", "timestamp": "2019-10-08T00:20:02Z", "text": "I know `Ctrl+C` cancels the current execution, but what does `Ctrl+V` do? Out of curiosity.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM967", "user": "bradwilson", "root": "ROOT96", "reply_to": "COM966", "timestamp": "2019-10-08T03:21:27Z", "text": "@KirillOsenkov https://superuser.com/a/421468", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM968", "user": "sgreenmsft", "root": "ROOT96", "reply_to": "COM967", "timestamp": "2019-10-10T21:18:04Z", "text": "My (admittedly uneducated) guess is the percentage of users expecting Ctrl+V to result in paste is substantially larger than the percentage of users expecting Ctrl+V to result in \"verbatim insert mode.\"", "meta": {"posReactions": "11", "negReactions": "4"}}
{"id": "COM969", "user": "impguard", "root": "ROOT96", "reply_to": "COM968", "timestamp": "2019-11-07T04:57:16Z", "text": "@sgreenmsft \r\n\r\nTo be honest, for users used to using Terminal from Linux, Ubuntu, OSX, etc. I don't expect ctrl-V to paste. And seeing how a lot of the purpose of terminal is geared in that direction (to finally have Windows be able to start having a culture around working in the terminal instead of in GUI apps, catering towards those users seems preferable).", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM9610", "user": "sgreenmsft", "root": "ROOT96", "reply_to": "COM969", "timestamp": "2019-11-07T18:31:23Z", "text": "@impguard \r\nI honestly don't know how frequently verbatim insert mode is used by folks in linux/osx.  My uneducated guess is \"very infrequently.\"  On the other hand, I suspect Ctrl+V is used quite frequently by folks familiar with cmd.exe and PowerShell.  If my uneducated assumptions are accurate, then having Ctrl+V perform paste makes the experience significantly better for Windows-background users at minimal cost to Linux/OSX-background users.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9611", "user": "durack1", "root": "ROOT96", "reply_to": "COM9610", "timestamp": "2019-11-24T21:21:36Z", "text": "I am new to Microsoft terminal (v0.6.2951.0) and am starting to warm up to the idea of having access to powershell, cmd, ubuntu/wsl and azure cloud shell baked directly into a native Windows 10 app.\r\n\r\nBUT, I was pulling my hair out today trying to copy the contents of a Ubuntu console, and would have assumed this functionality was baked in by default to a modern Win10 app. I acknowledge the ctrl-c issues above, but why not enable the copy functionality through a right mouse click, like that implemented in the more modern cmd versions? If you open cmd using Windows terminal there is no right click options enabled, whereas using the old cmd you get:\r\n![image](https://user-images.githubusercontent.com/3229632/69501798-3f30ec00-0ebd-11ea-97ce-f12331226c54.png)\r\n\r\nIt'd be great if a future version of Windows Terminal baked this in by default across all shells - it's really useful to have", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM9612", "user": "wleepang", "root": "ROOT96", "reply_to": "COM9611", "timestamp": "2019-12-29T20:53:20Z", "text": "I'm using Version: 0.5.2762.0, and was tripped up by this today.  While I agree that a mapping of \"copy\" => Ctrl+C is understood as the Windows default, it will also cause confusion with Linux based terminal applications.  My solution for now is to map:\r\n\r\n```json\r\n{\"command\": \"copy\", \"keys\": [\"ctrl+insert\"]},\r\n{\"command\": \"paste\", \"keys\": [\"ctrl+shift+insert\"]},\r\n```\r\n\r\nI've seen this mapping used before as an alternative.\r\n\r\nThat said, I originally wanted to use:\r\n\r\n```json\r\n{\"command\": \"copy\", \"keys\": [\"win+c\"]},\r\n{\"command\": \"paste\", \"keys\": [\"win+v\"]},\r\n```\r\n\r\nwhich maps to the muscle memory I've built using MacOS, however the linter in VSCode told me only `ctrl|shift|alt` are acceptable modifier keys.  Is there a way to allow the `win` key to be a modifier as well for custom key bindings?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9613", "user": "gdamore", "root": "ROOT96", "reply_to": "COM9612", "timestamp": "2020-01-18T19:45:19Z", "text": "I feel pretty strongly about this -- I'm a UNIX user (also the author of the popular tcell package for building console interface apps in Golang), and understand the need to separate copy from delivering the control-c to the application.  There are challenging trade-offs here.\r\n\r\nHowever, I really liked legacy conhost's solution to this -- if I have text selected, then Ctrl-C is copy just like windows.  And Ctrl-V is paste.  If I have no selected text, then CTRL-C is passed through to the application.  IMO, these should be the default settings.  They should be customizable, in case a user wants to change them.\r\n\r\n(On macOS its CMD-C and CMD-V, and I've bound those for Windows Terminal, but what really messes me up is that in every *other* app on Windows its CTRL. )\r\n\r\nTo be honest what I really wish is that I could change the rest of Windows to use ALT-C and ALT-V (or META-C and META-V) for copy/paste, which would not collide with most other uses but keep the control bindings available for terminal windows.  I do understand why that's not practical -- given the fact that each application manages it's own key bindings.\r\n\r\nAnother possible solution is to offer some extra modifier (e.g. SHIFT-CTRL-) that would send the control sequence to the application running in the window.  Even as a UNIX user, I know for a fact that I use CTRL-C and CTRL-V occasionally in the terminal to control my apps, but far less frequently than I use copy-paste.   So I'd prefer to require keyboard-twister in the uncommon case, and be able to use copy-paste like I do everywhere else by default.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM9614", "user": "kzu", "root": "ROOT96", "reply_to": "COM9613", "timestamp": "2020-01-29T21:46:42Z", "text": "Totally agree on making this \"smart\" depending on whether there's a selection at all. \r\n\r\nBTW, this is *exactly* how the integrated terminal in VS Code behaves, which is awesome.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9615", "user": "DHowett-MSFT", "root": "ROOT96", "reply_to": "COM9614", "timestamp": "2020-01-29T21:47:18Z", "text": "If you bind <kbd>Ctrl+C</kbd>, it will be \"smart\". There is no way to make <kbd>Ctrl+V</kbd> smart.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9616", "user": "kzu", "root": "ROOT96", "reply_to": "COM9615", "timestamp": "2020-01-29T22:05:34Z", "text": "If it will be \"smart\" already, then it's even more puzzling why this isn't already bound by default (again, as it is in VS Code terminal, where I think people seem to be mostly happy with it)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9617", "user": "KirillOsenkov", "root": "ROOT96", "reply_to": "COM9616", "timestamp": "2020-01-29T22:10:22Z", "text": "I'm curious if we have any data or telemetry to indicate what percentage of users prefer Ctrl+C and Ctrl+V to copy/paste. My intuition tells me it'll be the majority. Curious how many people turn on QuickEdit mode in cmd.exe.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9618", "user": "regs01", "root": "ROOT96", "reply_to": "COM9617", "timestamp": "2020-02-03T15:05:38Z", "text": "The same way as powershell, ctrl+c should copy if anything selected and break if nothing selected. Even cmd have it - Enter to copy if there is any selection and execute if there is no selection. Though Enter never been really convenient.\r\n\r\nThere is specifically Break button to enforce break of execution in case of emergency, if there is selection.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9619", "user": "eidylon", "root": "ROOT96", "reply_to": "COM9618", "timestamp": "2020-02-16T16:47:52Z", "text": "> \r\n> \r\n> Please don't do this. Ctrl+C already has meaning inside terminals that long outdates copy/paste.\r\n\r\nI would've expected that the shells hosted by Terminal would interpret the keystrokes. So since CTRL+C/CTRL+V were recently added to cmd.exe, I would've expected them to be passed down the shell and work as expected. \r\n\r\nIf you are using a different shell (PowerShell, Bash, etc), then I would expect they should be passed down to that shell for it to interpret as expected. \r\n\r\nI find it odd that Terminal is interpreting these keys instead of the shell currently in use. I would only expect Terminal to try to interpret any keys you have defined in the key-bindings. Otherwise yeah, they should just be interpreted by the shell in use, so as to provide consistency with what people expect in each shell.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM9620", "user": "shtirlic", "root": "ROOT96", "reply_to": "COM9619", "timestamp": "2020-03-05T16:53:28Z", "text": "Hi there, while `win+c` is working great, `win+v` does not, I disabled `win+v` shortcut in Explorer registry section since` win+v` is special paste in Windows now, but terminal does not respond to` win+v`\r\n```json\r\n    {\r\n      \"command\": \"copy\",\r\n      \"keys\": [ \"win+c\" ]\r\n    },\r\n    {\r\n      \"command\": \"paste\",\r\n      \"keys\": [ \"win+v\" ]\r\n    },\r\n\r\n``` \r\n\r\nSo my goal to mimic cmd+c and cmd+v behavior, and it's  99% ready, the only thing left  is just `win+v` handling with windows terminal", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9621", "user": "DHowett-MSFT", "root": "ROOT96", "reply_to": "COM9620", "timestamp": "2020-03-05T18:17:57Z", "text": "@shtirlic this isn't the right issue for your comment; this issue is for <kbd>ctrl</kbd>.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9622", "user": "randomascii", "root": "ROOT96", "reply_to": "COM9621", "timestamp": "2020-03-28T00:12:24Z", "text": "I don't understand why Windows Terminal Preview is favoring Xterm/Gnome compatibility over cmd.exe compatibility, especially for Ctrl+V. I think that will add frustration and will slow adoption from Windows users. But, I tried the recommended bindings to make it work. After reading the documentation I found where to put the recommended snippet (in the global section, in a \"keybindings\" array, but it is also important to notice the existing keybindings array, because if you paste a new one at then it gets overwritten by the empty array at the bottom. Yay .json!\r\n\r\nAnyway, paste this in over the empty keybindings array at the bottom:\r\n\r\n  \"keybindings\": [\r\n    {\r\n      \"command\": \"copy\",\r\n      \"keys\": [ \"ctrl+c\" ]\r\n    },\r\n    {\r\n      \"command\": \"paste\",\r\n      \"keys\": [ \"ctrl+v\" ]\r\n    }\r\n  ],\r\n\r\nAnd please consider favoring Windows compatibility, at least for Ctrl+V. Or make it easier to enable instead of requiring editing of error-prone .json files.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM9623", "user": "msftbot[bot]", "root": "ROOT96", "reply_to": "COM9622", "timestamp": "2020-04-22T17:15:57Z", "text": ":tada:This issue was addressed in #5217, which has now been successfully released as `Windows Terminal Preview v0.11.1121.0`.:tada:\n\nHandy links:\n* [Release Notes](https://github.com/microsoft/terminal/releases/tag/v0.11.1121.0)\n* [Store Download](https://www.microsoft.com/store/apps/9n0dx20hk701?cid=storebadge&ocid=badge)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9624", "user": "vadimkantorov", "root": "ROOT96", "reply_to": "COM9623", "timestamp": "2020-04-27T09:44:38Z", "text": "Given that \"Ctrl+C\" is now default copy keybinding on new installations. how will standard \"Ctrl+C\" for SIGINT work?\r\n\r\nImagine a long-running console program with some text selected and Ctrl+C typed. What will Windows Terminal do? Copy? Interrupt the program? Both? @carlos-zamora ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9625", "user": "zadjii-msft", "root": "ROOT96", "reply_to": "COM9624", "timestamp": "2020-04-27T13:48:55Z", "text": "* If the user is using the new keybindings:\r\n  - If text is selected: <kbd>Ctrl+c</kbd> will copy the selected text.\r\n  - If text is **NOT** selected: <kbd>Ctrl+c</kbd> will send a interrupt, the same way <kbd>Ctrl+c</kbd> usually behaves.\r\n\r\nIf the user doesn't like that behavior, it's pretty trivial to remove the new <kbd>Ctrl+c</kbd> binding from their `settings.json`, and rely on the <kbd>Ctrl+shift+c</kbd> binding that's in `defaults.json`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9626", "user": "randomascii", "root": "ROOT96", "reply_to": "COM9625", "timestamp": "2020-04-27T15:38:05Z", "text": "Does Enter now copy text by default? I realized when switching from cmd.exe to the new terminal that I use that to copy text a lot. I'm not sure if there is any significant disadvantage to making that the default, and it seems that the new terminal should, where possible, ease the transition from cmd.exe.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9627", "user": "zadjii-msft", "root": "ROOT96", "reply_to": "COM9626", "timestamp": "2020-04-27T17:00:23Z", "text": "@randomascii nope, but that is a lot less common of a scenario for our users then <kbd>Ctrl+C</kbd> for copy. There's a balance we need to strike between \"keeping the old behavior of conhost\" and \"making space to create a better experience\". For those of our users who actually do want copy on enter, adding it isn't terribly difficult:\r\n\r\n```json\r\n        { \"command\": \"copy\", \"keys\": [\"enter\"] },\r\n```\r\n\r\nbut I'd bet most people weren't even aware that feature existed in the original conhost \ud83d\ude06 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9628", "user": "rbreaves", "root": "ROOT96", "reply_to": "COM9627", "timestamp": "2020-05-31T05:21:52Z", "text": " \r\n> To be honest what I really wish is that I could change the rest of Windows to use ALT-C and ALT-V (or META-C and META-V) for copy/paste, which would not collide with most other uses but keep the control bindings available for terminal windows. I do understand why that's not practical -- given the fact that each application manages it's own key bindings.\r\n\r\n@gdamore What you\u2019ve suggested is actually the most practical thing in this thread. Checkout my https://github.com/rbreaves/kinto project.\r\n\r\n@kzu", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9629", "user": "stewSquared", "root": "ROOT96", "reply_to": "COM9628", "timestamp": "2020-06-27T15:17:53Z", "text": "Okay great. Now how do we disable this?\r\n\r\n-- sad linux user\r\n\r\nEdit: Nevermind. Found it in settings.json and deleted it.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "ROOT97", "user": "lll000111", "root": "ROOT97", "reply_to": null, "timestamp": "2019-07-20T10:43:52Z", "text": "Array.isArray refinement loses the array's type I realize there are  a number of related issues. However, some where about ReadonlyArray, some didn't see directly related at all even though it was pointed there.\r \r Also, this is a much smaller example, just a single line of code really:\r \r [Playground link](http://www.typescriptlang.org/play/index.html#code/GYVwdgxgLglg9mABAEwKYFs4AoZQFyICSUqATgIYBGANqgDxgjqVkB8AlAY82QNoC6iAN4AoROMQQEAZyiJypCgE9EAXkQBBReSUA6GNK3KcUdogD8iXIgK9d93PwDcIsRID07xABFU1GCwUJFy6tGAA5lAAFlbS8oiypDARiOio0XDIADSIlCByYHCIZKRwpLmoEOQg0qiIcMCIUEoADnUARORgSu2IwGWIYG7ipOkgpEgKyrro5C1YSKqsg6GoEdHsLgC+IkA)\r \r ```js\r function demo(it: Iterable<number>): number[] {\r     // THIS LINE: \"array\" is any[]\r     const array = Array.isArray(it) ? it : [...it];\r     // Deliberate: n.length is a string method, but no error because of type \"any\" for n\r     return array.map(n => n.length);\r }\r ```\r \r I know people will point to this ir that implementation or design decision detail &mdash; honestly guys, you got it REVERSED. The tool should serve the purpose, not the other way around!\r \r That the array loses all it's type information in such a simple example is A BUG.\r \r And **it is possible** to do much better: [See here!](https://flow.org/try/#0GYVwdgxgLglg9mABAEwKYFs4AoZQFyICSUqATgIYBGANqgDxgjqVkB8AlAY82QNoC6iAN4AoROMQQEAZyiJypCgE9EAXkQBBReSUA6GNK3KcUdogD8iXIgK9d93PwDcYiQHo3iACKpqMFhQkXLq0YADmUAAWVtLyiLKkMOGI6KhRcMgANIiUIHJgcIhkpHCkOagQ5CDSqIhwwIhQSgAOtQBE5GBKbYjApYhgruKkaSCkSArKuujkzVhIqqwDIajhUewuAL4iQA) I'm only pointing this out because at times the responses sound like \"We tried everything but it is just not possible\" when the competition shows that it *is* actually quite possible.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM970", "user": "AnyhowStep", "root": "ROOT97", "reply_to": "ROOT97", "timestamp": "2019-07-20T11:38:55Z", "text": "As a workaround, add overloads to Array.isArray() using declaration merging?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM971", "user": "fatcerberus", "root": "ROOT97", "reply_to": "COM970", "timestamp": "2019-07-20T12:32:12Z", "text": "Don\u2019t underestimate how difficult things like this are from a theoretical perspective.  Humans are much better at figuring these things out than computers.\r\n\r\nIn the *general case*, the compiler can\u2019t safely deduce that `Generic1<number> \u2014> Generic2<number>` unless both are in the union to be narrowed, because the type parameter might be used for different purposes in both types.\r\n\r\nIn this *specific case*, though, adding an overload:\r\n```ts\r\nisArray<T>(x: Iterable<T>): x is Array<T>\r\n```\r\nwould likely suffice.  I suspect this is probably how Flow does it.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM972", "user": "fatcerberus", "root": "ROOT97", "reply_to": "COM971", "timestamp": "2019-07-20T12:48:10Z", "text": "Proof of concept:\r\n[Try in TS Playground](https://www.typescriptlang.org/play/#code/JYOwLgpgTgZghgYwgAgIJSnAngYQPYgDOYUArgmHlAFADe1yjywh6mWAPACoB8AFHCgBzAFzIAkpEwAjADYRuPAJRjBQ5oTQZsigNzUAvtWoxSICsALIAJhAC2ePsDBjJ0OHIUhSd6dGVi3r7QANoAusj0TMgIBMTIguzIALxa7AB0LGzYTmBKyAD8zGDIYiHpFc5h+tFQEGCkUCAJ2ljpdnAADnzNyTzIIOnyIEJgABZKuowA9NPI0FBUYgDkIMsaAz5+NEZAA)\r\n\r\n```ts\r\ninterface ArrayConstructor\r\n{\r\n    isArray<T>(arg: Iterable<T>): arg is Array<T>;\r\n}\r\n\r\nfunction demo(it: Iterable<number>): number[] {\r\n    const array = Array.isArray(it) ? it : [...it];\r\n    return array.map(n => n.length);  // error: 'n' is number\r\n}\r\n```\r\n\r\n---\r\n\r\nFor the record, the current declaration of `isArray` is:\r\n```ts\r\n    isArray(arg: any): arg is Array<any>;\r\n```\r\n\r\nI wonder if that can be improved.  I'll need to give that some thought and maybe I'll open a PR.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM973", "user": "lll000111", "root": "ROOT97", "reply_to": "COM972", "timestamp": "2019-07-20T12:59:23Z", "text": "> Don\u2019t underestimate how difficult things like this are from a theoretical perspective\r\n\r\nI don't. I too write code. And...?\r\n\r\nA problem is a problem. If you decide to solve it what's the point of saying in the middle \"okay now it's too difficult\". I trust that there are very capable people working on this project who will _find a way_. :-)\r\n", "meta": {"posReactions": "0", "negReactions": "5"}}
{"id": "COM974", "user": "fatcerberus", "root": "ROOT97", "reply_to": "COM973", "timestamp": "2019-07-20T13:09:32Z", "text": "> And...? :-)\r\n\r\nThen you should already know that things that *appear* trivial can, in fact, turn out to be intractable, and being combative about that helps no one.\r\n\r\nBut anyway, in this case TS indeed has a mechanism (overloads) that can solve the problem, see above.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM975", "user": "lll000111", "root": "ROOT97", "reply_to": "COM974", "timestamp": "2019-07-20T13:16:49Z", "text": "> and being combative about that helps no one.\r\n\r\nSo _why are you_ being combative? Please check a mirror. Did you a) (only) respond to the issue, or did you b) choose to unnecessarily attack my experience? Not to mention that half of your first response was about something I had already covered in my initial post.\r\n\r\nAlso, I know the problem can be solved. So your point is? If a problem can be solved using \"obvious methods\" it does not have to be actually done (no need to report the issue))? Are you a mathematician? The theoretical solution is enough, \"I'll leave it to the reader to complete this trivial proof for themselves\"?\r\n", "meta": {"posReactions": "0", "negReactions": "8"}}
{"id": "COM976", "user": "kitsonk", "root": "ROOT97", "reply_to": "COM975", "timestamp": "2019-07-21T09:13:02Z", "text": "> So why are you being combative?\r\n\r\nSo feels like it is the other way around to me. \ud83e\udd37\u200d\u2642 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM977", "user": "RyanCavanaugh", "root": "ROOT97", "reply_to": "COM976", "timestamp": "2019-07-22T19:56:32Z", "text": "@lll000111 your attitude here makes my day measurably worse. Lots of people here manage to be constructive and positive and I'd appreciate your effort in not starting fights with us or other contributors. I've asked you to do this once already and am not going to ask a third time - if you continue to be combative to people just trying to help, we'll be asking you to discontinue your engagement on the issue tracker.\r\n\r\nTurning to the issue at hand, I think we need to figure out what the right solution is relative to #17002. In that issue (`Array.isArray` and `ReadOnlyArray<T>`), it seemed like the preference from people was that narrowing e.g. `string | ReadonlyArray<number>` with `isArray` should yield `ReadonlyArray<number>`. not `Array<number>`.\r\n\r\nIt'd be confusing if `string | Iterable<number>` narrowed to `Iterable<number>` but narrowing `Iterable<number>` produced `Array<number>` - the `isArray` type guard should uniformly either produce a subtype or filter a union, not do one or the other depending on whether the argument type has some unrelated (e.g. known-`false`-returning) union constituents.\r\n\r\nAlso an open question: surely it's not *just* `Iterable` and `ReadonlyArray` that want special treatment? Are there other types? How does this impact #28916", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM978", "user": "lll000111", "root": "ROOT97", "reply_to": "COM977", "timestamp": "2019-07-22T20:11:24Z", "text": "@RyanCavanaugh Please don't @-mention me in threads I'm not subscribed to. I refer to what I already wrote above. Your comment is insulting and more than useless. Go and learn some manners!", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM979", "user": "fatcerberus", "root": "ROOT97", "reply_to": "COM978", "timestamp": "2019-07-22T21:02:02Z", "text": "@RyanCavanaugh Interestingly, writing a type predicate `x is ReadonlyArray<T>` doesn\u2019t actually work from my tests: it narrows to `T[]` (sans readonly-ness) anyway.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9710", "user": "zpdDG4gta8XKpMCd", "root": "ROOT97", "reply_to": "COM979", "timestamp": "2019-07-22T22:17:15Z", "text": "bitch needs a slap", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9711", "user": "DanielRosenwasser", "root": "ROOT97", "reply_to": "COM9710", "timestamp": "2019-07-23T00:06:31Z", "text": "Alright, I am going to lock this issue. We can't tolerate abrasive language or tone on this issue tracker, and it has clearly become a problem here, so I'm closing the thread. Insults, disrespectful tone, and consistently abrasive language are violations of our [code of conduct](https://opensource.microsoft.com/codeofconduct/).\r\n\r\nKeep in mind that violations of the code of conduct can result in being banned. I always try to remind participants that we are *all* striving to make TypeScript better - but if you want to participate, the only way to do so is with respect. If you cannot do that, we cannot allow you to engage on the issue tracker.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT98", "user": "macengr", "root": "ROOT98", "reply_to": null, "timestamp": "2019-10-26T18:39:36Z", "text": "We cannot reach the server to update your progress.  **Edited by @moT01:**\r ## Anyone coming here with this issue should read through this, or specifically [go to this comment](https://github.com/freeCodeCamp/freeCodeCamp/issues/37571#issuecomment-547288864) and send an email.\r <hr>\r \r **Describe your problem and how to reproduce it:**\r \r I've been trying to submit several projects for a week and I get the subject message.\r \r **Add a Link to the page with the problem:**\r \r All pages\r \r **Tell us about your browser and operating system:**\r * Browser Name: \r * Browser Version: \r * Operating System: \r \r Version 78.0.3904.70 (Official Build) (64-bit),\r ![Capture](https://user-images.githubusercontent.com/8150967/67624427-6cc34080-f7fe-11e9-9ab0-4740b7619d30.JPG)\r  Windows 10\r \r **If possible, add a screenshot here (you can drag and drop, png, jpg, gif, etc. in this box):**\r ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM980", "user": "nandumoura", "root": "ROOT98", "reply_to": "ROOT98", "timestamp": "2019-10-26T21:58:24Z", "text": "i had the same problem\r\n\r\nBrowser: Firefox 68.2.0esr (64-bits) and chrome Version 78.0.3904.70  64 bits\r\nSO: Linux (Debian)\r\n\r\n![Captura de tela_2019-10-26_23-27-58](https://user-images.githubusercontent.com/3390120/67628683-72de0f00-f848-11e9-9280-e4b0f84f3400.png)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM981", "user": "thecodingaviator", "root": "ROOT98", "reply_to": "COM980", "timestamp": "2019-10-27T13:17:33Z", "text": "I haven't been able to reproduce the issue. Can both of you please check again? If the issue is still there, try checking your browser's proxy config and network settings in general", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM982", "user": "moT01", "root": "ROOT98", "reply_to": "COM981", "timestamp": "2019-10-27T15:19:58Z", "text": "Thanks for reporting this @macengr. It looks like this has been fixed and is waiting to be pushed to production. See https://github.com/freeCodeCamp/freeCodeCamp/issues/37381 for more info. We can close this since it has been resolved.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM983", "user": "macengr", "root": "ROOT98", "reply_to": "COM982", "timestamp": "2019-10-27T17:04:28Z", "text": "I'm not sure why you closed this because I am STILL unable to submit my projects. It's been over a week now. I've seen multiple people reporting this problem and it always ends the same way - oh, we fixed it, closed. It's not fixed until it works for the user.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM984", "user": "macengr", "root": "ROOT98", "reply_to": "COM983", "timestamp": "2019-10-27T17:07:04Z", "text": "Please see the comment I just left on 37571. It is most definitely NOT\nresolved.\n\nOn Sun, Oct 27, 2019 at 11:28 AM Tom <notifications@github.com> wrote:\n\n> Thanks for reporting this @macengr <https://github.com/macengr>. It looks\n> like this has been fixed and is waiting to be pushed to production. See\n> #37381 <https://github.com/freeCodeCamp/freeCodeCamp/issues/37381> for\n> more info. We can close this since it has been resolved.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/freeCodeCamp/freeCodeCamp/issues/37571?email_source=notifications&email_token=AB6F7N6RCBNTSBL5NMCUYV3QQWXQBA5CNFSM4JFOL3JKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECLAWZA#issuecomment-546704228>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AB6F7N5ULVNFSUWTRGWRK3TQQWXQBANCNFSM4JFOL3JA>\n> .\n>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM985", "user": "moT01", "root": "ROOT98", "reply_to": "COM984", "timestamp": "2019-10-27T18:45:29Z", "text": "The reason this can be closed is because the issue has been fixed on our development environment. We don't need open issues for something that is fixed. I just verified that it is fixed locally. I'm not sure when the next time the code will be added to the live site will be; but once it is added, you will be able to submit your projects normally. Thanks.\r\n\r\nEdit: it actually seems to be working for me on production as well. Can you try one more time @macengr?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM986", "user": "macengr", "root": "ROOT98", "reply_to": "COM985", "timestamp": "2019-10-27T19:10:47Z", "text": "No, still not working. My original data is the same (1st post). 3:09 PM EST 10/27/2019", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM987", "user": "RandellDawson", "root": "ROOT98", "reply_to": "COM986", "timestamp": "2019-10-27T19:28:23Z", "text": "@macengr I am reopening this issue, due to you still having the problem.  Are you using any browser extensions which could be blocking the requests?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM988", "user": "macengr", "root": "ROOT98", "reply_to": "COM987", "timestamp": "2019-10-27T19:36:31Z", "text": "Not that I know of, at least, none that I wasn't using before this started.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM989", "user": "macengr", "root": "ROOT98", "reply_to": "COM988", "timestamp": "2019-10-27T19:43:45Z", "text": "I've made a recording for you:\r\n\r\nhttps://www.loom.com/share/b6d7ad6899d7481a979ada644a1a93a6\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9810", "user": "moT01", "root": "ROOT98", "reply_to": "COM989", "timestamp": "2019-10-27T20:39:24Z", "text": "Sorry for closing this prematurely @macengr. I can't reproduce this with any browser on High Sierra.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9811", "user": "broregard", "root": "ROOT98", "reply_to": "COM9810", "timestamp": "2019-10-27T22:47:01Z", "text": "I've been getting the same error message. Doesn't matter what browser I use, although at this point I can no longer log into my account (signed up w/Github acct). I'm still logged into a session on Opera. Browser is up to date. No extensions. macOS 10.1.14\r\n\r\n<img width=\"913\" alt=\"Screen Shot 2019-10-27 at 6 41 09 PM\" src=\"https://user-images.githubusercontent.com/11634920/67643084-8097a100-f8e9-11e9-805a-7c4acfe6e404.png\">", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9812", "user": "stevejh1", "root": "ROOT98", "reply_to": "COM9811", "timestamp": "2019-10-28T11:22:55Z", "text": "I required a suggestion to solve [Yahoo 404 http](https://gmailtechnicalsupportnumbers.com/blog/fix-yahoo-mail-error-code-404/), I attempt all the steps known, and few more learned by internet if you have experience how to solve this please suggest the measures.      ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9813", "user": "broregard", "root": "ROOT98", "reply_to": "COM9812", "timestamp": "2019-10-28T15:10:48Z", "text": "Now that my account has been merged #37457, the projects I submitted are showing up", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9814", "user": "kelsiegosser", "root": "ROOT98", "reply_to": "COM9813", "timestamp": "2019-10-28T15:15:28Z", "text": "I am still experiencing the issue and I do not believe I have an account issue", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9815", "user": "ojeytonwilliams", "root": "ROOT98", "reply_to": "COM9814", "timestamp": "2019-10-28T16:12:07Z", "text": "Is anyone that is experiencing this issue able to log in and edit their user account settings?  The reason I ask is that that specific message should only appear if the browser can't detect the internet or the fcc servers have not returned your user details.\r\n\r\nIf not, then the problem is likely login issues, discussed further [here](https://github.com/freeCodeCamp/freeCodeCamp/issues/37457).\r\n\r\nIf yes and you can change your settings, submit other challenges and everything, aside from project submission, seems to be working, then this is definitely something new.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9816", "user": "kelsiegosser", "root": "ROOT98", "reply_to": "COM9815", "timestamp": "2019-10-28T16:13:49Z", "text": "Ok, I am unable to update my account settings. I receive this error when I try: \r\n![image](https://user-images.githubusercontent.com/23170565/67695962-5fcc5b80-f97c-11e9-804f-d0005d0c9a40.png)\r\n\r\nI will follow the issue mentioned above\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9817", "user": "macengr", "root": "ROOT98", "reply_to": "COM9816", "timestamp": "2019-10-28T16:51:11Z", "text": "I redceive the same error as Kelsie when I try to change my settings (e.g., switch to dark mode or submit an about message):\r\n\r\nhttps://www.loom.com/share/ccd4e968a1254a14a18ba53ed63d6027", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9818", "user": "ahmadabdolsaheb", "root": "ROOT98", "reply_to": "COM9817", "timestamp": "2019-10-29T07:17:57Z", "text": "Thank you for your patience.\r\n\r\nWe suspect this issue could be caused by of duplicate accounts.\r\n\r\nIf you could kindly send us an email support@freecodecamp.org with your username, we should be able to take a closer look and resolve this issue ASAP.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9819", "user": "nandumoura", "root": "ROOT98", "reply_to": "COM9818", "timestamp": "2019-10-29T12:00:44Z", "text": "is not resolved", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9820", "user": "kelsiegosser", "root": "ROOT98", "reply_to": "COM9819", "timestamp": "2019-10-29T12:06:56Z", "text": "After emailing support and having my duplicated accounts merged (for those following along, I had no idea that I had duplicated accounts - view issue #37457 for more info), I am able to submit my lessons and update my accounts settings. \r\n\r\nOne buggy thing which I included in an email to support is that when I click the freeCodeCamp logo, it appears to log me out. I press Sign In and I am able to see my curriculum again though.\r\n\r\nThanks for the help with this issue.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9821", "user": "thecodingaviator", "root": "ROOT98", "reply_to": "COM9820", "timestamp": "2019-10-29T12:21:44Z", "text": "@nandumoura \r\n\r\n> Thank you for your patience.\r\n> \r\n> We suspect this issue could be caused by of duplicate accounts.\r\n> \r\n> If you could kindly send us an email [support@freecodecamp.org](mailto:support@freecodecamp.org) with your username, we should be able to take a closer look and resolve this issue ASAP.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9822", "user": "ahmadabdolsaheb", "root": "ROOT98", "reply_to": "COM9821", "timestamp": "2019-10-30T08:20:56Z", "text": "> After emailing support and having my duplicated accounts merged (for those following along, I had no idea that I had duplicated accounts - view issue #37457 for more info), I am able to submit my lessons and update my accounts settings.\r\n> \r\n> One buggy thing which I included in an email to support is that when I click the freeCodeCamp logo, it appears to log me out. I press Sign In and I am able to see my curriculum again though.\r\n> \r\n> Thanks for the help with this issue.\r\n\r\nOur landing page looks like the log out version of /learn at the moment. It is likely that you have been redirected to the landing page without getting logged out.\r\n\r\nif not could you please create a separate issue for that? ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM9823", "user": "brianignacio5", "root": "ROOT98", "reply_to": "COM9822", "timestamp": "2019-11-01T09:05:33Z", "text": "@ahmadabdolsaheb I sent an email to check if my account is duplicated. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT99", "user": "MadsTorgersen", "root": "ROOT99", "reply_to": null, "timestamp": "2020-01-21T21:12:24Z", "text": "Top-level statements and functions # Top level statements and functions\r \r There are at least three somewhat conflicting scenarios around allowing statements and/or functions to be declared at the top level of program text. \r \r First I'll consider each in turn, and point out how they conflict with each other. Then I'll propose an approach for C# to take.\r \r ## Scenario 1: Simple programs\r \r There's a certain amount of boilerplate surrounding even the simplest of programs, because of the need for an explicit `Main` method. This seems to get in the way of language learning and program clarity.\r \r The simplest feature to address this would be to allow a sequence of *statements* to occur right before the *namespace_member_declaration*s of a *compilation_unit* (i.e. source file).\r \r The semantics are that if such a sequence of *statements* is present, the following type declaration would be emitted:\r \r ``` c#\r static class Program\r {\r     static async Task Main(string[] args)\r     {\r         // statements\r     }\r }\r ```\r \r This would make it an error for multiple compilation units to have statements, because you'd get two classes with the same name `Program`. If the assembly is run, it would also be an error to have other valid entry points, such as explicit `Main` methods.\r \r ## Scenario 2: Top-level functions\r \r C# restricts named functions to being declared as members of types, as well as local functions. The closest you can get to a notion of \"global\" (or \"namespace-global\") functions is to put them as static members in a class `C` and then say `using static C;` in places where you want to use the functions directly without prefixing with a class name. This adds ceremony to both the declaring side and the consuming side dealing with the class `C`.\r \r The simplest feature to address this is to add function declarations to *namespace-member_declaration*s - the kind of thing you can declare globally or in a namespace.\r \r The functions would be limited in the modifiers that apply: They cannot be `abstract`, `virtual`, `override` or `sealed`. Their accessibility, like that of top-level classes would be `internal` or `public`, with `internal` being the default. \r \r There's a design decision as to which kinds of function member declarations would be allowed: methods are key, but properties, indexers, etc. could also be considered. You could even consider stateful members (fields, auto-properties), and you would essentially get global variables. User defined operators and conversions are probably completely off the table, though, as they have relationships with their enclosing type, and there wouldn't be one.\r \r On the consuming side, the top-level members would be direct members of the namespace, just as top level types are. If the namespace is `using`ed, or is the global namespace, the members are directly in scope.\r \r The implementation would be that a partial class is generated to wrap the members as static members. The class name would probably be unspeakable, and would be chosen in such a way that the same name wouldn't be used twice in the same namespace across different assemblies. If any of the top-level members are public, the class would be public, and marked in such a way that a consuming assembly would know to expose the members directly.\r \r ## Scenario 3: Scripting\r \r There is currently a \"scripting dialect\" of C#, where top-level statements and functions are not only *allowed*, but are *the* way the program is specified. It's similar to scenario 1, except that the statements are freely scattered among type declarations. (Namespace declarations are currently not allowed in scripting, but that may change in the future.)\r \r The execution of a script is often performed by a \"host\", that is able to put specific things into scope of the script, as well as access the state of its \"local\" variables. This is enabled by the state being represented as instance fields of a generated class, of which the running script is an instance.\r \r Also, scripts can be executed as individual \"submissions\", one after the other, with subsequent ones being within the scope of their predecessors' declarations, modulo shadowing. In this mode submissions need to be captured as objects, and cannot allow stack-only things such as ref variables. Similarly, scripts are implicitly `async` so that `await` can be used freely, and this also limits the use of certain features.\r \r If we want to add top level statements and functions to C#, we don't want them to conflict with how those work in scripting. Rather we want to compile them in the requisite manner when necessary, but unify on the semantics of the features. This doesn't fully eliminate the scripting dialect, as we would still need to deal with the special directives and \"magic commands\" that it requires, but at the minimum we do need to avoid the same syntax to not mean materially different things.\r \r ## Problem\r \r The main conflict between these three scenarios is in how top-level functions are construed. Are they \"local-to-the-main-program\" functions (as in 1 and 3), or are they top level library declarations just like types (as in 2)?\r \r If the former, then top-level functions can only occur as part of a top-level program. They can see the local variables of that program, but they (and the local variables themselves) aren't visible to e.g. adjacent type declarations.\r \r If the latter, then top-level functions can occur everywhere top-level type declarations can occur. They wouldn't be able to access the state of a top-level program, unless we also interpret the \"locals\" of such a program as top-level \"global\" variables. The functions - as well as such global variables if we choose to embrace them - would be members of their namespace, visible to any code in the assembly, and, if declared `public`, to any other assemblies referencing it.\r \r # Proposal: Simple programs\r \r You can squint and imagine a merged feature that serves all the scenarios. It would require a lot of design work, and some corners cut. I do not propose that. Instead I suggest that we fully embrace scenario 1, essentially fleshing out and slightly generalizing the feature sketched out for that scenario above.\r \r The primary goal of the feature therefore is to allow C# programs without unnecessary boilerplate around them, for the sake of learners and the clarity of code. A secondary but important goal is to not introduce a fundamental conflict with scenarios 2 (which we may want to revisit in the future) and 3 (not having the meaning of top-level code differ between \"program\" and \"script\" scenarios).\r \r It should be relatively straightforward to ensure that, while more restrictive than scenario 3, for programs that *are* allowed, the semantics will be approximately the same; enough so that the two don't materially conflict. \r \r The approach more fundamentally clashes with scenario 2, and in its straightforward form it would bar us from extending the feature to embrace scenario 2 in the future. I propose that we build in additional restrictions to keep that design space open.\r \r (If we later find that there's a need for libraries of top-level functions, we can also consider an equivalent to VB's *modules*, which still provide a named wrapper for static members (similar to a static class), but put the names of those members in scope implicitly when the enclosing namespace is `using`ed, instead of requiring an explicit `using static`).\r \r ## Syntax\r \r The only additional syntax is allowing a sequence of *statement*s in a compilation unit, just before the *namespace_member_declaration*s:\r \r ``` antlr\r compilation_unit\r     : extern_alias_directive* using_directive* global_attributes? statement* namespace_member_declaration*\r     ;\r ```\r \r In all but one *compilation_unit* the *statement*s must all be local function declarations. \r \r Example:\r \r ``` c#\r // File 1 - any statements\r if (args.Length == 0\r     || !int.TryParse(args[0], out int n)\r     || n < 0) return;\r Console.WriteLine(Fib(n).curr);\r \r // File 2 - only local functions\r (int curr, int prev) Fib(int i)\r {\r     if (i == 0) return (1, 0);\r     var (curr, prev) = Fib(i - 1);\r     return (curr + prev, curr);\r }\r ```\r \r Note the use of `return` as a top-level statement. We may find that this looks/feels wrong since it's not visibly inside a body of a member. \r \r ## Semantics\r \r If any top-level statements are present in any compilation unit of the program, the meaning is as if they were combined in the block body of a `Main` method of a `Program` class in the global namespace, as follows:\r \r ``` c#\r static class Program\r {\r     static async Task Main(string[] args)\r     {\r         // File 1 statements\r         // File 2 local functions\r         // ...\r     }\r }\r ```\r \r If any one compilation unit has statements other than local function declarations, those statements occur first. The order of statement contributions (which would all be local functions) from other compilation units is undefined.\r \r Warnings about missing `await` expressions are omitted. \r \r Normally collision between multiple `Main` method entry points is only diagnosed if and when the program is run. However, we should consider forbidding any `Main` methods suitable as entry points to coexist with top-level statements. Or if we do allow them, we should not allow synchronous ones to silently take precedence over the async one generated from the top-level statements. That precedence was only reluctantly allowed over async `Main` methods for back compat reasons which do not apply here.\r \r The example above would yield the following `Main` method declaration:\r \r ``` c#\r static class Program\r {\r     static async Task Main(string[] args)\r     {\r         // Statements from File 1\r         if (args.Length == 0\r             || !int.TryParse(args[0], out int n)\r             || n < 0) return;\r         Console.WriteLine(Fib(n).curr);\r         \r         // Local functions from File 2\r         (int curr, int prev) Fib(int i)\r         {\r             if (i == 0) return (1, 0);\r             var (curr, prev) = Fib(i - 1);\r             return (curr + prev, curr);\r         }\r     }\r }\r ```\r \r ## Scope of top-level parameters, local variables and local functions\r \r Even though the `args` parameter and top-level local variables and functions are \"wrapped\" into the generated `Main` method, they should still be in scope throughout the program, as if they were declared with internal accessibility in the global namespace. \r \r This could lead to name collisions, ambiguous lookups and shadowing of imported names. If one is picked by name look-up, it should lead to an error instead of being silently bypassed. \r \r In this way we protect our future ability to better address scenario 2, and are able to give useful diagnostics to users who mistakenly believe them to be supported.\r \r LDM notes:\r - https://github.com/dotnet/csharplang/blob/master/meetings/2020/LDM-2020-01-22.md", "meta": {"posReactions": "101", "negReactions": "8"}}
{"id": "COM990", "user": "MadsTorgersen", "root": "ROOT99", "reply_to": "ROOT99", "timestamp": "2020-01-21T21:15:56Z", "text": "See relevant discussion at #2765.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM991", "user": "CyrusNajmabadi", "root": "ROOT99", "reply_to": "COM990", "timestamp": "2020-01-21T21:30:20Z", "text": "The primary thing that bothers me here is scoping.  i.e. both around 'args' as well as the scopes of variables introduced in teh statements that precede a namespace.  However, it may just be an initial aversion that i coudl get over.\r\n\r\nGiven that your goal is `Proposal: Simple programs`, i would say that there's actually no need for scoping to extend from teh statements elsewhere.  A simple program is just statements and little funcs.  The moment we get to namespaces/classes/etc, we're no longer \"simple\" and i personally would prefer stating that they shouldn't mix.\r\n\r\n--\r\n\r\nanother issue for me is that while this is pitched as 'simple programs' it seems to still allow the statements to coexist with namespaces/classes.  First, this isn't really 'simple' to me anymore.  Second, it actually opens up large cans of worms for me.  For example, if i were to be able to have top-level statements that can be in scope for the rest of my program, then I absolutely would want to be able to make those top level variables `readonly` so they couldn't just be overwritten by the rest of my code.\r\n\r\nI strongly like the idea of simple-programs.  But I actually don't think this goes far enough.  Perhaps a simple program should *only* be top level statements/local-funcs?", "meta": {"posReactions": "5", "negReactions": "2"}}
{"id": "COM992", "user": "HaloFour", "root": "ROOT99", "reply_to": "COM991", "timestamp": "2020-01-21T21:36:02Z", "text": "Where do imported namespaces come in?  Or do we need support for `using` directive within a method in order to support this?  Or would the compiler take `using` directives and \"promote\" them outside of the generated class?  What if multiple files want to import multiple and potentially colliding namespaces?\r\n\r\nIt's difficult to not have an immediate negative visceral reaction to this proposal.  It feels like it creates yet another dialect of the language without solving for any problems or the use cases suggested.  You wouldn't be able to take CSX and run it this way, not without additional syntax work.  You couldn't use most of the language as you'd expect.  All variables end up in some mixed global scope.\r\n\r\nFeels like tools like LINQPad already satisfy this need and do so in a vastly superior manner.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM993", "user": "orthoxerox", "root": "ROOT99", "reply_to": "COM992", "timestamp": "2020-01-21T22:54:18Z", "text": "@CyrusNajmabadi I agree that simple programs should remain simple. I am not even convinced that splitting your simple program into multiple simple files is something desirable. I imagine that `csc run hello.cs` or `dotnet run hello.cs` would be the preferred mode of running them. As soon as you have multiple files you need either a csproj or some other way to refer to multiple files. The former is complicated enough that you might as well rote learn `static void Main` as well, while the latter leads learners away from the \"proper\" way of doing things.\r\n\r\nOf course, the scripting dialect could invent its own way of including other files, but that's outside the scope of this issue.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM994", "user": "amdav", "root": "ROOT99", "reply_to": "COM993", "timestamp": "2020-01-22T00:51:06Z", "text": "I agree with @MadsTorgersen proposal, that this feature should be targeting simple programs and people learning the language (and should be a shortcut for what goes inside Main()).  It could be worth adding a little more detail (with examples) to the section on the scoping of local variables and functions just so everyone is clear.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM995", "user": "YairHalberstadt", "root": "ROOT99", "reply_to": "COM994", "timestamp": "2020-01-22T05:09:33Z", "text": "I'm feeling a little bit sceptical of this proposal.\r\n\r\nWriting a static Main function is not particularly difficult, and the tooling generates it for you anyway. In terms of benefits of top level statements I would suggest there's almost none from an actual use case perspective.\r\n\r\nInstead I feel this is more of a marketing issue. C# looks old and stuffy because you need so many things to create an app. Python you just type something and it runs.\r\n\r\nMarketing is important, but I don't think it's worth introducing a whole load of complexity for it. Instead I would keep this extremely simple. You can have a single file in a project with top level statements, which act exactly as if they're inside an async Main method. They are not globally scoped, and can't be referenced anywhere else. That should be enough to give beginners their python feel.", "meta": {"posReactions": "22", "negReactions": "6"}}
{"id": "COM996", "user": "fitdev", "root": "ROOT99", "reply_to": "COM995", "timestamp": "2020-01-22T08:20:02Z", "text": "For my part I really like Scenario 2. That would allow for significant time savings via less typing. And having worked with VB.NET for a number of years, I do miss VB's modules and their implicit imports.\r\n\r\n> User defined operators and conversions are probably completely off the table, though, as they have relationships with their enclosing type, and there wouldn't be one.\r\n\r\nI would love to have globally accessible implicit and other operators I could define even for existing CLR types. So if the team can find a way to include those it would add even more value to Scenario 2.\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM997", "user": "orthoxerox", "root": "ROOT99", "reply_to": "COM996", "timestamp": "2020-01-22T10:54:39Z", "text": "@YairHalberstadt I would absolutely use simple C# programs for throwaway scripts and tiny utilities. `dotnet new console` is fast, but it leaves behind a whole project folder with a bunch of binaries.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM998", "user": "YairHalberstadt", "root": "ROOT99", "reply_to": "COM997", "timestamp": "2020-01-22T10:58:14Z", "text": "@orthoxerox \r\nWould you require more than one file?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM999", "user": "orthoxerox", "root": "ROOT99", "reply_to": "COM998", "timestamp": "2020-01-22T11:48:16Z", "text": "@YairHalberstadt one file per utility/script. I've already written I don't think it's nesessary to support multi-file \"simple programs\".", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9910", "user": "HaloFour", "root": "ROOT99", "reply_to": "COM999", "timestamp": "2020-01-22T16:13:56Z", "text": "If all this proposal does is take the statements in the file(s) and put that into the middle of a generated `Main` method why does this need to be a part of the compiler or C# spec at all?  Couldn't a separate `dotnet` tool be shipped which does that for users?  A simplified tool could be geared towards making this as easy as possible.  And you could prototype this all out right now without having to touch Roslyn or the C# spec.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM9911", "user": "orthoxerox", "root": "ROOT99", "reply_to": "COM9910", "timestamp": "2020-01-22T16:55:53Z", "text": "@HaloFour It's a bit more complex than that, since the tool has to recognize the usings as well.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM9912", "user": "HaloFour", "root": "ROOT99", "reply_to": "COM9911", "timestamp": "2020-01-22T17:04:13Z", "text": "@orthoxerox \r\n\r\n> It's a bit more complex than that, since the tool has to recognize the usings as well.\r\n\r\nI see nothing in this proposal that claims that `using` directives would be supported.  That would land us firmly back into dialect territory since said directives aren't permitted mid-method.  But, if this proposal would need to support it, without a corresponding change to the language, then an external tool could also do so just as easily.  CSX already does it.\r\n\r\nIMO, we'd get more mileage making it easier to get/use CSX, and adding support for converting CSX scripts to a C# project.\r\n\r\n", "meta": {"posReactions": "2", "negReactions": "1"}}
{"id": "COM9913", "user": "svick", "root": "ROOT99", "reply_to": "COM9912", "timestamp": "2020-01-22T19:28:01Z", "text": "For me, the simple programs I would want to write:\r\n\r\n* Are single file.\r\n* Are ordered usings, types, functions, statements, e.g. (artificial example):\r\n\r\n    ```c#\r\n    using System;\r\n\r\n    class C\r\n    {\r\n        public int P { get; set; }\r\n    }\r\n\r\n    void Print(C c) => Console.WriteLine(c?.P);\r\n\r\n    Print(new C { P = 0 });\r\n    Print(null);\r\n    ```\r\n\r\n* Types don't need access to local variables from statements.\r\n\r\nThis means that for me, the suggested ordering of \"_statements_ right before the *namespace_member_declaration*s\" would not be natural, I'd prefer it the other way around.\r\n\r\nAnd being able to have top-level local functions in other files and being able to access top-level local variables from other files is unnecessary and probably undesirable.\r\n\r\nOn the other hand, the suggestion by @CyrusNajmabadi of having only \"top level statements/local-funcs\" goes too far: being able to declare types is necessary for the \"simple programs\" I want to write.", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM9914", "user": "CyrusNajmabadi", "root": "ROOT99", "reply_to": "COM9913", "timestamp": "2020-01-22T19:37:44Z", "text": "Very interesting point @svick .  Thanks!  \r\n\r\nThere's something definitely more appealing to me about that as it feels much more 'natural' in terms of scoping.  i.e if i think of the 'top level locals' i declare as similar to 'method locals', then placing them after everyting else feels 'better' (since locals can't be referenced by code that is earlier than their declaration).  ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM9915", "user": "orthoxerox", "root": "ROOT99", "reply_to": "COM9914", "timestamp": "2020-01-22T19:41:40Z", "text": "@HaloFour Take a look at the grammarlet Mads posted:\r\n\r\n```\r\ncompilation_unit\r\n    : extern_alias_directive* using_directive* global_attributes? statement* namespace_member_declaration*\r\n    ;\r\n```\r\n\r\nUsings are supported, and they must precede the statements. I actually don't mind if CSX is merged with mainline C#, I can then just treat this proposal as the first step in that direction.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM9916", "user": "Thaina", "root": "ROOT99", "reply_to": "COM9915", "timestamp": "2020-01-23T05:29:20Z", "text": "Would like to voice that I prefer the scenario 2 specifically\r\n\r\nIs it true that I could assume that top level function will be `internal static` by default? If it is then, as for simple program purpose, just one `void Main` is already reduced enough from the verbose class and `static`\r\n\r\nAnother main reason I really support this feature is that, outermost `void Main` will become exactly one in the whole program, never be any conflict thereafter. It also true for any same name singleton function we want\r\n\r\nAlso I would like to repeat myself that, I wish that we could not write top level statement. Only function and property. Because, unlike class that easily make dependency chain, we cannot expect timing and order of the statement aside from `void Main`", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM9917", "user": "DavidArno", "root": "ROOT99", "reply_to": "COM9916", "timestamp": "2020-01-23T08:33:30Z", "text": "Scenario 2 is also my preferred option. \r\n\r\nBut I disagree with @MadsTorgersen suggestion of:\r\n> Their accessibility, like that of top-level classes would be `internal` or `public`, with `internal` being the default. \r\n\r\n`private` should be supported and should be the default, in my view. Each file containing its own set of free functions should end up as a differently named static class, allowing each to contain its own private functions.\r\n\r\n", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM9918", "user": "YairHalberstadt", "root": "ROOT99", "reply_to": "COM9917", "timestamp": "2020-01-23T08:36:58Z", "text": "> private should be supported and should be the default, in my view. Each file containing its own set of free functions should end up as a differently named static class, allowing each to contain its own private functions.\r\n\r\nI think that would be very useful to support an FP rather than class based style of programming. Each file becomes a sort of module and defines a number of private, internal, and public functions.", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM9919", "user": "MgSam", "root": "ROOT99", "reply_to": "COM9918", "timestamp": "2020-01-23T15:57:27Z", "text": "I don't understand the use case here. Is something wrong with 'csx' scripts? Why can't 'learners' and those who want 'simple programs' just use the already-existing scripting dialect?\r\n\r\nIf the reason is \"no one is using it\"- that's a tooling and education problem, not a language design problem. You guys released  CSX and then did close to zero promotion of it- to my knowledge, no one official has ever blogged about it or demoed it at conferences, and development on  C# Interactive stopped almost as soon as it started.", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM9920", "user": "genlu", "root": "ROOT99", "reply_to": "COM9919", "timestamp": "2020-01-23T23:17:20Z", "text": "> I strongly like the idea of simple-programs. But I actually don't think this goes far enough. Perhaps a simple program should only be top level statements/local-funcs?\r\n\r\n@CyrusNajmabadi I agree. IMO, having both top level statements/local-funcs and \"regular\" C# code coexist as proposed here can work, but allowing them to mix might be against the simple program scenario that motivated this proposal in the first place. \r\n\r\nHowever, this would pretty much make it identical to a csx, right? It seems to me that making improvement to existing C# scripting would address the simple program scenario more effectively. ", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM9921", "user": "eyalalonn", "root": "ROOT99", "reply_to": "COM9920", "timestamp": "2020-01-24T00:07:51Z", "text": "@MgSam The motivation here is to come up with a single dialect where you wouldn't have to think about the environment regardless to proficiency or task, people who just want/need to write a \"simple program\" and run it shouldn't use a different tool just because now they want to define a top-level function or whatever but for beginners this might be a show stopper especially for new programmers with no prior knowledge and this barrier is a language concern because there are two different dialects and two different tools for the same language.", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM9922", "user": "eyalalonn", "root": "ROOT99", "reply_to": "COM9921", "timestamp": "2020-01-28T21:22:31Z", "text": "@AlgorithmsAreCool With all due respect your comment makes zero sense here.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM9923", "user": "AlgorithmsAreCool", "root": "ROOT99", "reply_to": "COM9922", "timestamp": "2020-01-29T00:25:38Z", "text": "@eyalsk In retrospect, I agree. I've removed it.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM9924", "user": "HaloFour", "root": "ROOT99", "reply_to": "COM9923", "timestamp": "2020-01-29T17:31:47Z", "text": "@RUSshy \r\n\r\nDoes it really solve that problem, though?  Sure, you might get \"Hello World\" off the ground faster, but for anything even slightly less trivial you're going to have to jump that same hurdle.\r\n\r\nAnd does that hurdle really exist, even for beginners?  Odds are that a beginner is starting from a tool like Visual Studio or `dotnet new` which writes all of that boilerplate for you.  If they're trying to write this program from the command line they've already had to vault significantly higher hurdles.\r\n\r\nIf adoption and outreach are the goals I'd suggest that there are significantly better opportunities that don't result in creating dialects of the language.  And if the Tiobe index is to be trusted it doesn't appear that C# is having too many issues attracting developers.  Neither do most of the other languages towards the top of that list most of which require some kind of syntactic boilerplate.\r\n\r\nOh, and bring back temporary solutions in Visual Studio.  The removal of that feature has been infinitely more annoying to my ability to toss together a quick&dirty project than having Visual Studio automatically generate some code around the code I want to write.\r\n\r\n", "meta": {"posReactions": "1", "negReactions": "3"}}
{"id": "COM9925", "user": "Thaina", "root": "ROOT99", "reply_to": "COM9924", "timestamp": "2020-01-29T17:44:14Z", "text": "@HaloFour \r\n\r\n> `dotnet new` which writes all of that boilerplate for you\r\n\r\nIn the eye of beginner programmer, even the word `namespace` and `class`  itself is already magic that require them to understand that they cannot put a logic code inside those block. They need to learn that they could only put code into the bracket of `void Main`\r\n\r\nStarting with `dotnet new` will present them a sudden 3 layers that require understanding. This proposal can reduce to only one (or zero, if we could write a top level statement)", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM9926", "user": "HaloFour", "root": "ROOT99", "reply_to": "COM9925", "timestamp": "2020-01-29T17:55:36Z", "text": "@Thaina \r\n\r\n> In the eye of beginner programmer, even the word `namespace` and `class` itself is already magic that require them to understand that they cannot put a logic code inside those block. They need to learn that they could only put code into the bracket of `void Main`\r\n\r\nI disagree that such syntax poses a burden to beginners, either to C# or to programming in general.  They're going to have to learn so much about the syntax of C# in order to put _anything_ anywhere anyway, and many of those concepts (like variables, definite assignment, etc.) are so much more complicated to grasp than requiring a single container around a method (`namespace` has always been optional).  What's next?  Implicit variable declaration by assignment?  Auto-importing namespaces?  Automatically emitting the output of any expression to the console?\r\n\r\nIf C# is going to seriously consider the addition of top-level functions it should do so in consideration as to how they would impact and benefit developers of all skill levels and projects of all shapes.", "meta": {"posReactions": "0", "negReactions": "5"}}
{"id": "COM9927", "user": "Thaina", "root": "ROOT99", "reply_to": "COM9926", "timestamp": "2020-01-29T18:35:19Z", "text": "> @Thaina\r\n> \r\n> > In the eye of beginner programmer, even the word `namespace` and `class` itself is already magic that require them to understand that they cannot put a logic code inside those block. They need to learn that they could only put code into the bracket of `void Main`\r\n> \r\n> I disagree that such syntax poses a burden to beginners, \r\n\r\nThis might be only my opinion. But I still remember when I myself was a beginner. So this is my direct experience. I have learn only a little bit of C and start learning Java and C# at the same time. I remember I feel much burden on the `package`/`namespace` and `class` that was unknown to me. I don't know what it is and what effect it has on my code. What can I change in that file. What is the meaning of it. Where could I start typing. Looking back now I still felt that burden, partly because I always want this feature so it always reminded me on that first day\r\n\r\nIt very easy when you have learn C or older language as a starting point to programming. You already know what a code of program really is. It really another story when you don't really know it but just start learning C# or Java as your first ever language in your life. And I think most of us here cannot experience that kind of experience anymore\r\n\r\nI have watch one 3Blue1Brown chapter, he talk about \"This problem seems hard, then it doesn't, but it really is\". He make that video about question in math competition that the organizer think it is quite easy, but the participant cannot solve it\r\nThe conclusive word he give is, \"It extremely hard to imagine what it feel like to not understand\". And I kind of thinking the same with our understanding of programming language. What we feel like easy is easy from our perspective with some experience. We then sometimes fail to understand what it feel like to not understand, because we can't imagine it anymore", "meta": {"posReactions": "8", "negReactions": "0"}}
{"id": "COM9928", "user": "Thaina", "root": "ROOT99", "reply_to": "COM9927", "timestamp": "2020-01-29T18:39:55Z", "text": "> If C# is going to seriously consider the addition of top-level functions it should do so in consideration as to how they would impact and benefit developers of all skill levels and projects of all shapes.\r\n\r\nAs for me I think this feature already benefit us if we could write only one `void Main` in the project. Made second and it will give a name collision error. It pin down that we would have only one entrypoint in the project ever. That was the main benefit for all singleton function\r\n\r\nMy point is, the benefit for beginner that some people talk about is also as real and also a great bonus for our language too", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM9929", "user": "ErikSchierboom", "root": "ROOT99", "reply_to": "COM9928", "timestamp": "2020-01-29T19:16:53Z", "text": "> In the eye of beginner programmer, even the word namespace and class itself is already magic that require them to understand that they cannot put a logic code inside those block. They need to learn that they could only put code into the bracket of void Main\r\n\r\nI agree with this. There is a rather significant amount a syntax a beginner would have to read and understand to know what is happening. The less this is happening, the best.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "ROOT100", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": null, "timestamp": "2017-09-03T14:32:42Z", "text": "RFS (Responsive font size) implementation Fixes #23053\r \r - RFS is disabled by default and can be switched on with `$enable-responsive-font-sizes`\r - `font-size`-properties are switched to the `@include font-size()`-mixin. Stylelint prevents the usage of `font-size` property.\r - Basic documentation added + link to github repo for further documentation.\r - RFS is enabled to rescale font-sizes of titles on the docs page.\r \r Demo with RFS enabled available here (this is not the default behaviour, but would be the behaviour if `$enable-responsive-font-sizes` was `true`): https://project-rfs.github.io/\r \r TODO:\r \r - [x] Remove fusv false warning workaround\r - [x] Decide whether or not we're going to keep `$input-height-sm` and `$input-height-lg` > no\r - [x] Test if we should increase the minimum font size to 1.25rem > yes", "meta": {"posReactions": "23", "negReactions": "0"}}
{"id": "COM1000", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "ROOT100", "timestamp": "2017-09-03T14:42:33Z", "text": "@mdo: what do you think about this?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1001", "user": "mdo", "root": "ROOT100", "reply_to": "COM1000", "timestamp": "2017-12-28T05:34:52Z", "text": "Thanks for keeping this up to date. I'm slating this for sure for 4.1, but I'll see if we should put it into 4.0 depending on a few other things.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM1002", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM1001", "timestamp": "2018-01-06T18:34:11Z", "text": "Update:\r\nIt's now possible to disable responsive font-sizes for page by adding the `.disable-responsive-font-size` class to the `body` or `html`. This class can also be added to other elements.\r\n\r\nMinimum font-size is also increased to `1rem`, which prevents the default text from scaling down.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1003", "user": "wolfy1339", "root": "ROOT100", "reply_to": "COM1002", "timestamp": "2018-01-15T19:14:14Z", "text": "`$enable-hover-media-query` was not deprecated", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1004", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM1003", "timestamp": "2018-01-15T19:36:34Z", "text": "@wolfy1339: https://github.com/twbs/bootstrap/pull/25270/files#diff-d8ee409a461718bfb6240710c8c73382", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1005", "user": "patrickhlauke", "root": "ROOT100", "reply_to": "COM1004", "timestamp": "2018-01-23T02:04:12Z", "text": "This is all voodoo to me, but one request: make sure that even if using `vh`/`vw` etc, that there's a component for font sizing tied to something else like `px`/`rem`/`em`. Otherwise (when a font size is purely related to viewport dimensions and nothing else) you kill the user's ability to (full page) zoom on desktop and change the size the text is rendered at (as yes, the viewport dimensions change, but the font size would then change proportionally in the opposite direction, meaning the apparent font size is never actually altered).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1006", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM1005", "timestamp": "2018-01-23T07:39:03Z", "text": "@patrickhlauke, It's possible to add the `disable-responsive-font-size` class to achieve this:\r\nhttps://codepen.io/MartijnCuppens/pen/PEgNVM?editors=1100\r\n\r\nAlso, the font size is never purely related to viewport.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1007", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM1006", "timestamp": "2018-08-04T16:53:35Z", "text": "There are several ways to implement this depending on what should be the default value for `$rfs-class`.\r\n\r\nIn the current implementation I've set `$rfs-class: \"disable\";`. This way, it's easy to disable responsive font sizes within the html by adding the `.disable-responsive-font-size` class. An example of this can be viewed here: https://codepen.io/MartijnCuppens/pen/PEgNVM?editors=1100 The class can also be added to the `html` or the `body` to disable responsive font sizes on the whole page. Downside of this implementation is that more css is generated (that's why I needed to increase the `maxSize` in `package.json`) and it increases specificity.\r\n\r\nAnother approach is to use `$rfs-class: false;`. This is the most performant solution but the `.disable-responsive-font-size` class cannot be added to elements. It can of course still be changed in scss, but I can imagine some people load the Bootstrap css via a CDN may prefer their font-size doesn't change. A possible solution for this is to generate 2 css versions: one with and one without responsive font-sizes.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1008", "user": "vladimirmartsul", "root": "ROOT100", "reply_to": "COM1007", "timestamp": "2018-08-22T05:26:46Z", "text": "@MartijnCuppens, why not a `$enable-rfs: false;` (disabled by default) param like other in _variables.scss ?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1009", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM1008", "timestamp": "2018-08-24T20:56:03Z", "text": "@vladimirmartsul, that might be a good idea. This wouldn't cause a lot of changes by default while developers can still easily enable responsive font sizes if they want to. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10010", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM1009", "timestamp": "2018-08-28T19:31:50Z", "text": "I discovered changing the padding of buttons and inputs from `em` to `rem` can cause issues when upgrading Bootstrap, working on a solution for that. \r\n\r\nI'll try to implement RFS in a way that it wouldn't have any influence on the current Bootstrap at all when it's disabled.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10011", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM10010", "timestamp": "2018-09-02T20:39:33Z", "text": "I've now disabled the responsive font sizing by default so that the css files are exactly the same (apart from property order). \r\n\r\nResponsive font sizing can be enabled with `$enable-responsive-font-sizes`.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10012", "user": "andresgalante", "root": "ROOT100", "reply_to": "COM10011", "timestamp": "2018-09-11T10:20:18Z", "text": "Hi @MartijnCuppens, thanks for another great PR. I think that responsive font sizing is a killer feature to have.\r\n\r\nMy worried is that what this feature asks contributors might outweigh its value. Once we merge it we'll be asking contributors to include `responsive-font-size` every time they define a base font size. This adds a new level of complexity that makes Bootstrap harder to maintain and develop.\r\n\r\nIt'll be up to @mdo to decide if he wants this feature in Bootstrap or not. If we decide to add it I think we should either have a very strong linter or some kind of postCSS that automatically adds the artifact around the font size declarations.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10013", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM10012", "timestamp": "2018-09-11T12:02:46Z", "text": "@andresgalante, at this moment there's also a `border-radius` and a `transition` mixin for other properties.\r\n\r\nI've also added the `font-size` property to the `declaration-property-value-blacklist` which will trigger an error if the `font-size` property is instead of the mixin.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10014", "user": "XhmikosR", "root": "ROOT100", "reply_to": "COM10013", "timestamp": "2018-10-20T12:52:37Z", "text": "@MartijnCuppens: can you rebase and squash the patches/rebase the branch?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10015", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM10014", "timestamp": "2018-10-20T15:37:19Z", "text": "@XhmikosR, I'll have a look at it tomorrow", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10016", "user": "XhmikosR", "root": "ROOT100", "reply_to": "COM10015", "timestamp": "2018-10-21T11:16:55Z", "text": "@MartijnCuppens: that's not a rebase/squash. I see this branch has too many conflicts and it'll be hard to do a proper rebase.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10017", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM10016", "timestamp": "2018-10-21T11:25:26Z", "text": "Working on it \ud83d\ude09", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10018", "user": "XhmikosR", "root": "ROOT100", "reply_to": "COM10017", "timestamp": "2018-10-21T12:49:43Z", "text": "@mdo: pinging for the final review :D\r\n\r\nWe still need to make the build pass, but the preview looks pretty good.\r\n\r\nOh and like @MartijnCuppens mentioned we might want to have this off by default for 4.2, but we should mention it clearly in the release notes/blog post so that people can experiment with it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10019", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM10018", "timestamp": "2018-10-21T14:30:46Z", "text": "After a conversation I had with @XhmikosR on slack, I applied some changes:\r\n\r\n**Moved the mixin to a vendor folder.**\r\nThere are some variables in `_rfs.scss` because the file is copied from the original project. We don't want to allow this in other Bootstrap scss files, so I moved this a vendor folder so it's clear it's a file included from another repo. I used the same approach for including vendor content as is used for mixins and utilities (one `scss/_vendor.scss` file which includes the vendor `scss`).\r\n\r\nOther changes:\r\n- use `abbr` tag\r\n- Update to v7.1.5 (caching of some function calls)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10020", "user": "XhmikosR", "root": "ROOT100", "reply_to": "COM10019", "timestamp": "2018-10-28T22:14:18Z", "text": "@mdo: when you have some time please review this. It seems it works fine, it's disabled by default.\r\n\r\nThe `fusv` workaround, we'll try to fix it soon and remove it from here.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10021", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM10020", "timestamp": "2018-11-07T22:04:08Z", "text": "Current status: ~WIP~ Requested changes applied", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10022", "user": "XhmikosR", "root": "ROOT100", "reply_to": "COM10021", "timestamp": "2018-11-13T07:05:30Z", "text": "@MartijnCuppens: this needs a rebase and squash into one patch.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10023", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM10022", "timestamp": "2018-11-13T07:35:43Z", "text": "@XhmikosR, done.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10024", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM10023", "timestamp": "2018-12-18T07:14:41Z", "text": "I'm going to make some changes upstream and sync the versions this week. I'm going to increase `$rfs-minimum-font-size` (which will be called `$rfs-base-font-size` in RFS v8) to `1.25rem` because this will not rescale the input fields by default.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM10025", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM10024", "timestamp": "2018-12-31T13:59:58Z", "text": "Time for some updates.\r\n- As suggested by @ysds, I've increased the `$rfs-base-font-size` to `1.25rem`. The result:\r\n  - Large inputs don't rescale by default\r\n  - It generates less css\r\n  - The displays rescale enough on smaller viewports, because I've also increased the `$rfs-factor`\r\n- Because of the changes to the form controls, the `$input-height-inner-sm` and `$input-height-inner-sm` became unneeded. I eventually dropped them because these are variables that are generated by other variables and not used anywhere else in the code, they were only used to calculate `$input-height-sm` & `$input-height-lg`.\r\n\r\nI did some changes upstream and made a branch for the next major version of RFS which is in sync with this PR: https://github.com/twbs/rfs/tree/v8. This branch has some automated testing, so that we'll not break anything if we're going to update things in the future.\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM10026", "user": "planetoftheweb", "root": "ROOT100", "reply_to": "COM10025", "timestamp": "2019-01-02T03:13:27Z", "text": "This is really slick. One of my pet peeves is that I always want fonts on my phone to be bigger, not smaller. I like the limits placed here on the sample site, they seem reasonable and I like that there's a variable for setting the minimum. Well done.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10027", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM10026", "timestamp": "2019-02-07T22:39:52Z", "text": "Never thought I would merge this myself, thanks a lot Bootstrap community \u2764\ufe0f", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM10028", "user": "weilinzung", "root": "ROOT100", "reply_to": "COM10027", "timestamp": "2019-02-11T20:20:17Z", "text": "Just updated to `4.3.0`. All of the font sizes are messed up.\r\n\r\nI use this custom `mixins` with the Bootstrap 4: https://www.smashingmagazine.com/2015/06/responsive-typography-with-sass-maps/\r\n\r\nI am confused because I add this `mixins` to as own which should not effect any updates from Bootstrap. All of updates below 4.3.0 are fine.\r\n\r\nWhen I inspect it, it looks like outputting the SASS.\r\n`font-size: (null: 3rem, 1.2, lg: 2.6rem, md-max: 1.6rem, xs-md: 1.5rem); `", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10029", "user": "MartijnCuppens", "root": "ROOT100", "reply_to": "COM10028", "timestamp": "2019-02-12T08:43:59Z", "text": "Hi @weilinzung,\r\n\r\nBootstrap now uses the `font-size` mixin from [RFS](https://github.com/twbs/rfs). It looks like you're passing a sass map to the mixin while you should just pass a font size to it. It doesn't work the same as the article you're referring to.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT101", "user": "MartinLion", "root": "ROOT101", "reply_to": null, "timestamp": "2014-10-28T16:41:25Z", "text": "loading my own datasets Hi all,  I am very new in scikit-learn.   My questions is: how to download my own dataset (csv file).  I will be highly appreciated any answers.  Thanks. Martin ", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM1010", "user": "AlexanderFabisch", "root": "ROOT101", "reply_to": "ROOT101", "timestamp": "2014-10-28T22:45:14Z", "text": "The documentation of sklearn is really very useful and should answer your question: http://scikit-learn.org (basically you have to put your data in numpy arrays)\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1011", "user": "jnothman", "root": "ROOT101", "reply_to": "COM1010", "timestamp": "2014-10-28T23:37:16Z", "text": "This is something that could have a bit more documentation than is in there\ncurrently. You might find Pandas useful.\n\nOn 29 October 2014 09:45, Alexander Fabisch notifications@github.com\nwrote:\n\n>  The documentation of sklearn is really very useful and should answer\n> your question: http://scikit-learn.org (basically you have to put your\n> data in numpy arrays)\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60845063\n> .\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1012", "user": "AlexanderFabisch", "root": "ROOT101", "reply_to": "COM1011", "timestamp": "2014-10-29T07:07:50Z", "text": "@jnothman Should we reopen this issue and add a new section in the documentation? For example in this section: http://scikit-learn.org/stable/tutorial/basic/tutorial.html (\"Loading your own data\").\n", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM1013", "user": "jnothman", "root": "ROOT101", "reply_to": "COM1012", "timestamp": "2014-10-29T07:25:02Z", "text": "see #2801\n\nOn 29 October 2014 18:07, Alexander Fabisch notifications@github.com\nwrote:\n\n>  @jnothman https://github.com/jnothman Should we reopen this issue and\n> add a new section in the documentation? For example in this section:\n> http://scikit-learn.org/stable/tutorial/basic/tutorial.html (\"Loading\n> your own data\").\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60882069\n> .\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1014", "user": "MartinLion", "root": "ROOT101", "reply_to": "COM1013", "timestamp": "2014-10-29T10:15:50Z", "text": "My own dataset means the dataset that I have collected by my self, not the\nstandard dataset that all machine learning have in their depositories (e.g.\niris or diabetes).\n\nI have a simple csv file and I on my desktop and I want to load it inside\nscikit-learn. That will allow me to use scikit-learn properly and introduce\nit to my colleges to serve our community.\n\nI need a very simple and easy way to do so.\n\nI will be highly appreciated any useful advice.\n\nOn 29 October 2014 15:25, jnothman notifications@github.com wrote:\n\n> see #2801\n> \n> On 29 October 2014 18:07, Alexander Fabisch notifications@github.com\n> wrote:\n> \n> > @jnothman https://github.com/jnothman Should we reopen this issue and\n> > add a new section in the documentation? For example in this section:\n> > http://scikit-learn.org/stable/tutorial/basic/tutorial.html (\"Loading\n> > your own data\").\n> > \n> > \u2014\n> > Reply to this email directly or view it on GitHub\n> > <\n> > https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60882069>\n> > \n> > .\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60883212\n> .\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1015", "user": "jnothman", "root": "ROOT101", "reply_to": "COM1014", "timestamp": "2014-10-29T11:12:22Z", "text": "See http://pandas.pydata.org/pandas-docs/stable/io.html\n\nOn 29 October 2014 21:15, MartinLion notifications@github.com wrote:\n\n>  My own dataset means the dataset that I have collected by my self, not\n> the\n> standard dataset that all machine learning have in their depositories\n> (e.g.\n> iris or diabetes).\n> \n> I have a simple csv file and I on my desktop and I want to load it inside\n> scikit-learn. That will allow me to use scikit-learn properly and\n> introduce\n> it to my colleges to serve our community.\n> \n> I need a very simple and easy way to do so.\n> \n> I will be highly appreciated any useful advice.\n> \n> On 29 October 2014 15:25, jnothman notifications@github.com wrote:\n> \n> > see #2801\n> > \n> > On 29 October 2014 18:07, Alexander Fabisch notifications@github.com\n> > wrote:\n> > \n> > > @jnothman https://github.com/jnothman Should we reopen this issue\n> > > and\n> > > add a new section in the documentation? For example in this section:\n> > > http://scikit-learn.org/stable/tutorial/basic/tutorial.html (\"Loading\n> > > your own data\").\n> > > \n> > > \u2014\n> > > Reply to this email directly or view it on GitHub\n> > > <\n> > \n> > https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60882069>\n> > \n> > > .\n> > \n> > \u2014\n> > Reply to this email directly or view it on GitHub\n> > <\n> > https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60883212>\n> > \n> > .\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60899671\n> .\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1016", "user": "MartinLion", "root": "ROOT101", "reply_to": "COM1015", "timestamp": "2014-10-29T12:19:24Z", "text": "Thanks for the link. I checked it out, but the process looks complicated.\nPerhaps if there is a short youtube video explains the process much easier,\notherwise I do not know what to do to solve this matter.\n\nOn 29 October 2014 19:12, jnothman notifications@github.com wrote:\n\n> See http://pandas.pydata.org/pandas-docs/stable/io.html\n> \n> On 29 October 2014 21:15, MartinLion notifications@github.com wrote:\n> \n> > My own dataset means the dataset that I have collected by my self, not\n> > the\n> > standard dataset that all machine learning have in their depositories\n> > (e.g.\n> > iris or diabetes).\n> > \n> > I have a simple csv file and I on my desktop and I want to load it\n> > inside\n> > scikit-learn. That will allow me to use scikit-learn properly and\n> > introduce\n> > it to my colleges to serve our community.\n> > \n> > I need a very simple and easy way to do so.\n> > \n> > I will be highly appreciated any useful advice.\n> > \n> > On 29 October 2014 15:25, jnothman notifications@github.com wrote:\n> > \n> > > see #2801\n> > > \n> > > On 29 October 2014 18:07, Alexander Fabisch notifications@github.com\n> > > \n> > > wrote:\n> > > \n> > > > @jnothman https://github.com/jnothman Should we reopen this issue\n> > > > and\n> > > > add a new section in the documentation? For example in this section:\n> > > > http://scikit-learn.org/stable/tutorial/basic/tutorial.html\n> > > > (\"Loading\n> > > > your own data\").\n> > > > \n> > > > \u2014\n> > > > Reply to this email directly or view it on GitHub\n> > > > <\n> > \n> > https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60882069>\n> > \n> > > > .\n> > > \n> > > \u2014\n> > > Reply to this email directly or view it on GitHub\n> > > <\n> > \n> > https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60883212>\n> > \n> > > .\n> > \n> > \u2014\n> > Reply to this email directly or view it on GitHub\n> > <\n> > https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60899671>\n> > \n> > .\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60906075\n> .\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1017", "user": "jnothman", "root": "ROOT101", "reply_to": "COM1016", "timestamp": "2014-10-29T12:45:42Z", "text": "It probably looks something like:\n\nimport pandas as pd\ndata = pd.read_csv(open('myfile.csv'))\ntarget = data[target_column_name]\ndel data[target_column_name]\n\n# Then fit a scikit-learn estimator\n\nSVC().fit(data, target)\n\nOn 29 October 2014 23:19, MartinLion notifications@github.com wrote:\n\n>  Thanks for the link. I checked it out, but the process looks complicated.\n> Perhaps if there is a short youtube video explains the process much\n> easier,\n> otherwise I do not know what to do to solve this matter.\n> \n> On 29 October 2014 19:12, jnothman notifications@github.com wrote:\n> \n> > See http://pandas.pydata.org/pandas-docs/stable/io.html\n> > \n> > On 29 October 2014 21:15, MartinLion notifications@github.com wrote:\n> > \n> > > My own dataset means the dataset that I have collected by my self, not\n> > > the\n> > > standard dataset that all machine learning have in their depositories\n> > > (e.g.\n> > > iris or diabetes).\n> > > \n> > > I have a simple csv file and I on my desktop and I want to load it\n> > > inside\n> > > scikit-learn. That will allow me to use scikit-learn properly and\n> > > introduce\n> > > it to my colleges to serve our community.\n> > > \n> > > I need a very simple and easy way to do so.\n> > > \n> > > I will be highly appreciated any useful advice.\n> > > \n> > > On 29 October 2014 15:25, jnothman notifications@github.com wrote:\n> > > \n> > > > see #2801\n> > > > \n> > > > On 29 October 2014 18:07, Alexander Fabisch <\n> > > > notifications@github.com>\n> > > > \n> > > > wrote:\n> > > > \n> > > > > @jnothman https://github.com/jnothman Should we reopen this\n> > > > > issue\n> > > > > and\n> > > > > add a new section in the documentation? For example in this\n> > > > > section:\n> > > > > http://scikit-learn.org/stable/tutorial/basic/tutorial.html\n> > > > > (\"Loading\n> > > > > your own data\").\n> > > > > \n> > > > > \u2014\n> > > > > Reply to this email directly or view it on GitHub\n> > > > > <\n> > \n> > https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60882069>\n> > \n> > > > > .\n> > > > \n> > > > \u2014\n> > > > Reply to this email directly or view it on GitHub\n> > > > <\n> > \n> > https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60883212>\n> > \n> > > > .\n> > > \n> > > \u2014\n> > > Reply to this email directly or view it on GitHub\n> > > <\n> > \n> > https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60899671>\n> > \n> > > .\n> > \n> > \u2014\n> > Reply to this email directly or view it on GitHub\n> > <\n> > https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60906075>\n> > \n> > .\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-60913843\n> .\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1018", "user": "MechCoder", "root": "ROOT101", "reply_to": "COM1017", "timestamp": "2014-10-29T13:40:34Z", "text": "You could also have a look at `np.genfromtxt` . Might be useful.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1019", "user": "MartinLion", "root": "ROOT101", "reply_to": "COM1018", "timestamp": "2014-10-29T14:08:48Z", "text": "Hi  jnothman, \nThank you so much for your help, I really appreciate your  cooperation.\n\nI tried applying your code. Thus, once I interned (import pandas as pd). Directly I had the following message in red color:\n\nimport pandas as pd\n No module named 'dateutil'\nTraceback (most recent call last):\n  File \"<pyshell#0>\", line 1, in <module>\n    import pandas as pd\n  File \"C:\\Python34\\lib\\site-packages\\pandas__init__.py\", line 7, in <module>\n    from . import hashtable, tslib, lib\n  File \"pandas\\tslib.pyx\", line 37, in init pandas.tslib (pandas\\tslib.c:76813)\nImportError: No module named 'dateutil'\n\nWhat should I do? \nThanks a lot\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10110", "user": "MechCoder", "root": "ROOT101", "reply_to": "COM1019", "timestamp": "2014-10-29T14:15:04Z", "text": "It just means you do not have the dateutil module installed. You can install it by doing \n\n```\nsudo apt-get install python-dateutil\n```\n\nhth\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10111", "user": "MechCoder", "root": "ROOT101", "reply_to": "COM10110", "timestamp": "2014-10-29T14:17:06Z", "text": "You can have a look at this for more details, http://stackoverflow.com/questions/20853474/importerror-no-module-named-dateutil-parser\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10112", "user": "MartinLion", "root": "ROOT101", "reply_to": "COM10111", "timestamp": "2014-10-29T15:55:28Z", "text": "Thanks MechCoder for your contribution. \n\nI tried \"sudo apt-get install python-dateutil\", but it is not clear to me at what stage should indicate  this code?\nDo you think that there is an easy way to load my (excel or csv) file suing any simple ways such as open folder (regular way). There is another matter also which how to determine the class label that I want to predict form my dataset using scikit-learn. But anyway this step supposed to be after loading the file itself. Not easy process at all.\n\nIs there any youtube tutorial about loading dataset (not iris which is everywhere or other famous. stuff). Video is easy than links  \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10113", "user": "afzal", "root": "ROOT101", "reply_to": "COM10112", "timestamp": "2015-08-22T00:33:11Z", "text": "HI all,\nI wrote the following code:\n\nimport pandas as pd\ndata= pd.read_csv(open(home/maxinet/Desktop/1.csv))\n\nand i got this error:\nFile \"<ipython-input-10-dd0ba70fe93f>\", line 2\n    data= pd.read_csv(open(home/maxinet/Desktop/1.csv))\n                                                                              ^\nSyntaxError: invalid syntax\n\ncould you plz guide me.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10114", "user": "AlexanderFabisch", "root": "ROOT101", "reply_to": "COM10113", "timestamp": "2015-08-22T06:11:03Z", "text": "We could tell you what the problem is but I think in this case you will learn more from it if you find it on your own. You should read the error message carefully. It is a Python syntax error.\n\n```\n  File \"\", line 2\n    data= pd.read_csv(open(home/maxinet/Desktop/1.csv))\n                                                    ^\nSyntaxError: invalid syntax\n```\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10115", "user": "MartinLion", "root": "ROOT101", "reply_to": "COM10114", "timestamp": "2015-08-22T08:03:55Z", "text": "On 22 Aug 2015 08:33, \"samira afzal\" notifications@github.com wrote:\n\n> HI all,\n> I wrote the following code:\n> \n> import pandas as pd\n> data= pd.read_csv(open(home/maxinet/Desktop/1.csv))\n> \n> and i got this error:\n> File \"\", line 2\n> data= pd.read_csv(open(home/maxinet/Desktop/1.csv))\n> ^\n> SyntaxError: invalid syntax\n> \n> could you plz guide me.\n\nI recommend you finding another tool where you can work with easily without\nheadache yourself with this particular one. This is what I did myself.\n\nGood luck\nMartin\n\n> \u2014\n> Reply to this email directly or view it on GitHub.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10116", "user": "jnothman", "root": "ROOT101", "reply_to": "COM10115", "timestamp": "2015-08-22T10:33:01Z", "text": "To be clear, these previous posters are saying that being somewhat\ncomfortable with the Python language is a prerequisite to using\nscikit-learn. You have missed some quotes around a string. This shows great\nunfamiliarity with Python (and a characteristic of most programming\nlanguages), and scikit-learn is probably not the best place to start.\n\nOn 22 August 2015 at 18:04, MartinLion notifications@github.com wrote:\n\n> On 22 Aug 2015 08:33, \"samira afzal\" notifications@github.com wrote:\n> \n> > HI all,\n> > I wrote the following code:\n> > \n> > import pandas as pd\n> > data= pd.read_csv(open(home/maxinet/Desktop/1.csv))\n> > \n> > and i got this error:\n> > File \"\", line 2\n> > data= pd.read_csv(open(home/maxinet/Desktop/1.csv))\n> > ^\n> > SyntaxError: invalid syntax\n> > \n> > could you plz guide me.\n> \n> I recommend you finding another tool where you can work with easily without\n> headache yourself with this particular one. This is what I did myself.\n> \n> Good luck\n> Martin\n> \n> > \u2014\n> > Reply to this email directly or view it on GitHub.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-133650026\n> .\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10117", "user": "davidavdav", "root": "ROOT101", "reply_to": "COM10116", "timestamp": "2015-11-27T08:45:51Z", "text": "Just want to support @MartinLion --- I am a scikit-learn newbie and have just have spent a frustrating time going thought the docs, and I can't find anywhere how to read my own data (and not a prepared toy dataset), and what the python format of data is.  \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10118", "user": "raghavrv", "root": "ROOT101", "reply_to": "COM10117", "timestamp": "2015-11-27T10:25:25Z", "text": "Kindly refer - \n- [How do I load my data to work with scikit-learn?](http://stackoverflow.com/q/21492726/3109769)\n- [How to load data from CSV file?](http://stackoverflow.com/q/11023411/3109769)\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10119", "user": "GaelVaroquaux", "root": "ROOT101", "reply_to": "COM10118", "timestamp": "2015-11-27T11:05:12Z", "text": ">   \u2022 How do I load my data to work with scikit-learn?\n>   \u2022 How to load data from CSV file?\n\nWe should add these in the FAQ.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10120", "user": "raghavrv", "root": "ROOT101", "reply_to": "COM10119", "timestamp": "2015-11-27T14:43:55Z", "text": "should we instead add as a section in the tutorial below/above [\"Loading an example dataset\"](http://scikit-learn.org/stable/tutorial/basic/tutorial.html#loading-an-example-dataset)?\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10121", "user": "raghavrv", "root": "ROOT101", "reply_to": "COM10120", "timestamp": "2015-11-27T14:46:10Z", "text": "Also could you tag this \"Question\", \"Documentation\" and reopen it?\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10122", "user": "GaelVaroquaux", "root": "ROOT101", "reply_to": "COM10121", "timestamp": "2015-11-27T14:50:54Z", "text": "> should we instead add as a section in the tutorial here?\n\nWe should reference it. But I don't see this as tutorial material because\nit is outside the scope of scikit-learn. We can only give pointers\n\nThat's an answer that the users really don't want to hear, because there\npoint of view is that they have a lump of data and they want it inside\nscikit-learn. The answer is: this is not a problem that scikit-learn\nsolves, go see pandas if you have CSV, scikit-image if you have images,\ndatabase connectors (SQLAlchemy?) if you work on databases...\n\nI guess that we should have a sentence like this in the tutorial, where\nyou reference, with pointers.\n\nAs a side note, the kind of errors hit by the users on the thread of this\nissue (lack of basic knowledge of Python for instance) tells me that we\ncannot solve their problem. They need to go to entry-level tutorials on\nPython, and get a bigger picture. Maybe we should make sure that we give\npointers to these in the right spots, eg early on in the tutorial.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10123", "user": "MartinLion", "root": "ROOT101", "reply_to": "COM10122", "timestamp": "2015-11-27T18:37:41Z", "text": "> > should we instead add as a section in the tutorial here?\n> \n> We should reference it. But I don't see this as tutorial material because\n> it is outside the scope of scikit-learn. We can only give pointers\n> \n> That's an answer that the users really don't want to hear, because there\n> point of view is that they have a lump of data and they want it inside\n> scikit-learn. The answer is: this is not a problem that scikit-learn\n> solves, go see pandas if you have CSV, scikit-image if you have images,\n> database connectors (SQLAlchemy?) if you work on databases...\n> \n> I guess that we should have a sentence like this in the tutorial, where\n> you reference, with pointers.\n> \n> As a side note, the kind of errors hit by the users on the thread of this\n> issue (lack of basic knowledge of Python for instance) tells me that we\n> cannot solve their problem. They need to go to entry-level tutorials on\n> Python, and get a bigger picture. Maybe we should make sure that we give\n> pointers to these in the right spots, eg early on in the tutorial.\n\nWell, take it easy!!!\n\nI don't know whether you are one of scikit-learn staff or not, but I need\nto say that your way of talking is harming both scikit-learn staff and\nusers (us), due to the two reasons:\n\nFirst reason, criticizing people (like what you did) and assuming that they\nare novice in Python so they don't know how to work with scikit-learn,\nmeans you or the staff are trying to blind their eyes to the truth that\nscikit-learn staff are not able to create a clear tutorial to allow loading\nthe real data, at least. In addition, pretending that the tutorial of\nscikit-learn is perfect in spite all the questions regarding loading the\nreal data (not the toy data as it is too easy to be imported comparing to\nthe real data) is something needs to be reconsidered, and this means that\nscikit-learn staff don't care about the name of scikit-learn at all.\n\nSecond, we can understand from your unsuitable way of talking that you\nalready forgot that  scikit-learn is a product, and we as users are\ncustomers, so either you or the staff of scikit-learn should respect all of\nus and thank us for any comment or bug fixing. This is the professional way\nof behavior. So I recommend you to think of your words before saying them. If\nyou are knowing the way of loading the real data and you'd like to help,\ndon't only say go see pandas, better you answer people's question nicely\nrather than hurting them with your words, but if you're simply not able to\ndo that, so keep quite.\n\nOn the other hand, regarding the question \"should we instead add as a\nsection in the tutorial here?\", I would like to say \"_YES_\", you or\nscikit-learn staff should add a section in the official tutorial about how\nto load your own data either CSV, or ARFF or text or whatever, as users are\ninterested to load their own data, this is very critical issue should be\nconsidered in the tutorial (not to be ignored). *If you rely on the user,\nthen what is your work? *\n\nNevertheless, for those who are still struggling with scikit-learn, I would\nlike to say, this is not the end of the world, and as I mentioned\npreviously, find another to tool make your life much easier. For this\nreason, and in order to save your time, I would like to recommend some\ntools to assist you in data mining procedures. For instance,  Waikato\nEnvironment for Knowledge Analysis (WEKA),\nhttp://www.cs.waikato.ac.nz/ml/weka/, last version is  WEKA 3-7-13, is a\ncollection of machine learning algorithms for data mining tasks. WEKA\nallows you to use its schemes either from GUI or writing Java code, so its\nvery easy for non-programmers. Additional to WEKA, R is also an excellent\ntool for data mining stuff, you can also perform tasks of R from WEKA or\nvice versa. However, if you have a patience to design a prediction process\nmanually (drag/drop), RapidMiner is a great tool for this propose where you\ncan design a very nice flow to achieve your target.\n\nThanks David van Leeuwen for your support.\n\nGood luck in your analysis.\n\nCheers,\nMartin\n\n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/scikit-learn/scikit-learn/issues/3808#issuecomment-160153930\n> .\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10124", "user": "raghavrv", "root": "ROOT101", "reply_to": "COM10123", "timestamp": "2015-11-27T20:48:25Z", "text": "Hey Martin,\n\nKindly don't be offended.\n\nHe did not criticize :) He, being one of the top contributors to scikit-learn has to make tough decisions as to what will go into our codebase and what will not, as a more verbose documentation or tutorial might not be preferable for a lot of people. Gael has in fact contributed a lot of user guides himself to scikit learn to help users.\n\nThe reason why he was opposing that addition to the tutorial was that there are multitude of ways in which users have their data stored and such a user guide on how to get the input data from all of them (a text file/csv file/database/zipped archive), is indeed out of scope for scikit learn, which is a machine learning library.\n\nThe most important thing to note here is that **it is very clearly explained by documentations of libraries which handle data, like numpy or pandas.**\n\nIt is expected from the user that he or she knows this! Since it seems to not be very clear, he suggests that we add a FAQ, pointing the user to such userguides, which are more elaborate than we could possibly get :)\n\nIt may appear that our tutorial could be a bit more elaborate on how the inputs are obtained. But the thing, in general, with userguides is that, it could _always_ be a little bit more elaborate, which makes us set a hard limit on how detailed our userguides can get, to help contain the userguide in a maintainable format :) If you think from that perspective, you yourself would understand our situation.\n\nAs this issue is open someone will indeed send a PR soon adding a nice FAQ entry and an example, maybe, which could help clarify your (or any other new user's) doubts on input formats.\n\nCheers!\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10125", "user": "emmanuelle", "root": "ROOT101", "reply_to": "COM10124", "timestamp": "2015-11-27T21:09:03Z", "text": "Hello @MartinLion ,\n\nwe understand your eagerness to solve your problem, and your frustration when it is not solved.\n\nHowever, you seem quite misinformed about what is scikit-learn, how it works, and how the project is developed. Therefore, I would like to make some points clear for you. As you can see from\nhttp://scikit-learn.org/stable/about.html, scikit-learn is a community effort that is developed by a team of volunteers, mostly on their free time. Ga\u00ebl is one of the creators of the project and its current leader:\nscikit-learn would certainly not be the same without his contribution (the same for other volunteers), and he certainly did not deserve your dismissive words.\n\nWhat I would like to emphasize is that there is no such thing as a scikit-learn \"product\", or scikit-learn \"staff\" (only a handful of people have worked full time on the project). You mention \"we as users are\ncustomers\", but how much are you paying for using scikit-learn? Despite the important development cost, users get scikit-learn for free (and of course that's how it's intended to be). In fact, the development of the project relies on a fragile alchemy: users' needs being a top priority for developers, and users reporting bugs and concerns in the most positive way. The kind of \"ranting\" that you wrote can be very discouraging for developers, who contribute their free time and their expertise just because they believe that scikit-learn is a useful tool for the community. Some prominent developers stopped contributing to open-source software precisely because of such \"customer-like attitude\" of a few people underlining only shortcomings, and dismissing the huge development efforts. Please try to see the bright side as well: you received advice and comments from a lot of people, I'm sure that there was something for you to learn out of it, even if it did not solve your problem. \n\nAlso, although users' needs are indeed a top priority of scikit-learn (it has an amazing documentation, of which most scientific Python packages can be jealous!), each software addresses a well-targeted niche of users, and it is just normal that scikit-learn cannot fit all users. For example, it is preferable to use scikit-learn with already a good knowledge of Scientific Python. So, I'm really glad that you found a\npackage that suited your needs better, but please also acknowledge the time and good will that people gave away when answering you.\n\nSo, folks, let's all show some good will and keep a constructive dialog.\nThat's how the project we love will keep on rocking!\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10126", "user": "AlexanderFabisch", "root": "ROOT101", "reply_to": "COM10125", "timestamp": "2015-11-27T23:13:01Z", "text": "> For this reason, and in order to save your time, I would like to recommend some tools to assist you in data mining procedures. For instance, Waikato Environment for Knowledge Analysis (WEKA), http://www.cs.waikato.ac.nz/ml/weka/, last version is WEKA 3-7-13, is a collection of machine learning algorithms for data mining tasks. WEKA allows you to use its schemes either from GUI or writing Java code, so its very easy for non-programmers. Additional to WEKA, R is also an excellent tool for data mining stuff, you can also perform tasks of R from WEKA or vice versa. However, if you have a patience to design a prediction process manually (drag/drop), RapidMiner is a great tool for this propose where you can design a very nice flow to achieve your target.\n\nMaybe we should make clear that scikit-learn is a Python **library**. It does not have the same scope as WEKA or RapidMiner. It fits perfectly into the [scientific Python ecosystem](http://www.scipy-lectures.org/) but you should be willing to write code if you want to use it.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10127", "user": "davidavdav", "root": "ROOT101", "reply_to": "COM10126", "timestamp": "2015-11-28T09:32:38Z", "text": "Perhaps I should elaborate on my original frustration, to give you some context. \n\nI've been programming in Python almost exclusively for a year now (I am a late convert), and am fairly familiar with the ecosystem---I've done lot's of webservice related things, but also manipulation of resources related to automatic speech recognition.  I do my scientific work in [Julia](http://julialang.org/) since a couple of years, and before that, in R, octave, c++/c (some 30 years in total).  The Julia ecosystem is quite dynamic, and it is all very exciting, but Python just has this very large ecosystem and very clean coding, which makes it very attractive to use for little side experiments.  This time I had to do some topic classification of (single sentence) text documents. \n\nNow there is an abundant choice of language technology tools in Python, and I believe that via [lda](https://pythonhosted.org/lda/index.html) I got to scikit-learn.  Great tutorials, lovely datasets and all, but I found it very difficult to find out how to organize my own data so that I could load this in.  Just now, I browsed through the user guide again to find the docs for \"load_files\", but I could't find an entry.  So a google search for \"sklearn.datasets.load_files\" got me there just now, and I happened to remember the particular module path from more painstaking searches yesterday (it is mentioned somewhere in a tutorial).  For me, the essential information would have been: \"Organize your data one document per file, one directory per class\"---more or less what's under the documentation for  [load_files](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_files.html).   This all makes perfect sense, but I come from a community where usual formats are \"one datapoint per line\", often with the class label on that line.  But having said all this, I am pretty impressed how the Python (text) community has standardized data representation, from what I've seen so far.  But perhaps because of the widely used standard data representation, this aspect has naturally less attention in documentation. \n\nAs a final note, whenever I try to teach students how to use some scientific tool set or another, I have to spend quite some time on \"how to import your data\".  Nobody likes to do it, it can be a lot of effort for what you potentially use only once, and is therefore always a difficult threshold. \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10128", "user": "GaelVaroquaux", "root": "ROOT101", "reply_to": "COM10127", "timestamp": "2015-11-28T09:58:25Z", "text": "@davidavdav \n\nI agree that loading data is a difficult and important thing. However, it is a domain-specific problem. You have a particular type of data. I have another. My data is medical images of brain activity. I can tell you how I organize my data and load them. I can even tell you that we have written a whole package about this, with its own documentation. But that will probably not help you.\n\nWhat you want is something that tells you how to organize and load _your_ data. Now, it may be that your data is something fairly classic, that many people have; for instance tabular data most often stored in CSV files. In which case there is a need for a package doing this data loading. I don't believe that it should be in scikit-learn. It needs to be in a package that is specialized for this data. For instance, we are not going to put image processing in scikit-learn. For tabular data, the dedicated package is pandas; as I mentioned in my reply we need to point to it. We, the scikit-learn team, want to make plugin pandas into scikit-learn easier. But it is not as easy as it may seem and it takes time (one of our core devs is prototyping something).\n\nI realize rereading your post that your data is most likely text documents. So my two examples of data (medical images and tabular data) were both wrong :$. Maybe the documentation on processing text with scikit-learn could indeed be improved and touch a bit on data organization. I don't know, I very seldom process text. But if you want to do add a few words on this, you are most welcomed to do a pull request. Anyhow, this illustrate my point about the diversity of the data: this whole thread is mostly about loading CSV files, as can be seen from earlier comments (before the thread exploded into a rant). The important thing is not the \"CSV\", which is the container, but the data model that underlies a CSV file. This data model is that of columns of data with different nature. It's a very different data model than processing text documents.\n\nAnd finally, you are unhappy that teaching people \"how to import your data\" is time consuming. I don't think that there is an easy fix for this, even in a specific domain. The reason being that data meaning (ie data semantics) is still very much an open area. It's intrinsically hard to describe what the data means and how it's organized. You can try a simple experience: grab a dataset from someone you don't know, about an experiment you don't know, and try understanding it. Not even loading it, just understanding it. I am sure that it will take time. What takes a human time tends to be very difficult for a computer.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10129", "user": "amueller", "root": "ROOT101", "reply_to": "COM10128", "timestamp": "2016-09-12T22:52:26Z", "text": "Hm I don't think we added pointers to the FAQ yet. It's certainly a FAQ.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT102", "user": "matti", "root": "ROOT102", "reply_to": null, "timestamp": "2020-09-03T20:22:01Z", "text": "cnn.com time to interactive is 11s-22s screenshot from pagespeed, which says 11s, my own i9 macbook16 says 22s with lighthouse\r \r <img width=\"1354\" alt=\"image\" src=\"https://user-images.githubusercontent.com/3893/92163261-0bb3c280-ee3c-11ea-94e6-9318eccbf30e.png\">\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1020", "user": "devtools-bot", "root": "ROOT102", "reply_to": "ROOT102", "timestamp": "2020-09-03T20:27:13Z", "text": "Thanks! Appreciate you filing this bug. :clap:\n\nThis is a known issue, most well described in #10657. So, **we'll automatically close this as a duplicate**.\n\n:robot: Beep beep boop. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1021", "user": "matti", "root": "ROOT102", "reply_to": "COM1020", "timestamp": "2020-09-03T20:31:55Z", "text": "@patrickhulce how is a clearly wrong result due to variability? anyone can see that cnn time to interactive is not 11s-22s", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1022", "user": "patrickhulce", "root": "ROOT102", "reply_to": "COM1021", "timestamp": "2020-09-03T20:38:28Z", "text": "Ah, from your bug report it appeared as though you were asking why it's 11s in one environment and 22s in another, which is an extremely common question answered by the linked documentation :)\r\n\r\n> anyone can see that cnn time to interactive is not 11s-22s\r\n\r\nI think there's a misunderstanding with what the \"Time to Interactive\" metric measures then. Have you read through [the TTI docs](https://web.dev/tti/)? CNN definitely has a ton of main-thread work and is one of the canonical examples of a high TTI.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1023", "user": "matti", "root": "ROOT102", "reply_to": "COM1022", "timestamp": "2020-09-03T20:50:01Z", "text": "So the docs say:\r\n\r\n> Measuring TTI is important because some sites optimize content visibility at the expense of interactivity. This can create a frustrating user experience: the site appears to be ready, but when the user tries to interact with it, nothing happens.\r\n\r\nBut this is simply not true, it does not take 11s for CNN to be interactive.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1024", "user": "hooligani", "root": "ROOT102", "reply_to": "COM1023", "timestamp": "2020-09-03T20:51:22Z", "text": "from web.dev\r\n\r\n```\r\nTTI measures how long it takes a page to become fully interactive. A page is considered fully interactive when:\r\n\r\nThe page displays useful content, which is measured by the First Contentful Paint,\r\nEvent handlers are registered for most visible page elements, and\r\nThe page responds to user interactions within 50 milliseconds.\r\n```\r\n\r\nJust open a browser to cnn.com and you can start clicking interacting with it after 1 second latest. No frustration from the user.\r\n\r\nJust making the case if TTI or LCP even try to model the REAL user experience or have we given up on that already.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1025", "user": "patrickhulce", "root": "ROOT102", "reply_to": "COM1024", "timestamp": "2020-09-03T21:12:48Z", "text": "> The page responds to user interactions within 50 milliseconds.\r\n\r\nThat is the root factor at play here. Lighthouse computes this value faithfully in the case of CNN because holy crap look at that main-thread (16\" Macbook i9).\r\n\r\n![image](https://user-images.githubusercontent.com/2301202/92168554-4c8de600-ee00-11ea-8773-aaf1c4377046.png)\r\n\r\n\r\nIt sounds like you disagree that this 50ms task limit is a reasonable condition to have in an interactivity metric, but that's not really something that's up for debate. That's the metric definition after years of work by a Chrome team dedicated to metrics and dozens of evaluated alternatives you're free to read about if you wish. \r\n\r\nIf it helps, the weight of TTI in the overall score has been steadily declining over the past 2 years and is unlikely to increase in the near future. It does, however, capture an important moment when the page is actually done loading all of its stuff, and it won't be disappearing anytime soon.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT103", "user": "metaphoricalsasquash", "root": "ROOT103", "reply_to": null, "timestamp": "2018-09-30T13:05:25Z", "text": "change keyframe value \"frame:\" when SpriteNode->Animation->HFrames changes **Godot version:**\r 3.0.6, 3.0.7, 3.1.alpha.calinou.c320d93\r \r **OS/device including version:**\r Win7Pro 64bit, Intel-internal/NVIDIA\r \r **Issue description:**\r Working in Frame-by-frame Animation with Spritesheets is a bit tedious right now, see discussion here: [12469](https://github.com/godotengine/godot/issues/12469)\r However another, maybe far more important issue, is the exponential workload created when adding frames to an existing animation in a spritesheet animation. **This makes iteration almost impossible.**\r Adding frames to the bottom of the spritesheet is no problem at all, as increasing the Vframe does not change existing keyframes. Adding frames horizontally however, breaks the animations, because frame: count the cells in the spritesheet from left to right and keyframes don't update their \"frame:\" value to added cells in every row.\r \r My current workaround involves numbering each frame in the spritesheet with current and previous keyframe numbers in an external graphics editor, then go to every Animation and every track and every keyframe and manually set the new value. I hope you can see how crazy this is and becomes even more so the more animations/tracks/keyframes you have. In addition to the stupidity of the task, it's super easy to incorporate mistakes in the procedure, and hence demands a lot of concentration. \r I do not wish this job on my fiercest enemy.\r \r **Proposed solution:**\r Update Keyframe value \"frame:\" when Hframes changed depending on what VFrame the frame: was set and how many Hframes where added. For instance:\r \r Hframes =+1:\r Keyframe in VFrame row 0: update frame: value = value \r Keyframe in VFrame row 1: update frame: value =-1\r Keyframe in VFrame row 5: update frame: value =-5\r \r Hframes =+3:\r Keyframe in VFrame row 0: update frame: value = value \r Keyframe in VFrame row 1: update frame: value =-3\r Keyframe in VFrame row 5: update frame: value =-15\r \r EDIT: \r I spend a day and a halve making another graphic in hopes newcomers to this issue can gasp it quickly:\r ![keyframes-example-explained2](https://user-images.githubusercontent.com/43533832/46406276-875ddf80-c6fa-11e8-801e-cfc1ff81bbd3.png)\r \r \r \r \r \r ![6x2gdicon](https://user-images.githubusercontent.com/43533832/46257896-4cb53680-c4b1-11e8-9633-a9d6b6a3d093.png)\r ![6x3gdicon](https://user-images.githubusercontent.com/43533832/46257898-4d4dcd00-c4b1-11e8-9a08-70d3b3319dd6.png)\r \r \r **Steps to reproduce:**\r \r 1. Create new Scene with Sprite and AnimationPlayer\r 2. Create a new Animation\r 3. Add Texture 6x2gdicon.png to the Sprite, in the Sprite Inspector under \"Animation\" set Vframe 6 and Hframe 2\r 4. Keyframe frames 0 to 11\r 5. Override or change 6x2gdicon.png with 6x3gdicon.png and **change Hframe to 3**\r 6. Watch a broken Animation\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1030", "user": "metaphoricalsasquash", "root": "ROOT103", "reply_to": "ROOT103", "timestamp": "2018-09-30T15:20:32Z", "text": "Is this not a bug? I cannot believe this is how it was intended to work.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1031", "user": "ghost", "root": "ROOT103", "reply_to": "COM1030", "timestamp": "2018-10-01T00:56:40Z", "text": "It's probably not a bug, unless I'm missing something.  There is a lot mentioned in the topic, so I wasn't too sure exactly where the focus was for it.\r\n\r\nRegarding the steps to reproduce.\r\n\r\nAt least on my end HFrames to 3 corrects the animation.  **Edit** - Am I missing something?\r\n\r\n![ezgif com-video-to-gif 1](https://user-images.githubusercontent.com/13004169/46265374-92641480-c52e-11e8-9ae0-d97f56c1dc75.gif)\r\n\r\n\r\nThere is no way to know what's actually on the sprite sheet.  It just uses row and column math to slice it up into identical rectangles.  You'll always have to specify these numbers and conform a spritesheet to fit that alignment.\r\n\r\nAs far as the workflow things, if you want to keep your keyframes correct, as you were saying, additions will probably have to go on the end.  I'm not exactly sure what kind of algorithm you could use that will know where you want to offset the values of existing keyframes to match the insertions into the middle of an updated spritesheet.\r\n\r\nThere is still nothing that knows the content of your spritesheet or what you want at what location.\r\n\r\nIn my experience at least, when I mangle these things in a large project, its just best to write a toolscript to automate the adjustments and fixes of AnimationPlayer keyframes.  Otherwise if its small, doing it by hand may be fastest.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1032", "user": "metaphoricalsasquash", "root": "ROOT103", "reply_to": "COM1031", "timestamp": "2018-10-01T01:47:26Z", "text": ">There is no way to know what's actually on the sprite sheet.\r\n\r\nGodot does not need to know what's on the sprite sheet. All it needs to know is that I when I add a column (increase of Hframes) it will change all already existing keyframes with the \"frame:\" value according to the algorithm proposed in the solution above.\r\n\r\nI do not see how this is **_not_** a bug, to be honest:\r\n**If you already have keyframes set for your frame-by-frame animation, why would you want the _displayed_ frames of already set keyframes change arbitrarily, only because you add a column or row to your spritesheet?**\r\n\r\nIt makes iteration impossible, because it forces you to either have a fixed number of animations or a fixed number of frames per animation when you start your project. \r\nThe only case when this would be less of a problem/bug is when you are creating an exact clone or mini game and you how exactly how many animations or how many frames you will need. But are these the the only kind of games we want for this engine?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1033", "user": "metaphoricalsasquash", "root": "ROOT103", "reply_to": "COM1032", "timestamp": "2018-10-01T02:05:06Z", "text": ">At least on my end HFrames to 3 corrects the animation. \r\n\r\nSadly it does not. What this does and what your gif shows is that it defines the correct cell size of the sprite sheet. What breaks the animation is that different cells are shown. Because \"frame:\" counts the cells from left to right until the end of the first row, then the second row from left to right and so on. Maybe make sure your animation plays slow, you can pause and see what frame it used to be, I've written it below the number of the current keyframe. The red frame for instance is 10, while it was and still should be 7.\r\n\r\nIf this would be a runcycle, the character would not run anymore because the frames would be all mixed up.\r\nI will add another example with a runcycle when I get home, maybe the issue is easier and quicker to grasp then. It will be a few hours though.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1034", "user": "ghost", "root": "ROOT103", "reply_to": "COM1033", "timestamp": "2018-10-01T04:58:16Z", "text": "I'm curious, are there any examples you have showing another game engine doing this kind of re-sequencing?\r\n\r\nPretty sure this is how the sprite sheets are designed, so it wouldn't be a \"bug\".\r\n\r\nThe idea behind it in the current form is that as long as you keep your frames in some kind of sequence going from left to right, top to bottom, it doesn't matter how you arrange the sheets.  The frames should still read in the correct frame order.\r\n\r\nLike doing this for example, wouldn't break your animation keyframes.\r\n\r\n## From 6 by 2\r\n![6x2](https://user-images.githubusercontent.com/13004169/46269799-0cef5d00-c54c-11e8-9fd2-95c5a12c27d8.png)\r\n\r\n## Into a 2 by 8\r\n![2x8](https://user-images.githubusercontent.com/13004169/46269801-0f51b700-c54c-11e8-9486-3ed919119ca4.png)\r\n\r\nSo you need to add some frames to this 2x8 sheet later, they would go in positions to the right of 11 and wrap into the new row.  And if you have a new row, increase it.\r\n\r\nYou would just have to organize and export your spritesheets to maintain this order, and nothing should break later.\r\n\r\nI think I understand that you have some particular workflow you want accommodated, where you use  completely symmetrical spritesheets, and need to extend or contract all cycles uniformly?  Again, not entirely sure.  It sounds at least like you want to toss in a new column, update the frame count, and have the engine modify all your keyframes in all animation players and animations that use that sprite sheet.\r\n\r\nIf that is roughly it, then what you're suggesting solves perhaps only just for that, but what about non-uniform spritesheets?\r\n\r\nIn my work at least, we stuff in animations of all differing lengths, and rarely do we have a set that even give us perfectly filled sheets.\r\n\r\nIn my case, having an update to a spritesheet property do widespread changes to the keyframes is undesirable.  I would think just the action of fiddling with the Hframe and Vframe properties will start mangling all our keyframes if it was making assumptions about how its organized.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1035", "user": "metaphoricalsasquash", "root": "ROOT103", "reply_to": "COM1034", "timestamp": "2018-10-01T17:16:43Z", "text": "hey avencherus, first of all, thank you sticking with me and trying to understand my arguments, I really appreciate it!\r\n\r\nI have no experience using large spritesheets and frame-by-frame animation in other engines, so sadly I cannot give you an example how this would be dealt with elsewhere.\r\n\r\n>The idea behind it in the current form is that as long as you keep your frames in some kind of sequence going from left to right, top to bottom, it doesn't matter how you arrange the sheets. The frames should still read in the correct frame order.\r\n\r\nYes I know. That's precisely the root of the problem.\r\nI do not think I have a particular workflow I want accommodated, the issue applies to the workflow you explained in your last comment just the same as soon as you want iteration and more than a few animations in a single sprite sheet for drawcall and performance reasons.\r\n\r\nPlease bear with me while I try to explain:\r\n![keyframes-example-explainedindetail](https://user-images.githubusercontent.com/43533832/46304171-78ade600-c59d-11e8-8ecb-161ce99c4b13.png)\r\nIf you know of any other way or option to organize, edit, manage and maintain larger amount of animations in a spritesheet, please do share.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1036", "user": "metaphoricalsasquash", "root": "ROOT103", "reply_to": "COM1035", "timestamp": "2018-10-01T18:29:30Z", "text": "Oh and thanks for proposing a solution (From 6 by 2 to 2 by 8)!\r\nWhile this is certainly feasibly for small projects and small Spritesheets, I do not see how it would be feasible for regular sized professional productions meaning anything more than 20 animations per sheet. Essentially, you would have to do the same tedious restructuring with the only difference being you would have to do it outside of Godot. Plus, if you do this for a while you get really \"unreadable\" spritesheets. So for me, that's actually even a bit worse than reassigning keyframe values inside Godot.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1037", "user": "ghost", "root": "ROOT103", "reply_to": "COM1036", "timestamp": "2018-10-01T20:10:22Z", "text": "No problem, I'm just trying to at least understand what you have in mind.  This is a very nice graphic you've made.\r\n\r\nAnd apologies, what you've outlined is all new to me.  This is my first time seeing anyone organize spritesheets that way, so maybe I'm completely in the dark about something.\r\n\r\n> There are basically two ways to organize frame by frame animation.\r\n\r\nI did not see our way in there, so you may feel this is illegitimate.  X)\r\n\r\n![samsheet](https://user-images.githubusercontent.com/13004169/46311022-aa3ca680-c5c9-11e8-834e-c2e80821782b.jpg)\r\n\r\nThat's the order we go with and it fits well with how Godot functions presently.  Yes, if we have to expand the frame count, well we have to just bite the bullet and re-keyframe some things.  It has been done a couple times and it only takes a few minutes for a dozen or so animations.\r\n\r\nMy impression of what you have explained above is that there appears to be a lot of wasted space in there.  This examples is a 15x11 and has 47 empty frames.  (28% empty?)\r\n\r\n![sheet](https://user-images.githubusercontent.com/13004169/46311456-ec1a1c80-c5ca-11e8-870f-794ec541a878.png)\r\n\r\nWhen I think about a 400x300ish frame size it would amount to 400x300x47 = 5,640,000 dead pixels.  Spritesheets already tend to be somewhat wasteful in favor of convenience, but just speaking for myself I wouldn't want to voluntarily take on so much more for this method.\r\n\r\nIf I were to try to put what you have into my own words, it resembles to me something like sub-spritesheets inside of spritesheets, or possibly a hybrid between a spritesheet and an atlas.  An atlas with the requirements that a texture be in a uniform size and then be organized in some adjacent manner.\r\n\r\nUnfortunately, I really think I'd have to see this one implemented in the wild and in practice to understand and evaluate it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1038", "user": "metaphoricalsasquash", "root": "ROOT103", "reply_to": "COM1037", "timestamp": "2018-10-01T21:16:24Z", "text": "The only downside I see with dead pixels is a larger download. The upside is a MUCH better overview, which is absolute indispensable, when you are doing pixelart, get more animations and frames and lower resolution sprites.\r\nCurrently I'm working on a 2D Pixelart project (something Godot praises itself for being a great fit) which means I have tons of frames that look almost indistinguishable next to each other. On top of that, naming each frame even each animation is impossible with frames just 32 pixel or 48 pixel wide which also have to accommodate the sprite.\r\nMy current (very incomplete) player base sprite has 67 rows and 8 columns, so 535 frames. The png is 112KB in size, so I honestly don't care a bit about unused pixels on my spritesheet. Even if it would be ten times as large, the ability to find animations and frames I'm looking for outweighs the 0.01 seconds additional download time a billion to one.\r\nI know you are not doing pixelart in your game (which looks absolutely awesome btw! I've been following for a while) but in pixelart animation you select move and copy previously created frames and past them into new animations all the time. That's the core of any pixelart animation. Every single pixelpush has a huge impact to your animation. So the ability to quicky jump through your spritesheet, find what you are looking for copy and paste it to someplace else in your spritesheet or compare single pixel locations from various places in your sheet, is absolutely necessary. You also have to do this because your newly created frame must match previously created ones by the pixel. Think a change from one idle into another.\r\n\r\n>Yes, if we have to expand the frame count, well we have to just bite the bullet and re-keyframe some things. It has been done a couple times and it only takes a few minutes for a dozen or so animations.\r\n\r\nThis is what this issue is about. For you it might be not that much of an issue. I suppose this is _because_ you are not making a pixel game and _because_ you are making a sidescoller with two directions of movement, not 8. Hence your spritesheets are a lot more clearly laid out by default and while the re-keyframing or rearranging of your spritesheets might be an inconvenience, it is not so much an issue. For me however, and I dare say anyone who wants to do a slightly more professional looking pixel art game with decently complex animation, I dare say it not just an inconvenient issue, it's clearly a Starship Trooper sized [brain bug](https://img.buzzfeed.com/buzzfeed-static/static/2014-12/30/16/imagebuzz/webdr04/anigif_optimized-24700-1419976712-3.gif) in Godots design. **I therefore would really appreciate if someone would review the \"enhancement\" tag and maybe consider replacing it with a \"bug\" tag.** ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1039", "user": "metaphoricalsasquash", "root": "ROOT103", "reply_to": "COM1038", "timestamp": "2018-10-01T21:32:44Z", "text": ">I did not see our way in there, so you may feel this is illegitimate\r\n\r\nYou way or organizing the spritesheet is just as legitimate as any other. It is however affected by this issue just the same. Hence not a solution. When scaling up production, your way of organizing it would fail exactly like the other options I've layed out so far. And for the same reason: _because keyframes don't update their \"frame:value\" when HFrames changes._\r\nSo you either end up having to rework all the sprites in your spritesheet externally and make the spritesheet less readable in the process, or re-set all keyframe \"frame:\" values in Godot.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10310", "user": "mrcdk", "root": "ROOT103", "reply_to": "COM1039", "timestamp": "2018-10-01T21:43:23Z", "text": "I don't understand this issue. What you are asking is not something any framework/engine I've used before supports. How do you expect Godot to understand that the image that you told it had 67 rows and 8 columns now has 70 rows and 8 columns and it should magically (?) offset all the frames of the other animations? That image doesn't even know that it has animations linked to it. Making sense of where one animation starts and when it ends is your job or yours programmer job. Godot doesn't know that your first row is the \"walk\" animation and your second is the \"run\" animation that's something you tell it and you will need to update if you change anything that affects it. The only thing that Godot knows and cares is that an image has `x` rows and `y` columns and uses that information to calculate where in that image the frame 10 is anything else is up to you.\r\n\r\nAlso, transparent pixels are still uploaded to the GPU and taking space in the video memory. PNGs are compressed lossless image files but the data you upload to the GPU is uncompressed so that 112KB png file is ~2.2MB uncompressed if my math isn't wrong (which isn't much but you can see why it can add up to a lot and why there are tools like [TexturePacker](https://www.codeandweb.com/texturepacker) that can remove all the transparent pixels around the sprite and pack them tightly into a smaller image). It has nothing to do with download speeds.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10311", "user": "metaphoricalsasquash", "root": "ROOT103", "reply_to": "COM10310", "timestamp": "2018-10-01T21:58:45Z", "text": ">What you are asking is not something any framework/engine I've used before supports. How do you expect Godot to understand that the image that you told it had 67 rows and 8 columns now has 70 rows and 8 columns and it should magically (?) offset all the frames of the other animations? That image doesn't even know that it has animations linked to it. Making sense of where one animation starts and when it ends is your job or yours programmer job. Godot doesn't know that your first row is the \"walk\" animation and your second is the \"run\" animation that's something you tell it and you will need to update if you change anything that affects it.\r\n\r\nI'm not asking for any of that. Please have a look at my proposal again.\r\n\r\n>The only thing that Godot knows and cares is that an image has x rows and y columns and uses that information to calculate where in that image the frame 10 is anything else is up to you.\r\n\r\nYes I know. If it remembers what the previous setting for Hframes and Vframes was and what the current new setting is, that's also all it needs to know to fix the issue and adjust keyframes with \"frame:\" values.\r\n\r\n>Also, transparent pixels are still uploaded to the GPU and taking space in the video memory. PNGs are compressed lossless image files but the data you upload to the GPU is uncompressed so that 112KB png file is ~2.2MB uncompressed if my math isn't wrong\r\n\r\nThank you for pointing this out. I was not sure about how the GPU handles the png compression. Still, even 22 MB uncompressed are nothing compared to an inability to iterate on animation, add frames or add animations in the production process. Texture Packer makes a lot of sense for Tilemaps in 2D HD games, not so much for animation in low res 2D pixelart games in Godot. At least I would not know how you could marry those two when it comes to frame-by-frame pixel animation. If you know, or have a tool, please let us know.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10312", "user": "mrcdk", "root": "ROOT103", "reply_to": "COM10311", "timestamp": "2018-10-01T23:18:16Z", "text": "It does make sense in 2D pixelart games. For example, I had to package all the sprites of this game I worked on https://store.steampowered.com/app/462100/Starr_Mazer_DSP/ (this isn't a Godot game) into big spritesheets because we were having issues running out of vram on mobile (although we didn't end releasing it on mobile) Like this:\r\n\r\n![https://i.imgur.com/hNyc1t8.png](https://i.imgur.com/hNyc1t8.png)\r\n\r\n(the spritesheets are transparent but windows is being windows)\r\n\r\nThose are ~14200 sprites (most of them is the japanese font ~10k \ud83d\ude05 )\r\n\r\nThe position of your sprites in the spritesheet doesn't matter because it's you (or your programmer) the one that will give meaning to it.\r\n\r\n> Yes I know. If it remembers what the previous setting for Hframes and Vframes was and what the current new setting is, that's also all it needs to know to fix the issue and adjust keyframes with \"frame:\" values.\r\n\r\nThe Sprite doesn't know that it has animations linked to it and the AnimationPlayer just has a track that points to a property of a node (in this case to the `frame` property of a Sprite) and doesn't know anything else about it (it doesn't even know that it's pointing to a specific Sprite just a NodePath)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10313", "user": "metaphoricalsasquash", "root": "ROOT103", "reply_to": "COM10312", "timestamp": "2018-10-02T01:22:04Z", "text": "Wow, congrats on working on such a beautiful game! \r\n\r\nOf course .. TexturePacker _**can**_ make a lot of sense even for pixel games, depending on your target platform ect ... If you want to release on C64, you most likely will have to dig much deeper than TexturePacker to make things work.\r\n\r\n>The Sprite doesn't know that it has animations linked to it and the AnimationPlayer just has a track that points to a property of a node (in this case to the frame property of a Sprite) and doesn't know anything else about it (it doesn't even know that it's pointing to a specific Sprite just a NodePath)\r\n\r\nSo maybe the Animation Player _should_ be notified when there is a change made of a Hframes property down the Node Path? What's wrong with having the Sprite Node emitting a signal to do just that?\r\n\r\n>The position of your sprites in the spritesheet doesn't matter because it's you (or your programmer) the one that will give meaning to it.\r\n\r\nIt does matter a whole lot to whoever is in the process of creating the spritesheet and keyframes if they have an interest to stay mentally sane. Once they are all done you are totally right. You can scramble and optimize the sprite frames order and position to their most efficient arrangement. That is as long as your code is supporting the simultaneous and automatic re-setting of your \"frame:\" values in all your keyframes. But if we would have this functionality in Godot already, we would not need to have this discussion here in the first place.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10314", "user": "metaphoricalsasquash", "root": "ROOT103", "reply_to": "COM10313", "timestamp": "2018-10-02T14:27:40Z", "text": "Hey guys I made another graphic, in hopes it's easier to understand for people hearing about this the first time, let me know what you think:\r\n![keyframes-example-explained2](https://user-images.githubusercontent.com/43533832/46406314-a492ae00-c6fa-11e8-8fa1-d255415469bd.png)\r\n\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10315", "user": "metaphoricalsasquash", "root": "ROOT103", "reply_to": "COM10314", "timestamp": "2018-10-06T17:13:47Z", "text": "@groud and others who have labeling rights:\r\n**I kindly request the \"enhancement\" label to be reviewed.**\r\nPlease have a look at the graphic I made. If you still don't think this is a bug, please be so kind and help me understand how this could be intended behavior. \r\nIt makes spritesheet work hard for no benefit and the trouble the issue causes increases exponentially with the size of the project. \r\nEveryone, no matter what their workflow is or how they structure their spritesheet or whether or not they use a spritesheet packer tool or not, everyone has to deal with this issue and the additional workload it creates. A workload, that becomes unfeasible to manage if the project becomes large.\r\n\r\nWe do not have an option yet to import timing for animation, so when designing our animation, we are depended on keyframes.  I'm just at the beginning of incorporating animation into my project. Luckily, I haven't set all my keyframes yet, just a tiny percentage. Still, I had to meticulously and painstakingly spend hours and hours selecting each frame, on every track on every animation, comparing the previous value with my desired current one and reset it, all the while praying I don't fuck up. There is no point in doing this. It's tedious and an invite for error. How was this ever intended behavior? And even if it was, it's buggy as hell.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM10316", "user": "opleks", "root": "ROOT103", "reply_to": "COM10315", "timestamp": "2018-11-19T15:39:00Z", "text": "I'm trying to use AnimatedSprites controlled by AnimationPlayer not even using spritesheets.. but individual, animated .png's. \"Only\" trying to get it somehow to work since about 40 hours. There is zero documentation for frame-animation. There's a few examples... but none of them go into different animations: Always a single kind of animation. When asking in help not enough people seem to be using this kind of animation as programmers probably just use some cutout sprites and stick to AnimationPlayer. I've set myself some workflow with other applications where I can decently animate something new and simple within 5 minutes or less. And I'm sure I'm not the only one who prefers NOT to directly animate in Godot if a different, more efficient pipeline is already setup. Please... do not enforce people to rigid workflows.. but enable them to use whatever they need. By: Enabling simple use of individual .pngs or Spritesheets in AnimatedSprites.. and letting those be controlled through AnimationPlayer. This is not about \"enhacement\". In the current state.. it seems impossible to actually use and get anything done. When I try to change the played Animation in AnimationPlayer... the only keyframed Animations played are actually the ones selected in \"Animation\" property of the AnimatedSprite. Having different animations in AnimatedSprites. Therefore completely has no effect. I am now forced to use a separate \"AnimatedSprite\" for each kind of animation. However that leads to all animations being shown on screen at once. This cumbersome workflow can't be intended by design: Especially since both AnimatedSprites and AnimationPlayer already have separate tracks for different animation-types... built... in.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10317", "user": "golddotasksquestions", "root": "ROOT103", "reply_to": "COM10316", "timestamp": "2019-01-25T14:48:33Z", "text": "I also have this issue and think it is a bug!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10318", "user": "groud", "root": "ROOT103", "reply_to": "COM10317", "timestamp": "2019-01-25T15:07:28Z", "text": "Let makes things clear. A bug is when something happens in a way it was not designed for.\r\nNo one designed Godot to keep the indices if you change your texture size, it is written down nowhere in the documentation. So right now, everything works as expected (indeed from the developers point of view), even if the current design has limitations.\r\n\r\nI do not mean to minimize the problem, the enhancement would be a significant improvement. But no, it is not a bug.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10319", "user": "golddotasksquestions", "root": "ROOT103", "reply_to": "COM10318", "timestamp": "2019-01-25T15:47:11Z", "text": "> A bug is when something happens in a way it was not designed for.\r\n\r\nThe design is to let the user assign a specific keyframe. Godot was not designed to change the displayed keyframe once it has been assigned unless the user resigns it. It works as specified in the design when expanding vertically. But not horizontally. Godot is also designed to allow changes in the spritesheet dimension. (HFrame and VFrame Inspector settings). \r\n\r\nTo me that's as clear cut a bug as the definition can be. The way I read and understand it, also according to your own definition.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10320", "user": "groud", "root": "ROOT103", "reply_to": "COM10319", "timestamp": "2019-01-25T16:10:38Z", "text": "> Godot was not designed to change the displayed keyframe once it has been assigned unless the user resigns it.\r\n\r\nYou are wrong here, it was designed to work that way. The indices are, by design, naturally set from left to right then from top to bottom. So yeah, if you extend the texture horizontally, the indices get offset. \r\n\r\nIt is said nowhere the indices should be kept when you change the texture size, and event if we did, people might even complain because their indices could go unordered when changing from one texture to another. It might even be compatibility breaking. So for now, by design, Godot does not support changing the size of your texture while keeping the indices. That's all.\r\n\r\nTo be honest, it is more like \"we did not think about this problem when we designed it\", but that's the  definition of an enhancement : it works as expected, we know it has limitations, but everything happening here is completely expected.\r\n\r\nBut also, I don't want to be mean but I would prefer not to have this kind of discussions. We are the ones working on fixing those issues, so please, respect the way we organize the work to be done. Unless if other contributors agree the issue should be moved to bugs, the tags are not going to change.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10321", "user": "groud", "root": "ROOT103", "reply_to": "COM10320", "timestamp": "2019-01-25T16:24:31Z", "text": "Anyway, I might be able to solve the problem easily. I'll try something.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM10322", "user": "golddotasksquestions", "root": "ROOT103", "reply_to": "COM10321", "timestamp": "2019-01-25T16:30:17Z", "text": ">please, respect the way we organize the work to be done\r\n\r\nI certainly do. So far noone has explained why this would be intended behavior and I am completely unfamiliar with the usecase you mention here.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10323", "user": "jaacko-torus", "root": "ROOT103", "reply_to": "COM10322", "timestamp": "2019-09-23T13:43:25Z", "text": "Ummmm, why this is closed? Newb here. Is there a solution already? What is this \"frame_coords\" thing and how does it work? Thank you devs for your hard work btw xD", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10324", "user": "golddotasksquestions", "root": "ROOT103", "reply_to": "COM10323", "timestamp": "2019-09-23T14:31:15Z", "text": "Groud made a pull request and already committed the fix: https://github.com/godotengine/godot/pull/25327\r\nAbove your comment you can see the purple graphic saying the pull request has been merged and added to Godot 3.2", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10325", "user": "golddotasksquestions", "root": "ROOT103", "reply_to": "COM10324", "timestamp": "2019-10-12T21:31:09Z", "text": "@akien-mga Please reopen this issue (not sure if OP is still around)\r\nhttps://github.com/godotengine/godot/pull/25327 does not fix this issue at all, animating the Sprite Frame property is still incredibly broken in 3.2 Alpha2 as described in the original post of this issue.\r\nI have a lot of animations and would really need to have this fixed.\r\n\r\n**Minimal test project:**\r\n[expand_spritesheet.zip](https://github.com/godotengine/godot/files/3721176/expand_spritesheet.zip)\r\nRun the project, click on the color buttons to see a spritesheet animation playing. Each animation plays a separate row of the \"test_spritesheet.png\" spritesheet.\r\n\r\nTo test the issue,\r\n- drag the \"test_spritesheet_expanded.png\" into the Sprite texture,\r\n- set \"Hframes\" from 7 to 11\r\n- run the project again to see the wrong cells being displayed in lower rows of the spritesheet (any but green, since green is the first row, the cell attribution for green obviously is unchanged.)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10326", "user": "groud", "root": "ROOT103", "reply_to": "COM10325", "timestamp": "2019-10-13T05:43:27Z", "text": "> #25327 does not fix this issue at all, animating the Sprite Frame property is still incredibly broken in 3.2 Alpha2 as described in the original post of this issue.\r\n\r\nThis is not broken, as I already explained this is the expected behavior. This is once again NOT a bug and it is up to you to now change the way you deal with your animations.\r\nThis should be doable via a script though, using the Animation API. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10327", "user": "golddotasksquestions", "root": "ROOT103", "reply_to": "COM10326", "timestamp": "2019-10-13T10:46:27Z", "text": "It is **not** expected _by users_ as you can see here in this thread.\r\n\r\nMaybe _you_ wrote it this way, or studied the source code intensively, then of course you expect to behave it like that, but _users_ of the Sprite Frame property obviously don't expect this behavior at all. \r\n\r\nHow should they expect this behaviour? What would be the underlying intention of a design that allows spritesheets to be extended only vertically, not horizontally? If that's a feature, it's the most stupid feature I've ever heard of. This \"feature\" effectively **breaks** animation as demonstrated in the minimal project and the thorough description of the original post.\r\n\r\nIf you don't want to call it a bug, it's very bad design at the very least. What ever you call it, it really needs fixing. \r\nI therefore once again ask like @jaacko-torus for this issue to be reopened.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10328", "user": "groud", "root": "ROOT103", "reply_to": "COM10327", "timestamp": "2019-10-13T11:32:39Z", "text": "I am **once again**, going to explain how the frame property works within the engine: you select a frame, which is numbered from left to right, then from top to bottom. So it **is expected** so that changing the number of column changes the ID of your frames. It's easy to understand, and without considering this texture resize problem, it does the job quite well. \r\n\r\n> It is not expected by users as you can see here in this thread.\r\n\r\nSorry, but this issue did not receive enough upvotes to be significantly representative about how the feature should work. \r\nBut anyway, what users think is not what matters to define what is a bug or not. A bug happens when a software does not behave as expected from the programmer point of view, not the user one. The user might just have, like here apparently, misunderstood how the feature was designed and the implied advantages/flaws. So the only bug here is maybe about adding a warning to the documentation, but I don't really call that a bug.\r\n\r\n> If you don't want to call it a bug, it's very bad design at the very least.\r\n\r\nYeah, in that case we can call it bad design. So for now this issue will not be opened again as this is not a bug, and you can now easily workaround it using the `frame_coords` feature. The update the \"frame\" animation to the \"frame_coord\" animation is another problem though, so if you face problem updating this should be another issue.\r\n\r\nIf you have a better design in mind, please open an issue on the [godot-proposal](https://github.com/godotengine/godot-proposals) repository. ", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM10329", "user": "golddotasksquestions", "root": "ROOT103", "reply_to": "COM10328", "timestamp": "2019-10-13T12:07:31Z", "text": "> A bug happens when a software does not behave as expected from the programmer point of view, not the user one\r\n\r\nHave you ever worked with a QA team? You don't see the problem with this philosophy at all? \r\n\r\n\r\n> Yeah, in that case we can call it bad design. So for now this issue will not be opened again as this is not a bug\r\n\r\nThis issue was not labeled as bug. To be reopend it does not need to be labeled as bug. You yourself labeled it as \" enhancement topic:editor usability\"\r\nI asked @akien-mga who closed it to reopen it, because nothing about it has been fixed. And it still needs fixing!\r\n\r\n> you can now easily workaround it using the frame_coords feature.\r\n\r\nNo you cannot. This would mean destroying and completely redoing each and every single Animation. In my case that's a year's worth of work.\r\n\r\nOnce again, this issue is about the [Frame](https://docs.godotengine.org/en/3.1/classes/class_sprite.html#class-sprite-property-frame) property. Not the newly added Coords. If the Frame property is still available in the engine, it still needs fixing.\r\n\r\n> explain how the frame property works within the engine: you select a frame, which is numbered from left to right, then from top to bottom.\r\n\r\nThis is not how the Frame property works for the user. **The frame property expects an integer**. The user therefore expects the same behavior if the spritesheet is expanded vertically or horizontally, again, see OPs graphic in the original post.\r\n\r\n> If you have a better design in mind, please open an issue on the godot-proposal repository.\r\n\r\nThe original post already has a fix proposed: \r\n**The cell IDs have to update if the Hframe property changed.**", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT104", "user": "MichaelJCole", "root": "ROOT104", "reply_to": null, "timestamp": "2018-06-28T20:50:01Z", "text": "Please support web standard crypto.subtle Node.js developed it's own crypto API before the WebCrypto API.\r \r Since then, browsers and the web have standardized implementations around the [WebCrypto API standard](https://www.w3.org/TR/WebCryptoAPI).\r \r This bug is about Node.js missing support for the WebCrypto standard API and reopens #2833 (from 2015).\r \r Asking 3rd party libraries to implement the WebCrypto standard is not responsible from a security standpoint for a variety of reasons from implementation expertise to malware.  It is not responsible to put this onto API end users (developers).\r \r Additionally, a variety of implementation differences ([like this one](https://stackoverflow.com/a/39651457/1483977)) make compatible implementations buggy and error-prone.\r \r Back in 2015, there were arguments for not supporting the WebCrypto standard in Node 0.12.\r \r Today, committing to not supporting the WebCrypto standard is committing to a lack of responsibility for Nodejs as a secure and standards based platform on the web.\r \r ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1040", "user": "bnoordhuis", "root": "ROOT104", "reply_to": "ROOT104", "timestamp": "2018-06-28T21:25:35Z", "text": "Largely a duplicate of #19826 from earlier this year.  The answer is still 'no'.\r\n\r\nPlaces where gaps in the existing crypto API make emulating WebCrypto hard can be taken into consideration.  Asking for WebCrypto to be added to core verbatim?  Not on the table.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1041", "user": "MichaelJCole", "root": "ROOT104", "reply_to": "COM1040", "timestamp": "2018-06-28T21:46:59Z", "text": "LOL, from that issue:\r\n\r\n\"@bnoordhuis Ben, why you always try to close \"WebCrypto-related\" issues so fast? What you are scary of? What \"plan\" did you mean? You have already written code, the only problem it is a Node plugin, not a native module. Or you are suggesting me to write a full-featured PR with the new code? I am really confused with the style you drive Node issues.\" - @YuryStrozhevsky", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1042", "user": "bnoordhuis", "root": "ROOT104", "reply_to": "COM1041", "timestamp": "2018-06-28T21:51:57Z", "text": "If you don't have anything relevant to say, stay quiet. You just sent email notification to 100+ people.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1043", "user": "MichaelJCole", "root": "ROOT104", "reply_to": "COM1042", "timestamp": "2018-06-28T21:56:18Z", "text": "@bnoordhuis I do have relevant things to say, as a user of the project Ben.  Your heavy-handed and dismissive approach to moderation diminishes the project and the whole community.  Just because you are afraid taking responsibility doesn't mean someone else won't step up to it.  \r\n\r\nWhat I'm trying to say Ben is that you are on a larger team, and that team can support you through the hard stuff.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1044", "user": "bnoordhuis", "root": "ROOT104", "reply_to": "COM1043", "timestamp": "2018-06-28T22:00:38Z", "text": "You asked a question and you got an answer.  Moderation doesn't factor into it, you just didn't like the answer.\r\n\r\nNow stop trying to read the motivations of someone you don't know.  You suck at it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1045", "user": "ryanmurakami", "root": "ROOT104", "reply_to": "COM1044", "timestamp": "2018-06-29T00:14:38Z", "text": "Locking the conversation. I don't see this conversation becoming productive.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT105", "user": "mihaimaruseac", "root": "ROOT105", "reply_to": null, "timestamp": "2019-09-07T14:38:48Z", "text": "Support for 32 bits architecture Several users are still using Python32 bits and they cannot install TensorFlow. For them, `pip install tensorflow` fails as no wheel matches the tags expected by their environment (to debug, `pip debug --verbose` shows only tags that don't math the filenames of our wheels).\r \r There is some requests to support 32 bits, see for example #31431 \r \r This is not going to be easy as we need to also compile the C++ codebase in 32 bits mode and that would cause issues with code written assuming types have a certain bit width.\r \r There is no change in the user visible API, just a new set of wheels to support more users.\r \r Opening this to reference in all similar issues.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1050", "user": "steffanjensen", "root": "ROOT105", "reply_to": "ROOT105", "timestamp": "2019-09-09T17:01:33Z", "text": "a few people have been asking me today about pip install 32 bit tensorflow support. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1051", "user": "mihaimaruseac", "root": "ROOT105", "reply_to": "COM1050", "timestamp": "2019-09-09T17:40:10Z", "text": "Will raise the issue upward.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1052", "user": "husligc", "root": "ROOT105", "reply_to": "COM1051", "timestamp": "2019-09-09T21:07:53Z", "text": "Having the same problem here. Would really appreciate a fix", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1053", "user": "steffanjensen", "root": "ROOT105", "reply_to": "COM1052", "timestamp": "2019-09-10T12:55:06Z", "text": "Also, got a few asking questions about this issue today.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1054", "user": "husligc", "root": "ROOT105", "reply_to": "COM1053", "timestamp": "2019-09-16T14:34:33Z", "text": "Any fix on this @mihaimaruseac ? Still having problems and I know a lot of others are too. Thanks so much", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1055", "user": "mihaimaruseac", "root": "ROOT105", "reply_to": "COM1054", "timestamp": "2019-09-16T15:39:45Z", "text": "This is best effort, we are not going to work into this this year. Compiling for both 32 bits and 64 bits is not that easy so we don't have this included in any milestones plan at the moment.\r\n\r\nHowever, if the community wants to contribute patches so 32 bit support can be provided, they would be very welcomed.", "meta": {"posReactions": "0", "negReactions": "3"}}
{"id": "COM1056", "user": "steffanjensen", "root": "ROOT105", "reply_to": "COM1055", "timestamp": "2019-09-16T16:57:08Z", "text": "Kk then I am going to stop supporting Tensoeflow. It does not make sense to use a framework which Python does not support by default. I even had people write to me to fix this today, that you guys are not seeing this is a huge issue like it is, shows where your priorities are. \r\n\r\nI know that @husligc also see people having this issues daily and even he has it, it's funny you guys dont think that is a huge problem.. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1057", "user": "Oyetomi", "root": "ROOT105", "reply_to": "COM1056", "timestamp": "2019-09-16T17:14:55Z", "text": "We would appreciate a python 32bit fix, some distros install python 32 bit by default and there's no way around it ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1058", "user": "mihaimaruseac", "root": "ROOT105", "reply_to": "COM1057", "timestamp": "2019-09-16T21:52:00Z", "text": "As I stated, there is not enough time to duplicate all CI builds and to fix all the bugs that would get uncovered from there. And clearly this is not an issue that can be solved overnight.", "meta": {"posReactions": "0", "negReactions": "3"}}
{"id": "COM1059", "user": "steffanjensen", "root": "ROOT105", "reply_to": "COM1058", "timestamp": "2019-09-16T23:00:57Z", "text": "This is a high priority for me someone just asked me again a few min ago on how to install TensorFlow 2.0 for windows 10 32bit version. \r\n\r\nThis thread will be going wild. Maybe I should tag Windows contributes into this thread.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM10510", "user": "steffanjensen", "root": "ROOT105", "reply_to": "COM1059", "timestamp": "2019-09-16T23:15:03Z", "text": "@petewarden @jhseu @terrytangyuan @xiejw @ezhulenev @feihugis @jsimsa @skye @ilblackdragon @asimshankar @MarkDaoust @yongtang @mrry @benoitsteiner", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10511", "user": "husligc", "root": "ROOT105", "reply_to": "COM10510", "timestamp": "2019-09-17T02:06:47Z", "text": "A lot of my clients asking for this too. would appreciate a fix", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM10512", "user": "steffanjensen", "root": "ROOT105", "reply_to": "COM10511", "timestamp": "2019-09-17T04:15:46Z", "text": "another one just asked me for a fix -_-", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10513", "user": "steffanjensen", "root": "ROOT105", "reply_to": "COM10512", "timestamp": "2019-09-18T17:05:04Z", "text": "more people have asked me private for a fix today", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10514", "user": "gunan", "root": "ROOT105", "reply_to": "COM10513", "timestamp": "2019-09-18T17:09:40Z", "text": "This is not on our roadmap. I do not think that will change for the next year.\r\nI will lock this thread, because added repeated requests will not change the roadmap.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT106", "user": "mikedn", "root": "ROOT106", "reply_to": null, "timestamp": "2020-01-07T17:40:31Z", "text": "Use movups instead of movdqu in block op codegen When VEX encoding is not availbale, movups encoding is one byte shorter. With VEX the two instructions have same length encoding so we can just use movups all the time.\r \r Also fix perf score latency for movups & co., it was incorrectly set higher than movdqu's latency.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1060", "user": "mikedn", "root": "ROOT106", "reply_to": "ROOT106", "timestamp": "2020-01-07T17:44:32Z", "text": "Somehow I missed this when improving block op codegen. Or perhaps I thought it's not relevant because it's only useful when VEX is not available and that should be rare these days. Well, unless you're crossgening\u2026\r\n\r\nDiff summary:\r\n```\r\nTotal bytes of diff: -105703 (-0.40% of base)\r\n    diff is an improvement.\r\nTop file improvements by size (bytes):\r\n      -53016 : Microsoft.Diagnostics.Tracing.TraceEvent.dasm (-1.59% of base)\r\n       -8062 : System.Private.CoreLib.dasm (-0.25% of base)\r\n       -7991 : Microsoft.CodeAnalysis.CSharp.dasm (-0.38% of base)\r\n       -7047 : Microsoft.CodeAnalysis.VisualBasic.dasm (-0.31% of base)\r\n       -6368 : System.Linq.Parallel.dasm (-1.08% of base)\r\n82 total files with size differences (82 improved, 0 regressed), 27 unchanged.\r\nTop method improvements by size (bytes):\r\n       -2074 (-3.36% of base) : Microsoft.Diagnostics.Tracing.TraceEvent.dasm - CtfTraceEventSource:InitEventMap():Dictionary`2\r\n       -1937 (-1.95% of base) : Microsoft.Diagnostics.Tracing.TraceEvent.dasm - ApplicationServerTraceEventParser:EnumerateTemplates(Func`3,Action`1):this\r\n       -1350 (-0.12% of base) : System.Linq.Expressions.dasm - FuncCallInstruction`3:Run(InterpretedFrame):int:this (3375 methods)\r\n       -1256 (-2.68% of base) : Microsoft.Diagnostics.Tracing.TraceEvent.dasm - KernelTraceEventParser:EnumerateTemplates(Func`3,Action`1):this\r\n       -1124 (-3.18% of base) : Microsoft.Diagnostics.Tracing.TraceEvent.dasm - ClrPrivateTraceEventParser:EnumerateTemplates(Func`3,Action`1):this\r\nTop method improvements by size (percentage):\r\n          -2 (-22.22% of base) : System.Private.CoreLib.dasm - Unsafe:WriteUnaligned(byref,Guid)\r\n          -2 (-22.22% of base) : System.Reflection.Metadata.dasm - ImportDefinitionCollection:.ctor(MemoryBlock):this\r\n          -2 (-22.22% of base) : System.Reflection.Metadata.dasm - GuidHeap:.ctor(MemoryBlock):this\r\n          -2 (-22.22% of base) : System.Reflection.Metadata.dasm - UserStringHeap:.ctor(MemoryBlock):this\r\n          -2 (-20.00% of base) : Microsoft.Diagnostics.Tracing.TraceEvent.dasm - StartStopActivity:set_ActivityID(Guid):this\r\n13429 total methods with size differences (13429 improved, 0 regressed), 133176 unchanged.\r\n```\r\nSeems like Microsoft.Diagnostics.Tracing.TraceEvent still hasn't gave up on its plan of taking over the world by copying itself thousands of times...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1061", "user": "tannergooding", "root": "ROOT106", "reply_to": "COM1060", "timestamp": "2020-01-07T19:41:42Z", "text": "Are there any penalties to using `movups` vs `movdqu` on modern CPUs? What about on older CPUs where VEX isn't available?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1062", "user": "tannergooding", "root": "ROOT106", "reply_to": "COM1061", "timestamp": "2020-01-07T19:46:47Z", "text": "Looks like Agner's indicates no penalty on newer processors, but on some older processors it can be an additional latency between 1-4 cycles: <https://www.agner.org/optimize/microarchitecture.pdf> (see `bypass delay` for various CPUs).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1063", "user": "sandreenko", "root": "ROOT106", "reply_to": "COM1062", "timestamp": "2020-01-07T20:38:35Z", "text": "@dotnet/jit-contrib ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1064", "user": "mikedn", "root": "ROOT106", "reply_to": "COM1063", "timestamp": "2020-01-07T21:13:22Z", "text": "> (see bypass delay for various CPUs).\r\n\r\nWhat bypass delay? These are load/stores so they're handled by the load/store units and not by FP/int units.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1065", "user": "tannergooding", "root": "ROOT106", "reply_to": "COM1064", "timestamp": "2020-01-07T21:35:39Z", "text": "For example, on Core2:\r\n> The load/store unit is closely connected with the integer unit, so that there is no additional\r\nlatency when transferring data between the integer unit and the load/store unit. There is a\r\none clock latency when transferring data from memory (load unit) to the floating point unit,\r\nbut there is no additional latency when transferring data from the floating point unit to\r\nmemory (store unit).\r\n\r\nOn the Nehalem section (in regards to a store):\r\n> Replacing the last MOVDQA with MOVAPS has no influence on latencies,\r\nbut it may have on future processors.\r\n\r\nOn the Sandy Bridge and Ivy Bridge pipeline:\r\n> There is only rarely a bypass delay when using the wrong\r\ntype of move instruction, for example MOVAPS instead of MOVDQA. \r\n\r\netc...\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1066", "user": "tannergooding", "root": "ROOT106", "reply_to": "COM1065", "timestamp": "2020-01-07T21:37:12Z", "text": "It doesn't look like something that is needed to be a consideration given that these are largely just for block copies and will generally be used with the integer pipeline in the end anyways. It was just something I was interested in as I understood their \"could\" be penalties in some scenarios.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1067", "user": "CarolEidt", "root": "ROOT106", "reply_to": "COM1066", "timestamp": "2020-01-07T21:43:02Z", "text": "This seems reasonable to me, especially as it is most relevant to the crossgen scenario where I believe the size is a bigger issue than at JIT time. @briansull for consideration of the PerfScore changes.\r\n@tannergooding - I take it you are on board with this change as well?", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1068", "user": "mikedn", "root": "ROOT106", "reply_to": "COM1067", "timestamp": "2020-01-07T23:28:44Z", "text": "@briansull Care to explain why did you deleted my comment?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1069", "user": "briansull", "root": "ROOT106", "reply_to": "COM1068", "timestamp": "2020-01-08T01:35:07Z", "text": "Mike you are a valued JIT contributor and I just thought that your last comment was a bit too harsh.\r\n\r\nI didn't really think about it too much.  I was just trying to keep things peaceful here.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10610", "user": "richlander", "root": "ROOT106", "reply_to": "COM1069", "timestamp": "2020-01-08T01:53:39Z", "text": "I didn't read the comment (it's deleted). In general, for comments that are just a bit too harsh, we typically \"hide\" them instead of deleting them. It's a soft way of communicating that a comment included some text that could be offensive to someone, and then only people that are really curious see it, and everyone generally gets on with the topic. That's what we've done elsewhere and something to consider.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10611", "user": "terrajobst", "root": "ROOT106", "reply_to": "COM10610", "timestamp": "2020-02-11T18:06:22Z", "text": "@mikedn \r\n\r\n> @briansull Care to explain why did you deleted my comment?\r\n\r\nBecause it was completely inappropriate. Telling other contributors to not comment because \"you have no clue what you're talking about\" is toxic behavior. OSS is also about building & nurturing a community and that also includes involving people who still learn and have passion for the subject. We're not just here to review, merge, and maintain *your* PRs and ideas. While your contributions are clearly valuable, you need to accept that you're part of a larger community and need to treat others with respect.\r\n\r\nSo to be clear: just because your contributions are valuable doesn't mean you get a pass on following our [Code of Conduct](https://dotnetfoundation.org/code-of-conduct).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10612", "user": "mikedn", "root": "ROOT106", "reply_to": "COM10611", "timestamp": "2020-02-11T18:19:06Z", "text": "@terrajobst \r\n\r\n> Telling other contributors to not comment because \"you have no clue what you're talking about\" is toxic behavior\r\n\r\nI don't remember what exactly the deleted comment contained but I'm pretty sure I did not tell anyone not to comment. I complained about his superficial behavior.\r\n\r\n> So to be clear: just because your contributions are valuable doesn't mean you get a pass on following our Code of Conduct.\r\n\r\nWell, I consider his behavior to show a lack of respect for other's people work and time. As such I don't care about what the code of conduct says because anyway I don't plan to contribute more work to this OSS project. Speaking about toxic behavior...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10613", "user": "drieseng", "root": "ROOT106", "reply_to": "COM10612", "timestamp": "2020-02-11T19:22:33Z", "text": "@mikedn Could it be that it's rather a cultural difference? I used to be a Mono contributor, and once had a conflict with a maintainer. His remarks were more harsh than the ones you made, and Miguel was very diplomatic in resolving the \"dispute\". I honestly believe that his harsh remarks were not intentional.\r\n\r\nI continued to be a contributer (until my work/life situation decided otherwise) as I believed in the project and I felt my contributions were appreciated.\r\n\r\nIn your situation, I think the MS maintainers handled the situation correctly (without being harsh, again this is from my point of view). There's no doubt your contributions are greatly appreciated; this by both the MS maintainers and the community.\r\n\r\nIt would be a great loss for the .NET community if you'd stop contributing. If you consider my comment to be negative, just tell me and I'll happily remove it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10614", "user": "mikedn", "root": "ROOT106", "reply_to": "COM10613", "timestamp": "2020-02-11T23:03:52Z", "text": "@drieseng \r\n>  Could it be that it's rather a cultural difference?\r\n\r\nI'm not sure what that difference might be. Nobody appreciates random/out of context quoting, straightforward answer avoidance, jumping to conclusions and whatnot. Well, some might be more tolerant to it than others but still.\r\n\r\n> There's no doubt your contributions are greatly appreciated; this by both the MS maintainers and the community.\r\n\r\nWell, I appreciate they're appreciated but at the same time I don't really care. I did not contribute to get praise, I only contributed for the fun of it. And it stops being fun if I have to deal with nonsense. If I want to deal with nonsense I can probably find that pretty easily at work, there's no need for me to come here and ruin my evening.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10615", "user": "mikedn", "root": "ROOT106", "reply_to": "COM10614", "timestamp": "2020-02-11T23:09:18Z", "text": "And to be clear: as far as I'm concerned this matter is closed. I have no idea why terrajobst felt the need to comment on it after more than a month.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10616", "user": "terrajobst", "root": "ROOT106", "reply_to": "COM10615", "timestamp": "2020-02-12T01:17:39Z", "text": "@drieseng\r\n\r\n> It would be a great loss for the .NET community if you'd stop contributing. If you consider my comment to be negative, just tell me and I'll happily remove it.\r\n\r\nI wholeheartedly agree with that. @mikedn has contributed greatly and we totally appreciate all the skills & expertise for that reason. But we need to be careful that we don't use valuable contributions as a currency to offset disrespectful behavior.\r\n\r\n@mikedn\r\n\r\n> I have no idea why terrajobst felt the need to comment on it after more than a month.\r\n\r\nPurely practical reasons -- I was only made aware of this issue today and I believe what I said needed to be said.\r\n\r\nOur goal is to create an inclusive and respectful community and that includes all of us: Microsoft employees, frequent contributors, and newcomers. But these are only hollow words unless we're willing to drive change where necessary. And that includes reminding people to be respectful if their actions aren't and removing people who refuse to do so. From looking at the OSS ecosystem and listening to other communities it's clear to me that ignoring toxic behavior in the spirit of taking the high road does nothing but normalizing said toxic behavior. That's why I said what I said.\r\n\r\n> Well, I appreciate they're appreciated but at the same time I don't really care. I did not contribute to get praise, I only contributed for the fun of it.\r\n\r\nI can very much relate to that. Thus, I'd ask you to consider that this applies to other people as well. As far as I know, the vast majority of folks working on .NET do that because they love working on this stuff.\r\n\r\nBut how much fun do you think it is to hear that someone you respect tells you that you don't know what you're are talking about?\r\n\r\nCode reviews and PR discussions are often controversial *because* people care. We're all guilty of saying things that come across much harsher than we intended. Being respectful doesn't mean not making mistakes, it means unwillingness to learn from them and/or doubling down on them. And I for one am not willing to tell people to suck it up because that's just the culture we have. We generally don't have that culture internally or with our community. And the places where we do I consider it a defect that needs to be fixed.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10617", "user": "mikedn", "root": "ROOT106", "reply_to": "COM10616", "timestamp": "2020-02-12T19:39:41Z", "text": "@terrajobst \r\n\r\n> But how much fun do you think it is to hear that someone you respect tells you that you don't know what you're are talking about?\r\n\r\nAnd if you really do not know what you are talking about then what? You shield yourself in the code of conduct and go OMG, how could people dare telling me that I'm wrong? Or perhaps you try to do better next time and avoid the not so fun part of messing up? Working for fun doesn't imply that you get to do whatever you want and that there are no consequences.\r\n\r\n> Code reviews and PR discussions are often controversial because people care.\r\n\r\nThere was no real controversy here. I asked a question and I was expecting a reasonable answer, especially considering that it wasn't me who started this. Instead of an answer I've got some gibberish that tries to pass as code review or whatever that is supposed to be.\r\n\r\n> Being respectful doesn't mean not making mistakes, it means unwillingness to learn from them and/or doubling down on them\r\n\r\nIt's exactly this unwillingness to learn from mistakes that brought us here. So now you're trying to explain to me how persistent shoot from the hip style commenting is respectful or not? Frankly I'm not sure what exactly it is. Let's just say that it is distasteful. Feel free to continue to go down this path, the only thing you'll achieve is to dig the hole deeper.\r\n\r\n> And I for one am not willing to tell people to suck it up.\r\n\r\nYet here you are, telling me exactly that.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10618", "user": "terrajobst", "root": "ROOT106", "reply_to": "COM10617", "timestamp": "2020-02-12T20:43:38Z", "text": "@mikedn\r\n\r\nTanner acted in good faith by asking questions to the best of his understanding. Telling him that he doesn't know what he's talking about is unacceptable. First of all, it's not an insightful comment from your end. If you want other people to learn, you need to give them more information beyond \"you're wrong\". But more importantly it's just plain rude. You're basically sending him the signal of \"you're not welcome here\".\r\n\r\nBut instead of apologizing or even just letting that feedback sink in, you're now trying to turn the tables by saying you got victimized by Tanner because he asked you a technical question and that it's unreasonable from our end to ask you to be respectful in your responses to him.\r\n\r\nYou're more than welcome to continue to contribute to .NET. But I'll be clear: if we observe behavior like this in the future, we'll ultimately block you. We can't have other contributors stop engaging with us because of your behavior. While your contributions are valued, they don't warrant losing other contributors as collateral damage.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT107", "user": "Mikotochan", "root": "ROOT107", "reply_to": null, "timestamp": "2019-12-19T10:59:09Z", "text": "Stop the censorship Please restore the comments in https://github.com/microsoft/vscode/issues/87268 and unlock https://github.com/microsoft/vscode/issues/87291.\r \r I enjoy reading drama, please don't take my only pleasure in life away.", "meta": {"posReactions": "74", "negReactions": "0"}}
{"id": "COM1070", "user": "Hamdullah-gif", "root": "ROOT107", "reply_to": "ROOT107", "timestamp": "2019-12-19T11:13:37Z", "text": "This censorship is literally a new holocaust!", "meta": {"posReactions": "19", "negReactions": "1"}}
{"id": "COM1071", "user": "jablpiotrek", "root": "ROOT107", "reply_to": "COM1070", "timestamp": "2019-12-19T11:14:39Z", "text": "I'm extremely offended by the fact that because of religious beliefs @Mikotochan 's only life pleasure has been taken away. ", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM1072", "user": "matks", "root": "ROOT107", "reply_to": "COM1071", "timestamp": "2019-12-19T11:15:06Z", "text": "> This censorship is literally a new holocaust!\r\n\r\nYou deserve an award for skyrocketting the level of drama of this topic \ud83d\udc4f \ud83c\udf7e \ud83c\udf96 !", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1073", "user": "PierreRambaud", "root": "ROOT107", "reply_to": "COM1072", "timestamp": "2019-12-19T11:15:41Z", "text": "Could we remove this logo\r\n![image](https://user-images.githubusercontent.com/1462701/71169433-2c5dcd00-2259-11ea-9a1d-64b90ce7930a.png)\r\n, it's against the insects life :thinking: ", "meta": {"posReactions": "28", "negReactions": "0"}}
{"id": "COM1074", "user": "ttoine", "root": "ROOT107", "reply_to": "COM1073", "timestamp": "2019-12-19T11:16:30Z", "text": "```\r\n /  __) (____) (____) (____) (____) (____) (__  \\ \r\n |_|                                          |_| \r\n  _      _                    _       _        _ \r\n | |    / |       _ __   ___ (_)_ __ | |_     | | \r\n | |    | |      | '_ \\ / _ \\| | '_ \\| __|    | | \r\n |_|    | |      | |_) | (_) | | | | | |_     |_| \r\n  _     |_|      | .__/ \\___/|_|_| |_|\\__|     _ \r\n | |             |_|                          | | \r\n | |                                          | | \r\n |_|     ____           _          _          |_| \r\n  _     / ___| ___   __| |_      _(_)_ __      _ \r\n | |   | |  _ / _ \\ / _` \\ \\ /\\ / / | '_ \\    | | \r\n | |   | |_| | (_) | (_| |\\ V  V /| | | | |   | | \r\n |_|    \\____|\\___/ \\__,_| \\_/\\_/ |_|_| |_|   |_| \r\n  _                                            _ \r\n | |__   ____   ____   ____   ____   ____   __| | \r\n \\____) (____) (____) (____) (____) (____) (____/\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1075", "user": "Phillipus", "root": "ROOT107", "reply_to": "COM1074", "timestamp": "2019-12-19T11:17:20Z", "text": "Good grief. Poor old Santa! BTW - solstice is a pagan festival and Santa was a shaman.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1076", "user": "s9w", "root": "ROOT107", "reply_to": "COM1075", "timestamp": "2019-12-19T11:21:47Z", "text": "How to ruin your stellar reputation in one easy step.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1077", "user": "Phillipus", "root": "ROOT107", "reply_to": "COM1076", "timestamp": "2019-12-19T11:27:09Z", "text": "No pressies for @Christian-Schiffer this year,. He's been a very naughty boy!", "meta": {"posReactions": "5", "negReactions": "1"}}
{"id": "COM1078", "user": "normano", "root": "ROOT107", "reply_to": "COM1077", "timestamp": "2019-12-19T11:40:23Z", "text": "@egamma Could stop this discussions if a more balanced approach was taken such as including configuration to enable disable these decorations. Can't imagine any controversy from that therefore these outbursts that take time away from other issues.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1079", "user": "TheRishabhB", "root": "ROOT107", "reply_to": "COM1078", "timestamp": "2019-12-19T11:45:01Z", "text": "We should stop using git as version control for vscode too.  One time a random person told me to \u201cgit good\u201d and since then, \u201cgit\u201d is extremely offensive to me. ", "meta": {"posReactions": "13", "negReactions": "1"}}
{"id": "COM10710", "user": "TimWelter", "root": "ROOT107", "reply_to": "COM1079", "timestamp": "2019-12-19T11:49:35Z", "text": "Please remove Python compatibility I'm scared of snakes.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM10711", "user": "Roguezilla", "root": "ROOT107", "reply_to": "COM10710", "timestamp": "2019-12-19T12:17:03Z", "text": "> @egamma Could stop this discussions if a more balanced approach was taken such as including configuration to enable disable these decorations. Can't imagine any controversy from that therefore these outbursts that take time away from other issues.\r\n\r\nWon't happen, the the people who code vscode are too scared to go against someone's beliefs. They removed a god damn hat for fucks sake, a hat that's related to a holiday that isn't celebrated for its religious symbolism anymore, the latter was issue for the amazing mastermind who made #87268. This is why we can't have nice things.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM10712", "user": "pmosko", "root": "ROOT107", "reply_to": "COM10711", "timestamp": "2019-12-19T12:35:22Z", "text": "It's funny and sad at the same time that one selfish issue can cause loss of hundrets of man-days (people-days?) across globe.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM10713", "user": "Phillipus", "root": "ROOT107", "reply_to": "COM10712", "timestamp": "2019-12-19T12:37:47Z", "text": "> It's funny and sad at the same time that one selfish issue can cause loss of hundrets of man-days (people-days?) across globe.\r\n\r\nSadder still is the amount of lives lost in the name of \"religion\".", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10714", "user": "Sunscratch", "root": "ROOT107", "reply_to": "COM10713", "timestamp": "2019-12-19T12:43:09Z", "text": "Merry Christmas and Happy New Year! \ud83c\udf85 \r\nYou can ban me now, `for pushing of religion`", "meta": {"posReactions": "5", "negReactions": "1"}}
{"id": "COM10715", "user": "pmosko", "root": "ROOT107", "reply_to": "COM10714", "timestamp": "2019-12-19T12:48:17Z", "text": "> Sadder still is the amount of lives lost in the name of \"religion\".\r\n\r\nI am not sure why you used quotes, but yes, lives lost or opressed at any occasion are depressing thing. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10716", "user": "kpucynski", "root": "ROOT107", "reply_to": "COM10715", "timestamp": "2019-12-19T12:51:55Z", "text": ":popcorn: ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10717", "user": "nitnelave", "root": "ROOT107", "reply_to": "COM10716", "timestamp": "2019-12-19T13:07:15Z", "text": "`git push --religion`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10718", "user": "chrisdias", "root": "ROOT107", "reply_to": "COM10717", "timestamp": "2019-12-19T18:58:12Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.\r\n\r\nHappy Coding!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT108", "user": "mjscosta", "root": "ROOT108", "reply_to": null, "timestamp": "2019-04-21T20:39:58Z", "text": "##vso[task.prependpath] in linux always results in an extra quote added wiht the prepended path ## Required Information\r \r Entering this information will route you directly to the right team and expedite traction.\r \r **Question, Bug, or Feature?**  \r *Type*: Bug\r \r **Enter Task Name**: ##vso[task.prependpath]\r \r ## Environment\r - Server - Azure Pipelines or TFS on-premises?\r    Azure Pipelines\r     \r     - If using Azure Pipelines, provide the account name, team project name, build definition name/build number: these are private data in private builds not to be tracked publicly.\r \r - Agent - Hosted or Private:  Hosted\r     \r     - If using Hosted agent, provide agent queue name: Hosted Ubuntu 1604\r \r ## Issue Description\r \r ### Test 1\r Using the following to set prepend the path results in an extra quote in the PATH\r ```\r   - script: \"echo '##vso[task.prependpath]$(Build.SourcesDirectory)/scripts1'\"\r   - script: 'echo \"PATH: ${PATH}\"'\r \r   - script: \"echo '##vso[task.prependpath]$(Build.SourcesDirectory)/scripts2'\"\r   - script: 'echo \"PATH: ${PATH}\"'\r ```\r output1:\r ```\r PATH: /home/vsts/work/1/s/scripts1:\"/home/vsts/.dotnet/tools:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin\"\r ```\r \r output2\r ```\r PATH: /home/vsts/work/1/s/scripts2:/home/vsts/work/1/s/scripts1:\"/home/vsts/.dotnet/tools:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin\"\r ```\r \r Expected result:\r ```\r PATH: /home/vsts/work/1/s/scripts2:/home/vsts/work/1/s/scripts1:/home/vsts/.dotnet/tools:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin\r ```\r \r This seems to be causing some paths on added not be used in the search", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1080", "user": "damccorm", "root": "ROOT108", "reply_to": "ROOT108", "timestamp": "2019-11-20T18:48:39Z", "text": "Hey @mjscosta - this looks like it might be the same issue as https://github.com/microsoft/azure-pipelines-tasks/issues/10331\r\n\r\nCould you try running `set +x` at the start of your script? If that doesn't work, could you try queuing a build with system diagnostics turned on and sharing the output?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1081", "user": "HughDevlin", "root": "ROOT108", "reply_to": "COM1080", "timestamp": "2019-12-05T16:00:20Z", "text": "Yesterday i lost a day cleaning up a spurious trailing single quote. Today I put together a minor variation on your \"Set variables in scripts\" YAML example on your \"Variables\" concept page. I hope this suggests some simple test cases.\r\n\r\n```\r\ntrigger: none\r\n\r\npool:\r\n  vmImage: 'ubuntu-latest'\r\n\r\nsteps:\r\n- checkout: none\r\n- script: |\r\n    FOO=BAR\r\n    echo $FOO\r\n    echo \"##vso[task.setvariable variable=myvar]$FOO\"\r\n    set\r\n  displayName: 'Reproduce vso trailing single quote bug; call vso'\r\n- script: |\r\n    echo my pipeline variable is $(myvar)\r\n  displayName: 'Reproduce vso trailing single quote bug; echo variable'\r\n```\r\n\r\nExpected: BAR\r\nActual: BAR'", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1082", "user": "damccorm", "root": "ROOT108", "reply_to": "COM1081", "timestamp": "2019-12-05T16:09:41Z", "text": "Hey @HughDevlin per my comment above, I think this is all probably related to #10331 - we're working on a better long term fix, but in the short term adding `set +x` should fix the problem.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1083", "user": "HughDevlin", "root": "ROOT108", "reply_to": "COM1082", "timestamp": "2019-12-05T17:07:37Z", "text": "No, adding `set +x` does not fix the problem, I'll test it if you won't:\r\n\r\n```\r\ntrigger: none\r\n\r\npool:\r\n  vmImage: 'ubuntu-latest'\r\n\r\nsteps:\r\n- checkout: none\r\n- script: |\r\n    set +x\r\n    FOO=BAR\r\n    echo $FOO\r\n    echo \"##vso[task.setvariable variable=myvar]$FOO\"\r\n    set\r\n  displayName: 'Reproduce vso trailing single quote bug; call vso'\r\n- script: |\r\n    echo my pipeline variable is $(myvar)\r\n  displayName: 'Reproduce vso trailing single quote bug; echo variable'\r\n```\r\nExpected: BAR\r\nActual: BAR'\r\n\r\nAlso, I note the potential duplicate you reference  #10331 is currently closed as no fault found which does not suggest a fix is in progress.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1084", "user": "HughDevlin", "root": "ROOT108", "reply_to": "COM1083", "timestamp": "2019-12-05T17:26:42Z", "text": "Please add ##vso[task.setvariable] to the description.Thanks.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1085", "user": "damccorm", "root": "ROOT108", "reply_to": "COM1084", "timestamp": "2019-12-05T17:28:14Z", "text": "> No, adding set +x does not fix the problem, I'll test it if you won't:\r\n\r\nOh, I see - this is the same type of root cause, but actually slightly different - sorry about that. Its actually the `set` command that is causing problems here which is why I didn't initially capture the issue.\r\n\r\nBash is setting the `$_` variable to the first arg of the previous command that was executed (see [here](https://unix.stackexchange.com/questions/280453/understand-the-meaning-of) for more info on this behavior). When you call `set`, that is getting written out to stdout. Since the previous command was a ## command, it writes out `_='##vso[task.setvariable variable=myvar]BAR'` - see [here](https://dev.azure.com/damccorm-repros/trailing-tick/_build/results?buildId=260&view=logs&j=12f1170f-54f2-53f3-20dd-22fc7dff55f9&t=f8ed7bd8-2a7f-56f6-9385-7fc29a8b5b7b&l=222) for a repro with diagnostics turned on that shows this behavior.\r\n\r\nSo this is actually the correct behavior here - I'd recommend wiping `$_` before running `set`, which I've confirmed works [here](https://dev.azure.com/damccorm-repros/trailing-tick/_build/results?buildId=262&view=logs&j=12f1170f-54f2-53f3-20dd-22fc7dff55f9)\r\n\r\n> Also, I note the potential duplicate you reference #10331 is currently closed as no fault found which does not suggest a fix is in progress.\r\n\r\nSure, probably should have been a little clearer here - right now, the system is working as designed. However, as you've seen here, this behavior is probably not desirable for all use cases. Since its not a bug, we're not going to change behavior here, but we are looking at a feature to workaround this by making some variables read only (so they can't get overwritten). You can see the spec for that feature here - https://github.com/microsoft/azure-pipelines-yaml/pull/396/files", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1086", "user": "damccorm", "root": "ROOT108", "reply_to": "COM1085", "timestamp": "2019-12-05T17:29:15Z", "text": "> Please add ##vso[task.setvariable] to the description.Thanks.\r\n\r\nI think its probably the same issue, I'd prefer to leave it to the issue author's discretion.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1087", "user": "HughDevlin", "root": "ROOT108", "reply_to": "COM1086", "timestamp": "2019-12-05T17:41:46Z", "text": "We agree, this behavior is not desirable.\r\nWe disagree, it is bug.\r\nAfter you implement a new category of variables, read-only variables, and ask customers to flag variables as read-only with a new parameter at variable creation, you will maintain the undesirable behavior for non-read-only variables, because it is a design feature?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1088", "user": "damccorm", "root": "ROOT108", "reply_to": "COM1087", "timestamp": "2019-12-05T18:18:01Z", "text": "_Updated the wording in my comment above for clarity_\r\n\r\nTo be clear, I think the behavior is undesirable for this use case, but in general it _is_ the behavior we want. The contract we have with the end user is essentially: any time you write something to stdout that matches our `##vso` commands, we'll process it. That includes when tools write something to stdout, or a command writes something to stdout. We have no way of differentiating between you trying to write something and the script accidentally writing something.\r\n\r\nIMO the only potentially questionable behavior here is that we don't require the `##vso` command to be at the start of a line. I see pros and cons on that one, but that's somewhat moot at this point because we wouldn't be able to change that without risking breaking a significant portion of customers. Even with that, its not a bug as much as a design question that you _could_ disagree with.\r\n\r\nDo you think that's fair?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1089", "user": "HughDevlin", "root": "ROOT108", "reply_to": "COM1088", "timestamp": "2019-12-05T18:43:06Z", "text": "> Bash is setting the $_ variable to the first arg of the previous command that was executed (see here for more info on this behavior). When you call set, that is getting written out to stdout. Since the previous command was a ## command, it writes out _='##vso[task.setvariable variable=myvar]BAR'\r\n\r\nSorry, I do not think that's fair.\r\n\r\nIf as you say setting $_ to an arbitrary value prior to invoking ##vso is a circumvention, it is very clear to me that ##vso is making an unjustified assumption about its execution environment, and that needs to be fixed, even if it is not an easy fix. Is that not clear to you?\r\n\r\nIf I invoke ##vso in a script, it behaves differently (undesirably) depending on the immediately previous command, and this is a design feature?\r\n\r\nIn other words, your demonstrated circumvention adding $_=blah before calling ##vso begs the question, well azure, maybe instead of asking customers to add this line to their scripts maybe ##vso should always do something similar under the covers? \r\n\r\nYour proposed feature enhancement leaves existing customers with non-read-only variables vulnerable to this undesirable behavior, bottom line ##vso setvariable without the readOnly=true flag are so undesirable as to be useless.\r\n\r\nFurther, it seems to me, that were the proposed feature enhancement implemented, and customers embraced the readOnly flag, that azure would occasionally issue warning messages \"attempt to update read only variable\" instead of occasionally tacking on a single quote, I guess MS could ask customers to add $_=blah before calling ##vso to suppress the warning message, but that hardly seems like progress to me.\r\n\r\nPlease add ##vso setvariable to the issue description so that other concerned parties, customer and MS, can more accurately recognize the scope of this issue and get more eyes on the proposed feature enhancement. Thank you.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10810", "user": "damccorm", "root": "ROOT108", "reply_to": "COM1089", "timestamp": "2019-12-05T19:07:30Z", "text": "I think I maybe haven't made the problem here clear, there seems to be a little bit of misunderstanding.\r\n\r\n>If as you say setting $_ to an arbitrary value prior to invoking ##vso is a circumvention, it is very clear to me that ##vso is making an unjustified assumption about its execution environment, and that needs to be fixed, even if it is not an easy fix. Is that not clear to you?\r\n> If I invoke ##vso in a script, it behaves differently (undesirably) depending on the immediately previous command, and this is a design feature?\r\n\r\nThe issue is not that `##vso` commands are dependent on the previous line - its actually that in Bash, `set` gives you different output dependent on the previous line (since it is very intentionally dependent on the environment). Since you have an environment variable `$_` now set to `_='##vso[task.setvariable variable=myvar]BAR'`, set prints that line which invokes the `##` command a second time. So what is happening here is:\r\n\r\n```\r\necho \"##vso[task.setvariable variable=myvar]$FOO\"\r\n// The variable has been set to BAR\r\nset\r\n// The variable now gets set to BAR'\r\n```\r\n\r\nThe `##` commands get masked from output which makes this a little challenging to see, but if you turn on diagnostics you can see that's what is happening. That's also why your case doesn't repro if you remove the `set` command.\r\n\r\n> In other words, your demonstrated circumvention adding $_=blah before calling ##vso begs the question, well azure, maybe instead of asking customers to add this line to their scripts maybe ##vso should always do something similar under the covers?\r\n\r\nThis is mostly addressed by what I said previously in this comment, but to be clear, you'd actually want the `$_=blah` before `set` since that's the problematic command. So it would look like:\r\n\r\n```\r\necho \"##vso[task.setvariable variable=myvar]$FOO\"\r\n$_=abc\r\nset\r\n```\r\n\r\nYou wouldn't need this if you were running a different command which doesn't print the environment.\r\n\r\nI would also kindly ask that we keep the conversation friendly and respectful. Please refer to our code of conduct: https://opensource.microsoft.com/codeofconduct/", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10811", "user": "HughDevlin", "root": "ROOT108", "reply_to": "COM10810", "timestamp": "2019-12-05T19:21:25Z", "text": "Dear friend,\r\n\r\nMay I respectfully advocate for intuitive behavior in our software, and may I respectfully suggest that if i need to turn on diagnostic tracing to understand how a bug is feature, perhaps it is a bug.\r\n\r\nMay i respectfully remind you and readers that the MS published idiom for ##vso usage is embedded in echo commands. Respectfully I do not agree that a fix is impossible. I think ##vso needs to be smarter.\r\n\r\nI think this issue and the proposed solution needs more eyes.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10812", "user": "damccorm", "root": "ROOT108", "reply_to": "COM10811", "timestamp": "2019-12-05T19:46:53Z", "text": "I'm going to ask again that we keep the conversation respectful going forward and work towards resolving the problem - otherwise I'll lock the thread to let the conversation cool off.\r\n\r\nAs far as the issue itself goes, I'd again reiterate that I think its working as intended, but we do have the read only feature coming to address use cases like yours. If you disagree, I'd appreciate clarification on how you believe the feature is working right now and how you believe it should work.\r\n\r\nFWIW, the relevant design is as follows:\r\n\r\nAny time a `##vso` command appears in stdout it is processed - regardless of where it appears in the output. If you set a variable twice, the second time you set it wins out. `##vso` commands are wiped from the output (though you can see that they were successfully processed in diagnostic mode).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10813", "user": "HughDevlin", "root": "ROOT108", "reply_to": "COM10812", "timestamp": "2019-12-05T20:51:48Z", "text": "Dear friend, may I respectfully ask where is this documented? My sincere apologies if I missed something.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10814", "user": "damccorm", "root": "ROOT108", "reply_to": "COM10813", "timestamp": "2019-12-05T21:20:45Z", "text": "Our ## syntax is documented here - https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops&tabs=yaml%2Cbatch#set-in-script\r\n\r\nIf you think we need further documentation please raise an issue in the docs repo - [this link](https://github.com/MicrosoftDocs/vsts-docs/issues/new?title=&body=%0A%0A%5BEnter%20feedback%20here%5D%0A%0A%0A---%0A%23%23%23%23%20Document%20Details%0A%0A%E2%9A%A0%20*Do%20not%20edit%20this%20section.%20It%20is%20required%20for%20docs.microsoft.com%20%E2%9E%9F%20GitHub%20issue%20linking.*%0A%0A*%20ID%3A%20dd7e0bd3-1f7d-d7b6-cc72-5ef63c31b46a%0A*%20Version%20Independent%20ID%3A%20dae87abd-b73d-9120-bcdb-6097d4b40f2a%0A*%20Content%3A%20%5BVariables%20-%20Azure%20Pipelines%5D(https%3A%2F%2Fdocs.microsoft.com%2Fen-us%2Fazure%2Fdevops%2Fpipelines%2Fprocess%2Fvariables%3Fview%3Dazure-devops%26tabs%3Dyaml%252Cbatch%23feedback)%0A*%20Content%20Source%3A%20%5Bdocs%2Fpipelines%2Fprocess%2Fvariables.md%5D(https%3A%2F%2Fgithub.com%2FMicrosoftDocs%2Fvsts-docs%2Fblob%2Fmaster%2Fdocs%2Fpipelines%2Fprocess%2Fvariables.md)%0A*%20Product%3A%20**devops**%0A*%20Technology%3A%20**devops-cicd**%0A*%20GitHub%20Login%3A%20%40juliakm%0A*%20Microsoft%20Alias%3A%20**jukullam**) should prepoluate it with the info needed to get it triaged/responded to fastest.\r\n\r\nI'm going to lock this thread since I think it has ceased being productive and respectful.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10815", "user": "damccorm", "root": "ROOT108", "reply_to": "COM10814", "timestamp": "2019-12-05T21:21:57Z", "text": "I'm also going to close since as it stands now this is still a no-op on our end.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT109", "user": "mkArtakMSFT", "root": "ROOT109", "reply_to": null, "timestamp": "2020-10-05T23:19:23Z", "text": "\u23f1\ufe0f Call to action: Help shape the future for ASP.NET Core Hi. Thanks for stopping by.\r \r We're actively working on .NET 6 planning and we would like your help with this.\r In the next few weeks we are going to scan through all the issues in our backlog and identify candidates for .NET 6. To make a decision whether an issue is a good candidate or not for the upcoming release, we also look into the number of upvotes \ud83d\udc4d (and other reactions). To help us prioritize the issues the community feels are most important, please find the issues you want to see resolved and upvote \ud83d\udc4d them.\r \r \r **\u26a0\ufe0f Please don't add descriptions of what you want to see as comments in this issue. Simply find an existing of file a new issue and upvote it**", "meta": {"posReactions": "45", "negReactions": "0"}}
{"id": "COM1090", "user": "boukenka", "root": "ROOT109", "reply_to": "ROOT109", "timestamp": "2020-10-06T09:14:28Z", "text": "AoT compilation https://github.com/dotnet/aspnetcore/issues/5466", "meta": {"posReactions": "186", "negReactions": "0"}}
{"id": "COM1091", "user": "boukenka", "root": "ROOT109", "reply_to": "COM1090", "timestamp": "2020-10-06T09:15:04Z", "text": "SVG Support in Blazor https://github.com/dotnet/aspnetcore/issues/18271", "meta": {"posReactions": "103", "negReactions": "0"}}
{"id": "COM1092", "user": "Julien-Marpault", "root": "ROOT109", "reply_to": "COM1091", "timestamp": "2020-10-06T09:22:33Z", "text": "HTML Autofocus supprt in Blazor WASM", "meta": {"posReactions": "45", "negReactions": "0"}}
{"id": "COM1093", "user": "Julien-Marpault", "root": "ROOT109", "reply_to": "COM1092", "timestamp": "2020-10-06T09:23:05Z", "text": "Projet Reload on save with Kestrel like IIS Express does.", "meta": {"posReactions": "96", "negReactions": "0"}}
{"id": "COM1094", "user": "glararan", "root": "ROOT109", "reply_to": "COM1093", "timestamp": "2020-10-06T11:08:41Z", "text": "#26091 Download compressed resources by default", "meta": {"posReactions": "28", "negReactions": "0"}}
{"id": "COM1095", "user": "199621616", "root": "ROOT109", "reply_to": "COM1094", "timestamp": "2020-10-06T11:17:57Z", "text": "MobileBlazorbindings in the experiment has got a good response. We hope that it can become a formal project of Microsoft as soon as possible, and can provide complete functions, so that users can focus on their own business logic, especially the hybrid applications. It seems to have a chance to surpass electron, more streamlined but more powerful.", "meta": {"posReactions": "58", "negReactions": "0"}}
{"id": "COM1096", "user": "rogihee", "root": "ROOT109", "reply_to": "COM1095", "timestamp": "2020-10-06T11:51:58Z", "text": "Editor & debugger improvements and Hot Reload (Edit & Continue) : [https://github.com/dotnet/aspnetcore/issues/5456](https://github.com/dotnet/aspnetcore/issues/5456)", "meta": {"posReactions": "168", "negReactions": "0"}}
{"id": "COM1097", "user": "expcat", "root": "ROOT109", "reply_to": "COM1096", "timestamp": "2020-10-06T13:19:32Z", "text": "#11558 \r\nStreaming API support to MVC\r\nExample: https://github.com/dotnet/aspnetcore/issues/4833#issuecomment-298857229\r\n```\r\npublic class MyStreamingApi : Controller\r\n{\r\n     [HttpGet(\"/tweets\")]\r\n     [Streaming]\r\n     public async IAsyncEnumerable<Tweet> Get()\r\n     {\r\n         while (var tweet = await GetOneTweet())\r\n         { \r\n             yield return tweet;\r\n         }\r\n     }\r\n}\r\n```", "meta": {"posReactions": "106", "negReactions": "0"}}
{"id": "COM1098", "user": "mkArtakMSFT", "root": "ROOT109", "reply_to": "COM1097", "timestamp": "2020-10-06T15:36:41Z", "text": "All this is great, folks. Please make sure to upvote on the related issues, rather than linking issues here. That's what we're going to look at after all.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1099", "user": "expcat", "root": "ROOT109", "reply_to": "COM1098", "timestamp": "2020-10-06T16:10:45Z", "text": "@mkArtakMSFT #11558 is locked, we can't to upvote.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10910", "user": "papyr", "root": "ROOT109", "reply_to": "COM1099", "timestamp": "2020-10-06T16:16:28Z", "text": "Feature Request: **`Drop-in component for ASP Identity Administration, Portals, UI, SSO, Claims, AD-Sync, Token, Multi.Tenant Management`** so that the Visual Studio templates don't require commercial licensed 3rd party components.\r\n\r\nI have been watching/waiting few yrs. patiently, however some recent changes have forced me to request -- Microsoft revisit this for their developer community, keeping in mind some of the pricing out there compares to the salaries of 10 to 15 developers in Bangladesh, Vietnam, India, Philippines etc.\r\n\r\nCore & Basic need, yet very complex and critical.\r\n\r\nThere's a void in .NET native drop-in solution, unlike the Java, PHP Stacks etc, where there are many native drop in Identity Administration & Management Frameworks options that are leveraged across all their platforms seamlessly by developers, for e.g. the J2EE Pluggable Identity Management Framework or JSR 168 or JSR 286 or JSR-351 or JSR-375.\r\n\r\nWhy is this important? because using Java or PHP, it has allowed easy, clear, core and basic functionalities in those native stacks. As a result if you look `JSR 168` or `JSR 286` or `JSR-351` or `JSR-375` Multi-tenants, [Group to roles, or to claims](https://javaee.github.io/security-spec/spec/jsr375-spec.html#_group_to_role_mapping) vice versa is so easy vs. NET , mobile devices, portals, they all work seamlessly and cohesively with security fixes managed by either IBM or SalesForce or Oracle or Red Hat etc. This is enables developer to be productive right out of the gate.\r\n\r\nIn .Net there is void/very limited support, always requiring a combination of 3rd parties as a barrier to entry & adoption of ASP app. This is non-trivial for developers and security vulnerability that requires the attention of Microsoft Experts.\r\n\r\nExample: We have private information sharing site non OSS for the community almost free (pay if you want), and when we started with web forms, then Simple Membership, the Identity, Identity 2 ASP MVC we had implement much of it on top of these from scratch, when we moved to .NET Core it was another effort. Besides the development there was a lot of confusion on the internal concepts and how they now meant new things. Roles, Claims, Federation, SAML then SAML 2.0 and then Open ID 2.\r\n\r\nDescribe the solution you'd like\r\n\r\n- A drop-in is extensible solution that supports ASP Identity eco-system, Administration, UI, SSO, Token, Multi-tenant Management\r\n- A configuration section to turn on-off the various features.\r\n- Embedded into VS Templates (remove Identity Server, use native MS option etc.)\r\n- Allow-Easy AD Active Directory Integration\r\n- `User Defined/Created Fields UDF` from the Admin level Support.\r\n- The current options and the pricing eliminate many of the existing applications from continuing usage on the .NET stack without extensive retooling or completely abandoning the MS framework.\r\n-  SAML2/CAS [per](https://github.com/dotnet/aspnetcore/issues/26625#issuecomment-710908106) @tbonham\r\n-  Allow template option `Configuration.MultiTenancy.IsEnabled = true;` [Global DataFilter for Tenant entities](https://github.com/dotnet/aspnetcore/issues/27006#issue-723795948)\r\n\r\nIts high time MS address this core gate-keeping feature!!", "meta": {"posReactions": "89", "negReactions": "4"}}
{"id": "COM10911", "user": "papyr", "root": "ROOT109", "reply_to": "COM10910", "timestamp": "2020-10-06T16:30:07Z", "text": "- [ ] Controller/API `DDOS throttling` support\r\n- [ ] Login Controller/API Captcha Anti Spambot support\r\n- [ ] Timeouts are easily by passed using Singal-R and there's [no way to force anonymous connections to disconnect](https://stackoverflow.com/questions/49590384/signalr-persist-connections-for-anonymous-users)\r\n- [ ] No way to handle anonymous chats on public website. For e.g. if _Web User is Surfing/browsing for help or FAQ on product/chat_ on ASP website with SignalR, we have to create a duct-taped solution for this, there is no way to identify them uniquely to create a chat stream/session unless they login. \r\n", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM10912", "user": "mkArtakMSFT", "root": "ROOT109", "reply_to": "COM10911", "timestamp": "2020-10-06T16:50:31Z", "text": "> @mkArtakMSFT #11558 is locked, we can't to upvote.\r\n\r\n@expcat I've reopened it!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10913", "user": "mkArtakMSFT", "root": "ROOT109", "reply_to": "COM10912", "timestamp": "2020-10-06T16:51:52Z", "text": "@papyr please upvote to the related issues and if you can't find such, create new issues for each one separately. That way we can actually track these requests. Otherwise many asks will be lost / forgotten.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM10914", "user": "gulshan", "root": "ROOT109", "reply_to": "COM10913", "timestamp": "2020-10-06T18:32:21Z", "text": "Built-in admin panel template and Vue integration.", "meta": {"posReactions": "8", "negReactions": "0"}}
{"id": "COM10915", "user": "papyr", "root": "ROOT109", "reply_to": "COM10914", "timestamp": "2020-10-06T20:59:43Z", "text": "@mrkarMSFT thanks for the idea \ud83d\udc4d but they keep closing my feature requests and locking them, so its not able to upvote!\r\n\r\nCan you please [unlock 26594](https://github.com/dotnet/aspnetcore/issues/26594) to allow voting on the feature please!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10916", "user": "papyr", "root": "ROOT109", "reply_to": "COM10915", "timestamp": "2020-10-06T21:02:43Z", "text": "> Built-in admin panel template and Vue integration.\r\n\r\nDo you mean Like Skoruba.Admin then upvote https://github.com/dotnet/aspnetcore/issues/26594", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10917", "user": "mnmr", "root": "ROOT109", "reply_to": "COM10916", "timestamp": "2020-10-06T22:33:17Z", "text": "RFC 7692 (WebSocket per-message compression) for SignalR. It seems this depends on [runtime#20004](https://github.com/dotnet/runtime/issues/20004) but it seems relevant in this context. There was an old [issue](https://github.com/aspnet/WebSockets/issues/19) referencing this, but it is now closed and I could find no equivalent open issue here, so I am recommending that people upvote on the runtime issue.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM10918", "user": "3GDXC", "root": "ROOT109", "reply_to": "COM10917", "timestamp": "2020-10-06T22:49:28Z", "text": "blazor wasm-to-wasm interop without javascript (WASI)  [https://github.com/WebAssembly/interface-types/blob/master/proposals/interface-types/Explainer.md]", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM10919", "user": "3GDXC", "root": "ROOT109", "reply_to": "COM10918", "timestamp": "2020-10-06T22:52:16Z", "text": "please provide a way to improve the user experience for blazor wasm load progress, progress bar and/or filename currently downloading.", "meta": {"posReactions": "22", "negReactions": "0"}}
{"id": "COM10920", "user": "3GDXC", "root": "ROOT109", "reply_to": "COM10919", "timestamp": "2020-10-06T22:55:19Z", "text": "project template blazor server/wasm using fast (components) as a user interface as quick start/example", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM10921", "user": "3GDXC", "root": "ROOT109", "reply_to": "COM10920", "timestamp": "2020-10-06T22:58:13Z", "text": "please add support for sftp", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM10922", "user": "seangwright", "root": "ROOT109", "reply_to": "COM10921", "timestamp": "2020-10-07T03:19:22Z", "text": "\"Proposal: View Component Slots\" is locked\r\n\r\n> Provide a built-in or otherwise framework supplied mechanism for View Components, when rendered via a tag helper, to render user-supplied child content that can be injected into the View Component's view template in pre-defined locations\r\n\r\nhttps://github.com/dotnet/aspnetcore/issues/4901", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM10923", "user": "saint4eva", "root": "ROOT109", "reply_to": "COM10922", "timestamp": "2020-10-07T04:25:39Z", "text": "In-house (Microsoft made) identity server and other security modules", "meta": {"posReactions": "89", "negReactions": "0"}}
{"id": "COM10924", "user": "valeriob", "root": "ROOT109", "reply_to": "COM10923", "timestamp": "2020-10-07T04:27:07Z", "text": "I can't find an issue regarding fast dev loop in general that is not mentioning blazor, I would like the whole dev experience  would be much faster", "meta": {"posReactions": "15", "negReactions": "0"}}
{"id": "COM10925", "user": "mrpmorris", "root": "ROOT109", "reply_to": "COM10924", "timestamp": "2020-10-07T12:15:25Z", "text": "Might it be a good idea to create a new call to action with comments disabled?\r\n@mkArtakMSFT ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM10926", "user": "mnmr", "root": "ROOT109", "reply_to": "COM10925", "timestamp": "2020-10-07T13:54:54Z", "text": "@mrpmorris @mkArtakMSFT You should seriously consider abandoning the whole call-to-action thing. Choosing what issues need solving based on community votes is why I never leave MS product feedback/bug reports anymore - if you don't have a social following or plenty of co-workers to upvote your issues they just languish and eventually get closed.\r\n\r\nMy suggestion would be to select topics / general directions that the project can move in, let people pick from those, and let that guide part of the overall effort, without making specific commitments to specific issues. ", "meta": {"posReactions": "7", "negReactions": "7"}}
{"id": "COM10927", "user": "mrpmorris", "root": "ROOT109", "reply_to": "COM10926", "timestamp": "2020-10-07T15:55:29Z", "text": "It's a non-binding advisory vote :)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10928", "user": "mkArtakMSFT", "root": "ROOT109", "reply_to": "COM10927", "timestamp": "2020-10-07T18:08:57Z", "text": "> @mrkarMSFT thanks for the idea \ud83d\udc4d but they keep closing my feature requests and locking them, so its not able to upvote!\r\n> \r\n> Can you please [unlock 26594](https://github.com/dotnet/aspnetcore/issues/26594) to allow voting on the feature please!\r\n\r\n@papyr looking into the issue I believe it's not something aligned with our long-term vision. And that's the reason why @blowdart has closed that issue. Given that, it seems we won't be able to prioritize that one for .NET 6 for sure.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM10929", "user": "mkArtakMSFT", "root": "ROOT109", "reply_to": "COM10928", "timestamp": "2020-10-07T18:10:26Z", "text": "@3GDXC you've listed multiple feature requests above. Please make sure you file separate issues for each one so we can track these better.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT110", "user": "mnn", "root": "ROOT110", "reply_to": null, "timestamp": "2019-10-29T08:51:43Z", "text": "Some parameter names of function lead to shader compilation errors **Godot version:** 3.1.1\r \r **OS/device including version:** Linux (Manjaro 18.1.2)\r \r **Issue description:**\r White rectangle is drawn (outside of image) when shader uses specific argument names in function.\r \r **Steps to reproduce:**\r Create 2D sprite and attach shader:\r ```glsl\r shader_type canvas_item;\r \r vec4 f(sampler2D TEXTURE, vec2 UV, float TIME) {\r \tvec4 tx = texture(TEXTURE, UV);\r \treturn tx;\r }\r \r void fragment() {\r \tCOLOR = f(TEXTURE, UV, TIME);\r }\r ```\r \r Looking at the compiled shader, I thought maybe `TEXTURE` and `UV` are magically accessible in functions.\r \r ```glsl\r vec4 g() {\r \tvec4 tx = texture(TEXTURE, UV);\r \treturn tx;\r }\r ```\r \r They are not: `Unknown identifier in expression: TEXTURE`.\r \r It's interesting that passing `TIME` works fine, but not the others mentioned above.\r \r <!--**Minimal reproduction project:**-->\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1100", "user": "Chaosus", "root": "ROOT110", "reply_to": "ROOT110", "timestamp": "2019-10-29T09:21:28Z", "text": "Duplicate of #32978", "meta": {"posReactions": "1", "negReactions": "1"}}
{"id": "COM1101", "user": "mnn", "root": "ROOT110", "reply_to": "COM1100", "timestamp": "2019-10-29T09:39:17Z", "text": "That \"duplicate\" doesn't mention shader being **broken**, only that it is possible to pass `TIME` and `UV` (btw `UV` doesn't work for me). From my testing it is clear `TEXTURE`, if named same, cannot be passed without second compiler (glsl?) crashing.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1102", "user": "Chaosus", "root": "ROOT110", "reply_to": "COM1101", "timestamp": "2019-10-29T09:51:27Z", "text": "It looking like the same issue, and happens for the same reason - comparsion with pre-existed shader variables for the function parameters does not exist.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1103", "user": "mnn", "root": "ROOT110", "reply_to": "COM1102", "timestamp": "2019-10-29T09:57:54Z", "text": "> It looking like the same issue, and happens for the same reason\r\n\r\nMaybe same reason, but the result is different and expected behaviour as well.\r\n\r\n> comparsion with pre-existed shader variables for the function parameters does not exist\r\n\r\nNot true (if I understand you correctly), `g` function clearly demonstrates the `TEXTURE` does not exist. And `f` is fed a valid variable from `fragment` function (unlike the \"duplicate\" issue), yet the shader **fails** to compile (also unlike the \"duplicate\" issue).\r\n\r\nKinda glad I will be leaving Godot, this \"duplicate\" labeling feels as lazy as on stackoverflow...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1104", "user": "Chaosus", "root": "ROOT110", "reply_to": "COM1103", "timestamp": "2019-10-29T10:03:00Z", "text": "You could add these descriptions to the original \"duplicate\" issue and this is fine. I'm very sorry if this will cause you to leave Godot.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1105", "user": "akien-mga", "root": "ROOT110", "reply_to": "COM1104", "timestamp": "2019-10-29T10:10:51Z", "text": "It *is* the same bug as #32978, I don't see why you're being so annoyed about it being closed as a duplicate.\r\n\r\nUse this code, it works fine:\r\n```\r\nshader_type canvas_item;\r\n\r\nvec4 f(sampler2D p_TEXTURE, vec2 p_UV, float p_TIME) {\r\n\tvec4 tx = texture(p_TEXTURE, p_UV);\r\n\treturn tx;\r\n}\r\n\r\nvoid fragment() {\r\n\tCOLOR = f(TEXTURE, UV, TIME);\r\n}\r\n```\r\n\r\nSo the issue *is* about the shader language allowing users to pass global, context-specific (`TEXTURE` is only available in `fragment()` for example) built-ins as argument names, and the shadowing doesn't work as it should. Most likely, the magic performed by Godot to replace built-in by their actual value also replaces it in the function where they have been declared as arguments. In your case, this function is outside `fragment()` and used `TEXTURE` which is fragment-only, so it breaks. Same bug, just different manifestation.\r\n\r\n> Kinda glad I will be leaving Godot, this \"duplicate\" labeling feels as lazy as on stackoverflow...\r\n\r\nThat's petty, but well. We have enough work not to have to keep duplicate issues open for entitled users.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1106", "user": "mnn", "root": "ROOT110", "reply_to": "COM1105", "timestamp": "2019-10-29T10:11:58Z", "text": "> I'm very sorry if I cause you to leave Godot.\r\n\r\nYou did not, simply my next project will be 3D and Godot is not yet there (I am hoping it will be).\r\n\r\n> You could add these descriptions to the original \"duplicate\" issue and this is fine\r\n\r\nBut, that bug is from an engine user perspecity entirely different:\r\n\r\nthis: crashes shader compilation results in white square\r\n\"duplicate\": magically works, even though it should'n\r\n\r\nthis: `TEXTURE` and `UV` doesn't work\r\n\"duplicate\": `UV` and `TIME` work, even though it shoudl'n\r\n\r\nthis: 2D\r\n\"duplicate\": 3D\r\n\r\nthis: I **am** passing correct values, yet compilation fails and result is broken sprite.\r\n\"duplicate\": passes incorrect values (constants), yet they are being replaced in a function by dynamic values of shader variables\r\n\r\nDo I need to continue? I don't understand how this can be a duplicate when result is different, variables are different (`TEXTURE`, `TIME`) or working differently (`UV`).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1107", "user": "akien-mga", "root": "ROOT110", "reply_to": "COM1106", "timestamp": "2019-10-29T10:14:47Z", "text": ">  \"duplicate\": magically works, even though it should'n\r\n\r\nIt does not work, read the code. If it worked the material would be plain white (`vec3(1.0, 1.0, 1) * sin(0.0)`).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1108", "user": "mnn", "root": "ROOT110", "reply_to": "COM1107", "timestamp": "2019-10-29T10:15:08Z", "text": "> That's petty, but well.\r\n\r\nMaybe, but factually correct.\r\n\r\n> We have enough work not to have to keep duplicate issues open for entitled users.\r\n\r\nI took the time to compile a bug report, only to be closed instantly as a duplicate when nothing in \"duplicate\" is same as in my bug report?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1109", "user": "akien-mga", "root": "ROOT110", "reply_to": "COM1108", "timestamp": "2019-10-29T10:18:48Z", "text": "At some point you have to trust engine contributors to know what bugs are. You see symptoms, we see the underlying cause for them, and we tell you that these are both symptoms of the exact same bug.\r\n\r\nA duplicate bug report is not a bad thing, it just confirms the bug with possibly slightly different steps to reproduce. It's pointless to keep two or 50 issues open about the same bug, so we close duplicates, usually keeping the oldest one open.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM11010", "user": "mnn", "root": "ROOT110", "reply_to": "COM1109", "timestamp": "2019-10-29T10:18:52Z", "text": "> It does not work, read the code. If it worked the material would be plain white (vec3(1.0, 1.0, 1) * sin(0.0)).\r\n\r\nI mean it compiles and runs, at least that what title suggests: \"Strange syntax is **allowed** to pass global parameters to the shader function\". It \"works\" as in the functions gets `TIME` from context of a `fragment` (not passed argument in call) which doesn't happen in my case - it crashes during compilation because probably renaming fails.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM11011", "user": "akien-mga", "root": "ROOT110", "reply_to": "COM11010", "timestamp": "2019-10-29T10:20:14Z", "text": "Here, renamed, be happy.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT111", "user": "Mystic8b", "root": "ROOT111", "reply_to": null, "timestamp": "2020-06-04T12:29:32Z", "text": "Incorrect wsl disk space <!--\r \ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\r \r I ACKNOWLEDGE THE FOLLOWING BEFORE PROCEEDING:\r 1. If I delete this entire template and go my own path, the core team may close my issue without further explanation or engagement.\r 2. If I list multiple bugs/concerns in this one issue, the core team may close my issue without further explanation or engagement.\r 3. If I write an issue that has many duplicates, the core team may close my issue without further explanation or engagement (and without necessarily spending time to find the exact duplicate ID number).\r 4. If I leave the title incomplete when filing the issue, the core team may close my issue without further explanation or engagement.\r 5. If I file something completely blank in the body, the core team may close my issue without further explanation or engagement.\r \r All good? Then proceed!\r -->\r \r <!--\r This bug tracker is monitored by Windows Subsystem for Linux development team and other technical folks.\r \r Important: When reporting BSODs or security issues, DO NOT attach memory dumps, logs, or traces to Github issues.\r Instead, send dumps/traces to secure@microsoft.com, referencing this GitHub issue. Ideally, please configure your machine to capture minidumps, repro the issue, and send the minidump from \"C:\\Windows\\minidump\\\".\r You can find instructions to do that here: https://support.microsoft.com/en-us/help/315263/how-to-read-the-small-memory-dump-file-that-is-created-by-windows-if-a\r \r If this is a console issue (a problem with layout, rendering, colors, etc.), please post the issue to the Terminal tracker: https://github.com/microsoft/terminal/issues\r For documentation improvements, please post to the documentation tracker: https://github.com/MicrosoftDocs/WSL/issues\r For any other questions on contributing please see our contribution guidelines: https://github.com/Microsoft/WSL/blob/master/CONTRIBUTING.md\r \r Please fill out the items below.\r -->\r \r ```\r # Environment\r Platform ServicePack Version      VersionString\r -------- ----------- -------      -------------\r  Win32NT             10.0.19041.0 Microsoft Windows NT 10.0.19041.0\r ```\r \r ```\r \u276f lsb_release -r\r Release:        20.04\r ```\r \r ```\r \u276f cat /proc/version\r Linux version 4.19.84-microsoft-standard (oe-user@oe-host) (gcc version 8.2.0 (GCC)) #1 SMP Wed Nov 13 11:44:37 UTC 2019\r ```\r \r # Steps to reproduce\r `df -h -> enter`\r <!--  What you're doing and what's happening. Copy&paste the full set of specific command-line steps necessary to reproduce the behavior, and their output. Include screenshots if that helps demonstrate the problem. -->\r \r <!-- \r If you'd like to provide logs you can provide an `strace(1)`  log of the failing command (if `some_command` is failing, then run `strace -o some_command.strace -f some_command some_args`, and link the contents of `some_command.strace` in a gist. \r More info on `strace` can be found here: https://www.man7.org/linux/man-pages/man1/strace.1.html\r You can use Github gists to share the output: https://gist.github.com/\r \r Additionally, For WSL launch issues, please collect detailed logs, instructions here: https://github.com/Microsoft/WSL/blob/master/CONTRIBUTING.md#8-detailed-logs \r -->\r \r #  Expected behavior\r Free space on wsl corresponds to reality\r \r <!-- A description of what you're expecting, possibly containing screenshots or reference material. -->\r \r # Actual behavior\r \r Free / occupied space does not correspond to reality\r ![image](https://user-images.githubusercontent.com/35394377/83756183-5aa05f00-a677-11ea-96f1-22f3f9d7d631.png)\r \r <!-- What's actually happening? -->\r \r \r \r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1110", "user": "benhillis", "root": "ROOT111", "reply_to": "ROOT111", "timestamp": "2020-06-04T16:48:31Z", "text": "/dev/sdb is not your C drive, it's a VHD that contains your root filesystem.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1111", "user": "Mystic8b", "root": "ROOT111", "reply_to": "COM1110", "timestamp": "2020-06-04T16:50:15Z", "text": "Yes, but there should be as much space on it as there is on the current drive, isn\u2019t it?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1112", "user": "therealkenc", "root": "ROOT111", "reply_to": "COM1111", "timestamp": "2020-06-04T17:52:44Z", "text": "No, because it isn't your drive. There is 250GiB on \"it\" (by default). Where the \"it\" here isn't a real drive. It is a virtual block device. The size of the _virtual device_ is 250GiB whether the _backing storage_ for the device lives on a 128 gigabyte ssd or a 128 terrabyte raid array. The size isn't real because the device isn't real.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1113", "user": "Mystic8b", "root": "ROOT111", "reply_to": "COM1112", "timestamp": "2020-06-04T17:56:46Z", "text": "Where is 250mb here? There 251GB\r\nI understand that this is a virtual device, but it must have a certain size occupied on the disk, as on the disks of virtual machines in a workstation, etc.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1114", "user": "benhillis", "root": "ROOT111", "reply_to": "COM1113", "timestamp": "2020-06-04T18:00:34Z", "text": "@Mystic8b - I don't see MB anywhere in the screenshot you posted, I might be looking at it wrong but I see.\r\n\r\n/dev/sdb size=251G used=2.8G\r\nC:\\ size=209G Used=98G", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1115", "user": "Mystic8b", "root": "ROOT111", "reply_to": "COM1114", "timestamp": "2020-06-04T18:02:05Z", "text": "> /dev/sdb size=251G used=2.8G\r\n> C:\\ size=209G Used=98G\r\n\r\nExactly. Where does 251gb come from?\r\nAbout megabytes, I never said a word\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1116", "user": "therealkenc", "root": "ROOT111", "reply_to": "COM1115", "timestamp": "2020-06-04T18:04:37Z", "text": "Type-o obv. 250 GiB (shows as 251GiB). That number is arbitrary ref #4373.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1117", "user": "Mystic8b", "root": "ROOT111", "reply_to": "COM1116", "timestamp": "2020-06-04T18:04:38Z", "text": "Okay, therealkenc edited his post, first he wrote 250mib\r\nSo you want to say that a 250GB virtual disk with a real free space of 111GB is normal?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1118", "user": "therealkenc", "root": "ROOT111", "reply_to": "COM1117", "timestamp": "2020-06-04T18:11:10Z", "text": "Very normal. You can have a dozen 250 GiB virtual disks (total of 3TiB of space that doesn't really exist) one 128 GiB SSD. [Which is why this is tag by-design already.]", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1119", "user": "benhillis", "root": "ROOT111", "reply_to": "COM1118", "timestamp": "2020-06-04T18:18:11Z", "text": "@therealkenc is right, the disk is dynamic and that is the maximum size.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM11110", "user": "Mystic8b", "root": "ROOT111", "reply_to": "COM1119", "timestamp": "2020-06-04T18:19:26Z", "text": "![image](https://user-images.githubusercontent.com/35394377/83796043-09a95e80-a6a9-11ea-833e-927b3694b2a4.png)\r\nbenhillis, kapish?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM11111", "user": "therealkenc", "root": "ROOT111", "reply_to": "COM11110", "timestamp": "2020-06-04T18:19:27Z", "text": "Thought of a clearer way to put this. Your ext4 filesystem is ~250GiB. It doesn't [resize](http://manpages.ubuntu.com/manpages/xenial/man8/resize2fs.8.html) every time you consume a few more bytes in Windows.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM11112", "user": "Mystic8b", "root": "ROOT111", "reply_to": "COM11111", "timestamp": "2020-06-04T18:22:27Z", "text": "damn, okay, it seems there is an opportunity to reduce the size of this disk, even so.\r\nty", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM11113", "user": "benhillis", "root": "ROOT111", "reply_to": "COM11112", "timestamp": "2020-06-04T18:27:08Z", "text": "This isn't constructive.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT112", "user": "NebelNidas", "root": "ROOT112", "reply_to": null, "timestamp": "2020-02-22T10:38:44Z", "text": "feat: Allow custom file extensions ## Summary\r As discussed in #4182, I'd like to request the addition of the \"override_ext\" front matter tag.\r \r ## Motivation\r I'm using php code on my website, like many others, too. I can create a \"test.php\" file, and the generated file will have the \".php\"-extension, all right. However, I want to use markdown for my blog posts, and these \".md\" files are automatically generated to \".html\" files! And because the posts have a .\"php\" layout with php code, but the file ends up as html, the site does not work. OK, I could create a permalink as suggested in the issue linked above, but that's a bad workaround because I don't want to hardcode the file name and directory.\r A similar request has been discussed already, but I find the [excuses](https://github.com/jekyll/jekyll/issues/5646#issuecomment-357329996) quite weak. As of now, it's hardcoded for markdown files to be converted to html files, and that's simply not right. Give us an option here!\r \r Edit: OK, it's not really needed for other files where I can already set my custom extension manually, this would just add more confusion. But for all files which jekyll automatically converts into a hardcoded format, this should be changeable - most likely in config.yml.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1120", "user": "jekyllbot", "root": "ROOT112", "reply_to": "ROOT112", "timestamp": "2020-04-22T11:10:18Z", "text": "\nThis issue has been automatically marked as stale because it has not been commented on for at least two months.\n\nThe resources of the Jekyll team are limited, and so we are asking for your help.\n\nIf this is a **bug** and you can still reproduce this error on the latest <code>3.x-stable</code> or <code>master</code> branch, please reply with all of the information you have about it in order to keep the issue open.\n\nIf this is a **feature request**, please consider building it first as a plugin. Jekyll 3 introduced [hooks](http://jekyllrb.com/docs/plugins/#hooks) which provide convenient access points throughout the Jekyll build pipeline whereby most needs can be fulfilled. If this is something that cannot be built as a plugin, then please provide more information about why in order to keep this issue open.\n\nThis issue will automatically be closed in two months if no further activity occurs. Thank you for all your contributions.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1121", "user": "MichaelCurrin", "root": "ROOT112", "reply_to": "COM1120", "timestamp": "2020-05-09T21:18:21Z", "text": "This is already possible based on answers here.\r\n\r\nhttps://stackoverflow.com/questions/14119772/how-to-change-extension-of-files-generated-by-jekyll\r\n\r\nAn arbitrary extension or no-extension file will be parsed with liquid if it has frontmatter and then jekyll outputs as .html\r\nAnd if you set the permalink in the file you can force the extension to be .json, .php , etc.\r\nMaybe set the permalink pattern globally in the config as a collection. You can set permalink for post but the response there was that it doesn't work in this case I think", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1122", "user": "NebelNidas", "root": "ROOT112", "reply_to": "COM1121", "timestamp": "2020-05-11T09:08:19Z", "text": "Yeah, that's the problem: I don't want to hardcode the path with permalinks, I just want to be able to adjust the file extension...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1123", "user": "NebelNidas", "root": "ROOT112", "reply_to": "COM1122", "timestamp": "2020-05-11T09:09:50Z", "text": "Also, @DirtyF: It would be nice to at least give an explanation before just closing an issue, this way nothing will get resolved,", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT113", "user": "nicknabdullah", "root": "ROOT113", "reply_to": null, "timestamp": "2019-10-22T03:35:35Z", "text": "Can't login for the last few days I'm trying to login for the last 3 days, using my google/github account but everytime getting the message: \r \r > \"Oops! Something went wrong. Please try again in a moment.\" \r \r I've tried clearing cache/cookies/incognito. But nothing is working. Also getting the same error when starting a project task. \r \r ![image](https://user-images.githubusercontent.com/13465486/67257769-48d6c680-f4af-11e9-8288-4c16cc3032f6.png)\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1130", "user": "raisedadead", "root": "ROOT113", "reply_to": "ROOT113", "timestamp": "2019-10-22T07:23:27Z", "text": "Hi @nicknabdullah \r\n\r\nChances are you have a duplicate account. Please email us at `supporr@freecodecamp.org` and We will try and get this resolved for you.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1131", "user": "cinziaa", "root": "ROOT113", "reply_to": "COM1130", "timestamp": "2019-10-22T09:34:49Z", "text": "Hi @raisedadead \r\nI've the same issue. I've tried revoking and granting access with Github and login with email and Google, but nothing. \r\nI hope you solve it soon. Thanks\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1132", "user": "raisedadead", "root": "ROOT113", "reply_to": "COM1131", "timestamp": "2019-10-22T10:50:24Z", "text": "> ### Chances are you have a duplicate account.\r\n\r\n**How to fix?**\r\n\r\n> #### Please email us at `support@freecodecamp.org` and we will get this resolved for you.\r\n\r\n**But why would I have duplicate accounts?**\r\n\r\nBack in June 2018, we had updated our platform. At that time, a bug had caused account duplications for some users. \r\n\r\nWith the recent Oct, 2019 update to the platform, we have identified that the bug was fixed but the account duplications remain in the database. These unfortunately have to fixed by our team manually. Users have progressed with the curriculum since last year and a programmatic fix may not be possible.\r\n\r\nNone of your progress is gone or lost. They are simply lying in a different account with the same email address or username attached to it.\r\n\r\n**Does this affect how I login? Can I use GitHub or other logins**\r\n\r\nWe simply rely on the email address that is received by us, as long as GitHub, Facebook, Google are returning the same email you have with us you will be signed into your correct account.\r\n\r\nThanks for your patience, and understanding with this. The newer platform is more resilient and we look forward to your feedback \r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1133", "user": "moT01", "root": "ROOT113", "reply_to": "COM1132", "timestamp": "2020-09-08T18:42:39Z", "text": "Closing as stale. Please read the comment above if you are having issues with your account. Thanks and happy coding \ud83c\udf89 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT114", "user": "nikolayval", "root": "ROOT114", "reply_to": null, "timestamp": "2020-02-29T04:13:58Z", "text": "How I can add Yandex RTB (Ads-code) to Gatsby? Hello!\r \r I'm using Gatsby-MDX for my posts. And I want to add Yandex RTB-code to my site. \r \r It's Google Adsense alternative from Yandex (in Russia). Here is example, how is looking Yandex RTB-code:\r \r ```\r <div id=\"rtb-1\"></div>\r <script type=\"text/javascript\">\r     (function (w, d, n, s, t) {\r         function renderRtb () {\r             Ya.Context.AdvManager.render({\r                 blockId: \"R-A-12345-1\",\r                 renderTo: \"rtb-1\",\r                 statId: 34567, // CROSS SECTION ID\r                 async: true\r             });\r         }\r         w[n] = w[n] || [];\r         w[n].push(renderRtb);\r         t = d.getElementsByTagName(\"script\")[0];\r         s = d.createElement(\"script\");\r         s.type = \"text/javascript\";\r         s.src = \"http://an.yandex.ru/system/context.js\";\r         s.async = true;\r         t.parentNode.insertBefore(s, t);\r     })(this, this.document, \"yandexContextAsyncCallbacks\");\r </script>\r ```\r \r Please, sir, tell me. What's there is best way to insert Yandex Ads into my MDX-posts? For example, can I create .txt-file. Then import .txt file (with Ads code) where I need into my MDX-posts?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1140", "user": "blainekasten", "root": "ROOT114", "reply_to": "ROOT114", "timestamp": "2020-02-29T16:16:07Z", "text": "Hey @nikoladev I'm assuming this is just some code you need to insert into the `head` element. If so, this document will tell you how to customize the html output. Follow the steps and put this script tag in the head tag. I'm not sure what else Yandex needs, but this is generally how google adsense works.\r\n\r\nhttps://www.gatsbyjs.org/docs/custom-html/\r\n\r\nI'm going to close this issue as I don't believe it's reporting a problem with Gatsby. I'm happy to keep the discussion going, so don't take this as a negative sign. Please report back if you need continued support! \ud83d\ude03", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1141", "user": "nikolayval", "root": "ROOT114", "reply_to": "COM1140", "timestamp": "2020-03-01T02:50:24Z", "text": "No, I don't need to insert a showed code between `<head>` tag's or in the footer. \r\n\r\nI should to insert the code into my MDX-posts. And it's show my Yandex Ads into my posts.\r\n\r\nFor example, I want to show Ads in the center of my MDX-posts. Or after some H2-tags etc. \r\n\r\nHow I can insert my code into MDX-posts?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1142", "user": "pvdz", "root": "ROOT114", "reply_to": "COM1141", "timestamp": "2020-03-10T11:00:49Z", "text": "@nikolayval Feels to me like this is more of an MDX question than Gatsby, is it not? I have little experience with MDX. Gatsby takes the MDX content and uses Babel (etc.) to generate the web pages. It's not really aware of this.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1143", "user": "DSchau", "root": "ROOT114", "reply_to": "COM1142", "timestamp": "2020-03-13T17:06:13Z", "text": "@nikbelikov You can do something like this: https://github.com/gatsbyjs/gatsby/blob/master/www/src/components/script-loader.js (and then you'd use a component for those ads that uses that component, and then you'd use that wrapping component in MDX)\r\n\r\nPlease in the future be a bit more careful in how you approach soliciting help from this community. We're glad to have you here, and value you using Gatsby, but we want to also be kind in how we request help from the core maintainers of Gatsby.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM1144", "user": "nikolayval", "root": "ROOT114", "reply_to": "COM1143", "timestamp": "2020-03-13T17:15:19Z", "text": "**Dschau**, thank you very much for answer. You are the best, and thank you thank you thank you thank you thank you! \r\n\r\nBut sorry, it's bullshit solution. \r\n\r\nIf I want to display specific script (in my case - it's Yandex Ads, like Google Adsense alternative from Russia) in MDX-posts (or markdown files), then I should create a custom script components with specific attributes. It's very hard and not convenient. \r\n\r\nMaybe Gatsby team can create plugin to render custom scripts into MDX or markdown files? I want to display Yandex Ads, Amazon Ads, Yahoo Ads or something else. And each time I should create hard components? WTF? ", "meta": {"posReactions": "0", "negReactions": "3"}}
{"id": "COM1145", "user": "DSchau", "root": "ROOT114", "reply_to": "COM1144", "timestamp": "2020-03-13T18:13:24Z", "text": "Then you would do something slightly different. It's hard to predict what you want, because it's not clear what you want.\r\n\r\nHere's an example Codesandbox that gets _closer_ to what you want, but it's still not working. This being said, I also wasn't even able to get the snippet you pasted above working, so I'm skeptical of the general approach.\r\n\r\n[React Codesandbox](https://codesandbox.io/s/angry-sun-4dfmf) | [Vanilla Codesandbox](https://codesandbox.io/s/festive-surf-4t6k4)\r\n\r\n> Failed to load resource: the server responded with a status of 404 ()\r\n\r\nI'm going to lock this, as I don't find this discussion productive nor valuable for us to be having. This is very much not a Gatsby problem, and is a general issue with loading Yandex scripts.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT115", "user": "nkkollaw", "root": "ROOT115", "reply_to": null, "timestamp": "2019-12-19T13:23:38Z", "text": "\ud83c\udf85 ", "meta": {"posReactions": "22", "negReactions": "2"}}
{"id": "COM1150", "user": "Phillipus", "root": "ROOT115", "reply_to": "ROOT115", "timestamp": "2019-12-19T13:25:38Z", "text": ":santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: ", "meta": {"posReactions": "27", "negReactions": "3"}}
{"id": "COM1151", "user": "tyber-io", "root": "ROOT115", "reply_to": "COM1150", "timestamp": "2019-12-19T13:26:52Z", "text": ":santa: ", "meta": {"posReactions": "13", "negReactions": "2"}}
{"id": "COM1152", "user": "tyber-io", "root": "ROOT115", "reply_to": "COM1151", "timestamp": "2019-12-19T13:38:58Z", "text": "people who thumb down the santa have never received a present from him, naughty boys", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM1153", "user": "egamma", "root": "ROOT115", "reply_to": "COM1152", "timestamp": "2019-12-19T19:42:38Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.\r\n\r\nHappy Coding!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT116", "user": "nkkollaw", "root": "ROOT116", "reply_to": null, "timestamp": "2019-12-19T13:33:05Z", "text": "Kernel panic when opening files I'm experiencing kernel panics when opening ANY FILE with Visual Studio Code.\r \r The kernel panics seems to be caused by the removal of the Santa hat.\r \r Please put back Santa hat.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1160", "user": "Phillipus", "root": "ROOT116", "reply_to": "ROOT116", "timestamp": "2019-12-19T13:34:19Z", "text": ":santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: :santa: ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1161", "user": "tyber-io", "root": "ROOT116", "reply_to": "COM1160", "timestamp": "2019-12-19T13:35:52Z", "text": "it seems like kernel trauma, it has befriended santa and now microsoft crushed its dreams", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1162", "user": "tyber-io", "root": "ROOT116", "reply_to": "COM1161", "timestamp": "2019-12-19T13:36:26Z", "text": "that's how skynet started", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1163", "user": "braindigitalis", "root": "ROOT116", "reply_to": "COM1162", "timestamp": "2019-12-19T13:38:53Z", "text": "Please dont put the santa hat back. Put a satan hat back.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1164", "user": "chrisdias", "root": "ROOT116", "reply_to": "COM1163", "timestamp": "2019-12-19T19:56:18Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.\r\n\r\nHappy Coding!\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT117", "user": "nkkollaw", "root": "ROOT117", "reply_to": null, "timestamp": "2019-12-19T13:41:26Z", "text": "Coding productivity decreased since last build Coding productivity has decreased enormously since the removal of the Santa hat.\r \r Please make it your top priority to bring Santa hat back.", "meta": {"posReactions": "37", "negReactions": "1"}}
{"id": "COM1170", "user": "vscodebot[bot]", "root": "ROOT117", "reply_to": "ROOT117", "timestamp": "2019-12-19T13:41:32Z", "text": "(Experimental duplicate detection)\nThanks for submitting this issue. Please also check if it is already covered by an existing one, like:\n- [Santa Hat Removal (#87318)](https://www.github.com/microsoft/vscode/issues/87318) <!-- score: 0.454 -->\n<!-- potential_duplicates_comment -->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1171", "user": "tyber-io", "root": "ROOT117", "reply_to": "COM1170", "timestamp": "2019-12-19T13:43:37Z", "text": "I also can't focus on my work since then, please let me be productive again", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM1172", "user": "brlebtag", "root": "ROOT117", "reply_to": "COM1171", "timestamp": "2019-12-19T13:54:46Z", "text": ":santa: will be back!", "meta": {"posReactions": "3", "negReactions": "1"}}
{"id": "ROOT118", "user": "Noemata", "root": "ROOT118", "reply_to": null, "timestamp": "2020-03-17T13:28:22Z", "text": "ETA for UWP support? Is there an ETA for when this library might support UWP?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1180", "user": "AArnott", "root": "ROOT118", "reply_to": "ROOT118", "timestamp": "2020-03-17T13:30:02Z", "text": "No. You might be the first person to express an interest in this. I'm surprised if it doesn't work. Are you thinking specifically about .NET Native support?\r\nWhat failures are you seeing?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1181", "user": "Noemata", "root": "ROOT118", "reply_to": "COM1180", "timestamp": "2020-03-17T13:41:39Z", "text": "As you already know, MessagePack bombs when compiled for .Net Native.  You yourself closed that issue here.  I'm now wondering whether there is an ETA for addressing this?  I don't want the ETA issue to get lost in the mix because we need a means of tracking how long it takes to sort out .Net Native problems.  Some of them can be addressed by design choices Microsoft makes.  Since Microsoft promoted UWP, a degree of accountability is required just so we all have visibility to what's at stake.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1182", "user": "AArnott", "root": "ROOT118", "reply_to": "COM1181", "timestamp": "2020-03-18T04:11:52Z", "text": "If the only failure in UWP happens when using this library with MessagePack, and the failure is within MessagePack itself, we should close this issue since it isn't a bug in StreamJsonRpc. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1183", "user": "Noemata", "root": "ROOT118", "reply_to": "COM1182", "timestamp": "2020-03-18T05:56:01Z", "text": "So now I'm going to reply exactly the way Microsoft replies to me.\r\n\r\n@MichalStrehovsky correctly stated that \"since ~.NET Framework 1.0\", the .Net Native compiler has had certain documented behaviors in the way it generates its code.   The implication being that an understanding of .Net Native characteristics requires different design choices.\r\n\r\nIt's a very convenient way of saying that the bug I had in my code was a bug with my design rather than the .Net Native compiler even though my code did/should work in any given .Net runtime context, but .Net Native is special, thus requiring special design considerations.\r\n\r\n@AArnott, before you close this issue you will have to adjust where you point the finger.  The problem isn't with MessagePack, according to @MichalStrehovsky the problem is your design choice since you, being on the inside of Microsoft, have an even better understanding of the way the .Net Native compiler works.\r\n\r\nOr, the problem is the .Net Native compiler documentation because even Microsoft staff are not aware of the design considerations they have to employ to build products that support Microsoft tech.\r\n\r\nOr, the problem is the way Microsoft operates internally because you folks are prepared to ignore each other and go off to build tooling that your customers are unable to use.\r\n\r\nOr, the problem is Microsoft knows what the future holds, and dumps technology support for its existing tech knowing that that tech is about to be invalidated by what comes next.\r\n\r\nThere are several other logical or cases.  You get the point.\r\n\r\nThis issue is not related to MessagePack.  I don't want it swept under the rug because either Microsoft is here to support the developers using its tech, or Microsoft does as it pleases regardless of how it affects the developers it has convinced to use its tech.\r\n\r\n@AArnott, I suggest you run this by your bosses.  Either you made a mistake, or the entire organization has.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1184", "user": "MichalStrehovsky", "root": "ROOT118", "reply_to": "COM1183", "timestamp": "2020-03-18T07:30:06Z", "text": "> \"since ~.NET Framework 1.0\", the .Net Native compiler has had certain documented behaviors in the way it generates its code\r\n\r\n@noemata are you referring to this issue: https://github.com/grpc/grpc/issues/18188#issuecomment-542712813 where you interacted with me? That comment is specifically to the behavior of the `Assembly.Location` API that returns the documented value when there's no filesytem location for the loaded assembly. .NET Native compiles apps into a single file and the original assemblies are gone. It has no choice but to return the only possible documented value. It could also throw, but that won't help in grpc's case either.\r\n\r\nI'm afraid you're sidetracking this discussion in a way that won't help you get a resolution in streamjsonrpc. I don't see `Assembly.Location` being called within this repo. Do you have an error message or a repro so that we can act on this?", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1185", "user": "Noemata", "root": "ROOT118", "reply_to": "COM1184", "timestamp": "2020-03-18T08:25:45Z", "text": "Thank you for chiming in @MichalStrehovsky.  Both the comment you make and the way @AArnott initiated the closure of this issue was disingenuous.  You folks are well aware of the .Net Native problems and design considerations.  The developer of MessagePack and @AArnott's contributions to that code base are not at fault here.  @AArnott is a very smart fellow as are you @MichalStrehovsky.\r\n\r\nIt may be a PITA to have .Net Native issues surfaced this way.  However, that's the real problem and characterizing it any other way is also a problem.  Sadly, I'm not expecting Microsoft to do anything other than replace the .Net Native compiler with whatever the new .Net Core AOT strategy will be.  Until that happens, you folks need to own up to where things are really headed.\r\n\r\nIt's obvious the reboot is well on the way.  Just say so and stop pretending that any of the .Net Native compiler problems will actually be addressed.  A year went by on the gRPC issue.  A year with no resolution!  I'd even be ok with a form of admission and a statement along the lines that we need to resolve these issues ourselves.   At least that way, time wouldn't be wasted on false expectations.\r\n\r\nThis library is a nice piece of work.  I'd like to be able to use it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1186", "user": "MichalStrehovsky", "root": "ROOT118", "reply_to": "COM1185", "timestamp": "2020-03-18T08:40:09Z", "text": "The `Assembly.Location` problem is headed into .NET Core proper: https://github.com/dotnet/designs/pull/90#discussion_r375120319. GRPC will have to fix it's bugs. More developers use .NET Core proper, so hopefully they'll be more incentivized to fix the problem. I'm sorry that you're ending up being a hostage to them ignoring the problem. Single file compilation greatly improves startup time of apps and simplifies the distribution a lot - that's why a of users are asking for that mode and we're going to add it outside .NET Native too. But some APIs simply don't make sense in that mode. `Assembly.Location` is one of those.\r\n\r\nAs I said, if you can get me the error message or repro for the streamjsonrpc issue I might be able to help you make progress on that one. For GRPC, the ball is really in their court.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1187", "user": "Noemata", "root": "ROOT118", "reply_to": "COM1186", "timestamp": "2020-03-18T09:02:18Z", "text": "Starting bottom up, MessagePack bombs on code like this:\r\n\r\n```\r\nusing System;\r\nusing System.Linq;\r\nusing MessagePack;\r\n\r\n// This example code shows how you could implement the required main function for a \r\n// Console UWP Application. You can replace all the code inside Main with your own custom code.\r\n\r\n// You should also change the Alias value in the AppExecutionAlias Extension in the \r\n// Package.appxmanifest to a value that you define. To edit this file manually, right-click\r\n// it in Solution Explorer and select View Code, or open it with the XML Editor.\r\n\r\nnamespace Tester\r\n{\r\n\t[MessagePackObject]\r\n\tpublic class Model\r\n\t{\r\n\t\t[Key(0)]\r\n\t\tpublic bool? Bool { get; set; }\r\n\r\n\t\t[Key(1)]\r\n\t\tpublic byte? Byte { get; set; }\r\n\r\n\t\t[Key(2)]\r\n\t\tpublic sbyte? SByte { get; set; }\r\n\r\n\t\t[Key(3)]\r\n\t\tpublic short? Short { get; set; }\r\n\r\n\t\t[Key(4)]\r\n\t\tpublic ushort? UShort { get; set; }\r\n\r\n\t\t[Key(5)]\r\n\t\tpublic int? Int { get; set; }\r\n\r\n\t\t[Key(6)]\r\n\t\tpublic uint? UInt { get; set; }\r\n\r\n\t\t[Key(7)]\r\n\t\tpublic long? Long { get; set; }\r\n\r\n\t\t[Key(8)]\r\n\t\tpublic ulong? ULong { get; set; }\r\n\r\n\t\t[Key(9)]\r\n\t\tpublic float? Float { get; set; }\r\n\r\n\t\t[Key(10)]\r\n\t\tpublic double? Double { get; set; }\r\n\r\n\t\t[Key(11)]\r\n\t\tpublic decimal? Decimal { get; set; }\r\n\r\n\t\t[Key(12)]\r\n\t\tpublic string String { get; set; }\r\n\r\n\t\t[Key(13)]\r\n\t\tpublic DateTime? DateTime { get; set; }\r\n\t}\r\n\r\n\tclass Program\r\n    {\r\n\r\n\t\tstatic void Main(string[] args)\r\n        {\r\n\t\t\tRandom rnd = new Random();\r\n\r\n\t\t\tModel[] datarange;\r\n\r\n\t\t\tdatarange = Enumerable.Repeat(\r\n\t\t\t\tnew Model\r\n\t\t\t\t{\r\n\t\t\t\t\tBool = rnd.Next(0, 1) == 0 ? false : true,\r\n\t\t\t\t\tByte = (byte)rnd.Next(0, 0xFF),\r\n\t\t\t\t\tSByte = (sbyte)rnd.Next(0, 0xFF),\r\n\t\t\t\t\tShort = (short)rnd.Next(-1, 1),\r\n\t\t\t\t\tUShort = 1,\r\n\t\t\t\t\tInt = -1,\r\n\t\t\t\t\tUInt = 1,\r\n\t\t\t\t\tLong = -1L,\r\n\t\t\t\t\tULong = 1UL,\r\n\t\t\t\t\tFloat = 1.0f,\r\n\t\t\t\t\tDouble = 1.0,\r\n\t\t\t\t\tDecimal = 1m,\r\n\t\t\t\t\tString = \"a string\",\r\n\t\t\t\t\tDateTime = new DateTime(2020, 1, 1)\r\n\t\t\t\t},\r\n\t\t\t\t10).ToArray();\r\n\r\n\t\t\tbyte[] testbinary = MessagePackSerializer.Serialize(datarange);\r\n\r\n\t\t\t// Crash here: \"A type initializer threw an exception.\"\r\n\t\t\tModel[] testdata = MessagePackSerializer.Deserialize<Model []>(testbinary);\r\n\r\n\t\t\tConsole.WriteLine(\"Press a key to continue: \");\r\n            Console.ReadLine();\r\n        }\r\n    }\r\n}\r\n```\r\nhttps://github.com/neuecc/MessagePack-CSharp/issues/840\r\n\r\nSo fixing MessagePack should fix streamjsonrpc.\r\n\r\nI wouldn't be too quick to blame gRPC, since Microsoft is using it and endorsing it as a replacement for WCF.  The current \"flaw\" in the gRPC code base is the way it makes use of Assembly.Location, which is used in a similar manner in many other libs.  Remove this bug and gRPC works in a UWP Release build as well as any other context.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1188", "user": "MichalStrehovsky", "root": "ROOT118", "reply_to": "COM1187", "timestamp": "2020-03-18T09:24:20Z", "text": "Thanks! This is failing with the following stack trace (if you check the checkbox next to \"Common Language Runtime Exceptions\" in the Visual Studio's Exception window:\r\n\r\n```\r\n \tSystem.Private.CoreLib.dll!System.Reflection.Emit.TypeBuilder.GetMethod(System.Type type, System.Reflection.MethodInfo method) Line 11\tC#\r\n \tMessagePack.dll!MessagePack.Internal.DynamicAssembly.DynamicAssembly(string moduleName)\tUnknown\r\n \tMessagePack.dll!MessagePack.Resolvers.DynamicEnumResolver.DynamicEnumResolver()\tUnknown\r\n \tSystem.Private.CoreLib.dll!System.Runtime.CompilerServices.ClassConstructorRunner.EnsureClassConstructorRun(System.Runtime.CompilerServices.StaticClassConstructionContext* pContext) Line 104\tC#\r\n \tSystem.Private.CoreLib.dll!System.Runtime.CompilerServices.ClassConstructorRunner.CheckStaticClassConstruction(void* returnValue, System.Runtime.CompilerServices.StaticClassConstructionContext* pContext) Line 38\tC#\r\n \tMessagePack.dll!MessagePack.Internal.StandardResolverHelper.StandardResolverHelper()\tUnknown\r\n \tSystem.Private.CoreLib.dll!System.Runtime.CompilerServices.ClassConstructorRunner.EnsureClassConstructorRun(System.Runtime.CompilerServices.StaticClassConstructionContext* pContext) Line 104\tC#\r\n \tSystem.Private.CoreLib.dll!System.Runtime.CompilerServices.ClassConstructorRunner.CheckStaticClassConstruction(void* returnValue, System.Runtime.CompilerServices.StaticClassConstructionContext* pContext) Line 38\tC#\r\n \tMessagePack.dll!MessagePack.Resolvers.StandardResolver.StandardResolver()\tUnknown\r\n \tSystem.Private.CoreLib.dll!System.Runtime.CompilerServices.ClassConstructorRunner.EnsureClassConstructorRun(System.Runtime.CompilerServices.StaticClassConstructionContext* pContext) Line 104\tC#\r\n \tSystem.Private.CoreLib.dll!System.Runtime.CompilerServices.ClassConstructorRunner.CheckStaticClassConstruction(void* returnValue, System.Runtime.CompilerServices.StaticClassConstructionContext* pContext) Line 38\tC#\r\n \tMessagePack.dll!MessagePack.MessagePackSerializerOptions.MessagePackSerializerOptionsDefaultSettingsLazyInitializationHelper.MessagePackSerializerOptionsDefaultSettingsLazyInitializationHelper()\tUnknown\r\n \tSystem.Private.CoreLib.dll!System.Runtime.CompilerServices.ClassConstructorRunner.EnsureClassConstructorRun(System.Runtime.CompilerServices.StaticClassConstructionContext* pContext) Line 104\tC#\r\n \tSystem.Private.CoreLib.dll!System.Runtime.CompilerServices.ClassConstructorRunner.CheckStaticClassConstruction(void* returnValue, System.Runtime.CompilerServices.StaticClassConstructionContext* pContext) Line 38\tC#\r\n \tMessagePack.dll!MessagePack.MessagePackSerializerOptions.Standard.get()\tUnknown\r\n \tMessagePack.dll!MessagePack.MessagePackSerializer.MessagePackSerializer()\tUnknown\r\n \tSystem.Private.CoreLib.dll!System.Runtime.CompilerServices.ClassConstructorRunner.EnsureClassConstructorRun(System.Runtime.CompilerServices.StaticClassConstructionContext* pContext) Line 104\tC#\r\n \tSystem.Private.CoreLib.dll!System.Runtime.CompilerServices.ClassConstructorRunner.CheckStaticClassConstruction(void* returnValue, System.Runtime.CompilerServices.StaticClassConstructionContext* pContext) Line 38\tC#\r\n \tMessagePack.dll!MessagePack.MessagePackSerializer.Serialize<System.__Canon>(System.__Canon value, MessagePack.MessagePackSerializerOptions options, System.Threading.CancellationToken cancellationToken)\tUnknown\r\n>\tMessPack.exe!MessPack.MainPage.OnNavigatedTo(Windows.UI.Xaml.Navigation.NavigationEventArgs e) Line 107\tC#\r\n```\r\n\r\nMessagePack relies on Reflection.Emit that is not supported by .NET Native.\r\n\r\nThere was a NuGet package created that makes it appear NetStandard supports reflection emit, but creating that NuGet package was a big mistake, because that API only works on two out of 4 implementation of NetStandard: https://github.com/dotnet/runtime/issues/26007. This created a situation that some NetStandard libraries can't work on all NetStandard runtimes. People in charge tried to fix the issue by unpublishing the package (so that we don't have a broken ecosystem), but had to roll that back because of outcry from users. This mistake is still haunting us years later, unfortunately.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1189", "user": "Noemata", "root": "ROOT118", "reply_to": "COM1188", "timestamp": "2020-03-18T09:48:11Z", "text": "So then the question is, why use MessagePack for streamjsonrpc?  If, as you say, only 2 out of 4 implementations of .Net Standard support it, why is Microsoft breaking parts of their own eco system?\r\n\r\nBy the way, I'm ok with your answer @MichalStrehovsky, you've essentially confirmed that @AArnott needs to either fix the way MessagePack uses reflection, or not use MessagePack within streamjsonrpc or any other .Net Lib that has Microsoft's name on it, else yet another piece of tooling from Microsoft is compromised in where it can be used and becomes a source of confusion and needless frustration.\r\n\r\nThat said, I would not want to see an endless timeline for such fixes, hence the ETA query at the very start of this thread.  It might be simpler to make proper design choices in the first place, and communicate broadly what those should be.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM11810", "user": "Noemata", "root": "ROOT118", "reply_to": "COM1189", "timestamp": "2020-03-18T10:12:41Z", "text": "I have one other suggestion, make Debug build enforce some of the limitations one sees on a Release build.  Especially things like Assembly.Location; these should all behave in Debug just as they do in Release.  Lots of problems will disappear in a hurry because most devs spend most of their life in Debug.  Throw in a flag on a per project basis to turn this off for instances where it's not appropriate.  That way the folks turning off the flag will likely know why they're doing so.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM11811", "user": "Noemata", "root": "ROOT118", "reply_to": "COM11810", "timestamp": "2020-03-18T10:16:43Z", "text": "[x] Enable Release Build Behavior", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM11812", "user": "Noemata", "root": "ROOT118", "reply_to": "COM11811", "timestamp": "2020-03-18T11:16:38Z", "text": "I read the discussion here: https://github.com/dotnet/designs/pull/90#discussion_r375120319\r\n\r\nERBB, an \"Enable Release Build Behavior\" flag mentioned above, takes away a lot of needless hoop jumping and allows current approaches to be preserved.  Not sure how much this would affect Debug tooling, but it would pre-emptively preclude poor design choices.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM11813", "user": "AArnott", "root": "ROOT118", "reply_to": "COM11812", "timestamp": "2020-03-18T13:11:07Z", "text": "@noemata You're wasting a lot of our time slandering our competence and I will likely lock this issue and you may be banned for violating our [code of conduct](https://opensource.microsoft.com/codeofconduct/) if you continue. Please consider yourself warned. Please read that code of conduct before submitting anything further to this or other Microsoft OSS repos.\r\n\r\nBy publishing and sharing StreamJsonRpc with the world, Microsoft hasn't committed to supporting it in every use case. Microsoft Support is something agreed upon between Microsoft and individual customers on a per-product basis. StreamJsonRpc is only officially supported in contexts where it ships with Microsoft products that are under support agreements. In other words, we are not obligated to make it work for you in .NET Native and have never made a promise that we would do so.\r\n\r\nJust because Microsoft makes two technologies does not guarantee that those technologies can work together. And just because I work at Microsoft doesn't mean I have any deeper understanding of the .NET Native toolchain than you do. Microsoft is a big place and one team rarely has unique insights into what another team/product is doing.\r\n\r\nFurther, you have yet to share any evidence that this is a StreamJsonRpc flaw at all. MessagePack clearly has issues on .NET Native, but StreamJsonRpc's support for MessagePack *as an option* hardly means that we're responsible to make MessagePack (a 3rd party OSS library) work under every possible Microsoft runtime. I expect you can use StreamJsonRpc on UWP just fine in its default configuration, although I haven't tested that nor are we promising support for that. \r\n\r\nNow if MessagePack proclaims support for .NET Native, and StreamJsonRpc *still* doesn't work on that platform, then re-opening an issue on this repo with the specific error you're seeing is welcome and subject to our limited capacity to offer free OSS support we may take a look at the problem and suggest how you can make it work or possibly offer a fix.\r\n\r\nIt's not just design choices -- there are simply features that .NET Native doesn't support. Some of these reasons I understand and some I don't. But this library does not nor I imagine ever will limit its feature set to what's available on the least capable of Microsoft platforms. For example we support dynamically generated client proxies, which is a great feature that I don't know if it can be used with .NET Native (even without MessagePack). Given dozens of applications and millions of users benefit from this feature, we wouldn't remove it or have suppressed its development just because it can't ever work on a platform that no one even asked for support for before now.\r\n\r\nSo as I stated before, I'm closing this issue because there's no reason to believe a fix is required in this repo. We will keep the .NET Native issue on messagepack open because we expect code fixes are required in that repo.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM11814", "user": "Noemata", "root": "ROOT118", "reply_to": "COM11813", "timestamp": "2020-03-18T15:05:40Z", "text": "The .Net Native compiler is a bit of an engineering marvel.  I'd like to see it persist.  It's sad that I have to use such a long winded approach to try and defend its future and get certain parts of Microsoft to cooperate with other parts.  If there is something fundamentally false in anything I'm expressing, please do highlight my error(s).\r\n\r\nIf any of your work is not intended to support UWP, @AArnott, then just add an exclusionary note, or say so in your opening remarks to such queries and I'll be happy to disappear.  I also don't want to waste my time.  I have merely pointed out that your design choices, not your competence, or your intellect, are at issue here.  And I had to go through a long winded process to make the point clear.\r\n\r\nYou can censor me if you like.  Just because you have the power to do so doesn't make that choice right either.\r\n\r\nWhen you stated \"I'm surprised if it doesn't work.\" You gave yourself away.  If I'm wrong in thinking that you knew it didn't work, then I apologize, because you closed the very issue that you had identified as the point of failure.  You see, I'm assuming you are quite bright @AArnott based on the high quality of your work.  The quality of your personal choices, in that realm, we obviously have a difference of opinion.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM11815", "user": "AArnott", "root": "ROOT118", "reply_to": "COM11814", "timestamp": "2020-03-19T00:46:43Z", "text": "> If there is something fundamentally false in anything I'm expressing, please do highlight my error(s).\r\n\r\nSure: essentially the whole of the part of this comment you addressed to me: https://github.com/microsoft/vs-streamjsonrpc/issues/432#issuecomment-600439129. You presented several alternatives and said it was one of those. They were all jaded, and none of them reflect reality.\r\n\r\n> If any of your work is not intended to support UWP, @AArnott, then just add an exclusionary note, or say so in your opening remarks to such queries and I'll be happy to disappear. \r\n\r\nI guess I could have been clearer in my very first comment on this issue that UWP isn't a supported scenario. We haven't tested it. But most code does Just Work on .NET Native, so my surprise that I expressed in my first comment was mild surprise that StreamJsonRpc wasn't among those things that Just Work. But it wasn't intended to express our current support for UWP.\r\n\r\n> When you stated \"I'm surprised if it doesn't work.\" You gave yourself away. \r\n\r\nWhat do you mean? \"You gave yourself away\" makes it sounds like you're saying I accidentally revealed something. I don't feel that way. The intent of all my interactions on this issue should have conveyed:\r\n\r\n1. We don't support UWP, but it might just work\r\n1. We don't keep open issues on a repo for which no code defects are present, or to support scenarios that we don't intend to support.\r\n\r\nAt some point, we might add UWP tests to this repo in which case we'll claim to support UWP. But even then, we might scope the supported feature set down to those that actually work on .NET Native. \r\n\r\n> because you closed the very issue that you had identified as the point of failure.\r\n\r\nWhich issue was that?\r\nYou opened this one, and two over at MessagePack that I'm aware of:\r\nhttps://github.com/neuecc/MessagePack-CSharp/issues/840\r\nhttps://github.com/neuecc/MessagePack-CSharp/issues/839\r\n\r\nI closed the above two because we already have an active issue tracking UWP support in MessagePack (https://github.com/neuecc/MessagePack-CSharp/issues/563). We only need one per repo with a defect.\r\nI closed *this* vs-streamjsonrpc issue because there's no bug here AFAIK, as the only issues I've seen are actually failures in MessagePack to support UWP, which we can discuss over at https://github.com/neuecc/MessagePack-CSharp/issues/563.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT119", "user": "ORESoftware", "root": "ROOT119", "reply_to": null, "timestamp": "2021-01-03T09:17:49Z", "text": "(removed) (removed)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1190", "user": "gopherbot", "root": "ROOT119", "reply_to": "ROOT119", "timestamp": "2021-01-03T09:27:24Z", "text": "This PR (HEAD: 24b505660f7bdeb4e15270a920dc93d255a13b81) has been imported to Gerrit for code review.\n\nPlease visit https://go-review.googlesource.com/c/go/+/281212 to see it.\n\nTip: You can toggle comments from me using the `comments` slash command (e.g. `/comments off`)\nSee the [Wiki page](https://golang.org/wiki/GerritBot) for more info", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1191", "user": "gopherbot", "root": "ROOT119", "reply_to": "COM1190", "timestamp": "2021-01-03T09:29:21Z", "text": "Message from Go Bot:\n\nPatch Set 1:\n\nCongratulations on opening your first change. Thank you for your contribution!\n\nNext steps:\nA maintainer will review your change and provide feedback. See\nhttps://golang.org/doc/contribute.html#review for more info and tips to get your\npatch through code review.\n\nMost changes in the Go project go through a few rounds of revision. This can be\nsurprising to people new to the project. The careful, iterative review process\nis our way of helping mentor contributors and ensuring that their contributions\nhave a lasting impact.\n\nDuring May-July and Nov-Jan the Go project is in a code freeze, during which\nlittle code gets reviewed or merged. If a reviewer responds with a comment like\nR=go1.11 or adds a tag like \"wait-release\", it means that this CL will be\nreviewed as part of the next development cycle. See https://golang.org/s/release\nfor more details.\n\n---\nPlease don\u2019t reply on this GitHub thread. Visit [golang.org/cl/281212](https://go-review.googlesource.com/c/go/+/281212#message-22d80d180abd44312803802d3e08e841097c6038).\nAfter addressing review feedback, remember to [publish your drafts](https://github.com/golang/go/wiki/GerritBot#i-left-a-reply-to-a-comment-in-gerrit-but-no-one-but-me-can-see-it)!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1192", "user": "gopherbot", "root": "ROOT119", "reply_to": "COM1191", "timestamp": "2021-01-03T11:23:05Z", "text": "This PR is being closed because [golang.org/cl/281212](https://go-review.googlesource.com/c/go/+/281212) has been abandoned.\n\nSending an empty patch is not the most efficient way to complain about something and make a feature request; please open a github issue, that's exactly what the issue tracker is for.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT120", "user": "OtherCrashOverride", "root": "ROOT120", "reply_to": null, "timestamp": "2015-08-29T10:09:56Z", "text": "Add Facebook, Twitter, and XBoxLive leader board support to System.Exception Current exceptions are not very helpful in assisting the developer.  We should add social networking features to facilitate a better debugging experience.  ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1200", "user": "ghost", "root": "ROOT120", "reply_to": "ROOT120", "timestamp": "2015-08-29T11:27:42Z", "text": "Aww.. Here, have a beer on me: :beer:\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1201", "user": "omariom", "root": "ROOT120", "reply_to": "COM1200", "timestamp": "2015-08-29T11:48:49Z", "text": "![](https://avatars2.githubusercontent.com/u/1781701) \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1202", "user": "OtherCrashOverride", "root": "ROOT120", "reply_to": "COM1201", "timestamp": "2015-08-29T11:49:37Z", "text": "There is also room now to put Google Ads in the exception messages. \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1203", "user": "ghost", "root": "ROOT120", "reply_to": "COM1202", "timestamp": "2015-08-29T11:50:29Z", "text": "Don't forget about those instagals! :dancer: \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1204", "user": "OtherCrashOverride", "root": "ROOT120", "reply_to": "COM1203", "timestamp": "2015-08-29T12:15:54Z", "text": "If you guys were young and open to new things like me, you would understand how mindblowingly game changing this is! :+1:  :+1:  :+1:  :+1: \n\nWe can now query StackOverflow when an exception happens and also include the top 10 suggestions in the exception!  Additionally, others that have the same exception can follow you to see if you come up with an answer.  Also!!!!111!!!!!1 We should include ILSPY in CoreCLR, so that you can get a decompiled listing of the code where the exception occurred\n\nI am going to start prototyping this soon!!!! :100:  :100: :100: \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1205", "user": "linquize", "root": "ROOT120", "reply_to": "COM1204", "timestamp": "2015-08-29T12:28:55Z", "text": "coreclr is not a GUI program. I cannot imagine integrating such services.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1206", "user": "OtherCrashOverride", "root": "ROOT120", "reply_to": "COM1205", "timestamp": "2015-08-29T12:48:53Z", "text": ">  I cannot imagine integrating such services.\n\ni was skyping with others and we decided we are going to change `System.Exception.Message` to a new and improved JSON format.  This will make integration with the services and DNX easier.\n\n[Edit]\nNuGet make its super simple to deploy this to everyone.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1207", "user": "CrshOverride", "root": "ROOT120", "reply_to": "COM1206", "timestamp": "2015-08-29T20:32:37Z", "text": "I'm so glad these suggestions are being made by the OTHER CrashOverride rather than myself...\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1208", "user": "terrajobst", "root": "ROOT120", "reply_to": "COM1207", "timestamp": "2015-08-29T20:52:52Z", "text": "![images](https://cloud.githubusercontent.com/assets/5169960/9564217/093c563a-4e54-11e5-8d85-b5b54130006b.jpg)\n\nOK, point taken and your feedback is being discussed in https://github.com/dotnet/corefx/issues/1187.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT121", "user": "outlace", "root": "ROOT121", "reply_to": null, "timestamp": "2015-11-09T17:41:26Z", "text": "OpenCL support I understand TensorFlow only supports CUDA. What would need to be done to add in OpenCL support? ", "meta": {"posReactions": "754", "negReactions": "0"}}
{"id": "COM1210", "user": "nmabhinandan", "root": "ROOT121", "reply_to": "ROOT121", "timestamp": "2015-11-09T18:21:24Z", "text": "It's strange that Google ditched open OpenCL for proprietary CUDA.\n![im-just-saying](https://cloud.githubusercontent.com/assets/1548848/11042379/c2cf01c6-873c-11e5-8216-a00474c8e717.jpg)\n", "meta": {"posReactions": "503", "negReactions": "8"}}
{"id": "COM1211", "user": "ebrevdo", "root": "ROOT121", "reply_to": "COM1210", "timestamp": "2015-11-09T18:24:40Z", "text": "At the very least, the [Eigen](http://eigen.tuxfamily.org) library would have to support OpenCL.\n", "meta": {"posReactions": "23", "negReactions": "0"}}
{"id": "COM1212", "user": "bhack", "root": "ROOT121", "reply_to": "COM1211", "timestamp": "2015-11-09T20:54:37Z", "text": ":+1:\n", "meta": {"posReactions": "61", "negReactions": "1"}}
{"id": "COM1213", "user": "jamesliu96", "root": "ROOT121", "reply_to": "COM1212", "timestamp": "2015-11-10T02:52:59Z", "text": ":+1: \n", "meta": {"posReactions": "2", "negReactions": "2"}}
{"id": "COM1214", "user": "alexatknit", "root": "ROOT121", "reply_to": "COM1213", "timestamp": "2015-11-10T23:53:16Z", "text": ":+1:\n", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM1215", "user": "dhess", "root": "ROOT121", "reply_to": "COM1214", "timestamp": "2015-11-11T05:01:46Z", "text": "thumbs up and all that.\n", "meta": {"posReactions": "9", "negReactions": "1"}}
{"id": "COM1216", "user": "gujunli", "root": "ROOT121", "reply_to": "COM1215", "timestamp": "2015-11-11T07:45:42Z", "text": "I will be interested in expanding Tensor Flow with OpenCL. As we have already released OpenCL caffe. https://github.com/amd/OpenCL-caffe.  Hopefully it can get integrated in light way? Is anyone interested in working together on this?\n", "meta": {"posReactions": "109", "negReactions": "0"}}
{"id": "COM1217", "user": "bhack", "root": "ROOT121", "reply_to": "COM1216", "timestamp": "2015-11-11T07:50:27Z", "text": "@gujunli Nice to see AMD here. /cc @naibaf7 @lunochod\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1218", "user": "nmabhinandan", "root": "ROOT121", "reply_to": "COM1217", "timestamp": "2015-11-11T08:20:57Z", "text": "would be great.\n", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM1219", "user": "sasadep", "root": "ROOT121", "reply_to": "COM1218", "timestamp": "2015-11-11T19:31:06Z", "text": ":+1:\n", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM12110", "user": "bhack", "root": "ROOT121", "reply_to": "COM1219", "timestamp": "2015-11-15T15:00:05Z", "text": "/cc @lukeiwanski for Eigen/OpenCL/SYCL\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12111", "user": "ankdesh", "root": "ROOT121", "reply_to": "COM12110", "timestamp": "2015-11-16T13:40:01Z", "text": "@gujunli Certainly would be interested in contributing. Please let me know when you plan to start. \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12112", "user": "lukeiwanski", "root": "ROOT121", "reply_to": "COM12111", "timestamp": "2015-11-25T11:05:13Z", "text": "Hi all, \n\nHere at Codeplay we are looking into Eigen's tensor running on GPU using SYCL (a modern C++ layer on top of OpenCL). From what we have gathered so far, GPU tensor design is very closely coupled with CUDA and it will require interface changes for another programming model and particularly a SYCL and OpenCL 1.2 version. \n\nIf anyone is interested in digging deeper / helping out, we are most certainly interested in contributing.\n\nThanks,\nLuke\n", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM12113", "user": "bhack", "root": "ROOT121", "reply_to": "COM12112", "timestamp": "2015-11-25T11:19:50Z", "text": "@lukeiwanski Thank you for the feedback. I think that @benoitsteiner worked at the tensor extension part of eigen.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12114", "user": "jszuppe", "root": "ROOT121", "reply_to": "COM12113", "timestamp": "2015-12-06T12:05:33Z", "text": ":+1: I can help code some OpenCL/SYCL if someone makes a plan, divides work into tasks etc. I recommend using Boost.Compute as a wrapper for OpenCL (it makes running kernels, testing, templating easier).\n", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM12115", "user": "ieee8023", "root": "ROOT121", "reply_to": "COM12114", "timestamp": "2015-12-07T16:43:05Z", "text": "+1\n", "meta": {"posReactions": "1", "negReactions": "1"}}
{"id": "COM12116", "user": "armish", "root": "ROOT121", "reply_to": "COM12115", "timestamp": "2015-12-07T20:36:54Z", "text": ":+1: \n", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM12117", "user": "lukeiwanski", "root": "ROOT121", "reply_to": "COM12116", "timestamp": "2015-12-08T18:19:13Z", "text": "Hi all,\n\nJust to keep you posted, we are still investigating how we can change the Eigen interface to better fit the SYCL/OpenCL 1.2 programming model. \nOnce we come up with a reasonable approach that targets heterogeneous programming models ( not only OpenCL / SYCL )  we will create a proposal. \n\nThanks,\nLuke\n", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM12118", "user": "gujunli", "root": "ROOT121", "reply_to": "COM12117", "timestamp": "2015-12-08T19:30:09Z", "text": "Pls keep me update. I developed opencl-caffe for AMD. I am also looking at\ntensor flow.\n\nThanks.\nJunlu\nOn Dec 8, 2015 10:19 AM, \"Luke Iwanski\" notifications@github.com wrote:\n\n> Hi all,\n> \n> Just to keep you posted, we are still investigating how we can change the\n> Eigen interface to better fit the SYCL/OpenCL 1.2 programming model.\n> Once we come up with a reasonable approach we will create a proposal.\n> \n> Thanks,\n> Luke\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/22#issuecomment-162967662\n> .\n", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM12119", "user": "bhack", "root": "ROOT121", "reply_to": "COM12118", "timestamp": "2015-12-09T08:41:10Z", "text": "/cc @ptillet @gongzg Is there any interest in this by Intel? I really hope that we don't fragment OPENCL here like in Caffe where we have an AMD fork, Intel unmerged PRs, another semi-unofficial AMD PR, and a long staging user PR (plus two old abandoned Opencl efforts). If somebody is interested in the history can take a look at https://github.com/BVLC/caffe/pull/2610 comments.\n", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM12120", "user": "gongzg", "root": "ROOT121", "reply_to": "COM12119", "timestamp": "2015-12-17T09:57:28Z", "text": "@bhack We do have interest in this. Thanks for letting me know. If there is a proposal for Eigen's OpenCL/SYCL implementation, we will see what we can do from Intel side.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12121", "user": "ZirconCode", "root": "ROOT121", "reply_to": "COM12120", "timestamp": "2015-12-23T14:57:34Z", "text": ":+1: \n", "meta": {"posReactions": "1", "negReactions": "2"}}
{"id": "COM12122", "user": "bhack", "root": "ROOT121", "reply_to": "COM12121", "timestamp": "2016-01-01T19:36:35Z", "text": "An interesting initiative at https://github.com/ptillet/isaac also if here we rely on Eigen tensor extension.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12123", "user": "DanMcLaughlin", "root": "ROOT121", "reply_to": "COM12122", "timestamp": "2016-01-19T15:42:59Z", "text": "I also would like to contribute. @benoitsteiner can you organize it?\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12124", "user": "bhack", "root": "ROOT121", "reply_to": "COM12123", "timestamp": "2016-01-19T15:50:17Z", "text": "This was included in the Roadmap but also tagged as contribution so a direction/bootstrap could be really useful.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12125", "user": "gujunli", "root": "ROOT121", "reply_to": "COM12124", "timestamp": "2016-01-19T16:50:52Z", "text": "I can contribute to organize it. who is responsible for OpenCL support in\nTensor flow now?\n\nThanks a lot.\nJunli\n\nOn Tue, Jan 19, 2016 at 7:50 AM, bhack notifications@github.com wrote:\n\n> This was included in the Roadmap but also tagged as contribution so a\n> direction/bootstrap could be really useful.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/22#issuecomment-172894538\n> .\n\n## \n\n---\n\nJunli Gu--\u8c37\u4fca\u4e3d\nCoordinated Science Lab\nUniversity of Illinois at Urbana-Champaign\n\n---\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12126", "user": "DanMcLaughlin", "root": "ROOT121", "reply_to": "COM12125", "timestamp": "2016-01-19T19:42:37Z", "text": "I just assumed Benoit because he self assigned the feature, but I think you've got it Junli! Maybe start with an email or forum thread of interested parties?\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12127", "user": "martinwicke", "root": "ROOT121", "reply_to": "COM12126", "timestamp": "2016-01-19T19:46:14Z", "text": "@benoitsteiner knows more about interested parties that may not have shown\nup in this thread (or this issue). I'd wait for him to coordinate to make\nsure we avoid duplicating work.\n\nOn Tue, Jan 19, 2016 at 11:42 AM Dan McLaughlin notifications@github.com\nwrote:\n\n> I just assumed Benoit because he self assigned the feature, but I think\n> you've got it Junli! Maybe start with an email or forum thread of\n> interested parties?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/22#issuecomment-172963537\n> .\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12128", "user": "MikalaiDrabovich", "root": "ROOT121", "reply_to": "COM12127", "timestamp": "2016-01-19T20:20:44Z", "text": "I'm interested. Is there any roadmap?\n\n> On Jan 19, 2016, at 11:46 AM, Martin Wicke notifications@github.com wrote:\n> \n> @benoitsteiner knows more about interested parties that may not have shown\n> up in this thread (or this issue). I'd wait for him to coordinate to make\n> sure we avoid duplicating work.\n> \n> On Tue, Jan 19, 2016 at 11:42 AM Dan McLaughlin notifications@github.com\n> wrote:\n> \n> > I just assumed Benoit because he self assigned the feature, but I think\n> > you've got it Junli! Maybe start with an email or forum thread of\n> > interested parties?\n> > \n> > \u2014\n> > Reply to this email directly or view it on GitHub\n> > https://github.com/tensorflow/tensorflow/issues/22#issuecomment-172963537\n> > .\n> > \n> > \u2014\n> > Reply to this email directly or view it on GitHub.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12129", "user": "hsaputra", "root": "ROOT121", "reply_to": "COM12128", "timestamp": "2016-01-19T20:44:37Z", "text": "Is there a list of CUDA dependency libraries that Tensorflow relying on?\n\nThis would help to see if we could have immediate OpenCL alternatives.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT122", "user": "pakkpl", "root": "ROOT122", "reply_to": null, "timestamp": "2020-06-26T11:13:32Z", "text": "Change #BlackLivesMatter notification to #AllLivesMatter on angular.io main page. Change #BlackLivesMatter to #AllLivesMatter", "meta": {"posReactions": "25", "negReactions": "13"}}
{"id": "COM1220", "user": "ncrawlins", "root": "ROOT122", "reply_to": "ROOT122", "timestamp": "2020-06-26T13:09:06Z", "text": "Nice, the only notable contribution you've ever made anywhere on Github is making sure everyone at Google knows you're a racist.", "meta": {"posReactions": "1", "negReactions": "8"}}
{"id": "COM1221", "user": "pakkpl", "root": "ROOT122", "reply_to": "COM1220", "timestamp": "2020-06-26T13:17:11Z", "text": "Where you see racism in #AllLivesMatter ? \r\nIn my opinion #BlackLivesMatter is racist slogan against white people.\r\nBeside, why technology web page contains these things? It should contains angular related things only.", "meta": {"posReactions": "7", "negReactions": "2"}}
{"id": "COM1222", "user": "thecp", "root": "ROOT122", "reply_to": "COM1221", "timestamp": "2020-06-26T13:45:32Z", "text": "Obviously nobody denies that all lives matter but this is not the point. Structural racism is a problem almost everywhere and people of color are affected whereas white people are not (or less).\r\n\r\nJust imagine a house burning and the fire department coming and trying to extinguish the fire. Would you try to convince the fire department to put water on the other houses? No, because the other houses don't seem to have a problem. But that's what the AllLivesMatter slogan is saying and that's what makes this slogan problematic.\r\n\r\nBlackLivesMatter is not meant to be a racist statement, except you see it like this. Supporting BlackLivesMatter is about drawing attention to social injustices. Think about that.", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM1223", "user": "djleonskennedy", "root": "ROOT122", "reply_to": "COM1222", "timestamp": "2020-06-26T13:50:59Z", "text": "@thecp seems like that's problem in USA only, we're respect all races in Ukraine for example, doesn't matter where are you from or etc.\r\nSo you need fix it in you county, and do not force your problems to all world!", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM1224", "user": "mlc-mlapis", "root": "ROOT122", "reply_to": "COM1223", "timestamp": "2020-06-26T14:10:25Z", "text": "Only a short notice. We all together should be also very careful about the tendency, when one or the other side wants to win, even at any price and on any conditions, just the believing: \"We won in the end.\" We have one proverb: `Be careful not to spill the baby with the bath.`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1225", "user": "ericmartinezr", "root": "ROOT122", "reply_to": "COM1224", "timestamp": "2020-06-26T15:56:59Z", "text": "As I was told, caring about people is racist. Categorizing people by their skin color is the definition of racism, and that's what google is: racist. \r\n\r\nRead this\r\nhttps://www.projectveritas.com/news/facebook-on-project-veritas-video-comments-made-are-not-consistent-with-our/\r\n\r\nThat's everywhere ;)\r\n\r\nEdit:\r\n\r\nAnyway this issue will be closed without an answer since Google doesn't care about people but sticking to their narrative. Everyone here will be called a white supremacist antiblack antiasian antilgtbteq1324 and risking to be banned from the repo. \r\n\r\nWelcome to 1984.", "meta": {"posReactions": "1", "negReactions": "1"}}
{"id": "COM1226", "user": "Achilles1515", "root": "ROOT122", "reply_to": "COM1225", "timestamp": "2020-06-26T16:11:58Z", "text": "Just noticed the #BlackLivesMatter banner on the home page for the first time...what a joke.\r\n\r\nAnyone have a list of other political movements endorsed by the Angular site?\r\n\r\nNothing more cringey than tech framework sites posting about politics, even if you agree with the sentiment.\r\nDidn't one of the #BlackLivesMatter \"leaders\" call to take down statues of Jesus depicted as Caucasian, as this is a form of \"racist propaganda\"?\r\n\r\nCan we change the hashtag on the main page to #WhiteJesusIsHoldingYouBack ?\r\n\r\nYou know what, the white \"A\" in the Angular logo is all of a sudden making me feel uncomfortable...maybe even a little oppressed. Hmm, could the Angular team be racists??? Maybe we should make a separate issue to change the color to black.", "meta": {"posReactions": "3", "negReactions": "2"}}
{"id": "COM1227", "user": "robinbastien", "root": "ROOT122", "reply_to": "COM1226", "timestamp": "2020-06-26T16:28:44Z", "text": "> Where you see racism in #AllLivesMatter ?\r\n> In my opinion #BlackLivesMatter is racist slogan against white people.\r\n> Beside, why technology web page contains these things? It should contains angular related things only.\r\n\r\nSilence is violence. It's important for business to get behind social causes to advance past the sins of humanity of the past. There is clearly a systemic discrimination toward the black community in the west. Of course all lives matter, but for all lives to matter you need to include black lives \u2014 which clearly is not being represented equally ", "meta": {"posReactions": "3", "negReactions": "3"}}
{"id": "COM1228", "user": "lazarljubenovic", "root": "ROOT122", "reply_to": "COM1227", "timestamp": "2020-06-26T16:36:58Z", "text": "> Nice, the only notable contribution you've ever made anywhere on Github is making sure everyone at Google knows you're a racist.\r\n\r\nWhat's racist about it? Also don't shame others based on their skills and development experience. That's against the code of conduct.\r\n\r\n> BlackLivesMatter is not meant to be a racist statement, except you see it like this.\r\n\r\n\"All lives matter\" isn't racist either, yet [apparently saying that makes you a white supremacist](https://github.com/angular/angular/pull/37407#issuecomment-637864531) or something.\r\n\r\n> that's problem in USA only\r\n\r\nPrecisely this. Angular/Google are just using the platform to promote their local political views on the matter. It reminds me of the day when gay marriage was legalized in the US and Stack Overflow celebrated it with a rainbow logo.  [This answer explained it nicely](https://meta.stackoverflow.com/a/298045/2131286):\r\n\r\n>The owners and operators of Stack Exchange and Stack Overflow have made it amply clear that while we as users and contributors are not permitted to use the site and our audience here to promote our political and social beliefs, they, as the owners may.\r\n\r\nWith an unfortunate conclusion:\r\n\r\n> If you do not like this you should no longer contribute to Stack Exchange.\r\n\r\nIndeed, there's not much you can do about it. People can express their opinions but the mods are just gonna lock it away \"cause y'all can't behave\" and \"the discussion is getting out of hand and is not productive anymore\".\r\n\r\n> Anyone have a list of other political movements endorsed by the Angular site?\r\n\r\nFrom the top of my head, previously it's been determined that [blacklist and whitelist is racist](https://github.com/angular/angular/pull/28529). Funny how the first comment is being sarcastic about [the master branch](https://github.com/angular/angular/pull/28529#issuecomment-460658997) and that [is actually non-ironically happening now](https://www.zdnet.com/article/github-to-replace-master-with-alternative-term-to-avoid-slavery-references/), because apparently there exist people who hear \"master\" and immediately think about slavery. I guess I'll give up my Master's degree to show solidarity.\r\n\r\n[Also a man being smart is sexist towards women because why not.](https://github.com/angular/angular/issues/25643)\r\n\r\nNot really political, but I get the same vibe from [stating that simple things are simple offends beginners](https://github.com/angular/angular/issues/33209).", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1229", "user": "robinbastien", "root": "ROOT122", "reply_to": "COM1228", "timestamp": "2020-06-26T16:50:41Z", "text": "> \"All lives matter\" isn't racist either, yet [apparently saying that makes you a white supremacist](https://github.com/angular/angular/pull/37407#issuecomment-637864531) or something.\r\n\r\nI agree with this, \"All lives matter\" isn't inherently racist and is a very true statement. In this context, it's undermining the BLM movement where special attention is warranted for the systemic discrimination over many many years. \r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12210", "user": "lazarljubenovic", "root": "ROOT122", "reply_to": "COM1229", "timestamp": "2020-06-26T17:07:50Z", "text": "> > \"All lives matter\" isn't racist either, yet [apparently saying that makes you a white supremacist](https://github.com/angular/angular/pull/37407#issuecomment-637864531) or something.\r\n> \r\n> I agree with this, \"All lives matter\" isn't inherently racist and is a very true statement. In this context, it's undermining the BLM movement where special attention is warranted for the systemic discrimination over many many years.\r\n\r\nThe discussion is not about whether you should support a movement or not; it's about why is it on the front-page of a TypeScript platform for building web, mobile and desktop applications. Yes, black lives matter, white lives matter, Asian lives matter, Latino lives matter, gay lives matter, lesbian lives matter, vegan lives matter, stutterer lives matter, little people lives matter, disabled lives matter, left-handed people lives matter, colorblind lives matter. \r\n\r\nThe question is, why is it on the front-page of Angular and **what is the criteria** which determines what gets on the front page. **Who decides what's important enough?**\r\n\r\nThe very fact that these discussions \"produce heat\" is an indication that people are divided on it. If everyone really agreed that the banner makes sense on the Angular's front page, there wouldn't be an issue about it and [the original PR](https://github.com/angular/angular/pull/37407) wouldn't have been locked immediately. If you're so sure that it's such a good idea, why do you have to act so quick about locking it so as not to give people a chance to give their opinion on the matter?\r\n\r\nAgain, Angular team is not required to provide an answer. They can just lock this thread again with a generic \"we care about everyone and we hear y'all, we'll talk it internally, we promise \ud83d\udd12\", and there's nothing anyone can do about it -- legally or otherwise. It's their framework and their repo; as long as they abide the GitHub rules, they're fine. Even if they don't, it's up to GitHub to punish them if they break it.\r\n\r\nBut it just feels less and less a framework and more and more a political board. \"Something happened in America that aligns with who Imma vote for soon? LETS POST IT NOW, QUICK\" \"[Highly voted issues from 2016?](https://github.com/angular/angular/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc) crickets [crickets](https://github.com/angular/angular/issues/15280#issuecomment-584121619) crickets\"", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12211", "user": "mgechev", "root": "ROOT122", "reply_to": "COM12210", "timestamp": "2020-06-26T17:12:34Z", "text": "Yes, we're on the same page that all lives matter. I read some thoughtful and reasonable responses in this thread, and I understand how everyone has their point of view. We're all part of a very diverse community, and having different opinions is understandable.\r\n\r\nI also don't see bad intentions in the thread, which is all encouraging. We're all aiming for racial equality, and that is how it is supposed to be.\r\n\r\nAt the same time, I'm hoping for us all to provide solidarity to the black community. Again, all lives matter, but for this to be true, black lives should matter as well.\r\n\r\nI'll lock this thread now since the discussion is getting a little too heated.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT123", "user": "patelh", "root": "ROOT123", "reply_to": null, "timestamp": "2018-10-22T22:24:44Z", "text": "Expose report generator as public interface I need to be able to push generated results to a DB, by exposing the report generator as public interface, I can provide a custom report generator which can push results to DB.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1230", "user": "slandelle", "root": "ROOT123", "reply_to": "ROOT123", "timestamp": "2018-10-23T10:58:16Z", "text": "Additional stats export fall into the scope of FrontLine.", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM1231", "user": "patelh", "root": "ROOT123", "reply_to": "COM1230", "timestamp": "2018-10-23T21:27:07Z", "text": "Thanks, will have to move to a real open source tool like JMeter instead of gatling.  Sad.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1232", "user": "phpillet", "root": "ROOT123", "reply_to": "COM1231", "timestamp": "2018-10-24T07:44:38Z", "text": "We are really sorry to hear this. We sincerely hope you will continue to use Gatling. As we explained to you earlier, our team spends time on both projects: our open-source solution and our Enterprise solution, Gatling FrontLine.\r\nThe way we decided to split our R&D is as follows: Everything related to Gatling itself, like new support protocols, will be open-sourced (eg. HTTP/2, closed workload model and new feeders features in our latest release); On the other hand, everything related to reporting and automation features is in the scope of Gatling FrontLine. Please note that our Enterprise version helps develop both projects and have a team of 7 full-time employees. We hope you understand.\r\nAnyway, we would gladly continue this talk with you, feel free to contact us directly. We will now close this thread.\r\nBest regards", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT124", "user": "penn5", "root": "ROOT124", "reply_to": null, "timestamp": "2018-11-05T11:33:47Z", "text": "Push: NoneType has no attribute Write I am getting the error: \r ```\r b'device'\r Traceback (most recent call last):\r   File \"autoroot.py\", line 123, in <module>\r     install_firmware(dloadfirmware, device)\r   File \"autoroot.py\", line 120, in install_firmware\r     print(device.Push(os.path.join(d, 'Software', 'dload'), storage+'/dload', timeout_ms=100000))\r   File \"/home/penn/python-adb/adb/adb_commands.py\", line 269, in Push\r     progress_callback=progress_callback)\r   File \"/home/penn/python-adb/adb/adb_commands.py\", line 280, in Push\r     mtime=int(mtime), progress_callback=progress_callback, **kwargs)\r   File \"/home/penn/python-adb/adb/filesync_protocol.py\", line 149, in Push\r     cnxn.Send(b'DATA', data)\r   File \"/home/penn/python-adb/adb/filesync_protocol.py\", line 207, in Send\r     self._Flush()\r   File \"/home/penn/python-adb/adb/filesync_protocol.py\", line 254, in _Flush\r     self.adb.Write(self.send_buffer[:self.send_idx])\r AttributeError: 'NoneType' object has no attribute 'Write'\r ```\r \r I've confirmed that the path I'm pushing to exists. I'm pushing a directory to another directory. I'm using Ubuntu 18.04. I am able to use the Shell command fine.\r \r This looks similar to #125 except in Push not Pull.\r \r The adbd is running as root on the phone, as is python3 on my PC.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1240", "user": "vBlackOut", "root": "ROOT124", "reply_to": "ROOT124", "timestamp": "2018-11-13T08:51:22Z", "text": "Hello, what is your version Android me it's 8.1 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1241", "user": "vBlackOut", "root": "ROOT124", "reply_to": "COM1240", "timestamp": "2018-11-13T16:20:42Z", "text": " Look here for me solve my problem temporary https://github.com/google/python-adb/issues/132 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1242", "user": "caffeinatedMike", "root": "ROOT124", "reply_to": "COM1241", "timestamp": "2018-11-13T16:55:13Z", "text": "@VBlackOut Read @fahhem's response. That is not the way to solve the issue. \n\nAlso, something odd is happening, your replies are either getting auto-deleted on threads (likely because of the repetitive comments) or you're deleting them yourself. For my Issue you posted the same comment and NO, that does not fix the problem and NO that is not the answer to the bug. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1243", "user": "vBlackOut", "root": "ROOT124", "reply_to": "COM1242", "timestamp": "2018-11-13T17:08:43Z", "text": "It's just re-identify the id if change ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1244", "user": "vBlackOut", "root": "ROOT124", "reply_to": "COM1243", "timestamp": "2018-11-13T17:09:15Z", "text": "Not best practice but it's works", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1245", "user": "vBlackOut", "root": "ROOT124", "reply_to": "COM1244", "timestamp": "2018-11-13T17:11:22Z", "text": "Sorry I use GitHub on phone (fasthub) it's not ideal for comment and explore the interface GUI", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1246", "user": "caffeinatedMike", "root": "ROOT124", "reply_to": "COM1245", "timestamp": "2018-11-13T17:16:00Z", "text": "I use the same app and have zero issues with comments, etc. Also, your explanation still makes zero sense \"It's just re-identify the id if change\" isn't even a proper sentence. And even after being told by the main contributor of the repo that that is not a fix you continue to spam peoples' posts with this. Just PLEASE STOP. Listen to his comment and stop suggesting this crudely thought-up bandaid of a \"fix\". ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1247", "user": "vBlackOut", "root": "ROOT124", "reply_to": "COM1246", "timestamp": "2018-11-13T17:32:37Z", "text": "It's just forward fix but it's not finally real fix ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1248", "user": "vBlackOut", "root": "ROOT124", "reply_to": "COM1247", "timestamp": "2018-11-13T17:33:01Z", "text": "I just for understand the code ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1249", "user": "fahhem", "root": "ROOT124", "reply_to": "COM1248", "timestamp": "2018-11-13T17:44:37Z", "text": "Whoa let's all calm down please. @vBlackOut is just trying to help (and clearly english isn't his first language, so give him a break), it seems you're a little too caffeinated here :)\r\n\r\nLet's start over in a new issue to avoid this exchange.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT125", "user": "Phillipus", "root": "ROOT125", "reply_to": null, "timestamp": "2019-12-19T13:13:37Z", "text": "Issues tracker being spammed with SantaGate silliness: proposed fix Bring back the hat.\r \r :santa:", "meta": {"posReactions": "25", "negReactions": "1"}}
{"id": "COM1250", "user": "shika-blyat", "root": "ROOT125", "reply_to": "ROOT125", "timestamp": "2019-12-19T13:14:19Z", "text": "I strongly support that fix !", "meta": {"posReactions": "9", "negReactions": "1"}}
{"id": "COM1251", "user": "chrisdias", "root": "ROOT125", "reply_to": "COM1250", "timestamp": "2019-12-19T18:53:54Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.\r\n\r\nHappy Coding!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT126", "user": "phpnode", "root": "ROOT126", "reply_to": null, "timestamp": "2018-08-29T17:08:04Z", "text": "Bump major version before releasing license change. A polite and hopefully unnecessary reminder that when the license change is released it should be a major version bump. I'm imagining the fall out that would occur if this were released as a patch version and it wouldn't be pretty. \r \r > Note: Arguments for / against the license change are happening in other issues, let's please keep them out of this one.\r ", "meta": {"posReactions": "37", "negReactions": "0"}}
{"id": "COM1260", "user": "jamiebuilds", "root": "ROOT126", "reply_to": "ROOT126", "timestamp": "2018-08-29T18:07:59Z", "text": "maybe", "meta": {"posReactions": "0", "negReactions": "68"}}
{"id": "COM1261", "user": "hallister", "root": "ROOT126", "reply_to": "COM1260", "timestamp": "2018-08-29T18:11:25Z", "text": "You're going to introduce a major license change, refuse to change the license name and do it in a minor version bump? What the actual hell is your goal here? ", "meta": {"posReactions": "19", "negReactions": "0"}}
{"id": "COM1262", "user": "jamiebuilds", "root": "ROOT126", "reply_to": "COM1261", "timestamp": "2018-08-29T18:17:02Z", "text": "To screw with companies that support ICE, was that not clear?", "meta": {"posReactions": "3", "negReactions": "72"}}
{"id": "COM1263", "user": "hallister", "root": "ROOT126", "reply_to": "COM1262", "timestamp": "2018-08-29T18:27:50Z", "text": "By releasing a major license change as a minor version bump and using an incorrect license in the license field? You're screwing Lerna, not the companies listed. Ignoring you politicizing something that has no business being political (especially as a former Facebook employee... come on), literally every company listed is going to update their packages to pull from https://github.com/LernaOpenSource/LernaOpenSource and go back to work. Meanwhile you're getting massive community backlash that's only going to continue if you decide to be a child and inappropriately release this as a minor version bump or with the MIT license.\r\n\r\nThe best thing feasible for Lerna at this point is you leaving the project. But since that's not going to happen since you apparently enjoy your soap box, the second best thing is everyone moving to a fork of the project without a politician having any control. \r\n\r\nThe irony is I 100% agree with your politics, but this is not the place to express them. ", "meta": {"posReactions": "61", "negReactions": "0"}}
{"id": "COM1264", "user": "phpnode", "root": "ROOT126", "reply_to": "COM1263", "timestamp": "2018-08-29T18:28:29Z", "text": "@jamiebuilds i would personally appreciate some certainty around this, because if you're likely to release this under a patch version I now need to go through all my clients' repos to make sure they're using lock files, fixed versions or a fork. Not because my clients are Microsoft et al but because they have contractually approved lists of licenses that we can use and this license will not qualify. \r\n\r\n> To screw with companies that support ICE, was that not clear?\r\n\r\nThe intent is pretty clear, but the unfortunate side effect is that it also screws with many developers who use this tool. I know this wasn't your intention but it sucks if I have to spend my evening checking a bunch of old repos because you'll _maybe_ release this as a patch. ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1265", "user": "jamiebuilds", "root": "ROOT126", "reply_to": "COM1264", "timestamp": "2018-08-29T18:32:44Z", "text": "> The best thing feasible for Lerna at this point is you leaving the project.\r\n\r\nI left the Lerna project a long time ago, I've gone as far as to replace Lerna with a new tool called Bolt.\r\n\r\n> The irony is I 100% agree with your politics, but this is not the place to express them.\r\n\r\nAll technology is political, open source is especially political. It would not exist if not for political reasons. Open sourcing something is in itself a political act.\r\n\r\n> I know this wasn't your intention but it sucks if I have to spend my evening checking a bunch of old repos because you'll maybe release this as a patch.\r\n\r\nWe'll release it as major\r\n\r\n\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "9"}}
{"id": "COM1266", "user": "jamiebuilds", "root": "ROOT126", "reply_to": "COM1265", "timestamp": "2018-08-29T18:34:26Z", "text": "> especially as a former Facebook employee... come on\r\n\r\nOnce upon a time I thought I had to go work for those big corporations that I hate in order to do the kind of open source work I want to do. That turned out to be incredibly false. So I fucked off and told them to eat shit.", "meta": {"posReactions": "2", "negReactions": "40"}}
{"id": "COM1267", "user": "siziyman", "root": "ROOT126", "reply_to": "COM1266", "timestamp": "2018-08-29T18:38:57Z", "text": "> I left the Lerna project a long time ago, \r\n\r\nAs long as you're maintaining the repository and represent it in the face of other contributors and open source community members - no, you did not. Maintainer is a part of a project.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1268", "user": "jamiebuilds", "root": "ROOT126", "reply_to": "COM1267", "timestamp": "2018-08-29T18:39:58Z", "text": "Cool story", "meta": {"posReactions": "0", "negReactions": "63"}}
{"id": "ROOT127", "user": "Porkechebure", "root": "ROOT127", "reply_to": null, "timestamp": "2019-09-27T10:12:25Z", "text": "WHy angular is retarded? Spoiler: no template i have no time to waste\r \r Problem: Reactive forms\r div with [ngClass] directive:\r \r ``div\r                     class=\"custom-control custom-checkbox\"\r                     style=\"padding-left:80px; padding-top:30px;\"\r                     [ngClass]=\"{\r                       'd-none': f.somereactiveformcontrol.value !== '1'\r                     }\"\r                   >``\r f is a getter in .ts file that returns all controls (and work everywhere else)\r d-none is bootstrap display:none class\r f.somereactiveformcontrol.value is a select/option dropdown which if !==1 shows div else hides it as you can guess\r \r When dropdown activated manually it works\r when the dropdown changes because changed from code (using your (change) method binding)\r it doesn't change\r \r I'm fed up the whole framework is filled with this crap. Why you even do double way binding if works half the needed cases? Don't even make a framework at this point\r \r I've read about observable something, but why would I use the whole framework if I had to use another framework and do my own implementation? It has no fucking sense.\r \r If the customer didn't specifically asked for angular I would have thrown this piece of trash in the toilet long time ago\r \r How to solve\r \r EDIT: Thumbs down my ass, it's reality  that smacks your face \ud83d\udc4d \r Instead of thumbing down like twitter and facebook kids, show me I'm wrong \ud83e\udd47 ", "meta": {"posReactions": "1", "negReactions": "6"}}
{"id": "COM1270", "user": "Porkechebure", "root": "ROOT127", "reply_to": "ROOT127", "timestamp": "2019-09-27T10:48:46Z", "text": "https://github.com/udos86/ng-dynamic-forms/issues/253\r\n\r\nLAWL EVEN PEOPLE IS ASKING FOR IT\r\nthumbs down don't bother me, take some relief on your real life frustration and let them rain down \ud83d\udcaf ", "meta": {"posReactions": "1", "negReactions": "3"}}
{"id": "COM1271", "user": "Porkechebure", "root": "ROOT127", "reply_to": "COM1270", "timestamp": "2019-09-27T10:52:09Z", "text": "HAHAHAHAHA look at which hacks people has to resort\r\nhttps://github.com/udos86/ng-dynamic-forms/issues/253#issuecomment-318623092", "meta": {"posReactions": "1", "negReactions": "3"}}
{"id": "COM1272", "user": "sarunint", "root": "ROOT127", "reply_to": "COM1271", "timestamp": "2019-09-27T11:00:50Z", "text": "> Instead of thumbing down like twitter and facebook kids, show me I'm wrong \ud83e\udd47\r\n\r\nSure.\r\n\r\nI'll go issue by issue.\r\n\r\n> Spoiler: no template i have no time to waste\r\n\r\nFirstly, the Angular repository receives **hundreds** of issues a day. The issue template ensure that the report is structured so the team can understand the issue quickly.\r\n\r\n> \r\n> Problem: Reactive forms\r\n> div with [ngClass] directive:\r\n> \r\n> `<div class=\"custom-control custom-checkbox\" style=\"padding-left:80px; padding-top:30px;\" [ngClass]=\"{ 'd-none': f.somereactiveformcontrol.value !== '1' }\" >`\r\n> f is a getter in .ts file that returns all controls (and work everywhere else)\r\n> d-none is bootstrap display:none class\r\n> f.somereactiveformcontrol.value is a select/option dropdown which if !==1 shows div else hides it as you can guess\r\n> \r\n> When dropdown activated manually it works\r\n> when the dropdown changes because changed from code (using your (change) method binding)\r\n> it doesn't change\r\n> \r\n\r\nBecause you change the DOM, but didn't change the `ControlValueAccessor` behind it. I suggest you use [`f.somereactiveformcontrol.setValue`](https://angular.io/api/forms/FormControl#setvalue) instead.\r\n\r\n\r\n> I'm fed up the whole framework is filled with this crap. Why you even do double way binding if works half the needed cases? Don't even make a framework at this point\r\n> \r\n\r\nNo, Angular does not have two-way binding. AngularJS does. (Even the `[()]` thingy is one-way binding underneath.)\r\n\r\n> I've read about observable something, but why would I use the whole framework if I had to use another framework and do my own implementation? It has no fucking sense.\r\n> \r\n\r\nRxJS is not a framework. It's library which enables reactive programming in Angular.\r\n\r\n> If the customer didn't specifically asked for angular I would have thrown this piece of trash in the toilet long time ago\r\n> \r\n> How to solve\r\n> \r\n\r\nI'm not able to reply on this one.\r\n\r\n> EDIT: Thumbs down my ass, it's reality that smacks your face \ud83d\udc4d\r\n\r\n[This is not cool.](https://github.com/angular/angular/blob/master/CODE_OF_CONDUCT.md)", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1273", "user": "Porkechebure", "root": "ROOT127", "reply_to": "COM1272", "timestamp": "2019-09-27T11:14:35Z", "text": "> > Instead of thumbing down like twitter and facebook kids, show me I'm wrong \ud83e\udd47\r\n> \r\n> Sure.\r\n> \r\n> I'll go issue by issue.\r\n\r\nThank you\r\n> \r\n> > Spoiler: no template i have no time to waste\r\n> \r\n> Firstly, the Angular repository receives **hundreds** of issues a day. The issue template ensure that the report is structure so the team can understand the issue quickly.\r\n> \r\n\r\nThe issue is Angular then. Hundreds of issues at day you say. A stable and mature and professional product after all these years shouldnt. Thats the damn problem.\r\n\r\nI mean... what kind of working product in IT receives \"hundreds\" of issues each day....\r\nI once developed a C# utility library which was used for most of the tasks in the main programs of my company and so, used on customers machines. Given enough time to test it, It worked very well and the problems related to it were quite little and I had to put hands back into it like 8 times in 5 years for something that was trouble and not expanding it with new required functionalities. But it was used in companies with thousands of workers, in our company and in mostly all of our software.\r\n\r\nThe functionalities where broad and large since in C# you can do anything, it was about managing file i/o, mail sending receive, attachments management, network synchronicazion (RabbitMQ and other queue managers of IBM if I remember well), database CRUDS, serialization (xml, json), automation of tasks, orchestrating various windows services through network and more and more.\r\n\r\nThis has to do one thing: Web dev, yet it gets hundreds of issues each day, like web dev has changed much in the last years (and it's not, the only thing it changed is that anyone felt to be a great programmer and to excrete out a new js framework like it would be the new holy grail of web dev).\r\nSo this means the whole framework is unpolished, untested and lazy coded.\r\nThis [sums it up really well](http://imgs.xkcd.com/comics/standards.png) \r\n\r\n> > Problem: Reactive forms\r\n> > div with [ngClass] directive:\r\n> > `<div class=\"custom-control custom-checkbox\" style=\"padding-left:80px; padding-top:30px;\" [ngClass]=\"{ 'd-none': f.somereactiveformcontrol.value !== '1' }\" >`\r\n> > f is a getter in .ts file that returns all controls (and work everywhere else)\r\n> > d-none is bootstrap display:none class\r\n> > f.somereactiveformcontrol.value is a select/option dropdown which if !==1 shows div else hides it as you can guess\r\n> > When dropdown activated manually it works\r\n> > when the dropdown changes because changed from code (using your (change) method binding)\r\n> > it doesn't change\r\n> \r\n> Because you change the DOM, but didn't change the `ControlValueAccessor` behind it. I suggest you use [`f.somereactiveformcontrol.setValue`](https://angular.io/api/forms/FormControl#setvalue) instead.\r\n> \r\n\r\nAnd? It's matter of the framework taking care of it because of two way data binding (check below), not my worry, otherwise I could as well do things on my own like I always did.\r\n\r\nBut there is an even more FUNNY thing. I AM ACTUALLY ALREADY USING setValue even before writing this post!!! \r\n\r\nThis is the actual code:\r\n\r\non the changing select element:\r\n`(change)=\"onClienteChange($event)\"`\r\n\r\n```\r\nonClienteChange(e) {\r\n    const customer= this.getCustomer(\r\n      e.target.value.toString()\r\n    );``\r\n\r\n ``this.orderForm.controls.paymentMethod.setValue(\r\n      customer.paymentMethod\r\n    );\r\n}\r\n```\r\n\r\n\r\n\r\n\r\nSo to follow up your discussion, I am already using the recommened method.\r\n\r\n> > I'm fed up the whole framework is filled with this crap. Why you even do double way binding if works half the needed cases? Don't even make a framework at this point\r\n> \r\n> No, Angular does not have two-way binding. AngularJS does. (Even the `[()]` thingy is one-way binding underneath.)\r\n> \r\n\r\nhttps://angular.io/api/forms/NgModel\r\nQuoting from official website:\r\n\r\n> If you have a two-way binding with [()] syntax (also known as 'banana-box syntax')\r\n\r\nIf they make fool of me it's not my fault\r\n\r\n> > I've read about observable something, but why would I use the whole framework if I had to use another framework and do my own implementation? It has no fucking sense.\r\n> \r\n> RxJS is not a framework. It's library which enables reactive programming in Angular.\r\n> \r\n\r\nIt's the same. Angular should leverage it to avoid me pulling hair or doing heavy lifting. Instead it leaves you clueless with these kind of things and stupid documentation which is a copy paste from semi working code samples from tour of heroes which in some case alre also wrong and with errors in it.\r\n\r\n> > If the customer didn't specifically asked for angular I would have thrown this piece of trash in the toilet long time ago\r\n> > How to solve\r\n> \r\n> I'm not able to reply on this one.\r\n> \r\n> > EDIT: Thumbs down my ass, it's reality that smacks your face \ud83d\udc4d\r\n> \r\n> [This is not cool.](https://github.com/angular/angular/blob/master/CODE_OF_CONDUCT.md)\r\n\r\nAngular is  [NOT COOL](https://medium.com/hackernoon/why-angular-made-me-quit-web-dev-f63b83a157af)\r\n\r\nAnd about the above article, I can second and confirm personally by experience EACH SINGLE point showed. It's all true and still relevant to the most up to date version of the angular framework.\r\n\r\nThis long reply is to show that I'm not just an angry fool, lot of people is fed up with it and it actually is an half baked crippled tool\r\n\r\nYeah @thetric don't cry in silence and show us your strong arguments against my point", "meta": {"posReactions": "1", "negReactions": "4"}}
{"id": "COM1274", "user": "petebacondarwin", "root": "ROOT127", "reply_to": "COM1273", "timestamp": "2019-09-27T12:01:00Z", "text": "Closing and locking this issue as it is not acceptable language to use on our issue tracker. Please adhere to our code of conduct https://github.com/angular/code-of-conduct.\r\n\r\n@Porkechebure - clearly you are feeling frustrated and angry right now. I can understand how that can happen. It is important that we work constructively to solve our problems and not resort to insults.\r\n\r\nPlease take a while to cool down and then open a more appropriate issue if you would like a problem with the framework to be addressed.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT128", "user": "povsister", "root": "ROOT128", "reply_to": null, "timestamp": "2020-10-27T06:48:32Z", "text": "http2 client: enable http2 connection health check **What type of PR is this?**\r /kind bug\r \r \r **What this PR does / why we need it**:\r There are several confirmed client connection issues with Go's http2 implementation.\r And [it's also proved](https://github.com/kubernetes/kubernetes/issues/87615#issuecomment-671814091) that enabling http2 connection health check helps kubernetes client recover from such issues.\r \r This PR updates golang.org/x/net to required version and enables http2 health check by default.\r \r **Which issue(s) this PR fixes**:\r Fixes #87615 #91963 #92164\r \r **Special notes for your reviewer**:\r Do we need a release note for this ?\r \r \r **Does this PR introduce a user-facing change?**:\r ```release-note\r NONE\r ```\r \r **Additional documentation e.g., KEPs (Kubernetes Enhancement Proposals), usage docs, etc.**:\r ```docs\r \r ```\r /area dependency\r /sig api-machinery\r \r /cc @liggitt @JensErat", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1280", "user": "k8s-ci-robot", "root": "ROOT128", "reply_to": "ROOT128", "timestamp": "2020-10-27T06:48:35Z", "text": "@povsister: GitHub didn't allow me to request PR reviews from the following users: JensErat.\n\nNote that only [kubernetes members](https://github.com/orgs/kubernetes/people) and repo collaborators can review this PR, and authors cannot review their own PRs.\n\n<details>\n\nIn response to [this](https://github.com/kubernetes/kubernetes/pull/95898):\n\n>**What type of PR is this?**\r\n>/kind bug\r\n>\r\n>\r\n>**What this PR does / why we need it**:\r\n>There are several confirmed client connection issues with Go's http2 implementation.\r\n>And [it's also proved](https://github.com/kubernetes/kubernetes/issues/87615#issuecomment-671814091) that enabling http2 connection health check helps kubernetes client recover from such issues.\r\n>\r\n>This PR updates golang.org/x/net to required version and enables http2 health check by default.\r\n>\r\n>**Which issue(s) this PR fixes**:\r\n>Fixes #87615 #91963 #92164\r\n>\r\n>**Special notes for your reviewer**:\r\n>Do we need a release note for this ?\r\n>\r\n>\r\n>**Does this PR introduce a user-facing change?**:\r\n>```release-note\r\n>NONE\r\n>```\r\n>\r\n>**Additional documentation e.g., KEPs (Kubernetes Enhancement Proposals), usage docs, etc.**:\r\n>```docs\r\n>\r\n>```\r\n>/area dependency\r\n>/sig api-machinery\r\n>\r\n>/cc @liggitt @JensErat\n\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.\n</details>", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1281", "user": "k8s-ci-robot", "root": "ROOT128", "reply_to": "COM1280", "timestamp": "2020-10-27T06:48:41Z", "text": "Hi @povsister. Thanks for your PR.\n\nI'm waiting for a [kubernetes](https://github.com/orgs/kubernetes/people) member to verify that this patch is reasonable to test. If it is, they should reply with `/ok-to-test` on its own line. Until that is done, I will not automatically test new commits in this PR, but the usual testing commands by org members will still work. Regular contributors should [join the org](https://git.k8s.io/community/community-membership.md#member) to skip this step.\n\nOnce the patch is verified, the new status will be reflected by the `ok-to-test` label.\n\nI understand the commands that are listed [here](https://go.k8s.io/bot-commands?repo=kubernetes%2Fkubernetes).\n\n<details>\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.\n</details>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1282", "user": "k8s-ci-robot", "root": "ROOT128", "reply_to": "COM1281", "timestamp": "2020-10-27T06:49:13Z", "text": "[APPROVALNOTIFIER] This PR is **NOT APPROVED**\n\nThis pull-request has been approved by: *<a href=\"https://github.com/kubernetes/kubernetes/pull/95898#\" title=\"Author self-approved\">povsister</a>*\nTo complete the [pull request process](https://git.k8s.io/community/contributors/guide/owners.md#the-code-review-process), please assign **liggitt** after the PR has been reviewed.\nYou can assign the PR to them by writing `/assign @liggitt` in a comment when ready.\n\nThe full list of commands accepted by this bot can be found [here](https://go.k8s.io/bot-commands?repo=kubernetes%2Fkubernetes).\n\n<details open>\nNeeds approval from an approver in each of these files:\n\n- **[OWNERS](https://github.com/kubernetes/kubernetes/blob/master/OWNERS)**\n- **[staging/src/k8s.io/api/OWNERS](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/api/OWNERS)**\n\nApprovers can indicate their approval by writing `/approve` in a comment\nApprovers can cancel approval by writing `/approve cancel` in a comment\n</details>\n<!-- META={\"approvers\":[\"liggitt\"]} -->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1283", "user": "aojea", "root": "ROOT128", "reply_to": "COM1282", "timestamp": "2020-10-27T10:22:16Z", "text": ":thinking: it looks a duplicate of https://github.com/kubernetes/kubernetes/pull/94844", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1284", "user": "dims", "root": "ROOT128", "reply_to": "COM1283", "timestamp": "2020-10-27T10:49:15Z", "text": "@povsister - @aojea is right. please check the other one out and ensure that fixes your problem as well.\r\n\r\n/close", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1285", "user": "k8s-ci-robot", "root": "ROOT128", "reply_to": "COM1284", "timestamp": "2020-10-27T10:49:29Z", "text": "@dims: Closed this PR.\n\n<details>\n\nIn response to [this](https://github.com/kubernetes/kubernetes/pull/95898#issuecomment-717155585):\n\n>@povsister - @aojea is right. please check the other one out and ensure that fixes your problem as well.\r\n>\r\n>/close\n\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.\n</details>", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1286", "user": "povsister", "root": "ROOT128", "reply_to": "COM1285", "timestamp": "2020-10-27T10:50:46Z", "text": "> \ud83e\udd14 it looks a duplicate of #94844\r\n\r\nNot really, original solution proposed in #94844 uses a modified http2 package which breaks backward compatibility and is not merged into golang/net master.\r\nAnd he didn't push another fix till I proposed this fix.\r\n\r\nTo be honest(no offense), code and commit history in #94844 looks nasty...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1287", "user": "dims", "root": "ROOT128", "reply_to": "COM1286", "timestamp": "2020-10-27T10:52:50Z", "text": "/reopen", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1288", "user": "k8s-ci-robot", "root": "ROOT128", "reply_to": "COM1287", "timestamp": "2020-10-27T10:53:05Z", "text": "@dims: Reopened this PR.\n\n<details>\n\nIn response to [this](https://github.com/kubernetes/kubernetes/pull/95898#issuecomment-717157525):\n\n>/reopen\n\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.\n</details>", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1289", "user": "dims", "root": "ROOT128", "reply_to": "COM1288", "timestamp": "2020-10-27T10:53:41Z", "text": "@povsister please comment on your concerns in the other PR. that is already approved and is likely to merge first.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12810", "user": "povsister", "root": "ROOT128", "reply_to": "COM1289", "timestamp": "2020-10-27T10:57:03Z", "text": "Thx, I am on mobile right now. Will check out for another PR later.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12811", "user": "aojea", "root": "ROOT128", "reply_to": "COM12810", "timestamp": "2020-10-27T13:08:51Z", "text": "I think it doesn' t hurt if we test it in the meantime :sweat_smile: \r\n/ok-to-test", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12812", "user": "povsister", "root": "ROOT128", "reply_to": "COM12811", "timestamp": "2020-10-27T13:22:21Z", "text": "@aojea Thanks, seem one test job got OOMKilled. I will re-trigger it later.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12813", "user": "duyanghao", "root": "ROOT128", "reply_to": "COM12812", "timestamp": "2020-10-27T14:12:24Z", "text": "> > \ud83e\udd14 it looks a duplicate of #94844\r\n> \r\n> Not really, original solution proposed in #94844 uses a modified http2 package which breaks backward compatibility and is not merged into golang/net master.\r\n> And he didn't push another fix till I proposed this fix.\r\n> \r\n> To be honest(no offense), code and commit history in #94844 looks nasty...\r\n\r\n@povsister I don't know why you're so hysterical about which PR should be merged, and what I want to clarify here is that obviously I found this problem before you, and I have not even found the existence of golang/net@08b3837 until @fisherxu mentioned it in my PR, that why I push a new commit using http2.ConfigureTransports today and open this [PR](https://github.com/golang/net/pull/84) trying to fix the problem before. And besides I didn't have any reference on your PR as I have not even noticed you before.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12814", "user": "povsister", "root": "ROOT128", "reply_to": "COM12813", "timestamp": "2020-10-27T14:43:59Z", "text": "@duyanghao Calm down. I do not mind whose PR get merged. We are talking things technically, don't make it personal. \r\nIf you insist. I'd like to tell you that [we have already talked about this issue months ago](https://github.com/kubernetes/kubernetes/issues/87615#issuecomment-647915537).\r\n\r\nI prefer forward-looking solution instead of solving questions at hand. That's why I have opposition to your PR.\r\n\r\nI have every concern with cause and conclusion posted in you PR, that's technical.\r\nYou have disagreement but no reason. That's personal.\r\n\r\nIf you feel disrespect on \"nasty\", I apologize. I have neat freak on coding : )\r\nAnd you should learn how to use Git with clear&clean commit history.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12815", "user": "povsister", "root": "ROOT128", "reply_to": "COM12814", "timestamp": "2020-10-27T14:49:59Z", "text": "/retest", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12816", "user": "aojea", "root": "ROOT128", "reply_to": "COM12815", "timestamp": "2020-10-27T14:54:06Z", "text": "This is not a competition and please respect the code of conduct\r\nhttps://kubernetes.io/community/code-of-conduct/#contributor-code-of-conduct\r\n\r\nThere are certain comments in this thread that are clearly uncalled-for.\r\n\r\n\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM12817", "user": "povsister", "root": "ROOT128", "reply_to": "COM12816", "timestamp": "2020-10-27T16:02:28Z", "text": "/retest", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12818", "user": "povsister", "root": "ROOT128", "reply_to": "COM12817", "timestamp": "2020-10-27T17:42:34Z", "text": "Looks like the update to golang.org/x/sys package breaks azure disk driver?\r\n\r\n It says `event for azuredisk-volume-tester-pbml9-84db65759d-9p2vq: {kubelet 9131k8s000} FailedMount: Unable to attach or mount volumes: unmounted volumes=[test-volume-1], unattached volumes=[test-volume-1 default-token-klq5d]: timed out waiting for the condition`\r\n\r\nCode problem should not cause operation timeout. I think it maybe overload of test infra. I will retry next morning.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12819", "user": "povsister", "root": "ROOT128", "reply_to": "COM12818", "timestamp": "2020-10-27T20:05:14Z", "text": "/retest", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12820", "user": "fedebongio", "root": "ROOT128", "reply_to": "COM12819", "timestamp": "2020-10-27T20:12:31Z", "text": "/assign @sttts @p0lyn0mial ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12821", "user": "fedebongio", "root": "ROOT128", "reply_to": "COM12820", "timestamp": "2020-10-27T20:12:42Z", "text": "/triage accepted\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12822", "user": "povsister", "root": "ROOT128", "reply_to": "COM12821", "timestamp": "2020-10-27T23:00:02Z", "text": "@JensErat Thanks for your comments. Just pushed another commit to fix typo.\r\nIf this get approved, I'll squash the rest commits.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12823", "user": "aojea", "root": "ROOT128", "reply_to": "COM12822", "timestamp": "2020-10-28T08:24:43Z", "text": "> At Daimler, our workaround was patching x/net to keep `PingTimeout` default at 15 seconds but enforce a `ReadIdleTimeout` of 30 seconds. I guess this is sufficient for Kubernetes work loads, and at the same time should not really trigger \"additional\" keep-alive efforts in production too often. \r\n\r\n> If I get it right, this PR sets the default to 90/2=45 seconds, and `t1.IdleConnTimeout` is never set in the entire Kubernetes organization to anything but the default values.\r\n\r\n\r\nmaybe it is me, but I prefer hardcoded timeouts than formulas, is not easy to me to understand which values I'm using this way.\r\nPersonally, as I user, I'd like to use the defaults timeouts provided or the ones I set directly, is my mistake if I set them wrong.\r\nI found weird that I set `pingTimeout` to 3 seconds for whatever reason and something configures it to 15 seconds without I'm noticing, or I'm not understanding correctly it?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12824", "user": "povsister", "root": "ROOT128", "reply_to": "COM12823", "timestamp": "2020-10-28T09:47:19Z", "text": "> If I get it right, this PR sets the default to 90/2=45 seconds, and t1.IdleConnTimeout is never set in the entire Kubernetes organization to anything but the default values.\r\n\r\nBy default Kubernetes always set `t1.IdleConnTimeout` to default 90s. I added the if-compare section just for possible exceptions in the future, it ensures functionality of healthCheck.\r\n\r\n> Personally, as I user, I'd like to use the defaults timeouts provided or the ones I set directly, is my mistake if I set them wrong.\r\n\r\nFor now, http2 Transport configuration is purely internal. We do not expose such configuration to users, that's probably why we don't need release note.\r\nSo I think we'd better make it reasonable even with some confusing formula.(still can be explained by sufficient comments in code, It should not be a big problem.)", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM12825", "user": "liggitt", "root": "ROOT128", "reply_to": "COM12824", "timestamp": "2020-10-28T12:44:19Z", "text": "/uncc\r\n/cc @caesarxuchao \r\n/assign @caesarxuchao ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12826", "user": "duyanghao", "root": "ROOT128", "reply_to": "COM12825", "timestamp": "2020-10-28T13:08:17Z", "text": "> @duyanghao Calm down. I do not mind whose PR get merged. We are talking things technically, don't make it personal.\r\n> If you insist. I'd like to tell you that [we have already talked about this issue months ago](https://github.com/kubernetes/kubernetes/issues/87615#issuecomment-647915537).\r\n> \r\n> I prefer forward-looking solution instead of solving questions at hand. That's why I have opposition to your PR.\r\n> \r\n> I have every concern with cause and conclusion posted in you PR, that's technical.\r\n> You have disagreement but no reason. That's personal.\r\n> \r\n> If you feel disrespect on \"nasty\", I apologize. I have neat freak on coding : )\r\n> And you should learn how to use Git with clear&clean commit history.\r\n\r\n@povsister You are so unbelievably arrogant that I don't want to waste my time arguing with you. And I am able to do git sqaush, besides this is my reason against your proposal\r\n>>I do think users should not care much about the http2 health check, and it's not something Kubernetes even want users to notice, therefore I still suggest to set it by some reasonable default values. Besides, in your \u2018proud\u2019 PR, the http2 Transport ReadIdleTimeout is configured as the half of http Transport IdleConnTimeout, Is this reasonable?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12827", "user": "liggitt", "root": "ROOT128", "reply_to": "COM12826", "timestamp": "2020-10-28T13:31:57Z", "text": "@povsister @duyanghao thank you both for working to resolve the network connection issue. However, the discussion in this PR and in #94844 is distracting from the main goal of fixing the issue, and is violating the [Kubernetes code of conduct](https://kubernetes.io/community/code-of-conduct/) with insulting/derogatory comments. I've locked the discussion here and in #94844 for that reason, and will ask @caesarxuchao to take a look at the approaches in the two PRs and settle on a way to make use of the PingTimeout capability he added.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12828", "user": "lavalamp", "root": "ROOT128", "reply_to": "COM12827", "timestamp": "2020-10-28T22:18:33Z", "text": "This isn't how we have technical disagreements. No amount of technical correctness can make up for treating other people poorly; please don't repeat that behavior. I will close both of these PRs. I'm available via slack or email if more explanation is needed.\r\n\r\nInstead, I've asked @caesarxuchao to send a fix for the issue in question.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT129", "user": "powercode", "root": "ROOT129", "reply_to": null, "timestamp": "2018-03-30T10:34:14Z", "text": "Weird slowness scolling text in the console When outputting text from PowerShell on a Dell XPS 15, the rendering speed is amazingly slow.\r \r ~~I have not come across this on any other machine.~~\r \r Attached a short windows performance recording of this. \r conhost.exe (1608) and pwsh.exe (19432) are the relevant processes.\r \r [STAFFANX15.03-30-2018.11-25-22.zip](https://github.com/Microsoft/console/files/1863382/STAFFANX15.03-30-2018.11-25-22.zip)\r \r Hopefully someone more well versed in this domain can help figure out what is going on.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1290", "user": "IISResetMe", "root": "ROOT129", "reply_to": "ROOT129", "timestamp": "2018-03-30T11:41:01Z", "text": "It's caused by `conhost.exe` excessively hammering the registry to query the following two values:\r\n\r\n    HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\ImmersiveShell\\TabletMode\r\n    HKCU\\Software\\Microsoft\\Windows\\DWM\\ColorPrevalence\r\n\r\nHaving previously reported this issue through Feedback Hub (to no avail), let me offer my observations from debugging this issue:\r\n\r\n - It's not specific to Dell's XPS series - I've been able to reproduce on any Windows 10 installation from version 1703 and up\r\n - It only occurs when the console application writes output that causes the console to *scroll*\r\n - It only occurs when the console application in question is in foreground/focus\r\n - Each reg value mentioned above is queried 6 times, per scroll!!!\r\n\r\nAn easy way of show the resulting difference in speed is to compare to anything piped to `Out-String`:\r\n\r\n    $WindowHeight = $Host.UI.RawUI.WindowSize.Height\r\n    Clear-Host\r\n    $StopWatch = [Diagnostics.Stopwatch]::StartNew()\r\n    &{\r\n        1..($WindowHeight * 2)|ForEach-Object{\r\n            Write-Output \"test\"\r\n        }\r\n    }\r\n    $MultiString = $StopWatch.Elapsed\r\n    Clear-Host\r\n    $StopWatch = [Diagnostics.Stopwatch]::StartNew()\r\n    &{\r\n        1..($WindowHeight * 2)|ForEach-Object{\r\n            Write-Output \"test\"\r\n        }\r\n    } | Out-String\r\n    $SingleString = $StopWatch.Elapsed\r\n\r\nEven though we add overhead from `Out-String`, and the number of lines that the console host eventually need to write to the screen buffer are exactly the same, you'll find that the `$MultiString` measurement is significantly larger that `$SingleString`, presumably because the former caused the console host to scroll `$WindowsHeight` where as the latter only had to cause a single scroll.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1291", "user": "zadjii-msft", "root": "ROOT129", "reply_to": "COM1290", "timestamp": "2018-03-30T15:45:05Z", "text": "So I've definitely noticed this from time to time on my own laptop, which is an HP something or other - though it's definitely not something I've found to be consistently reproducible. \r\n\r\nI also know that conhost isn't the one doing this - at least not directly. From the sounds of it, DWM is getting involved during our paint and slowing us down, but I wouldn't have the faintest clue how to start debugging that. \r\n\r\n@bitcrazed anyone on the DWM, or composition, or something team that we can forward this issue to to have them take a look?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1292", "user": "powercode", "root": "ROOT129", "reply_to": "COM1291", "timestamp": "2018-03-31T07:09:05Z", "text": "![image](https://user-images.githubusercontent.com/3505151/38160780-2155300e-34c3-11e8-805c-b67a1dedabb5.png)\r\n\r\nIt is not obviously DWM.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1293", "user": "powercode", "root": "ROOT129", "reply_to": "COM1292", "timestamp": "2018-04-01T15:18:16Z", "text": "It is correlated to font size. Almost grinds to a halt with font size set to 36.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1294", "user": "IISResetMe", "root": "ROOT129", "reply_to": "COM1293", "timestamp": "2018-04-01T15:37:50Z", "text": "Interestingly enough, I updated my Win10 Pro 1709 Friday night, and now (build **10.0.16299.309**) `conhost.exe` is no longer querying the registry keys mentioned above, but DWM queries this value:\r\n\r\n    HKCU\\Software\\Microsoft\\Windows\\DWM\\ColorPrevalence\r\n\r\n10 times per scroll. Still digging", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1295", "user": "powercode", "root": "ROOT129", "reply_to": "COM1294", "timestamp": "2018-04-03T20:12:57Z", "text": "fontdrvhost.exe shows up in the traces on machines where this is slow. On machines where this isn't slow, fontdrvhost.exe uses no CPU at all. \r\n\r\nAnd it seems related to scrolling.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1296", "user": "powercode", "root": "ROOT129", "reply_to": "COM1295", "timestamp": "2018-04-03T21:25:16Z", "text": "![image](https://user-images.githubusercontent.com/3505151/38276632-ded3fb2c-3795-11e8-96b2-5f22c2e93fb3.png)\r\n\r\nThere is some ping-pong between `conhost.exe` and `fontdrvhost.exe`.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1297", "user": "powercode", "root": "ROOT129", "reply_to": "COM1296", "timestamp": "2018-04-03T21:33:01Z", "text": "\r\n\r\n[conhost_fontdrvhost.zip](https://github.com/Microsoft/console/files/1873451/conhost_fontdrvhost.zip)\r\n\r\nA less noisy ETW trace.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1298", "user": "powercode", "root": "ROOT129", "reply_to": "COM1297", "timestamp": "2018-04-03T23:18:41Z", "text": "The machines where you have seen it being slow, did they all have touch screens?\r\n\r\nSee the `IncDevice!vector scalar destructor` in the call stack. That doesn't show up on my machines where this is a lot faster.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1299", "user": "bitcrazed", "root": "ROOT129", "reply_to": "COM1298", "timestamp": "2018-04-04T17:35:01Z", "text": "Thanks all. Have reached out to the DWM team. Let's see what they say.", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM12910", "user": "powercode", "root": "ROOT129", "reply_to": "COM1299", "timestamp": "2018-04-19T10:27:02Z", "text": "@bitcrazed Any news?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12911", "user": "bitcrazed", "root": "ROOT129", "reply_to": "COM12910", "timestamp": "2018-04-19T22:08:39Z", "text": "We are looking into this. Sorry for the delay - Build prep is eating up a lot of people x hours right now ;)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12912", "user": "bitcrazed", "root": "ROOT129", "reply_to": "COM12911", "timestamp": "2018-04-19T22:45:23Z", "text": "@powercode - Okay, we have some suspicions as to what's happening here (thanks CD for your help with this \ud83d\ude00) \r\n\r\nCould we ask:\r\n1. What is the size & resolution of your screen?  15.6\" @ 3200 x 1800?\r\n1. What DPI scaling factor are you using?\r\n1. What is the font face & size of your affected Console(s)?\r\n1. Does this problem disappear if you decrease your Console font size to ~12pt when running at 200% DPI?\r\n\r\nBTW - MANY thanks for capturing traces - they've been ENORMOUSLY helpful!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12913", "user": "powercode", "root": "ROOT129", "reply_to": "COM12912", "timestamp": "2018-04-20T05:45:35Z", "text": "Resolution 3840x2160.\r\nScaling 250. Both the recommended setup.\r\n\r\nI have tried different fonts but have not stumbled upon any that worked, but have not on the other hand made exhaustive tests. Consolas is affected, as is Deja Vu Sans Mono for PowerLine, and several other PowerLine fonts. \r\n\r\nWow! Setting the resolution scaling to 200% improves perf  a lot.\r\n```\r\nDuration         CommandLine\r\n--------         -----------\r\n00:00:15.4034821 ls -recurse   # 250%, 36 pt\r\n00:00:03.1567607 ls -recurse   # 200%, 36 pt\r\n00:00:00.2825821 ls -recurse   # 200%, 12 pt\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12914", "user": "powercode", "root": "ROOT129", "reply_to": "COM12913", "timestamp": "2018-04-20T06:18:09Z", "text": "And @bitcrazed, thank you, and Microsoft, for making it so easy to both gather and look at perf recordings. It is a game changer for me!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12915", "user": "bitcrazed", "root": "ROOT129", "reply_to": "COM12914", "timestamp": "2018-04-20T17:16:04Z", "text": "Ahhhh! Yeah, you're getting hit by the known issue! Anyone else seeing this, you'll likely see perf return to normal if you keep scaling <= 200% and your font <24pt., though not guarantees. \r\n\r\nI found the dev owner yesterday and he was literally working on fix for this issue that surfaced elsewhere but is the same root cause!\r\n\r\nRe. XPerf/WPA - **I KNOW, RIGHT**!! I was talking with aforementioned dev and was recalling how hard it was, back in the dark ages, to diagnose issues like these without the benefit of detailed perf traces!!\r\n\r\nThank goodness for progress ;)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12916", "user": "powercode", "root": "ROOT129", "reply_to": "COM12915", "timestamp": "2018-04-21T12:39:28Z", "text": "Yes! Thank goodness for progress, and @randomascii, for his incredibly helpful blog posts on analysing the data. Learned so much from him! Huge props!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12917", "user": "randomascii", "root": "ROOT129", "reply_to": "COM12916", "timestamp": "2018-04-23T09:15:57Z", "text": "I'm always glad to hear when my blog posts are useful.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM12918", "user": "powercode", "root": "ROOT129", "reply_to": "COM12917", "timestamp": "2018-08-08T06:33:45Z", "text": "Any update? ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12919", "user": "bitcrazed", "root": "ROOT129", "reply_to": "COM12918", "timestamp": "2018-08-08T17:17:43Z", "text": "Are you still seeing this issue on recent Insider builds?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12920", "user": "powercode", "root": "ROOT129", "reply_to": "COM12919", "timestamp": "2018-08-08T17:24:00Z", "text": "That machine is not on insider builds :(", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12921", "user": "bitcrazed", "root": "ROOT129", "reply_to": "COM12920", "timestamp": "2018-08-09T17:07:37Z", "text": "Just checked with the engineer who worked on this: The specific issue you're seeing has been mitigated which should result in you no longer seeing it's effect. A more comprehensive fix is on the backlog and will be triaged into a future release.\r\n\r\nTo test / confirm, you'll need to install a recent RS5 Insider build, or wait until RS5 ships later this year. Once you do get onto RS5, please update this thread with your findings and close this issue if it's resolved.\r\n\r\nMany thanks again for filing and your help in diagnosing this issue.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12922", "user": "powercode", "root": "ROOT129", "reply_to": "COM12921", "timestamp": "2018-08-12T19:28:05Z", "text": "Installed RS5 - Issue still present.\r\n\r\n11 seconds to dir a folder with fondsize 36. 1.8 on size 14. Both horribly slow.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12923", "user": "powercode", "root": "ROOT129", "reply_to": "COM12922", "timestamp": "2018-08-12T19:41:12Z", "text": "[STAFFANX15.08-12-2018.21-38-27.etl.7z.zip](https://github.com/Microsoft/console/files/2281268/STAFFANX15.08-12-2018.21-38-27.etl.7z.zip)\r\n\r\nUploaded trace. It's a 7z archive with an added zip extension to allow the upload.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12924", "user": "bitcrazed", "root": "ROOT129", "reply_to": "COM12923", "timestamp": "2018-08-13T20:40:26Z", "text": "Thanks. Will take a look.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12925", "user": "bitcrazed", "root": "ROOT129", "reply_to": "COM12924", "timestamp": "2018-08-13T23:48:55Z", "text": "Hey @Powercode - any chance you could share repro steps - we'd like to see, trace, and measure the perf issue you're seeing.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12926", "user": "powercode", "root": "ROOT129", "reply_to": "COM12925", "timestamp": "2018-08-14T06:45:29Z", "text": "Start powershell.\r\nSet font size to 36.\r\nRun ls.\r\n\r\nStill on a computer with high resolution (3840x2160) and scaling on 200%.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM12927", "user": "bitcrazed", "root": "ROOT129", "reply_to": "COM12926", "timestamp": "2018-08-14T22:11:01Z", "text": "Hey @powercode. I've been doing some repro'ing on my SP4 with an external 4K 28\" screen:\r\n\r\n| Font @ 18pt, Console @ 81x25 chars | Font @ 36pt, Console @ 81x25 chars |\r\n|:-|:-|\r\n| Command:  dir C:\\Windows\\System32\\ -recurse | Command:  dir C:\\Windows\\System32\\ -recurse | \r\n| Start:   12:50:21.47 | Start:   12:52:04.63 |\r\n| End:     12:50:23.52 | End:     12:52:09.44 |\r\n| Elapsed: 00:00:02.05 | Elapsed: 00:00:04.81 |\r\n\r\n> FWIW, I used my [timing script](https://github.com/bitcrazed/PowerRazzle/blob/master/TimedRun.cmd) to measure the elapsed time to execute and render the recursive listing command above.\r\n\r\nWith the font set at 36pt, there is indeed a marked slow-down, but remember:\r\n1. Console currently uses GDI to draw text which uses your CPU to render text glyphs\r\n1. GDI generates and caches glyphs, and then BLITs them onto the screen\r\n1. The larger the glyph, the fewer can be cached\r\n1. At 18pt, the client area is 1053x675. At 36pt, the client area is 2025x1350 and the resulting glyphs are 4x bigger ... that's a lot of LARGE bitmaps to BLIT\r\n1. And since scrolling often results in significant text changes between iterations of the render loop, the entire client area can end up being \"dirtied\", resulting in the full Console client area having to be fully re-rendered each time! 2025x1350 x 4bytes each pixel == 10MB per frame x 60 fps == 656MB/s we have to force from your CPU to the GPU's frame buffer every second!. \r\n\r\nThat's a lot of data by anyone's measure, and it makes one's machine do a lot of work:\r\n\r\n![recursive-dir](https://user-images.githubusercontent.com/961950/44121072-5daffba8-9fd3-11e8-9831-49e00faa5233.png)\r\n\r\nNow, can we go faster? HELLS YEAH! \ud83d\ude1c\r\n\r\nThe GDI team recently improved their glyph caching mechanism, with more improvements planned for future releases, but increased the Glyph Cache buffer to mitigate the above factors until those improvements can be made.\r\n\r\nAlso, Console plans on replacing our GDI renderer to DirectWrite at some point in the future which should eliminate this issue anyhow. \r\n\r\n_Also_ we have some other tricks up our sleeves that we hope will noticeably improve text rendering perf, esp. while scrolling. Bear with us ;)\r\n\r\nI'll leave this issue open for now, and we'll update it when we have any solid perf improvements to share.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM12928", "user": "mixmastamyk", "root": "ROOT129", "reply_to": "COM12927", "timestamp": "2018-10-07T00:43:16Z", "text": "Hi, understood that there is a lot of graphics to push around on 4k.  However, what about the issue mentioned above with querying the registry 10x per scroll?  Might be an easy fix to cache that value:\r\n\r\n    HKCU\\Software\\Microsoft\\Windows\\DWM\\ColorPrevalence", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM12929", "user": "levicki", "root": "ROOT129", "reply_to": "COM12928", "timestamp": "2018-11-09T10:23:25Z", "text": "Hello, I would like to point out that poor console performance in Windows 10 is still present in 1809.\r\n\r\nResolution is 1920x1080, scaling is 100%, console font size is 16pt Consolas.\r\n\r\nIn my case, running IDA Pro interactive disassembler (idaw.exe) in the console results in a totally absurd situation where conhost.exe is using more CPU than the program itself:\r\n\r\n![image](https://user-images.githubusercontent.com/16415478/48256712-bb6ea380-e410-11e8-99b6-26c2fd7bd8ce.png)\r\n\r\nLooking at the threads of conhost.exe the culprits are obvious:\r\n![image](https://user-images.githubusercontent.com/16415478/48256869-3041dd80-e411-11e8-831d-e56a73bcd0a7.png)\r\n\r\nThe only part of the console window being updated is highlighted:\r\n![image](https://user-images.githubusercontent.com/16415478/48256955-654e3000-e411-11e8-9a21-6959e58a5115.png)\r\n\r\nWhy is drawing 8 characters at a fixed position using 10% of the 3.2 GHz quad-core CPU, and what is more important, why is this slowing down the console program so much that something which took minutes in Windows XP takes hours in Windows 10?\r\n\r\nPeople were drawing full screen graphics on 1 MHz Motorola 6502 CPU 3 decades ago without dedicated graphics hardware, this is how far modern programmers have fallen.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT130", "user": "prikhodkoalexey", "root": "ROOT130", "reply_to": null, "timestamp": "2019-12-19T13:19:24Z", "text": "Please rename your project VSCode implies that you are versus the code as a concept.\r I like the code and many people like the code too.\r I suggest ASCode as a new name.\r AS is an acronym for \"alongside\".", "meta": {"posReactions": "21", "negReactions": "1"}}
{"id": "COM1300", "user": "Phillipus", "root": "ROOT130", "reply_to": "ROOT130", "timestamp": "2019-12-19T13:21:23Z", "text": "Better still `SAnta Code`.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM1301", "user": "ivanpopelyshev", "root": "ROOT130", "reply_to": "COM1300", "timestamp": "2019-12-19T13:22:48Z", "text": "It will remind everyone about ActionScript: it had ints and uints, while JavaScript does not.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1302", "user": "egamma", "root": "ROOT130", "reply_to": "COM1301", "timestamp": "2019-12-19T19:34:09Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.\r\n\r\nHappy Coding!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT131", "user": "probonopd", "root": "ROOT131", "reply_to": null, "timestamp": "2020-05-19T19:10:14Z", "text": "[Bug] Name clash with Maui Linux and MauiKit ### Description\r \r A multi-platform app UI toolkit with the name of __maui__ was introduced by Microsoft on May 19th, 2020 according to https://devblogs.microsoft.com/dotnet/introducing-net-multi-platform-app-ui/:\r \r > **MAUI** simplifies the choices for .NET developers, providing a single stack that supports all modern workloads: Android, iOS, macOS, and Windows. The native features of each platform and UI control are within reach in a simple, cross-platform API for you to deliver no-compromise user experiences while sharing even more code than before.\r \r There has been https://mauilinux.org/ for a long time:\r \r > Fast and easy to use, yet powerful for computer users of all levels, **Maui** is a part-rolling distribution based on KDE Neon/Ubuntu. Maui features its own managed repositories and backport channels and ships with the following software components and applications for day-to-day use\r \r According to [Wikipedia](https://fr.wikipedia.org/wiki/Maui_Linux), Maui Linux has been around sine 2016.\r \r Also, there has been [**Maui**Kit](https://mauikit.org/) for a long time:\r \r > **MauiKit**, a free and modular front-end framework for developing fast and compelling user experiences\r \r There is clearly a name clash.\r \r ### Steps to Reproduce\r \r 1.  Visit https://mauilinux.org/ and https://fr.wikipedia.org/wiki/Maui_Linux\r 2. Visit https://mauikit.org//\r 3. Visit https://devblogs.microsoft.com/dotnet/introducing-net-multi-platform-app-ui/\r \r ### Expected Behavior\r \r Microsoft chooses names not already used in the Linux community.\r \r ### Actual Behavior\r \r Microsoft chooses names already used in the Linux community.\r \r ### Screenshots\r \r ![](https://user-images.githubusercontent.com/2480569/82367816-effaec80-9a03-11ea-9887-9d5675f11698.png)", "meta": {"posReactions": "33", "negReactions": "2"}}
{"id": "COM1310", "user": "dansiegel", "root": "ROOT131", "reply_to": "ROOT131", "timestamp": "2020-05-19T19:16:05Z", "text": "Perhaps the Linux project should change its name as they've conflicted with a city in Hawaii which existed long before. Look again, the name isn't Maui, the name is Multi-platform App UI which abbreviates to M.A.U.I. ", "meta": {"posReactions": "3", "negReactions": "45"}}
{"id": "COM1311", "user": "veggero", "root": "ROOT131", "reply_to": "COM1310", "timestamp": "2020-05-19T19:17:12Z", "text": "I feel like there's much less confusion between a city in Hawaii and a multi platform app framework both called Maui than a multi platform app framework and a multi platform app framework both called Maui. ", "meta": {"posReactions": "29", "negReactions": "2"}}
{"id": "COM1312", "user": "IlyaBizyaev", "root": "ROOT131", "reply_to": "COM1311", "timestamp": "2020-05-19T19:24:15Z", "text": "So you think of a Hawaian city when reading \"Maui\", but not when reading \"MAUI\"? Really?", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM1313", "user": "dansiegel", "root": "ROOT131", "reply_to": "COM1312", "timestamp": "2020-05-19T19:25:22Z", "text": "You find the comparison between a city in Hawaii and MauiKit ridiculous just like I find your comparison between an the Maui abbreviation and MauiKit ridiculous", "meta": {"posReactions": "2", "negReactions": "28"}}
{"id": "COM1314", "user": "IlyaBizyaev", "root": "ROOT131", "reply_to": "COM1313", "timestamp": "2020-05-19T19:27:06Z", "text": "> You find the comparison between a city in Hawaii and MauiKit ridiculous just like I find your comparison between an the Maui abbreviation and MauiKit ridiculous\r\n\r\nThe project is called Maui, has been called that for a long time, and is even stylized as \"MAUI\" on https://mauikit.org. So yeah, there's an obvious naming clash here.", "meta": {"posReactions": "26", "negReactions": "0"}}
{"id": "COM1315", "user": "ptdave20", "root": "ROOT131", "reply_to": "COM1314", "timestamp": "2020-05-19T19:27:55Z", "text": "This is a non issue.\n\nOn Tue, May 19, 2020, 3:25 PM Dan Siegel <notifications@github.com> wrote:\n\n> You find the comparison between a city in Hawaii and MauiKit ridiculous\n> just like I find your comparison between an the Maui abbreviation and\n> MauiKit ridiculous\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dotnet/maui/issues/35#issuecomment-631032369>, or\n> unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AADLMQT5NYLHCA2IPY67BHDRSLMLFANCNFSM4NFIXXSQ>\n> .\n>\n", "meta": {"posReactions": "5", "negReactions": "32"}}
{"id": "COM1316", "user": "veggero", "root": "ROOT131", "reply_to": "COM1315", "timestamp": "2020-05-19T19:30:23Z", "text": "How is having two product with the same name and same basic scope (multi platform framework) a non issue?", "meta": {"posReactions": "16", "negReactions": "0"}}
{"id": "COM1317", "user": "dansiegel", "root": "ROOT131", "reply_to": "COM1316", "timestamp": "2020-05-19T19:30:49Z", "text": "You can be mad all you want, but let's be realistic here... this project you're fighting for so passionately, doesn't have as many stars as I have thumbs down for telling you that you'e being ridiculous \r\n\r\n![image](https://user-images.githubusercontent.com/3860573/82369702-4b10ed00-99cc-11ea-8090-18139fe8d746.png)\r\n", "meta": {"posReactions": "2", "negReactions": "31"}}
{"id": "COM1318", "user": "IlyaBizyaev", "root": "ROOT131", "reply_to": "COM1317", "timestamp": "2020-05-19T19:31:43Z", "text": "That's because GitHub stars are not a currency in which you measure a project that is not even developed on GitHub.", "meta": {"posReactions": "25", "negReactions": "0"}}
{"id": "COM1319", "user": "veggero", "root": "ROOT131", "reply_to": "COM1318", "timestamp": "2020-05-19T19:32:01Z", "text": "That's because it's a mirror. The actual project is developed in KDE gitlab instance.", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM13110", "user": "TheAssassin", "root": "ROOT131", "reply_to": "COM1319", "timestamp": "2020-05-19T19:32:13Z", "text": "They even refer _themselves_ to Hawaii. Check https://github.com/dotnet/maui/commit/c7e2c55ace3ec55a0858f1c4bb55476375ea72f8, its commit message says, \"Aloha fix\".\r\n\r\nI don't think they took into account either confusion with the \"Linux project\" *nor with the Hawaiian island*.\r\n\r\n(By the way, is it seriously necessary to mention that when there's an obvious name conflict with some other free software project in the exactly same domain (UI toolkit)? Come on, get over this \"Linux vs. Windows\" mantra you still seem to follow.)\r\n\r\nEdit: yes, this was half sarcasm, half serious comment. I think you can figure out which half's which.", "meta": {"posReactions": "19", "negReactions": "0"}}
{"id": "COM13111", "user": "mirkobrombin", "root": "ROOT131", "reply_to": "COM13110", "timestamp": "2020-05-19T19:36:22Z", "text": "> You can be mad all you want, but let's be realistic here... this project you're fighting for so passionately, doesn't have as many stars as I have thumbs down for telling you that you'e being ridiculous\r\n> \r\n> ![image](https://user-images.githubusercontent.com/3860573/82369702-4b10ed00-99cc-11ea-8090-18139fe8d746.png)\r\n\r\nLet's pretend that this is not a mirror but the official repository (not so).. can a project name be stolen because it has less fame? ", "meta": {"posReactions": "22", "negReactions": "0"}}
{"id": "COM13112", "user": "ptdave20", "root": "ROOT131", "reply_to": "COM13111", "timestamp": "2020-05-19T19:41:56Z", "text": "It's a non issue because things are allowed to have the same or similar\nnames. To be honest, I never heard of the others except for the location.\n\nNo matter the name, there is probably someone or something using it.\n\nOn Tue, May 19, 2020, 3:32 PM TheAssassin <notifications@github.com> wrote:\n\n> They even refer *themselves* to Hawaii. Check c7e2c55\n> <https://github.com/dotnet/maui/commit/c7e2c55ace3ec55a0858f1c4bb55476375ea72f8>,\n> its commit message says, \"Aloha fix\".\n>\n> I don't think they took into account either confusion with the \"Linux\n> project\" *nor with the Hawaiian island*.\n>\n> (By the way, is it seriously necessary to mention that when there's an\n> obvious name conflict with some other free software project in the exactly\n> same domain (UI toolkit)? Come on, get over this \"Linux vs. Windows\" mantra\n> you still seem to follow.)\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dotnet/maui/issues/35#issuecomment-631035738>, or\n> unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AADLMQUXWUEQOZ73GC33W33RSLNEZANCNFSM4NFIXXSQ>\n> .\n>\n", "meta": {"posReactions": "2", "negReactions": "20"}}
{"id": "COM13113", "user": "probonopd", "root": "ROOT131", "reply_to": "COM13112", "timestamp": "2020-05-19T19:43:16Z", "text": "https://en.wikipedia.org/wiki/Confusing_similarity", "meta": {"posReactions": "11", "negReactions": "0"}}
{"id": "COM13114", "user": "veggero", "root": "ROOT131", "reply_to": "COM13113", "timestamp": "2020-05-19T19:46:19Z", "text": "And this is not even a confusing _similarity_.\r\nWe are talking about a multi platform framework called MAUI, and a multi platform framework called MAUI. You could've at least googled the name you were giving to your product before doing so, or choose one that's used from a product with a different scope.\r\n\r\nKDE is one of the very biggest community in linux. Maui is part of KDE. So much for Microsoft \u2764\ufe0f Linux.", "meta": {"posReactions": "20", "negReactions": "0"}}
{"id": "COM13115", "user": "IlyaBizyaev", "root": "ROOT131", "reply_to": "COM13114", "timestamp": "2020-05-19T19:47:33Z", "text": "> No matter the name, there is probably someone or something using it.\r\n\r\nSomehow all other cross-platform frameworks I can think of have managed to choose a name that would not conflict with other similar projects. I wonder what's so different here that would prevent Microsoft from finding a scope-unique name.", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM13116", "user": "dansiegel", "root": "ROOT131", "reply_to": "COM13115", "timestamp": "2020-05-19T19:47:46Z", "text": "@probonopd @mirkobrombin so you like this cute little side project... but let's be honest here when it comes to being a serious project it's not one. There isn't major support for MauiKit, the likelihood is that most people probably never heard of it before today, and there is no widespread adoption of it. Can you name 10 large companies that have adopted it?\r\n\r\nYour attitude is as if Microsoft is being some big evil corporation. The reality is I highly doubt anybody heard of MauiKit, and frankly nobody cares.\r\n\r\n> Let's pretend that this is not a mirror but the official repository (not so).. can a project name be stolen because it has less fame?\r\n\r\nOk let's look at kde... there are 10 open issues... are you seriously going to tell me that a serious cross platform framework has 10 open issues... that's not realistic in any shape way or form. So again your complaints are just being ridiculous.", "meta": {"posReactions": "1", "negReactions": "23"}}
{"id": "COM13117", "user": "UriHerrera", "root": "ROOT131", "reply_to": "COM13116", "timestamp": "2020-05-19T19:49:21Z", "text": "@dansiegel Are you an _official_ Microsoft or Xamarin representative, and if so, is this the official position of your company?.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM13118", "user": "IlyaBizyaev", "root": "ROOT131", "reply_to": "COM13117", "timestamp": "2020-05-19T19:49:31Z", "text": "> ridiculous\r\n> cute little side project\r\n> nobody cares\r\n> anybody heard of\r\n\r\nI hope this is not Microsoft's general attitude towards open source projects these days...", "meta": {"posReactions": "20", "negReactions": "0"}}
{"id": "COM13119", "user": "veggero", "root": "ROOT131", "reply_to": "COM13118", "timestamp": "2020-05-19T19:51:44Z", "text": "> Your attitude is as if Microsoft is being some big evil corporation. The reality is I highly doubt anybody heard of MauiKit, and frankly nobody cares.\r\n\r\nBecause it's a recent project. It has been under development for two years, but it's public. It was - until today - literally the first result when searching for \"maui framework\". \r\n\r\n> Ok let's look at kde... there are 10 open issues... are you seriously going to tell me that a serious cross platform framework has 10 open issues... that's not realistic in any shape way or form. So again your complaints are just being ridiculous.\r\n\r\nMicrosoft's Maui has 21 issues. 10 issues bad, 21 issues good?\r\n\r\n", "meta": {"posReactions": "14", "negReactions": "0"}}
{"id": "COM13120", "user": "TheAssassin", "root": "ROOT131", "reply_to": "COM13119", "timestamp": "2020-05-19T19:53:52Z", "text": "What do you expect, providing some real arguments against nonsense or offending replies like \"you're all mad\" or \"it's the others' fault, they need to rename\" (aka \"we are Microsoft (related), we are bigger, you need to comply\" or, my favorite, \"same name is not a problem at all\", pretending that confusion was not an issue...\r\n\r\n@dansiegel great strategy, being offending once you run out of arguments! Really! Is that how Microsoft's unpaid marketers aka \"Microsoft MVP\" are chosen? How can you seriously accuse others of like, thinking in this old \"it's a big evil company\" way (which nobody really has), while yourself being extremely off-putting towards the open-source community? It makes no sense...\r\n\r\nRemember, Microsoft recently admitted [they've been on the wrong side of history with regard to open source](https://www.theregister.co.uk/2020/05/15/microsoft_brad_smith_open_source/). You have *zero* reason to belittle this or _any_ other open-source project. Especially since this one's also open-source.", "meta": {"posReactions": "14", "negReactions": "0"}}
{"id": "COM13121", "user": "Manueljlin", "root": "ROOT131", "reply_to": "COM13120", "timestamp": "2020-05-19T19:55:00Z", "text": "Imagine trying to put up a fa\u00e7ade with ms\u2764\ufe0flinux, then turning stuff into a dick size competition with repo stars and other stats because you know you messed up and don't want to admit it lmfao", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM13122", "user": "ChaseFlorell", "root": "ROOT131", "reply_to": "COM13121", "timestamp": "2020-05-19T19:55:04Z", "text": "> @dansiegel Are you an official Microsoft or Xamarin representative, and if so, is this the official position of your company?.\r\n\r\nHe is not affiliated with MS at all, but he definitely has done more for the .NET Ecosystem than anyone else in these comments. [>3 million downloads](https://www.nuget.org/packages/Prism.Core/)", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM13123", "user": "IlyaBizyaev", "root": "ROOT131", "reply_to": "COM13122", "timestamp": "2020-05-19T19:56:30Z", "text": "> he definitely has done more for the .NET Ecosystem than anyone else in these comments\r\n\r\nHow much has he done for the Qt Ecosystem though? ;)", "meta": {"posReactions": "16", "negReactions": "0"}}
{"id": "COM13124", "user": "dansiegel", "root": "ROOT131", "reply_to": "COM13123", "timestamp": "2020-05-19T19:56:58Z", "text": "@UriHerrera you can see my profile.. I am a member of the Xamarin developer community, I do not work for Microsoft. And if you don't like it nobody is forcing you to use it, use MauiKit if that's what you love, but developers who actually use this tech think you're being ridiculous.\r\n\r\n> Microsoft's Maui has 21 issues. 10 issues bad, 21 issues good?\r\n\r\nMaui was just created... and is a port of Xamarin.Forms so yeah you want to see what a real Open Source application framework looks like I suggest you start taking notes. \r\n\r\n@TheAssassin - bro I am an Open Source author and maintainer so don't try lecturing me about being against \"off-putting towards the open-source community\"", "meta": {"posReactions": "1", "negReactions": "19"}}
{"id": "COM13125", "user": "boingo-00", "root": "ROOT131", "reply_to": "COM13124", "timestamp": "2020-05-19T19:57:33Z", "text": "> there are 10 open issues\r\n\r\nThis is a tiny amount, big projects have bigger issue count, and this is OK\r\nWhy you even pointing on this? It is unethical, you are don't have any arguments?\r\n_P.S. replying in epic thread_", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM13126", "user": "UriHerrera", "root": "ROOT131", "reply_to": "COM13125", "timestamp": "2020-05-19T19:58:55Z", "text": "> > @dansiegel Are you an official Microsoft or Xamarin representative, and if so, is this the official position of your company?.\r\n> \r\n> He is not affiliated with MS at all, but he definitely has done more for the .NET Ecosystem than anyone else in these comments. [>3 million downloads](https://www.nuget.org/packages/Prism.Core/)\r\n\r\nThat is great, but I did not ask that. If no representative wants to even _talk_  about this, so be it. I'll take that as Microsoft and Xamarin's official position regarding this issue.", "meta": {"posReactions": "8", "negReactions": "0"}}
{"id": "COM13127", "user": "mirkobrombin", "root": "ROOT131", "reply_to": "COM13126", "timestamp": "2020-05-19T20:00:32Z", "text": "> @probonopd @mirkobrombin so you like this cute little side project... but let's be honest here when it comes to being a serious project it's not one. There isn't major support for MauiKit, the likelihood is that most people probably never heard of it before today, and there is no widespread adoption of it. Can you name 10 large companies that have adopted it?\n> \n> Your attitude is as if Microsoft is being some big evil corporation. The reality is I highly doubt anybody heard of MauiKit, and frankly nobody cares.\n> \n> > Let's pretend that this is not a mirror but the official repository (not so).. can a project name be stolen because it has less fame?\n> \n> Ok let's look at kde... there are 10 open issues... are you seriously going to tell me that a serious cross platform framework has 10 open issues... that's not realistic in any shape way or form. So again your complaints are just being ridiculous.\n\nSo a project has value based on open issues?\n\nI have nothing against Microsoft, here we talk about a name and who chose it before (in the same context). \n\nI don't know how you can question the seriousness of one of the biggest communities that drive open source principles many years before Microsoft fell in love with open source.\n\n ", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM13128", "user": "ChaseFlorell", "root": "ROOT131", "reply_to": "COM13127", "timestamp": "2020-05-19T20:00:34Z", "text": ">  If no representative wants to even talk about this\r\n\r\nSince the issue was opened a mere 60 minutes ago \ud83d\ude02", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM13129", "user": "IlyaBizyaev", "root": "ROOT131", "reply_to": "COM13128", "timestamp": "2020-05-19T20:02:10Z", "text": "> you want to see what a real Open Source application framework looks like I suggest you start taking notes\r\n\r\nThere appear to be more passive-aggressive comments towards another project in this thread from you alone than there are from all other people towards this .NET repository. That's not because others really love .NET, but because they try to stay constructive here.\r\n\r\n> I am an Open Source author and maintainer so don't try lecturing me\r\n\r\nI am afraid this is not how most open source maintainers respond in a community.", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "ROOT132", "user": "PrzemyslawPolrolniczak", "root": "ROOT132", "reply_to": null, "timestamp": "2019-12-19T09:34:56Z", "text": "Santa Claus hat as an option in VS Code settings <!-- Please search existing issues to avoid creating duplicates. -->\r \r <!-- Describe the feature you'd like. -->\r Hey,\r \r maybe instead of removing Santa Claus hat because 1 SJW, can you make an option to turn it on and off in options? Really, why you have to remove it?", "meta": {"posReactions": "62", "negReactions": "2"}}
{"id": "COM1320", "user": "vscodebot[bot]", "root": "ROOT132", "reply_to": "ROOT132", "timestamp": "2019-12-19T09:35:02Z", "text": "(Experimental duplicate detection)\nThanks for submitting this issue. Please also check if it is already covered by an existing one, like:\n- [Removal of the Santa hat and kowtowing to a single fake user is offensive to me (#87328)](https://www.github.com/microsoft/vscode/issues/87328) <!-- score: 0.527 -->\n- [Santa Hat Removal (#87318)](https://www.github.com/microsoft/vscode/issues/87318) <!-- score: 0.514 -->\n- [Removal of the Santa Hat and kowtowing to SJWs (#87314)](https://www.github.com/microsoft/vscode/issues/87314) <!-- score: 0.452 -->\n<!-- potential_duplicates_comment -->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1321", "user": "MaurogDark", "root": "ROOT132", "reply_to": "COM1320", "timestamp": "2019-12-19T09:40:20Z", "text": "That's way too rational, a guy was extremely offended, please have some consideration!\r\n\r\nWe must remove the hat, all mentions of the hat, all mentions of removing the mentions of the hat and so on, just to be sure. Oh no, I just mentioned way too many forbidden things, so this is getting removed too. Along with this thread. And me. And you.", "meta": {"posReactions": "32", "negReactions": "1"}}
{"id": "COM1322", "user": "Vallek", "root": "ROOT132", "reply_to": "COM1321", "timestamp": "2019-12-19T10:03:46Z", "text": "The removing of the Santa hat and catering to vocal minority of sjw idiots is very offensive to me. Please stop.", "meta": {"posReactions": "23", "negReactions": "1"}}
{"id": "COM1323", "user": "Segfaultd", "root": "ROOT132", "reply_to": "COM1322", "timestamp": "2019-12-19T11:24:55Z", "text": "Who is going to submit the PR?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1324", "user": "doylemark", "root": "ROOT132", "reply_to": "COM1323", "timestamp": "2019-12-19T11:37:19Z", "text": "Why was that guy even pandered to in the first place? The story of Santa Claus is not directly tied to any religion in particular. While yes, it's stems from Christianity, nowadays it's completely secular.. If Santa is a religious figure, then so is the Grinch,\r\n\r\nIt's so sad that people are so sensitive in the world we live in today that this sort of thing is even worth discussion..", "meta": {"posReactions": "10", "negReactions": "1"}}
{"id": "COM1325", "user": "laurentb", "root": "ROOT132", "reply_to": "COM1324", "timestamp": "2019-12-19T13:03:41Z", "text": "> While yes, it's stems from Christianity, nowadays it's completely secular.. \r\n\r\nMy understanding is that he was actually upset of the pagan origins :man_shrugging: ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1326", "user": "nkkollaw", "root": "ROOT132", "reply_to": "COM1325", "timestamp": "2019-12-19T13:27:40Z", "text": "\ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM1327", "user": "chrisdias", "root": "ROOT132", "reply_to": "COM1326", "timestamp": "2019-12-19T19:01:34Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.\r\n\r\nHappy Coding!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT133", "user": "quasis", "root": "ROOT133", "reply_to": null, "timestamp": "2018-06-12T20:53:49Z", "text": "Deno \r Ryan Dahl pinpoints the core problems of node.js: http://tinyclouds.org/jsconf2018.pdf\r The community, judging by the amount of stars on https://github.com/ry/deno, feels the same.\r \r How do you feel about addressing those issues? Is it doable? May be a fork?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1330", "user": "Trott", "root": "ROOT133", "reply_to": "ROOT133", "timestamp": "2018-06-12T21:13:42Z", "text": "> Ryan Dahl pinpoints the core problems of node.js\r\n\r\nDon't confuse \"decisions he says he regrets\" with \"core problems of node.js\". \r\n\r\n> The community, judging by the amount of stars on https://github.com/ry/deno, feels the same.\r\n\r\nJudging by the amount of stars seems like a pretty poor way to judge. \"I am interested in seeing where this project goes\" is not necessarily the same as \"Right on! I agree that the other project has huge problems!\"\r\n\r\n> How do you feel about addressing those issues? Is it doable? May be a fork?\r\n\r\nSorry, this isn't really much of a question appropriate for the issue tracker. This is more of a Call For Hot Takes, which is not particularly helpful here IMO.\r\n\r\nMany of the core devs on Node.js have commented (e.g. on Twitter) on what aspects of the presentation they agree with and disagree with. You can do some web searches if you really care what the core devs think. Or maybe a few will weigh in here. (Sorry, I won't be one of them.)\r\n\r\nIf you have a very specific question, feel free to post it in an appropriate forum. Depending on the question, this issue tracker *might* be the right forum.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1331", "user": "Trott", "root": "ROOT133", "reply_to": "COM1330", "timestamp": "2018-06-12T21:18:47Z", "text": "> (Sorry, I won't be one of them.)\r\n\r\nOK, maybe I will comment a little bit. Some of these so-called \"core problems of node.js\" are just unimportant things we'll have to keep supporting or else break the entire ecosystem. So no, they won't get \"fixed\". But they're also not \"broken\". For example, supporting \"index.js\" as the default file for modules is maybe a less-than-perfect original decision, but now that there are hundreds of thousands of modules that do this, we're not going to change. The benefit of changing is negligible and the cost of changing is enormous.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1332", "user": "addaleax", "root": "ROOT133", "reply_to": "COM1331", "timestamp": "2018-06-12T21:29:09Z", "text": "Maybe to add one thing: If you, or somebody else, think Node.js *should* address one of the particular concerns, and are willing to help in making that happen, I\u2019m sure we can arrange that. :slightly_smiling_face: ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1333", "user": "quasis", "root": "ROOT133", "reply_to": "COM1332", "timestamp": "2018-06-12T21:31:22Z", "text": "> Don't confuse \"decisions I regret\" with \"core problems of node.js\".\r\n\r\nRyan is not the first to mention them, there were others along the road who complained about packaging, gyp and node_modules.\r\n\r\nSecurity is a major issue IMHO, its only a matter of time until someone will plant a malware in some popular module.\r\n\r\n> Judging by the amount of stars seems like a pretty poor way to judge. \"I am interested in seeing where this project goes\" is not necessarily the same as \"Right on! I agree that the other project has huge problems!\"\r\n\r\nPossibly. Lets say only 1/3 of these people starred the project because they feel that node has problems - it is still a lot for a fresh project on GitHub.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1334", "user": "bnb", "root": "ROOT133", "reply_to": "COM1333", "timestamp": "2018-06-12T21:36:21Z", "text": "There is quite a bit of work being done in each of those areas, most of which it seemed Ryan was unaware of. I suggest checking out the discussion in [nodejs/modules](https://github.com/nodejs/modules), discussions around migrating away from gyp, and the [Security Working Group](https://github.com/nodejs/security-wg/).\r\n\r\nIf you'd like to contribute to any of those and help us address the perceived issues you mentioned, we'd welcome contributions with open arms.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1335", "user": "othiym23", "root": "ROOT133", "reply_to": "COM1334", "timestamp": "2018-06-12T21:40:43Z", "text": "\"Too heated\" doesn't really capture it, but none of the choices fit perfectly. On the whole, though,\u00a0I agree with @Trott that this is a topic best addressed through individual discussions, and trying to handle it all in a single issue is unproductive.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1336", "user": "joyeecheung", "root": "ROOT133", "reply_to": "COM1335", "timestamp": "2018-06-12T21:45:21Z", "text": "> How do you feel about addressing those issues? Is it doable? May be a fork?\r\n\r\nI believe most of the points raised in the talk are not new to the project, but out of compatibility concerns it would be hard to do anything about them at this point. Deno is new and is free to experiment with ideas, but Node.js cannot afford that luxury with the enormous user base and the existing code out there - people may be upset when the existing design is not perfect, but they are usually more upset when their working code gets broken or when they are told to upgrade their massive code base to a more idiomatic style. Starting a general discussion around the issues may be helpful to make progress, but it is likely to go nowhere without anything actionable proposed.\r\n\r\nThe current ways of introducing significant changes into Node.js core are:\r\n\r\n1. Start a working group, or a team, like [nodejs/modules](https://github.com/nodejs/modules), that may or may not does periodic meetings and has their own issue tracker to tackle the cross-cutting concerns and reach consensus before starting the implementation in core\r\n2. Start a new repo under this organization that contains a fork of Node.js core (there is usually a team started for it as well), work on the implementation there and sync with the upstream from time to time, but it's not going to have its own release (maybe that can be improved). When the team thinks it's ready, submit a PR back to the upstream. Past examples that have been merged into core:  [nodejs/http2](https://github.com/nodejs/http2) and [nodejs/abi-stable-node](https://github.com/nodejs/abi-stable-node) (prototype of N-API, you'll need to switch branches to find the prototypes and the collaboration happened there)\r\n\r\nFor both type of efforts we will usually have an item listed in the [strategic initiatives](https://github.com/nodejs/TSC/blob/master/Strategic-Initiatives.md) and a champion (usually TSC member) who reports the status of the initiative every week at the TSC meeting, which is live-streamed on [YouTube](https://www.youtube.com/channel/UCQPYJluYC_sn_Qz_XE-YbTQ) with a public Q&A session (there are also recordings in the channel) and the [meetings minutes are available in the TSC repo](https://github.com/nodejs/TSC/tree/master/meetings).\r\n\r\nThe members of those initiatives do not have to be Node.js core collaborators or even members of this organization, but the team will decide how they recruit new members (it's usually a call-for-participants kind of thing). If you want to start an initiative, I think the best way is to [go to the #node-dev IRC](http://nodeirc.info/) and find people who are interested in a particular item, and discuss about starting a new team for it. It is also important to make sure that the stakeholders are aware and willing to participate (like the VM vendors in the case of N-API), reaching out to them in private should help as well. A lot of work (coordination is work and it's hard) would be needed to make this happen so you'll either do it yourself, or find people who are interested in spending their time on that.\r\n\r\nThere used to be [node-eps](https://github.com/nodejs/node-eps) but it's not used anymore.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT134", "user": "r1k0", "root": "ROOT134", "reply_to": null, "timestamp": "2019-02-04T14:53:36Z", "text": "use to_list() instead of [] notation +label: docsite_pr\r \r ##### SUMMARY\r when there is a single interface, data['TABLE_interface']['ROW_interface'] is a dict, not an array (case handled like populate_structured_neighbors_lldp)\r \r <!--- HINT: Include \"Fixes #nnn\" if you are fixing an existing issue -->\r \r ##### ISSUE TYPE\r - Bugfix Pull Request\r \r ##### COMPONENT NAME\r nxos_facts.py\r \r ##### ADDITIONAL INFORMATION\r \r \r \r BEFORE fix\r ```paste below\r PLAY [nxos] ****************************************************************************************************\r \r TASK [Gathering Facts] *****************************************************************************************\r ok: [xxxxxxxxx]\r \r TASK [nxos_facts : nxos_facts | get nxos facts] ****************************************************************\r An exception occurred during task execution. To see the full traceback, use -vvv. The error was: TypeError: string indices must be integers\r fatal: [xxxxxxxxxx]: FAILED! => {\r     \"changed\": false, \r     \"rc\": 1\r }\r \r MSG:\r \r MODULE FAILURE\r See stdout/stderr for the exact error\r \r \r MODULE_STDERR:\r \r Traceback (most recent call last):\r   File \"/home/xxx/.ansible/tmp/ansible-local-1379dtiyx8/ansible-tmp-1549291810.13-164228265130085/AnsiballZ_nxos_facts.py\", line 113, in <module>\r     _ansiballz_main()\r   File \"/home/xxx/.ansible/tmp/ansible-local-1379dtiyx8/ansible-tmp-1549291810.13-164228265130085/AnsiballZ_nxos_facts.py\", line 105, in _ansiballz_main\r     invoke_module(zipped_mod, temp_path, ANSIBALLZ_PARAMS)\r   File \"/home/xxx/.ansible/tmp/ansible-local-1379dtiyx8/ansible-tmp-1549291810.13-164228265130085/AnsiballZ_nxos_facts.py\", line 48, in invoke_module\r     imp.load_module('__main__', mod, module, MOD_DESC)\r   File \"/tmp/ansible_nxos_facts_payload_Txdrav/__main__.py\", line 1003, in <module>\r   File \"/tmp/ansible_nxos_facts_payload_Txdrav/__main__.py\", line 986, in main\r   File \"/tmp/ansible_nxos_facts_payload_Txdrav/__main__.py\", line 387, in populate\r   File \"/tmp/ansible_nxos_facts_payload_Txdrav/__main__.py\", line 422, in populate_structured_interfaces\r TypeError: string indices must be integers\r \r \r \r msg:\r MODULE FAILURE\r See stdout/stderr for the exact error\r \r PLAY RECAP *****************************************************************************************************\r xxxxxxx              : ok=1    changed=0    unreachable=0    failed=1   \r ```\r AFTER fix\r \r ```\r PLAY [nxos] ****************************************************************************************************\r \r TASK [Gathering Facts] *****************************************************************************************\r ok: [xxxxxxxxxx]\r \r TASK [nxos_facts : nxos_facts | get nxos facts] ****************************************************************\r ok: [xxxxxxxxx]\r \r PLAY RECAP *****************************************************************************************************\r xxxxxxxxx                 : ok=2    changed=0    unreachable=0    failed=0   \r \r \r \r \r ```\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1340", "user": "ansibot", "root": "ROOT134", "reply_to": "ROOT134", "timestamp": "2019-02-04T14:57:20Z", "text": "cc @GGabriele @jedelman8 @mikewiebe @rahushen @rcarrillocruz @trishnaguha @tstoner\n[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)\n<!--- boilerplate: notify --->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1341", "user": "ansibot", "root": "ROOT134", "reply_to": "COM1340", "timestamp": "2019-02-04T14:57:20Z", "text": "@r1k0, just so you are aware we have a dedicated Working Group for network.\nYou can find other people interested in this in `#ansible-network` on Freenode IRC\nFor more information about communities, meetings and agendas see https://github.com/ansible/community\n\n[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)\n<!--- boilerplate: community_workgroups --->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1342", "user": "ansibot", "root": "ROOT134", "reply_to": "COM1341", "timestamp": "2019-02-04T19:00:51Z", "text": "@r1k0 this PR contains the following merge commits:\n\n* https://github.com/ansible/ansible/commit/234d5988faec3639aa0bcdeb7775d963c52a9b21\n\nPlease [rebase your branch](http://docs.ansible.com/ansible/devel/dev_guide/developing_rebasing.html) to remove these commits.\n\n[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)\n<!--- boilerplate: merge_commit_notify --->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1343", "user": "r1k0", "root": "ROOT134", "reply_to": "COM1342", "timestamp": "2019-02-04T20:15:29Z", "text": "@trishnaguha somehow your suggestion fails the check. I tried twice via github gui (dont have git installed and no rights to) and I probably shouldn't make any more PR as they will fail.\r\nimo, should merge what works and then iterate not the other way around.  it's ok to not merge the original commit, plugins are fine.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1344", "user": "trishnaguha", "root": "ROOT134", "reply_to": "COM1343", "timestamp": "2019-02-05T04:39:32Z", "text": "@r1k0 Please feel free to reopen the pull request so that we can discuss about the CI failure. Your original commit in the PR looked fine and will work, but the review I submitted is how ansible code base does it. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1345", "user": "r1k0", "root": "ROOT134", "reply_to": "COM1344", "timestamp": "2019-02-05T19:17:54Z", "text": "@trishnaguha I'm sorry I don't have much time for other things beside work and family. I didn't realize a 4 line PR would pull me into a discussion on how to improve it by implementing a new code base and consequently figure why shippable would fail. I understand your request but I'm not sure it is the most efficient. Release fast and refactor after by actors that have an interest (they'll make time) in it (dissecting to_list() brings not value to my use case). Look, 24h later, a valid tiny patch is still not merged and we'd need to \"discuss\" why shippable failed on its improvement, not even on the patch itself. It's clearly less effective than merge and refactor later added to the fact I feel my time creating that PR was wasted, so not rewarding, hence I'll think twice before making another PR. There is much more to gain by going fast on smalls steps/iteration and securing what you have asap, that's my way of working anyway so very subjective I'll give you that. Feel free do whatever you see fit, I'm off to other things, good luck & sorry for the noise.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT135", "user": "realtebo", "root": "ROOT135", "reply_to": null, "timestamp": "2018-12-22T15:23:14Z", "text": "docs: Add a theme step to Step by Step Tutorial Plase, add a step on the Step by Step Tutorial to demonstrate how to theme the just finished demo app.\r \r ## Motivation\r \r 1. Theming is not an obvious task for a newbie like me. Also, doc speaks about gem based and 'regular' file themes. It's confusin  a bit.\r 2. At the end of demo app it's more beautiful to leave in the han of the user a well looking demo\r \r ## Idea\r \r Please include istructions on \r - how to enable default gem base theme\r - how to customized if possible a gem theme\r - how to switch to a regular file based theme\r - idem, how to customize it\r \r ... or ...\r \r Create a guide on how to start theming AND then include previous steps into the new tutorial.\r \r Thanks for this excellent piece of software !!!!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1350", "user": "DirtyF", "root": "ROOT135", "reply_to": "ROOT135", "timestamp": "2018-12-22T16:31:30Z", "text": "On how to start theming for Jekyll, I'd recommend @daviddarnes articles:\r\n\r\n1. https://www.siteleaf.com/blog/making-your-first-jekyll-theme-part-1/\r\n2. https://www.siteleaf.com/blog/making-your-first-jekyll-theme-part-2/", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM1351", "user": "realtebo", "root": "ROOT135", "reply_to": "COM1350", "timestamp": "2018-12-24T18:51:08Z", "text": "Thanks, but it's better have an official doc, and not links to external resources. IMHO", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1352", "user": "daviddarnes", "root": "ROOT135", "reply_to": "COM1351", "timestamp": "2018-12-26T21:36:33Z", "text": "If it's validation you're looking for then I can 100% endorse these tutorials \u2728. However if you want this set in stone then maybe we could link to these tutorials in the official docs? Maybe in https://jekyllrb.com/tutorials/home/ or https://jekyllrb.com/resources/. What do you day @DirtyF?", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1353", "user": "jpasholk", "root": "ROOT135", "reply_to": "COM1352", "timestamp": "2018-12-27T18:49:58Z", "text": "Oooh, I like @desiredpersona\u2019s idea.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1354", "user": "ashmaroli", "root": "ROOT135", "reply_to": "COM1353", "timestamp": "2018-12-27T19:06:28Z", "text": "IMHO, Documentation is one thing and a (sponsored) community blog is an entirely different league altogether. They should not be intermingled.\r\nDocumentation is translating \"the code base\" into layman lingo. (*Point-of-View: Maintainers -> Users*)\r\nCommunity blog is about sharing experience with the code base. (*Point-of-View: One User -> Other Users*)\r\nBringing the sponsors into the mix, is just complicating things, unnecessarily.........", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1355", "user": "realtebo", "root": "ROOT135", "reply_to": "COM1354", "timestamp": "2018-12-27T21:46:45Z", "text": "Sorry but ... To rest in topic... A simple step added to main step by step intro is so wrong?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1356", "user": "daviddarnes", "root": "ROOT135", "reply_to": "COM1355", "timestamp": "2018-12-28T17:40:59Z", "text": "I don\u2019t see what is wrong with referring to a tutorial on another site? Yes the tutorial was paid for, but tutorials of that size take time to create. Maybe we could add some more detail on the points people are getting stuck on in the docs?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1357", "user": "realtebo", "root": "ROOT135", "reply_to": "COM1356", "timestamp": "2018-12-28T19:20:18Z", "text": "If I see a tutorial on an external website it soon or later will become obsolete.\n\nIf I see a tutorial on main site I think that must be ok, tested, and updated. \n\nSimply. Close this issue\n\nA company that does not understand the need of a full doc do not will offer a serious support in the long time\n\nBye bye.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1358", "user": "DirtyF", "root": "ROOT135", "reply_to": "COM1357", "timestamp": "2018-12-28T19:44:12Z", "text": "> A company that does not understand the need of a full doc do not will offer a serious support in the long time\r\n\r\nJekyll is an open-source project **freely maintained by volunteers**, it has been around for 10 years now and powers hundred of thousands of websites around the world. \r\n\r\nJekyll has a great [community](https://talk.jekyllrb.com/) and docs are continuously improved with the help of the contributors.\r\n\r\nJekyll themes _are_ [documented](https://jekyllrb.com/docs/themes/#understanding-gem-based-themes). I'll see if I can add some links to point to theming at the end of the step-by-step guide.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT136", "user": "relrod", "root": "ROOT136", "reply_to": null, "timestamp": "2020-04-24T20:15:41Z", "text": "Add Ubuntu 20.04 to CI and ansible-test ##### SUMMARY  What the title says  ##### ISSUE TYPE <!--- Pick one below and delete the rest --> - Bugfix Pull Request  ##### COMPONENT NAME  tests", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM1360", "user": "ansibot", "root": "ROOT136", "reply_to": "ROOT136", "timestamp": "2020-04-27T15:45:30Z", "text": "@relrod this PR contains the following merge commits:\n\n* https://github.com/ansible/ansible/commit/081bde4b74fed4f7e068665d01f6298f7262af20\n\nPlease [rebase your branch](http://docs.ansible.com/ansible/devel/dev_guide/developing_rebasing.html) to remove these commits.\n\n[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)\n<!--- boilerplate: merge_commit_notify --->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1361", "user": "SophieDeBenedetto", "root": "ROOT136", "reply_to": "COM1360", "timestamp": "2020-05-20T11:12:19Z", "text": "Hi, just checking in on this PR--are there plans to merge soon?", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM1362", "user": "geerlingguy", "root": "ROOT136", "reply_to": "COM1361", "timestamp": "2020-07-22T16:50:32Z", "text": "As more people are upgrading their systems to Ubuntu 20.04, old builds that used Ansible's official PPA are breaking and more people are switching to Pip installs... from @sivel's [last comment](https://github.com/ansible/ansible/issues/68645#issuecomment-610460321) before closing #68645, he mentioned:\r\n\r\n> Packages for new Ubuntu releases are only created during the Ansible release process, and as Focal has yet to be released, a package will not be made available until the next release that is made after Focal has been released.\r\n\r\nFocal was released in April, and Ansible has had a number of releases since then... is it possible to get this merged soon? Is it held up on tests?", "meta": {"posReactions": "8", "negReactions": "0"}}
{"id": "COM1363", "user": "relrod", "root": "ROOT136", "reply_to": "COM1362", "timestamp": "2020-07-22T18:33:31Z", "text": "@geerlingguy It's held up by Ubuntu. See https://github.com/ansible/ansible/issues/69203 and https://bugs.launchpad.net/ubuntu/+source/python-virtualenv/+bug/1880749 -- there's not much we can do until that is fixed.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1364", "user": "zxiiro", "root": "ROOT136", "reply_to": "COM1363", "timestamp": "2020-08-11T14:00:45Z", "text": "I see the Ubuntu issue is set to resolved. Are we unblocked here?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1365", "user": "sivel", "root": "ROOT136", "reply_to": "COM1364", "timestamp": "2020-08-11T14:06:39Z", "text": "The issue is fixed in the latest _development_ release of Ubuntu, but not in 20.04.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1366", "user": "quhsi", "root": "ROOT136", "reply_to": "COM1365", "timestamp": "2020-08-12T09:49:15Z", "text": "For those who came here because the PPA does not contain a suitable package,\r\nnote that Ansible 2.9.6 is included in [Ubuntu's standard repositories](https://packages.ubuntu.com/focal/ansible).", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1367", "user": "mikerev", "root": "ROOT136", "reply_to": "COM1366", "timestamp": "2020-08-20T15:03:14Z", "text": "> For those who came here because the PPA does not contain a suitable package,\r\n> note that Ansible 2.9.6 is included in [Ubuntu's standard repositories](https://packages.ubuntu.com/focal/ansible).\r\n\r\nBroken link.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1368", "user": "quhsi", "root": "ROOT136", "reply_to": "COM1367", "timestamp": "2020-08-20T15:31:23Z", "text": "> > For those who came here because the PPA does not contain a suitable package,\r\n> > note that Ansible 2.9.6 is included in [Ubuntu's standard repositories](https://packages.ubuntu.com/focal/ansible).\r\n> \r\n> Broken link.\r\n\r\nI cannot confirm that. Broken network?\r\n\r\n![Screenshot](https://user-images.githubusercontent.com/66925589/90792551-1fb6da80-e2fa-11ea-8796-1d3f7128892e.png)", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1369", "user": "mikerev", "root": "ROOT136", "reply_to": "COM1368", "timestamp": "2020-08-20T15:45:39Z", "text": "> > > For those who came here because the PPA does not contain a suitable package,\r\n> > > note that Ansible 2.9.6 is included in [Ubuntu's standard repositories](https://packages.ubuntu.com/focal/ansible).\r\n> > \r\n> > \r\n> > Broken link.\r\n> \r\n> I cannot confirm that. Broken network?\r\n> \r\n> ![Screenshot](https://user-images.githubusercontent.com/66925589/90792551-1fb6da80-e2fa-11ea-8796-1d3f7128892e.png)\r\n\r\nYeah sorry the server was picking up but requests returned something in the 500's, link was fine. All good now tho.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13610", "user": "ansibot", "root": "ROOT136", "reply_to": "COM1369", "timestamp": "2020-10-20T16:16:34Z", "text": "The test `ansible-test sanity --test validate-modules` [[explain](https://docs.ansible.com/ansible/devel/dev_guide/testing/sanity/validate-modules.html)] failed with 1 error:\n```\nlib/ansible/modules/system/systemd.py:0:0: option-incorrect-version-added: version_added for new option (user) should be '2.10'. Currently StrictVersion ('0.0')\n```\n<!-- job_id: 5f88a4b1b9af300007db9e37 -->\n<!-- job_id: 5f88a4b20d11080007d6ca82 -->\n<!-- job_id: /testresults/ansible-test-sanity-validate-modules.json -->\n\n[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)\n<!--- boilerplate: shippable_test_result --->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13611", "user": "DWSR", "root": "ROOT136", "reply_to": "COM13610", "timestamp": "2020-10-22T01:35:42Z", "text": "Bump on this. Ideally I'd love to avoid using something like `pipx` to install Ansible on Focal. What still needs to be done here?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT137", "user": "RemusMar", "root": "ROOT137", "reply_to": null, "timestamp": "2018-07-05T08:46:40Z", "text": "SEA3D vs GLTF This is the current (july 2018) GLTF status.\r Test case: the same skinned mesh exported from 3DS Max 2018.\r Standard material: Diffuse + Specular + Normal\r \r 1) SEA3D exporter + SEA3D importer:\r http://necromanthus.com/Test/html5/Lara.html \r SEA file size: 658 KB\r Result: close to perfect\r \r 2) Babylon3D GLTF exporter + GLTF importer:\r http://necromanthus.com/Test/html5/Lara_gltf.html \r GLB file size: 1,850 KB\r Result: messed up materials\r \r I've also tested the FBX2GLTF utility (by Facebook): the same wrong results\r \r Important note: there is nothing wrong with THREE.js and PBR materials:\r http://necromanthus.com/Test/html5/Lara_PBR.html \r \r In any case, PBR was a bad choice for GLTF and also, all the current converters are collection of bugs.\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1370", "user": "Mugen87", "root": "ROOT137", "reply_to": "ROOT137", "timestamp": "2018-07-05T12:37:30Z", "text": "I don't think this repo is the right place for this post. It's neither a feature request, nor a bug. So my question is: What are you trying to accomplish with this issue? Bashing `glTF`?\r\n\r\nIf you encounter problems with an exporter or converter, I suggest you open an issue at the respective github repo.\r\n\r\n> In any case, PBR was a bad choice for GLTF and also, all the current converters are collection of bugs.\r\n\r\nI generally reject such Trump-like statements. They have a provocative nature and are not objective at all.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1371", "user": "RemusMar", "root": "ROOT137", "reply_to": "COM1370", "timestamp": "2018-07-05T12:42:38Z", "text": "> I don't think this repo is the right place for this post.\r\n\r\nIt's the best place for sure and it shows the current GLTF status.\r\n\r\n> I generally reject such Trump-like statements.\r\n\r\nReally?\r\nHere is a statement from Trump: Google already failed with UTF8.\r\n\r\n> If you encounter problems with an exporter or converter, I suggest you open an issue at the respective github repo.\r\n\r\nMany of them blame THREE.js for bad GLTF results.\r\nThe posted samples prove they are wrong.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1372", "user": "looeee", "root": "ROOT137", "reply_to": "COM1371", "timestamp": "2018-07-05T14:31:57Z", "text": "@RemusMar are you suggesting any particular actions we should take? If not I vote to close this issue.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1373", "user": "RemusMar", "root": "ROOT137", "reply_to": "COM1372", "timestamp": "2018-07-05T14:41:18Z", "text": "> RemusMar are you suggesting any particular actions we should take?\r\n\r\nThree possible causes for the wrong GLTF results:\r\n1. the Babylon3D exporter is buggy (they say it's not)\r\n2. the FBX2GLTF converter is buggy (they say it's not)\r\n3. the GLTF importer is buggy.\r\n\r\nBut you and Mugen87 want to close the topic because there is no issue and everytbody is happy ...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1374", "user": "looeee", "root": "ROOT137", "reply_to": "COM1373", "timestamp": "2018-07-05T14:51:12Z", "text": "> the GLTF importer is buggy\r\n\r\nYou mean the GLTFLoader? Can you identify what the bug is? It would be especially helpful if you can find a very simple model that demonstrates the bug.\r\n\r\n>  (they say it's not)\r\n\r\nIf you've made bug reports on the Babylon3D exporter and FBX2GLTF can you link to them here?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1375", "user": "RemusMar", "root": "ROOT137", "reply_to": "COM1374", "timestamp": "2018-07-05T14:59:04Z", "text": "> You mean the GLTFLoader? \r\n\r\nYes.\r\nImporter = Loader + Parser\r\n\r\n> It would be especially helpful if you can find a very simple model that demonstrates the bug.\r\n\r\nYou have everything you need to study the issue.\r\nAny PHONG material (Diffuse + Specular + Normal) exported or converted to GLTF gives wrong results.\r\np.s.\r\nPHONG represents 50-60% of the current samples, compared to Physical less than 1%.\r\nThat's why I said that PBR was a bad choice for GLTF.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1376", "user": "looeee", "root": "ROOT137", "reply_to": "COM1375", "timestamp": "2018-07-05T15:08:13Z", "text": "> You have everything you need to study the issue\r\n\r\nIn other words you want someone else to do the work for you \ud83d\ude44\r\n\r\nRegarding Phong materials and glTF, I agree that this makes glTF a bad choice for converting older models - especially models originally exported as FBX which only supports Phong or Lambert shading.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1377", "user": "RemusMar", "root": "ROOT137", "reply_to": "COM1376", "timestamp": "2018-07-05T15:09:50Z", "text": "> n other words you want someone else to do the work for you\r\n\r\nI don't have enough spare time for \"GitHub activities\".\r\nYou got the report and the working samples.\r\nThat's all for now.\r\ncheers", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1378", "user": "looeee", "root": "ROOT137", "reply_to": "COM1377", "timestamp": "2018-07-05T15:20:58Z", "text": "In that case, I still don't consider this to be a complete or actionable bug report and I continue to vote to close this issue.", "meta": {"posReactions": "3", "negReactions": "1"}}
{"id": "COM1379", "user": "mrdoob", "root": "ROOT137", "reply_to": "COM1378", "timestamp": "2018-07-06T03:06:29Z", "text": "Hey @RemusMar,\r\n\r\nThanks for reporting this. Some notes...\r\n\r\n**File size**\r\nI'm not sure where you're getting these numbers, this is what I see:\r\n\r\n```\r\nLara.sea: 1,032,525 bytes \r\nLara.glb: 1,850,164 bytes\r\n\r\nLara.sea.gz: 1,031,840 bytes\r\nLara.glb.gz: 919,712 bytes \r\n```\r\n\r\n**Materials**\r\nYour model uses `Diffuse + Specular`. Unfortunately, seems like the specular texture is not being exported. GLTF supports 2 PBR modes: `Metalness + Roughness` and `Specular + Glossiness`. You want to export your model using the second mode. `GLTFLoader` supports both but maybe the Babylon.js doesn't have an option to export in that mode? In that case you may want to do a feature request on their project.\r\n\r\nLet us know what you find out.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13710", "user": "RemusMar", "root": "ROOT137", "reply_to": "COM1379", "timestamp": "2018-07-06T06:56:27Z", "text": "Hi Ricardo,\r\n\r\n1. File size.\r\nIf you download the files (with Firefox) you'll get:\r\nLara.sea: 658,901 bytes\r\nLara.glb: 1,850,964 bytes\r\nEven more: the GLB file does not even contain the equivalent (Metalness) of the Specular texture !\r\n\r\n2) Materials\r\nAs I said before, the original MAX  and FBX files contain a standard PHONG material:\r\nDiffuse + Specular + Normal \r\nNone of the current GLTF exporters and converters is able to generate a correct Physical material.\r\nPHONG is way more popular than Physical.\r\n\r\np.s.\r\nI'm not interested in the GLTF format (SEA3D is better from any point of view).\r\nI just want to help other poeple.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13711", "user": "RemusMar", "root": "ROOT137", "reply_to": "COM13710", "timestamp": "2018-07-06T10:11:28Z", "text": "Another userful sample:\r\nHere is a NATIVE Physical material in 3DS Max 2018 exported to GLTF with Babylon3D exporter:\r\nhttp://necromanthus.com/Test/html5/Lara_gltf_physical.html \r\nNow the metalness is present, but the result is still wrong:\r\n- it looks emissive (but it's not)\r\n- it has a red color bump\r\n\r\nHowever, this GLB file looks better (compared to THREE) in the Babylon sandbox ( https://sandbox.babylonjs.com ).\r\nAgain, this is how the Physical material should look in THREE:\r\nhttp://necromanthus.com/Test/html5/Lara_PBR.html \r\n\r\nSo let's forget now about PHONG and buggy exporters and converters.\r\nWe should investigate why the GLB file looks better in the Babylon sandbox.\r\nBuggy GLTF Loader in THREE ?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13712", "user": "pailhead", "root": "ROOT137", "reply_to": "COM13711", "timestamp": "2018-07-06T19:30:26Z", "text": "If one could quickly prototype some hacks over the existing phong / standard implementations i bet it would be pretty useful \ud83d\ude09 \r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13713", "user": "mrdoob", "root": "ROOT137", "reply_to": "COM13712", "timestamp": "2018-07-08T10:53:47Z", "text": "@RemusMar Seems like the glb includes a `AmbientLight`.\r\n\r\n<img width=\"766\" alt=\"screen shot 2018-07-08 at 7 44 30 pm\" src=\"https://user-images.githubusercontent.com/97088/42419015-7a49ede0-82e7-11e8-8067-ae27f0b0937a.png\">\r\n\r\nIf you set `visible` to `false` to the imported `AmbientLight` the character starts to look less red.\r\n\r\nThe last thing to do is setting `renderer.gammaOutput = true`. (Needed when using GLTF #12766)\r\n\r\n<img width=\"634\" alt=\"screen shot 2018-07-08 at 7 48 00 pm\" src=\"https://user-images.githubusercontent.com/97088/42419034-dca797b2-82e7-11e8-8548-e9f204aa7b54.png\">\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13714", "user": "RemusMar", "root": "ROOT137", "reply_to": "COM13713", "timestamp": "2018-07-08T12:46:45Z", "text": "> Seems like the glb includes a AmbientLight.\r\n\r\nGood catch Ricardo! :thumbsup: \r\n\r\n> If you set visible to false to the imported AmbientLight the character starts to look less red.\r\n\r\nSomething better (no wasted resources):\r\n```javascript \r\n\t\tgltf.scene.remove( gltf.scene.children[2] );\r\n```\r\n\r\n> The last thing to do is setting renderer.gammaOutput = true. (Needed when using GLTF #12766)\r\n\r\nThat indicates buggy GLTF Loader (and it has to be fixed).\r\nIf I use that for other loaders, I get wrong colors for the loaded models.\r\nJust think about this scenario: use various loaders for the same scene and one of them is GLTF.\r\nIt will mess up the entire scene!\r\n\r\nAnyway, after removing that ambient light and using this workaround, this is the result:\r\nhttp://necromanthus.com/Test/html5/Lara_gltf_physical.html \r\nMuch better compared to the initial GLTF one, but the material quality is far away from this one:\r\nhttp://necromanthus.com/Test/html5/Lara_PBR.html \r\nImpressive lighting response and great metalness for bra and bikini.\r\n\r\nAt this stage I won't use GLTF in any serious project.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13715", "user": "mrdoob", "root": "ROOT137", "reply_to": "COM13714", "timestamp": "2018-07-08T14:56:45Z", "text": "Can you try adding a `envMap` cubemap to these examples too? PBR looks the best when a `envMap` is supplied.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13716", "user": "RemusMar", "root": "ROOT137", "reply_to": "COM13715", "timestamp": "2018-07-08T15:34:07Z", "text": "> Can you try adding a envMap cubemap to these examples too?\r\n> PBR looks the best when a envMap is supplied.\r\n\r\nI've added offline.\r\nOf course it looks better, but PHONG with Environment map still looks WAY better (in THREE).\r\nAlso, the envMap does not fix the GLTF Loader issue(s).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13717", "user": "mrdoob", "root": "ROOT137", "reply_to": "COM13716", "timestamp": "2018-07-08T16:57:42Z", "text": "> I've added offline.\r\n\r\nCould you update the online samples?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13718", "user": "donmccurdy", "root": "ROOT137", "reply_to": "COM13717", "timestamp": "2018-07-09T02:43:59Z", "text": "The glTF format supports PBR and unlit shaders at this time. Whether the BabylonJS and FBX2GLTF tools do the Phong-to-PBR conversion in a way that preserves Phong specular maps, I don't know \u2014 that would be a question for the repos of those tools. If you are trying to preserve the exact appearance of models using classic Phong shaders, you may have an easier time with other formats.\r\n\r\n> > The last thing to do is setting renderer.gammaOutput = true.\r\n> \r\n> That indicates buggy GLTF Loader (and it has to be fixed).\r\n\r\nThis is a deliberate decision and not a bug. Base color and emissive textures in glTF (and, typically, diffuse textures in any format...) are in sRGB colorspace. GLTFLoader marks them as such (`material.map.encoding = THREE.sRGBEncoding`), so that they're converted to linear colorspace for correct PBR lighting calculations. Finally colors should be converted back to sRGB (e.g. `renderer.gammaOutput=true`).\r\n\r\nIf you skip all of this, with any format, lighting calculations are incorrect. SEA3DLoader, FBXLoader, and ColladaLoader never touch the `.encoding` property of any texture, and leave it to the end user to change texture colorspace and renderer colorspace. I'm pretty confident that the large majority of three.js users are passing sRGB colors into three.js without converting, despite the fact that renderer lighting calculations assume linear colorspace, and getting results that are \"good enough\" but inconsistent with other engines and authoring environments. For correct results you should be using `renderer.gammaOutput=true`, and marking sRGB textures as sRGB.\r\n\r\nNone of these issue are specific to glTF (see https://github.com/mrdoob/three.js/issues/11337), but with GLTFLoader we're trying to achieve consistency with other engines and 3D authoring environments, and have chosen to treat all sRGB textures as sRGB for a first step. If you're mixing models from other formats in the scene, then yes it's awkward, and you'd need to either mark the diffuse textures of those formats as sRGB or mark the colorspace on the glTF models to linear (the latter is incorrect for all model formats involved, but may look good enough if you don't need precise colors).\r\n\r\n***\r\n\r\nIt does not seem like there is anything actionable here, unless there are specific issues we can report to the tools mentioned. @RemusMar if you are happy with your SEA3D workflow, that's great \u2014 I'm not interested in debating formats or persuading you to change from something that is already working well for you.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13719", "user": "RemusMar", "root": "ROOT137", "reply_to": "COM13718", "timestamp": "2018-07-09T06:46:25Z", "text": "> Could you update the online samples?\r\n\r\nRicardo,\r\nPHONG looks great with Diffuse + Specular only.\r\nPBR does not look great with BaseColor + MetallicRoughness only.\r\nThat's the main problem here.\r\nThe Normal/Bump and Environment textures are irrelevant at this point.\r\nOn top of that: more texture layers = bigger file size and performances drop\r\n\r\n> If you skip all of this, with any format, lighting calculations are incorrect. SEA3DLoader, FBXLoader, and ColladaLoader never touch the .encoding property of any texture\r\n\r\nThat was a wise decision.\r\n\r\n> I'm not interested in debating formats or persuading you to change from something that is already working well for you.\r\n\r\nDon,\r\nI'm not debating the \"PBR only\" bad choice for GLTF.\r\nThis topic shows GLTFLoader design flaws.\r\nWe don't reinvent the wheel here, so \"renderer.gammaOutput = true\" is not an option now, when GLTF represents less than 1% of the market.\r\ncheers", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13720", "user": "RemusMar", "root": "ROOT137", "reply_to": "COM13719", "timestamp": "2018-07-09T08:28:15Z", "text": "> Can you try adding a envMap cubemap to these examples too? PBR looks the best when a envMap is supplied.\r\n> Could you update the online samples?\r\n\r\nBecause you asked me to:\r\n\r\nSEA3D + Phong: http://necromanthus.com/Test/html5/Lara_envMap.html \r\nvs\r\nGLTF + PBR: http://necromanthus.com/Test/html5/Lara_gltf_envMap.html \r\n\r\nThe quality drop is obvious.\r\nAlso, in 3DS Max 2018 the Physical material looks WAY better than the GLTF result.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13721", "user": "RemusMar", "root": "ROOT137", "reply_to": "COM13720", "timestamp": "2018-07-09T12:25:36Z", "text": "> None of these issue are specific to glTF (see #11337), but with GLTFLoader we're trying to achieve consistency with other engines and 3D authoring environments,\r\n\r\nThat's completely wrong Don!\r\nHere we're talking about GLTFLoader and THREE.js\r\nThe users are interested in the best results with THREE.\r\nOther engines and 3D authoring environments are irrelevant here.\r\n\r\nAnd you still don't understand the main problem here.\r\nFor the last time:\r\n\r\n1) JSONLoader (or SEA3D loader) + PBR = GOOD results (close to Phong):\r\nhttp://necromanthus.com/Test/html5/Lara_PBR.html \r\n\r\n2) GLTFLoader + PBR = BAD results\r\nhttp://necromanthus.com/Test/html5/Lara_gltf_physical.html \r\n\r\np.s.\r\nIn the first sample you don't even need \"renderer.gammaOutput = true\" to get good results !!!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13722", "user": "donmccurdy", "root": "ROOT137", "reply_to": "COM13721", "timestamp": "2018-07-09T15:11:57Z", "text": "\r\n> The users are interested in the best results with THREE. Other engines and 3D authoring environments are irrelevant here.\r\n\r\nBeing able to author a PBR model in Substance Painter or download one from Sketchfab, and have the model appear as the artist designed it, is good for three.js users. I don't think there's any definition of \"best result\" where that sort of consistency can be dismissed.\r\n\r\n> This topic shows GLTFLoader design flaws. We don't reinvent the wheel here, so \"renderer.gammaOutput = true\" is not an option now...\r\n\r\nThis isn't reinventing any wheels, and it isn't a design flaw. PBR calculations are done in linear space, with every engine I'm aware of. If you pass sRGB data into the renderer and pretend it's linear, the lighting and blending math will come out wrong. The difference is not huge, and so this not a major concern for many three.js users, but nevertheless it is not as good as it could be. For that reason, your \"good\" result example is not actually correct. But as you've said before, backward-compatibility is important, so I'm not here to advocate for changing any three.js defaults. But because glTF is a new format, and because we're trying to get PBR right, we're going to mark sRGB textures as sRGB, even if other loaders are not doing so.\r\n\r\nSee [this article about Unreal](http://artbyplunkett.com/Unreal/unrealgamma.html) \u2014 \r\n\r\n> ...textures that are used for color information should have the sRGB flag checked, and textures that are used for masks and numerical calculations in shaders and effects (like Normal maps) should have it unchecked. And if you follow this simple guideline you mostly get the best effect.\r\n\r\nThis is precisely what we are doing.", "meta": {"posReactions": "4", "negReactions": "1"}}
{"id": "COM13723", "user": "looeee", "root": "ROOT137", "reply_to": "COM13722", "timestamp": "2018-07-09T18:39:25Z", "text": "> ...I'm pretty confident that the large majority of three.js users are passing sRGB colors into three.js without converting, despite the fact that renderer lighting calculations assume linear colorspace\r\n\r\nYou are talking about PBR materials with glTF, but I assume this is just as much a problem with a Phong material?\r\n\r\n> ...because glTF is a new format, and because we're trying to get PBR right, we're going to mark sRGB textures as sRGB, even if other loaders are not doing so.\r\n\r\n@donmccurdy should other loaders be doing so? It seems like this inconsistency between loaders is a point of confusion for users, and it would make sense for all of them to treat sRGB textures the same way if possible. ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM13724", "user": "donmccurdy", "root": "ROOT137", "reply_to": "COM13723", "timestamp": "2018-07-09T19:16:30Z", "text": "> You are talking about PBR materials with glTF, but I assume this is just as much a problem with a Phong material?\r\n\r\nYes, the problem is the same for Phong materials or PBR materials loaded in any other format.\r\n\r\n> ...should other loaders be doing so? It seems like this inconsistency between loaders is a point of confusion for users, and it would make sense for all of them to treat sRGB textures the same way if possible.\r\n\r\nIf we had a time machine, yes, the other loaders should also be marking sRGB textures containing color data as sRGB. But making the change now would cause confusion and break backward-compatibility, and the `gammaOutput=true` setting needed to fix output is not intuitive \u2014 I don't think changing other loaders can be justified given those issues.\r\n\r\nLet's keep an eye on https://github.com/mrdoob/three.js/issues/11337. I hope the resolution there will make color workflows more intuitive. With that and NodeMaterial, there may be opportunities to fix some existing issues without breaking anyone's existing applications.", "meta": {"posReactions": "2", "negReactions": "1"}}
{"id": "COM13725", "user": "RemusMar", "root": "ROOT137", "reply_to": "COM13724", "timestamp": "2018-07-10T06:40:10Z", "text": "> Being able to author a PBR model in Substance Painter or download one from Sketchfab,\r\n\r\nThey are irrelevant.\r\nI get much better results in 3DS Max and that tells me that the GLTFLoader and/or your PBR model are not properly implemented.\r\n\r\n> The difference is not huge, and so this not a major concern for many three.js users, but nevertheless it is not as good as it could be.\r\n\r\nYour girlfriend looks bad but you're happy because your boss told you that's normal.\r\nOMG ...\r\n\r\n> For that reason, your \"good\" result example is not actually correct.\r\n\r\nIn fact you should fix your \"correct\" example to look good.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13726", "user": "looeee", "root": "ROOT137", "reply_to": "COM13725", "timestamp": "2018-07-14T14:36:45Z", "text": "> If we had a time machine, yes, the other loaders should also be marking sRGB textures containing color data as sRGB.  \r\n\r\nYeah, it's unfortunate but I agree that it's not worth breaking backwards compatibility over this. \r\n\r\nHowever, as I've been working with larger FBX scenes consisting of multiple models, animated cameras and so on I've found myself wishing that the output of the loader was something more like GLTFLoader's output - that is, it should return an `fbx` object with properties:\r\n\r\n```\r\nfbx.animations; // Array<THREE.AnimationClip>\r\nfbx.models; // Array <THREE.Group, THREE.Mesh, THREE.SkinnedMesh>\r\nfbx.cameras; // Array<THREE.Camera>\r\nfbx.asset; // Object\r\n```\r\n\r\nThere may be other loaders that would benefit from a similar change.  We should add this to the backburner (and certainly wait on #11337), but if any loaders do have breaking changes made for whatever reason, then we can use that as opportunity to apply this change as well. \r\n\r\nPerhaps we should open a new issue to keep track of this? ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13727", "user": "Mugen87", "root": "ROOT137", "reply_to": "COM13726", "timestamp": "2018-07-14T15:05:50Z", "text": "> Perhaps we should open a new issue to keep track of this?\r\n\r\nPlease do. That's better than resume the conversation in this closed thread.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13728", "user": "RemusMar", "root": "ROOT137", "reply_to": "COM13727", "timestamp": "2018-07-20T09:58:03Z", "text": "Just removed the FORCED sRGB encoding in the GLTFLoader.\r\n```javascript\r\n//\t\t\tif ( material.map ) material.map.encoding = THREE.sRGBEncoding;\r\n//\t\t\tif ( material.emissiveMap ) material.emissiveMap.encoding = THREE.sRGBEncoding;\r\n//\t\t\tif ( material.specularMap ) material.specularMap.encoding = THREE.sRGBEncoding;\r\n```\r\n\r\nThe result is better from any point of view:\r\n- better lighting and material quality\r\n- no need of \"renderer.gammaOutput = true\" anymore (a bad idea anyway)\r\n- now you can use the GLTFLoader with other loaders for the same scene (renderer)\r\n\r\nSEA3D + Phong: http://necromanthus.com/Test/html5/Lara_envMap.html\r\nvs\r\nGLTF + PBR: http://necromanthus.com/Test/html5/Lara_gltf_envMap.html\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13729", "user": "donmccurdy", "root": "ROOT137", "reply_to": "COM13728", "timestamp": "2018-07-20T17:07:02Z", "text": "I've addressed each of those points in https://github.com/mrdoob/three.js/issues/14419#issuecomment-403513554 \u2014 we will not be removing the sRGB encoding assignment to sRGB textures in GLTFLoader. If you would like to override that, it is easy to change the texture encoding after loading the model.\r\n\r\nIf there are no other actions to take here, this issue should be closed.", "meta": {"posReactions": "1", "negReactions": "1"}}
{"id": "ROOT138", "user": "reyjrar", "root": "ROOT138", "reply_to": null, "timestamp": "2017-12-28T22:12:37Z", "text": "Conditionally import_playbook aka include_playbook ##### ISSUE TYPE\r  - Feature Idea\r \r ##### COMPONENT NAME\r import_playbook\r \r ##### ANSIBLE VERSION\r <!--- Paste verbatim output from \"ansible --version\" between quotes below -->\r ```\r 2.4.0.0\r ```\r \r ##### CONFIGURATION\r <!---\r If using Ansible 2.4 or above, paste the results of \"ansible-config dump --only-changed\"\r Otherwise, mention any settings you have changed/added/removed in ansible.cfg\r (or using the ANSIBLE_* environment variables).\r -->\r \r n/a\r \r ##### OS / ENVIRONMENT\r \r CentOS 6\r \r ##### SUMMARY\r \r I need to conditionally import a playbook, which isn't possible.  The keyword I'm missing is \"include_playbook\" which would allow a \"when\" to apply to it.  Why?\r \r I have a playbook that performs some maintenance, OS, Kernel, package, and firmware upgrades.  For Major upgrades, we track progress in a ticketing system.  So, during those runs, I'd like to conditionally import a playbook that updates the ticket information.  In order for that to work, I need to pass the user's password to the ticketing system, so there's a `vars_prompt` in the ticket update playbook.  If the user specifies which ticket they're working to the maintenance playbook, I'd like the ticket update playbook to be called after the maintenance is performed.\r \r If there's another way for this to work, I'm open to alternate ideas, but I think conditionally playbook imports would be generically useful.  I'm not understanding why tasks could be included dynamically, but a playbook wouldn't be.\r \r ##### STEPS TO REPRODUCE\r <!---\r For bugs, show exactly how to reproduce the problem, using a minimal test-case.\r For new features, show how the feature would be used.\r -->\r \r <!--- Paste example playbooks or commands between quotes below -->\r ```yaml\r # Maintenance Play Runs first, then conditionally import a second playbook\r - import_playbook: update-ticket.yaml\r   when: ticket_id is defined\r ```\r \r <!--- You can also paste gist.github.com links for larger files -->\r \r ##### EXPECTED RESULTS\r <!--- What did you expect to happen when running the steps above? -->\r \r I expect `update-ticket.yaml` to only import if the `ticket_id` is defined.\r \r ##### ACTUAL RESULTS\r <!--- What actually happened? If possible run with extra verbosity (-vvvv) -->\r \r no parse error, and playbook `update-ticket.yaml` is imported 100% of the time.\r ", "meta": {"posReactions": "103", "negReactions": "0"}}
{"id": "COM1380", "user": "ansibot", "root": "ROOT138", "reply_to": "ROOT138", "timestamp": "2017-12-28T22:18:52Z", "text": "Files identified in the description:\n* [lib/ansible/modules/utilities/logic/import_playbook.py](https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/utilities/logic/import_playbook.py)\n\nIf these files are inaccurate, please update the `component name` section of the description or use the `!component` bot command.\n\n[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)\n<!--- boilerplate: components_banner --->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1381", "user": "MarSik", "root": "ROOT138", "reply_to": "COM1380", "timestamp": "2018-01-29T15:17:35Z", "text": "We have similar need. We have a main playbook that prepares the system, but we allow the user to provide some extra steps by creating a playbook files in a well known directories. We do not know what files will be present there in advance. For this we would really like to have include_playbook that supports with_fileglob (or with_items).", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM1382", "user": "MarSik", "root": "ROOT138", "reply_to": "COM1381", "timestamp": "2018-01-29T15:21:43Z", "text": "Just to explain why include_tasks is not enough. The system is clustered and the tasks talk to localhost, other physical hosts and virtual machines. We could in theory use delegate_to if it supported host groups.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1383", "user": "TonyApuzzo", "root": "ROOT138", "reply_to": "COM1382", "timestamp": "2018-03-22T02:21:37Z", "text": "I also have this need in order to import different playbooks to configure Vagrant guests differently depending on the active hypervisor.\r\n\r\nAlternate to `when` is something like (this is also not supported):\r\n```YAML\r\n- import_playbook: \"install_{{ 'virtualbox' if ansible_product_name == 'VirtualBox' else 'vmware' if ansible_product_name = 'VMware Virtual Platform' else 'noop' }}_extensions.yml\"\r\n```\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1384", "user": "ssbarnea", "root": "ROOT138", "reply_to": "COM1383", "timestamp": "2018-04-23T09:27:31Z", "text": "Is this going to be fixed soon? I find it as a serious source of problems because the optional playbook code ca be huge when it comes to number of tasks, causing over **extensive console/log verbosity** of tasks that are never supposed to be loaded.\r\n\r\nThe `skip_reason\": \"Conditional result was False\"` is not of much help either because the user will not see any condition on those tasks, the condition being few nested includes/imports away in another file.\r\n\r\nIt helps nobody that Ansible will list hundreds of lines of files that were never supposed to be run, making much harder to investigate them.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1385", "user": "user140547", "root": "ROOT138", "reply_to": "COM1384", "timestamp": "2018-05-05T20:55:47Z", "text": "As a workaround until this is possible, if the use case is to support different host groups it is possible to use an include_task with a conditional on group names, i.e. a task include for a group `foo` is included when a file `tasks_directory/foo.yml` is provided:\r\n\r\n```\r\n- include_tasks: \"{{item}}\"\r\n  with_fileglob: \"tasks_directory/*.yml\"\r\n  vars:\r\n    file_host_group: \"{{ (item | basename | splitext)[0]}}\"\r\n  when: \"file_host_group in group_names\"\r\n```\r\n\r\nThe playbook including this construct has to run for all hosts.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1386", "user": "watsonb", "root": "ROOT138", "reply_to": "COM1385", "timestamp": "2018-08-31T19:06:38Z", "text": "Is this still being worked at all?  I'm kind of implementing something like an `ansible-galaxy` style method of \"installing\" playbooks into a playbooks sub-directory and then I want to `include_playbook` a playbook that was just \"installed\".  \r\n\r\nHere is what I've got so far:\r\n\r\n```yaml\r\n- name: PLAY | Install other required playbooks\r\n  hosts: localhost\r\n  connection: local\r\n  tasks:\r\n\r\n    - name: INCLUDE_VARS | include variables to discover other needed playbooks\r\n      include_vars:\r\n        dir: playbooks/\r\n        files_matching: requirements.yml\r\n        depth: 1\r\n\r\n    - name: GIT | Clone playbooks\r\n      git:\r\n        repo: \"{{ item.src }}\"\r\n        dest: \"playbooks/{{ item.src.split('/')[-1] }}\"\r\n        version: \"{{ item.version }}\"\r\n      loop: \"{{ elk_required_playbooks }}\"\r\n\r\n    - name: SHELL | Install included playbooks roles\r\n      shell: ansible-galaxy install -r roles/requirements.yml -p roles/\r\n      args:\r\n        chdir: \"playbooks/{{ item.src.split('/')[-1] }}\"\r\n      loop: \"{{ elk_required_playbooks }}\"\r\n\r\n- name: PLAY | Run the installed helloWorld playbook\r\n  import_playbook: \"playbooks/ap_hello_world/helloWorld.yml\"\r\n```\r\nIf I run this as-is, I get an import error because the playbook to be imported isn't there yet.\r\n\r\n```bash\r\nERROR! Unable to retrieve file contents\r\nCould not find or access '/path/to/playbooks/ap_hello_world/helloWorld.yml'\r\n```\r\nIf I comment out the `import_playbook` play, the functionality above that works nearly like `ansible-galaxy` and \"installs\" the playbooks I need (and the roles they need).  \r\n\r\n```bash\r\nPLAY [PLAY | Install other required playbooks] *************************************************************************************************************************************\r\n\r\nTASK [Gathering Facts] *************************************************************************************************************************************************************\r\nFriday 31 August 2018  13:54:13 -0500 (0:00:00.239)       0:00:00.240 ********* \r\nFriday 31 August 2018  13:54:13 -0500 (0:00:00.237)       0:00:00.237 ********* \r\nok: [localhost]\r\n\r\nTASK [INCLUDE_VARS | include variables to discover other needed playbooks] *********************************************************************************************************\r\nFriday 31 August 2018  13:54:15 -0500 (0:00:01.366)       0:00:01.606 ********* \r\nFriday 31 August 2018  13:54:15 -0500 (0:00:01.366)       0:00:01.604 ********* \r\nok: [localhost]\r\n\r\nTASK [GIT | Clone playbooks] *******************************************************************************************************************************************************\r\nFriday 31 August 2018  13:54:15 -0500 (0:00:00.124)       0:00:01.730 ********* \r\nFriday 31 August 2018  13:54:15 -0500 (0:00:00.124)       0:00:01.728 ********* \r\nchanged: [localhost] => (item={u'src': u'<gir_url>/ap_hello_world', u'version': u'v0.3.0'})\r\n\r\nTASK [SHELL | Install included playbooks roles] ************************************************************************************************************************************\r\nFriday 31 August 2018  13:54:17 -0500 (0:00:02.591)       0:00:04.322 ********* \r\nFriday 31 August 2018  13:54:17 -0500 (0:00:02.591)       0:00:04.319 ********* \r\nchanged: [localhost] => (item={u'src': u'<git_url>/ap_hello_world', u'version': u'v0.3.0'})\r\n\r\nPLAY RECAP *************************************************************************************************************************************************************************\r\nlocalhost                  : ok=4    changed=2    unreachable=0    failed=0 \r\n```\r\nAnd now I can run the same playbook again, this time with the `import_playbook` play not commented and it works as I desire:\r\n\r\n```bash\r\nPLAY [PLAY | Install other required playbooks] *************************************************************************************************************************************\r\n\r\nTASK [Gathering Facts] *************************************************************************************************************************************************************\r\nFriday 31 August 2018  14:00:30 -0500 (0:00:00.244)       0:00:00.244 ********* \r\nFriday 31 August 2018  14:00:30 -0500 (0:00:00.241)       0:00:00.241 ********* \r\nok: [localhost]\r\n\r\nTASK [INCLUDE_VARS | include variables to discover other needed playbooks] *********************************************************************************************************\r\nFriday 31 August 2018  14:00:32 -0500 (0:00:01.471)       0:00:01.716 ********* \r\nFriday 31 August 2018  14:00:32 -0500 (0:00:01.471)       0:00:01.713 ********* \r\nok: [localhost]\r\n\r\nTASK [GIT | Clone playbooks] *******************************************************************************************************************************************************\r\nFriday 31 August 2018  14:00:32 -0500 (0:00:00.138)       0:00:01.854 ********* \r\nFriday 31 August 2018  14:00:32 -0500 (0:00:00.138)       0:00:01.852 ********* \r\nok: [localhost] => (item={u'src': u'<git_url>/ap_hello_world', u'version': u'v0.3.0'})\r\n\r\nTASK [SHELL | Install included playbooks roles] ************************************************************************************************************************************\r\nFriday 31 August 2018  14:00:35 -0500 (0:00:02.821)       0:00:04.675 ********* \r\nFriday 31 August 2018  14:00:35 -0500 (0:00:02.821)       0:00:04.673 ********* \r\nchanged: [localhost] => (item={u'src': u'<git_url>/ap_hello_world', u'version': u'v0.3.0'})\r\n\r\nPLAY [PLAY | BEGIN Setup & Timing] *************************************************************************************************************************************************\r\n\r\nTASK [set_fact] ********************************************************************************************************************************************************************\r\nFriday 31 August 2018  14:00:36 -0500 (0:00:01.323)       0:00:05.999 ********* \r\nFriday 31 August 2018  14:00:36 -0500 (0:00:01.323)       0:00:05.997 ********* \r\nok: [localhost]\r\n\r\nTASK [debug] ***********************************************************************************************************************************************************************\r\nFriday 31 August 2018  14:00:36 -0500 (0:00:00.155)       0:00:06.154 ********* \r\nFriday 31 August 2018  14:00:36 -0500 (0:00:00.155)       0:00:06.152 ********* \r\nok: [localhost] => {\r\n    \"msg\": \"Start Time - 2018-08-31 14:00:36\"\r\n}\r\n\r\nPLAY [PLAY | Say Hello to My Little Friend] ****************************************************************************************************************************************\r\n\r\nTASK [SHELL | echo something] ******************************************************************************************************************************************************\r\nFriday 31 August 2018  14:00:36 -0500 (0:00:00.096)       0:00:06.251 ********* \r\nFriday 31 August 2018  14:00:36 -0500 (0:00:00.096)       0:00:06.249 ********* \r\nok: [knebawils001]\r\n\r\nTASK [DEBUG | debug host's standard output] ****************************************************************************************************************************************\r\nFriday 31 August 2018  14:00:37 -0500 (0:00:00.714)       0:00:06.965 ********* \r\nFriday 31 August 2018  14:00:37 -0500 (0:00:00.714)       0:00:06.963 ********* \r\nskipping: [knebawils001]\r\n\r\nPLAY [PLAY | Say Hello via an Ansible Role] ****************************************************************************************************************************************\r\n\r\nTASK [ar_hello_world : SHELL | echo role's message on host] ************************************************************************************************************************\r\nFriday 31 August 2018  14:00:37 -0500 (0:00:00.151)       0:00:07.117 ********* \r\nFriday 31 August 2018  14:00:37 -0500 (0:00:00.151)       0:00:07.115 ********* \r\nok: [knebawils001]\r\n\r\nTASK [ar_hello_world : DEBUG | debug host shell standard output] *******************************************************************************************************************\r\nFriday 31 August 2018  14:00:37 -0500 (0:00:00.342)       0:00:07.459 ********* \r\nFriday 31 August 2018  14:00:37 -0500 (0:00:00.342)       0:00:07.457 ********* \r\nskipping: [knebawils001]\r\n\r\nPLAY [PLAYBOOK | END Setup & Timing] ***********************************************************************************************************************************************\r\n\r\nTASK [set_fact] ********************************************************************************************************************************************************************\r\nFriday 31 August 2018  14:00:38 -0500 (0:00:00.212)       0:00:07.672 ********* \r\nFriday 31 August 2018  14:00:38 -0500 (0:00:00.212)       0:00:07.669 ********* \r\nok: [localhost]\r\n\r\nTASK [debug] ***********************************************************************************************************************************************************************\r\nFriday 31 August 2018  14:00:38 -0500 (0:00:00.179)       0:00:07.851 ********* \r\nFriday 31 August 2018  14:00:38 -0500 (0:00:00.178)       0:00:07.848 ********* \r\nok: [localhost] => {\r\n    \"msg\": \"Start Time - 2018-08-31 14:00:36, End Time - 2018-08-31 14:00:38, Elapsed Time - 0:00:02\"\r\n}\r\n\r\nPLAY RECAP *************************************************************************************************************************************************************************\r\nknebawils001          : ok=2    changed=0    unreachable=0    failed=0   \r\nlocalhost                  : ok=8    changed=1    unreachable=0    failed=0\r\n```\r\nI suppose this could be split up into two (2) separate playbooks in the same Git repo.  The first would be called `prepare.yml` or maybe `prerequisites.yml` to \"install\" the other needed playbooks and the second main playbook (`playbook.yml`) will do the necessary imports, etc.  I was really wanting to make this a \"one-shot\" playbook.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1387", "user": "gunbo13", "root": "ROOT138", "reply_to": "COM1386", "timestamp": "2018-09-11T15:27:00Z", "text": "Include conditionals are very useful for creating branches in our playbooks.  Will it be ensured that import_playbook will support conditionals in the next release citing this issue?\r\n\r\nIf not, you are losing a lot of power and will end up creating a lot of hacks.  Not to mention breaking a ton of include playbook conditionals in end user plays.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1388", "user": "davedittrich", "root": "ROOT138", "reply_to": "COM1387", "timestamp": "2018-09-24T04:10:28Z", "text": "+1 on implementing a \"when\" conditional.", "meta": {"posReactions": "14", "negReactions": "0"}}
{"id": "COM1389", "user": "DanyC97", "root": "ROOT138", "reply_to": "COM1388", "timestamp": "2018-10-03T21:31:39Z", "text": "soon-ish we approaching 1 y since this request was open and no progress so far ...  any chance this get some attention @bcoca ? much thanks !", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13810", "user": "tonk", "root": "ROOT138", "reply_to": "COM1389", "timestamp": "2018-10-10T08:58:25Z", "text": "I would like to vote a '+1'as well.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM13811", "user": "ivovangeel", "root": "ROOT138", "reply_to": "COM13810", "timestamp": "2018-10-10T11:24:10Z", "text": "+1", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM13812", "user": "SDerksen", "root": "ROOT138", "reply_to": "COM13811", "timestamp": "2018-10-10T14:04:16Z", "text": "+1 as well, would love to see this feature", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13813", "user": "sebastiaanluca", "root": "ROOT138", "reply_to": "COM13812", "timestamp": "2018-10-10T14:10:29Z", "text": "Please use the \ud83d\udc4d  button to let the maintainers know you need this feature. Getting a ton of emails from these +1s.", "meta": {"posReactions": "32", "negReactions": "0"}}
{"id": "COM13814", "user": "rfjschutte", "root": "ROOT138", "reply_to": "COM13813", "timestamp": "2018-10-12T11:32:02Z", "text": "+1", "meta": {"posReactions": "0", "negReactions": "4"}}
{"id": "COM13815", "user": "amarao", "root": "ROOT138", "reply_to": "COM13814", "timestamp": "2018-10-18T14:41:38Z", "text": "If someone is interested how to use play-level variables for conditional playbook-import:\r\n1. Set up that variable as a fact in the play\r\n2. Use `when` with `import_playbook` to check this variable (with full path, `hostvars.hostname.a_variable`)\r\n\r\nIf someone is interested, I managed to make import_playbook be conditional on `--limit` in the command line:\r\n\r\nhttps://medium.com/opsops/import-playbook-with-play-level-condition-775122fe78ff\r\n\r\nAn example:\r\n\r\n```\r\n- hosts: all,localhost\r\n  gather_facts: no\r\n  run_once: True\r\n  tasks:\r\n   - set_fact:\r\n        full_run: '{{ play_hosts == groups.all }}'\r\n     delegate_to: localhost\r\n     delegate_facts: yes\r\n\r\n- import_playbook: test.yaml\r\n  when: hostvars.localhost.full_run\r\n```", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM13816", "user": "brotaxt", "root": "ROOT138", "reply_to": "COM13815", "timestamp": "2019-04-02T09:38:34Z", "text": "is this issue/request still up to date in a more current version of ansible? Iam using ansible 2.6.1 and the when condition doesn't seem to work when I use the import_playbook function.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13817", "user": "amarao", "root": "ROOT138", "reply_to": "COM13816", "timestamp": "2019-04-02T10:00:11Z", "text": "@brotaxt  You need to initialize variables before doing `when`. Just add some random task to random host (before doing first 'import_playbook'). F.e., do set_fact on localhost, as in example above.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13818", "user": "brotaxt", "root": "ROOT138", "reply_to": "COM13817", "timestamp": "2019-04-02T13:47:30Z", "text": "@amarao \r\n\r\nmany thanks for the quick response. :+1:  Unfortunately it doesn't seem to work for me. Even if answer the prompt with \"no\" the playbook \"vmware_createsnap.yml\" gets invoked. The other tasks are working as expected. What I am doing wrong? \r\n\r\n\r\nMy playbook: \r\n\r\n```\r\n---\r\n-\r\n  hosts: all\r\n  gather_facts: true\r\n  vars_prompt:\r\n   - name: \"snapshots_required\"\r\n     prompt: \"Do you want to automatically create VMWare Snapshots? [yes/no]\"\r\n     private: no\r\n  name: \"Install all available Updates\"\r\n  tasks:\r\n\r\n   - name: Check for Updates\r\n     include: checkforupdates.yml\r\n\r\n   - name: setting fact for hosts which have outstanding updates\r\n     set_fact:\r\n       updates_available: \"yes\"\r\n     when: \"yumoutput.changed or zypperoutput.changed\"\r\n\r\n\r\n   - name: setting fact for hosts which have no outstanding updates\r\n     set_fact:\r\n       updates_available: \"false\"\r\n     when: updates_available is not defined\r\n\r\n\r\n- import_playbook: vmware_createsnap.yml\r\n  when: snapshots_required = \"yes\"\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13819", "user": "bcoca", "root": "ROOT138", "reply_to": "COM13818", "timestamp": "2019-04-02T14:09:58Z", "text": "@brotaxt  this is a feature request, you currently CANNOT conditionally import playbooks, the conditions above happen to skip all the tasks in one, but this is not a supported behaviour and not guaranteed to work across versions of Ansible.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13820", "user": "Kriechi", "root": "ROOT138", "reply_to": "COM13819", "timestamp": "2019-04-02T14:14:33Z", "text": "just to be clear:\r\nimport or include? because I think the current implementation or naming is actually wrong, based on the definition in https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_includes.html\r\n\r\nDoes import_playbook actually \"lazy load\" or does it get loaded & parsed with the yaml file?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13821", "user": "bcoca", "root": "ROOT138", "reply_to": "COM13820", "timestamp": "2019-04-02T14:28:04Z", "text": "@Kriechi neither, it gets loaded at 'playbook compile time' which is before execution but not on file load\r\n\r\nthere is no include_playbook, that is the whole purpose of this feature request, to add one", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13822", "user": "Kriechi", "root": "ROOT138", "reply_to": "COM13821", "timestamp": "2019-04-02T14:31:08Z", "text": "@bcoca mhm that sounds even more wrong - or am I missing the big picture here?\r\nI would have expected that `import_task` and `include_task` have an `*_playbook` sibling...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13823", "user": "bcoca", "root": "ROOT138", "reply_to": "COM13822", "timestamp": "2019-04-02T14:32:46Z", "text": "@Kriechi the engine never supported that, why `include:` was very misleading and we had to separate it into the different include_X/import_X options and make each behaviour explicit. So include_X is dynamic aka runtime, while import_X is 'static' aka 'compile time'.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13824", "user": "Kriechi", "root": "ROOT138", "reply_to": "COM13823", "timestamp": "2019-04-02T14:36:14Z", "text": "ok - so `include_playbook` would be a feature request? Or can we track it here?\r\n\r\nE.g., I'm running a git-checkout task on localhost, and then want to `include_playbook: some/repo/foo.yml`\r\nThis should include (lazy-load) the updated playbook from that repository, AFTER pulling the latest commit from the remote. Currently, `import_playbook` imports the \"old\" playbook, then pulls, and then runs the outdated playbook.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13825", "user": "bcoca", "root": "ROOT138", "reply_to": "COM13824", "timestamp": "2019-04-02T15:23:28Z", "text": "@Kriechi  ... please read the subject of this ticket, that is EXACTLY what we are tracking here", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM13826", "user": "Kriechi", "root": "ROOT138", "reply_to": "COM13825", "timestamp": "2019-04-02T15:37:22Z", "text": "true - the part the confused me is \"conditionally import...\".\r\n`import_playbook` and `include_playbook` are the feature we want.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13827", "user": "decet", "root": "ROOT138", "reply_to": "COM13826", "timestamp": "2019-05-23T17:30:07Z", "text": "I'm trying to do what [watsonb](https://github.com/ansible/ansible/issues/34281#issuecomment-417762220) was, using ansible-galaxy to install roles, and then using the roles. \r\n\r\nI found a decent workaround for the all-in-one playbook, which was to place the playbooks, in the order that you want them to execute, on the command line. In Watsonb's case, that would look like\r\n\r\nansible-playbook ... prepare.yml playbook.yml\r\n\r\nAny variables that you set on the command line are passed to the playbooks, sequentially.\r\n\r\nThis might also solve [MarSik's](https://github.com/ansible/ansible/issues/34281#issuecomment-361277446) problem, also, using file globbing on the command line instead of in the playbook.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13828", "user": "MarSik", "root": "ROOT138", "reply_to": "COM13827", "timestamp": "2019-05-23T18:47:20Z", "text": "@decet It could, but that would basically mean using a top level bash script as the entrypoint and spliting the main ansible playbook into multiple stage files. Not too horrible, just ugly.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM13829", "user": "watsonb", "root": "ROOT138", "reply_to": "COM13828", "timestamp": "2019-05-24T00:37:55Z", "text": "I've overcome this in my own way as follows.  First, my typical playbook directory structure:\r\n\r\n```bash\r\n.\r\n\u251c\u2500\u2500 .ansible-lint\r\n\u251c\u2500\u2500 .gitignore\r\n\u251c\u2500\u2500 .yamllint\r\n\u251c\u2500\u2500 ansible.cfg\r\n\u251c\u2500\u2500 callback_plugins\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 junit.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 log_plays.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 profile_roles.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 profile_tasks.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 timer.py\r\n\u251c\u2500\u2500 check_ansible_lint.sh\r\n\u251c\u2500\u2500 check_syntax.sh\r\n\u251c\u2500\u2500 check_yaml_lint.sh\r\n\u251c\u2500\u2500 create.yml\r\n\u251c\u2500\u2500 destroy.yml\r\n\u251c\u2500\u2500 Jenkinsfile\r\n\u251c\u2500\u2500 localhost_inventory.yml\r\n\u251c\u2500\u2500 playbooks\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ap_linux_instance\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 requirements.yml\r\n\u251c\u2500\u2500 prerequisites.yml\r\n\u251c\u2500\u2500 README.md\r\n\u251c\u2500\u2500 reports\r\n\u251c\u2500\u2500 requirements.txt\r\n\u251c\u2500\u2500 roles\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ar_linux_ansible_venv\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ar_linux_cname\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 config_encoder_filters\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 requirements.yml\r\n\u2514\u2500\u2500 VERSION.md\r\n```\r\n\r\nMy .gitignore ignores most sane OS/language/IDE things, but also ignores everything in the `roles/` and `playbooks/` folders except for the `requirements.yml` files in each folder.  The requirements.yml file within the playbooks folder is similar to your Galaxy-style requirements.yml, but rather than calling out dependent playbooks by Galaxy owner.name, I specify the full Git source (Galaxy supports this of course).  The requirements.yml within the roles/ folder is just your traditional Galaxy-style requirements.\r\n\r\nI have this `prerequisites.yml` playbook, that looks like this:\r\n\r\n```yaml\r\n---\r\n\r\n- name: PLAY | Install other required playbooks\r\n  hosts: localhost\r\n  connection: local\r\n  tasks:\r\n\r\n    - name: INCLUDE_VARS | include variables to discover other needed playbooks\r\n      include_vars:\r\n        dir: playbooks/\r\n        files_matching: requirements.yml\r\n        depth: 1\r\n\r\n    - name: GIT | Clone playbooks\r\n      git:\r\n        repo: \"{{ item.src }}\"\r\n        dest: \"playbooks/{{ item.src.split('/')[-1] }}\"\r\n        version: \"{{ item.version }}\"\r\n      loop: \"{{ required_playbooks }}\"\r\n\r\n    - name: SHELL | Install included playbooks roles\r\n      shell: ansible-galaxy install -r roles/requirements.yml -p roles/ --force\r\n      args:\r\n        chdir: \"playbooks/{{ item.src.split('/')[-1] }}\"\r\n      loop: \"{{ required_playbooks }}\"\r\n      when: item.galaxy\r\n      changed_when: false\r\n      tags: [ skip_ansible_lint ]\r\n```\r\nAnd, assuming that my \"big bang\" create.yml depends on a playbook and its roles from another playbook project, I import it like this:\r\n\r\n```yaml\r\n# ~~~~~~~~~~\r\n# Ensure that all of the host VMs in the inventory are up and running\r\n# either on-prem or in Azure as specified in the inventory\r\n#\r\n- name: Ensure inventory hosts are present\r\n  import_playbook: \"playbooks/ap_linux_instance/create.yml\"\r\n  tags: [ base_server, hosts ]\r\n```\r\n\r\nAnd so, the work-flow to run my \"big bang\" (e.g. create.yml) is a 3-liner:\r\n\r\n```bash\r\nansible-playbook prerequisites.yml\r\nansible-galaxy install -r roles/requirements -p roles/\r\nansible-playbook create.yml -i <path_to_inventory>\r\n```\r\n\r\nYou could, of course, wrap the above 3-liner in a `create.sh` shell script for convenience.  This method has served me well for some fairly complex playbook projects that depend on other playbook projects.  This forces us to keep roles and playbooks fairly self-contained and re-usable and factor variables out into their own inventory projects.  When performed with discipline, it makes it really easy to migrate unaltered roles/playbooks to other environments, then just update inventory variables that are unique to that environment.\r\n\r\n**This doesn't solve the conditional import problem**, mind you, but does help me use the `import_playbook` statement for something that may not exist just yet.  It kind of gets around a conditional in my very specific use-case.  I make use of tagging on the `import_playbook` to leverage the command-line `--tags` and `--skip-tags` features if I need scalpel-like precision at run-time. But if you had to make an import decision based on some other conditional logic (e.g., OS family), well, we still need that as a language feature I think.  For now, I just handle those cases with sub-playbooks and chain them together ensuring I target the appropriate hosts/groups that should or should not be targeted based on how I've setup my inventory (yes, it can get messy).\r\n\r\nThis is all pretty wild and requires a high degree if what I commonly refer to as \"4th dimensional thinking\", especially when you consider branches/versions of things and running them from CI/CD platforms like Jenkins or even AWX.  But I still find Ansible fascinating and use it daily.\r\n\r\nHTH,\r\n\r\nBen", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "ROOT139", "user": "rocnogu", "root": "ROOT139", "reply_to": null, "timestamp": "2020-03-07T19:23:43Z", "text": "curriculum not on 100% short story: curriculum not on 100%\r long story:\r \"\"Basic HTML and HTML5\"\" is \"\"Not Passed\"\" because \"\"Use the value attribute with Radio Buttons and Checkboxes\"\" doesn't complete.\r  I complete it 3 times and it shows: \"\"Basic HTML and HTML5\r 100% complete\"\"\r \r but in the curriculum is not.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1390", "user": "RandellDawson", "root": "ROOT139", "reply_to": "ROOT139", "timestamp": "2020-03-07T19:41:49Z", "text": "@rocnogu I am not understanding what the problem is.  Can you explain how we can recreate the issue?\r\n\r\nDo you have screen shots you can share of the problem you are trying to describe?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1391", "user": "rocnogu", "root": "ROOT139", "reply_to": "COM1390", "timestamp": "2020-03-07T23:19:08Z", "text": "@RandellDawson   i finish the assignment but the system doesn't recognize it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1392", "user": "RandellDawson", "root": "ROOT139", "reply_to": "COM1391", "timestamp": "2020-03-07T23:46:52Z", "text": "@rocnogu Please use [our forum](https://www.freecodecamp.org/forum) for debugging the code of your projects.  If the forum members determine there is nothing wrong with your code, you can request this issue to be reopened.  GitHub issues are meant for reporting bugs and not troubleshooting the code in your projects.\r\n\r\nThank you for understanding.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1393", "user": "rocnogu", "root": "ROOT139", "reply_to": "COM1392", "timestamp": "2020-03-08T02:43:49Z", "text": "how about you do it?\r\nit's literally your job.\r\nor you are here just to spam random stuff till people get pissed off and leave?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1394", "user": "RandellDawson", "root": "ROOT139", "reply_to": "COM1393", "timestamp": "2020-03-08T03:48:28Z", "text": "I am a volunteer as most of Free Code Camp's contributors are.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT140", "user": "rocnogu", "root": "ROOT140", "reply_to": null, "timestamp": "2020-03-07T19:47:41Z", "text": "Night mode doesnt work by me. **Looking forward for reporting a security issue:**\r Please report security issues by sending an email to `security@freecodecamp.org` instead of raising a GitHub issue.\r \r **Describe the bug**\r A clear and concise description of what the bug is.\r \r **To Reproduce**\r Steps to reproduce the behavior:\r 1. Go to '...' https://www.freecodecamp.org/settings\r 2. click on night mode ON\r 4. See error: Something is not quite right. A report has been generated and the freeCodeCamp.org team have been notified.\r \r **Expected behavior**\r Night mode \r \r **Screenshots**\r no\r \r **Desktop (please complete the following information):**\r  - OS: [] win 10 pro 64b 18262.657\r  - Browser [ chrome, ]\r  - Version [] Version 80.0.3987.132 (Official Build) (64-bit)\r \r \r \r **Additional context**\r i tried to log in from microsoft edge and torch browser but it failed. should i open one more bug report?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1400", "user": "RandellDawson", "root": "ROOT140", "reply_to": "ROOT140", "timestamp": "2020-03-07T20:19:28Z", "text": "@rocnogu Are you logged into your account when this happens?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1401", "user": "rocnogu", "root": "ROOT140", "reply_to": "COM1400", "timestamp": "2020-03-07T23:32:32Z", "text": "@RandellDawson  \r\nbot or something? your comments look absolutely random with quite zero connection to the reality. either a bot or ... very unintelligent person. which is fine by me as long as you keep a distance from me. so, if you don't know a solution, DO NOT POST ANY COMMENTS.\r\nit says: Member of freeCodeCamp.org but that means you actually know the system. do you?\r\ncan you go to https://www.freecodecamp.org/settings without logging in?\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...' https://www.freecodecamp.org/settings\r\n2. click on night mode ON\r\n4. See error: Something is not quite right. A report has been generated and the freeCodeCamp.org team have been notified.\r\n\r\nand again\r\n if you don't know a solution, DO NOT POST ANY COMMENTS.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1402", "user": "lasjorg", "root": "ROOT140", "reply_to": "COM1401", "timestamp": "2020-03-08T01:16:35Z", "text": "@rocnogu There is no need for personal insults or caps. You may want to go over the [Contribution Guidelines](https://github.com/freeCodeCamp/freeCodeCamp/blob/master/CONTRIBUTING.md) and read the [Code of Conduct](https://www.freecodecamp.org/news/code-of-conduct/).\r\n\r\n1. Do you get any error messages in the console when you try to switch modes?\r\n\r\n2. Can you try in [Incognito mode](https://support.google.com/chrome/answer/95464) and/or in Firefox just to test?\r\n\r\nI can't reproduce it. So we need something more to go on.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1403", "user": "rocnogu", "root": "ROOT140", "reply_to": "COM1402", "timestamp": "2020-03-08T02:40:30Z", "text": "@lasjorg\r\ni dint yet started the insults. its called personal observation. look it up.\r\n\r\n1 what consoles and what modes? (did you actually read the ''To Reproduce'' ????? i have the feeling you didnt)\r\n\r\n2 i don't have firefox at all. never had.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1404", "user": "rocnogu", "root": "ROOT140", "reply_to": "COM1403", "timestamp": "2020-03-08T02:55:01Z", "text": "@lasjorg\r\nafter bit thinking...\r\nconsole is the settings page?\r\nmodes is night/light modes?\r\n\r\nregardless firefox, ill just repeat my self:\r\ni tried to log in from microsoft edge and torch browser but it failed. should i open one more bug report?\r\n\r\nnow i have the feeling you didn't read anything at all.\r\ndid you try to do this from ANY other browser? or you just assume that if it works for you work for absolutely everyone?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1405", "user": "rocnogu", "root": "ROOT140", "reply_to": "COM1404", "timestamp": "2020-03-08T03:18:48Z", "text": "firefox give the same error", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1406", "user": "RandellDawson", "root": "ROOT140", "reply_to": "COM1405", "timestamp": "2020-03-08T03:47:07Z", "text": "@ronaldcs I am closing this issue as you keep throwing out insults when we are only trying to help. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1407", "user": "raisedadead", "root": "ROOT140", "reply_to": "COM1406", "timestamp": "2020-03-08T10:34:54Z", "text": "Hi @rocnogu \r\n\r\nI am from the freeCodeCamp.org Staff.\r\n\r\nI would like to draw your attention that freeCodeCamp is safe place for all. You are currently in violation of our [code of conduct](https://www.freecodecamp.org/news/code-of-conduct/), with comments.\r\n\r\nWe sure understand that you would like to report something is broken or not working, but we absolutely do not tolerate any violation of the CoC.\r\n\r\nWe have gone ahead and banned your account from posting comments on freeCodeCamp.org\r\n\r\nIf you wish to get this re-instated please let us know, why we should do that. Have a great day ahead.\r\n\r\nThanks.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT141", "user": "ryanolsonx", "root": "ROOT141", "reply_to": null, "timestamp": "2018-04-13T17:30:52Z", "text": "Windows update failed: Access is denied Log from %HOME%\\AppData\\Local\\Temp\\vscode-inno-updater.log\r \r ```\r Apr 13 11:27:40.666 INFO Starting: C:\\Program Files\\Microsoft VS Code\\Code.exe, false\r Apr 13 11:27:40.670 INFO Checking for running Code.exe processes... (attempt 1)\r Apr 13 11:27:40.670 INFO Code.exe is running, wait a bit\r Apr 13 11:27:41.148 INFO Checking for running Code.exe processes... (attempt 2)\r Apr 13 11:27:41.153 INFO Code.exe is running, wait a bit\r Apr 13 11:27:41.654 INFO Checking for running Code.exe processes... (attempt 3)\r Apr 13 11:27:41.666 INFO Code.exe is not running\r Apr 13 11:27:41.666 INFO Starting update, silent = false\r Apr 13 11:27:41.691 INFO do_update: \"C:\\\\Program Files\\\\Microsoft VS Code\\\\Code.exe\", _\r Apr 13 11:27:41.692 INFO move_update: \"C:\\\\Program Files\\\\Microsoft VS Code\\\\unins000.dat\", _\r Apr 13 11:27:41.696 INFO Delete: \"Code.exe\" (attempt 1)\r Apr 13 11:27:41.744 INFO Delete: \"Code.exe\" (attempt 2)\r Apr 13 11:27:41.945 INFO Delete: \"Code.exe\" (attempt 3)\r Apr 13 11:27:42.396 INFO Delete: \"Code.exe\" (attempt 4)\r Apr 13 11:27:43.197 INFO Delete: \"Code.exe\" (attempt 5)\r Apr 13 11:27:44.448 INFO Delete: \"Code.exe\" (attempt 6)\r Apr 13 11:27:46.249 INFO Delete: \"Code.exe\" (attempt 7)\r Apr 13 11:27:48.700 INFO Delete: \"Code.exe\" (attempt 8)\r Apr 13 11:27:51.901 INFO Delete: \"Code.exe\" (attempt 9)\r Apr 13 11:27:55.952 INFO Delete: \"Code.exe\" (attempt 10)\r Apr 13 11:28:00.953 INFO Delete: \"Code.exe\" (attempt 11)\r Apr 13 11:28:00.953 ERRO Access is denied. (os error 5)\r ```\r \r On Windows 10 64 bit", "meta": {"posReactions": "14", "negReactions": "0"}}
{"id": "COM1410", "user": "vscodebot[bot]", "root": "ROOT141", "reply_to": "ROOT141", "timestamp": "2018-04-13T17:30:57Z", "text": "(Experimental duplicate detection)\nThanks for submitting this issue. Please also check if it is already covered by an existing one, like:\n- [Failed to install VS Code update. Please download and reinstall VS Code. os error 145 (#47778)](https://www.github.com/Microsoft/vscode/issues/47778) <!-- score: 0.748 -->\n- [Failed to install VS Code update. Please download and resinstall VS Code. (#47494)](https://www.github.com/Microsoft/vscode/issues/47494) <!-- score: 0.591 -->\n<!-- potential_duplicates_comment -->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1411", "user": "joaomoreno", "root": "ROOT141", "reply_to": "COM1410", "timestamp": "2018-04-25T13:26:44Z", "text": "This is a puzzle to me, because we know Code isn't running... so why can't the updater remove Code... unless it is really running?\r\n\r\n---\r\n\r\n@ryanolsonx @gitDylanHub @OfficerHalf @SwingCoder911\r\n\r\nCan you run this little app I've created, while Code is running?  [rust-playground.zip](https://github.com/Microsoft/vscode/files/1947172/rust-playground.zip)\r\n\r\nIt will output all running process numbers and names. Something like this:\r\n\r\n![image](https://user-images.githubusercontent.com/22350/39248610-db1c90c6-489c-11e8-80d1-d4ea07835502.png)\r\n\r\nDoes Code appear in that list, for you? Can you show me the output of the app in your system?\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1412", "user": "OfficerHalf", "root": "ROOT141", "reply_to": "COM1411", "timestamp": "2018-04-25T14:09:34Z", "text": "I'll do you one better. I'm attaching the output of that before running the update, while running the update, and at the point when I get the error message.\r\n[pre-update.txt](https://github.com/Microsoft/vscode/files/1947327/pre-update.txt)\r\n[mid-update2.txt](https://github.com/Microsoft/vscode/files/1947330/mid-update2.txt)\r\n[error.txt](https://github.com/Microsoft/vscode/files/1947331/error.txt)\r\n\r\nIt certainly doesn't look like Code is running. That doesn't necessarily mean that some other process isn't preventing its deletion, though.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1413", "user": "joaomoreno", "root": "ROOT141", "reply_to": "COM1412", "timestamp": "2018-04-25T14:32:23Z", "text": "@OfficerHalf Awesome, it's great that you can reliably reproduce it. Any thoughts on who might be preventing that deletion? Just to confirm, the setup runs elevated, correct? Does the `inno-updater.exe` process also run elevated?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1414", "user": "OfficerHalf", "root": "ROOT141", "reply_to": "COM1413", "timestamp": "2018-04-25T14:45:45Z", "text": "Well, there are at least two pieces of security software running on my machine: ESET Security and CrowdStrike Falcon (though CrowdStrike is a recent addition, and I think this issue was present before it was installed), neither of which I have any control over. There are also various other controls in place as this is a managed Enterprise installation of Windows. I have co-workers that use Code without issue though so I doubt it's those. My guess was more along the lines of zombie processes spawned by Code that were still holding some resource.\r\n\r\nA quick check in the task manager shows that all three update processes (inno_updater.exe, CodeSetup-insider-guid.exe, and CodeSetup-insider-guid.tmp) are elevated.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1415", "user": "joaomoreno", "root": "ROOT141", "reply_to": "COM1414", "timestamp": "2018-04-25T15:56:42Z", "text": "OK. I just need you to use the task manager and find those zombie processes and what is their full command line.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1416", "user": "OfficerHalf", "root": "ROOT141", "reply_to": "COM1415", "timestamp": "2018-04-25T16:13:48Z", "text": "[FindZombieHandles](https://github.com/randomascii/blogstuff/tree/master/FindZombieHandles) reports nothing. I'm at a loss.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1417", "user": "joaomoreno", "root": "ROOT141", "reply_to": "COM1416", "timestamp": "2018-04-25T16:56:26Z", "text": "And can you manually delete the executable file yourself, in the file explorer?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1418", "user": "OfficerHalf", "root": "ROOT141", "reply_to": "COM1417", "timestamp": "2018-04-26T13:07:37Z", "text": "I can delete it manually. Even attempted to do so during the update, though it still failed with a complaint that the file *didn't* exist. Make up your mind, updater... \ud83d\ude01 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1419", "user": "joaomoreno", "root": "ROOT141", "reply_to": "COM1418", "timestamp": "2018-04-26T13:34:48Z", "text": "The updater, as admin, can't. Yet you can easily delete it. \ud83e\udd14  Did you get an elevation prompt to delete the file?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14110", "user": "OfficerHalf", "root": "ROOT141", "reply_to": "COM1419", "timestamp": "2018-04-26T13:55:40Z", "text": "I was not asked to elevate. I just get the usual 'are you sure you want to delete this' prompt.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14111", "user": "gitDylanHub", "root": "ROOT141", "reply_to": "COM14110", "timestamp": "2018-05-08T12:16:59Z", "text": "Same issue that was originally reported here with the most recent update as well.  So, had this issue on 1.22 and again now on 1.23.  Be kind of annoying if I have to uninstall and download to get the latest features.  Definitely a work related only issue though, can update on my personal easily. Probably good old McAfee locking everything down in the registries with some unique rule. ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14112", "user": "joaomoreno", "root": "ROOT141", "reply_to": "COM14111", "timestamp": "2018-05-29T14:28:24Z", "text": "@OfficerHalf Hope you're still here and facing the issue! I have one more ask for you. Can you reproduce it and upon seeing the error message popup, can you use Process Hacker and figure out whether `inno_updater.exe` is indeed elevated? ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14113", "user": "OfficerHalf", "root": "ROOT141", "reply_to": "COM14112", "timestamp": "2018-05-29T14:41:30Z", "text": "Though I have no idea what changed, I'm actually no longer able to reproduce this. If it shows back up I'll let you know, but I'm not using Insiders on my work machine anymore - mostly because of this bug (I didn't want to get as many update notifications that I couldn't do anything about).\r\n\r\nI installed Insiders 1.23.0 and successfully updated to 1.24.0.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14114", "user": "joaomoreno", "root": "ROOT141", "reply_to": "COM14113", "timestamp": "2018-05-29T15:20:37Z", "text": "Too bad... a lot of other users are hitting it too (see duplicate issues linked), I was hoping we could narrow down further why this happens.\r\n\r\nMy current thinking is that `inno_updater.exe` actually wouldn't run as elevated, even though it would be spawned from an elevated process. Which is something I clearly can't repro:\r\n\r\n<img width=\"1351\" alt=\"screen shot 2018-05-29 at 17 13 00\" src=\"https://user-images.githubusercontent.com/22350/40668374-98cd5b50-6364-11e8-8a72-868e62de6386.png\">\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14115", "user": "joaomoreno", "root": "ROOT141", "reply_to": "COM14114", "timestamp": "2018-05-30T09:53:03Z", "text": "@scragly @amitesh-gaurav @Clarkey @azarc3 @abmagil @Austen-Oberheu @DeltaIndiana @nickdeppe @maddes @alvarofelipe12 @ojintoad @LouieK22\r\n\r\nI'm pinging all of you since you all reported the same error `Access is denied`. I want to ask you to try to reproduce it, so we get more info from it.\r\n\r\nIn order to reproduce it, close Code, open the `C:\\Program Files\\Microsoft VS Code\\resources\\app\\product.json` and change the `commit` field to `outdated`. Start Code, you should get an update flow. If the issue reproduces and you get the dialog which asks you to send us the log file, please do the following:\r\n\r\n1. Open [Process Hacker](https://processhacker.sourceforge.io/)\r\n2. Enable the `Elevation`, `Integrity` and `Command line` columns in Process Hacker\r\n3. Search for any `Code.exe` processes running. If they are running, copy the full command line of each and show me.\r\n4. Check what is the elevation and integrity of the `inno_updater.exe`, does it match its parent?\r\n\r\nThanks for your help here, looking forward to learn more about this and fixing it!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14116", "user": "abmagil", "root": "ROOT141", "reply_to": "COM14115", "timestamp": "2018-05-31T13:48:42Z", "text": "@joaomoreno on my machine, the `C:\\Program Files\\Microsoft VS Code\\app` folder does not exist...\r\n\r\nThis is after a couple more failed upgrades (same symptoms as https://github.com/Microsoft/vscode/issues/49460#issue-321192492) if that provides any insight.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14117", "user": "joaomoreno", "root": "ROOT141", "reply_to": "COM14116", "timestamp": "2018-06-01T08:23:38Z", "text": "@abmagil Please completely remove VS Code, reinstall it and give the above steps a try. Thanks!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14118", "user": "abmagil", "root": "ROOT141", "reply_to": "COM14117", "timestamp": "2018-06-01T13:25:49Z", "text": "@joaomoreno same story with a fresh install.\r\n\r\n1. I went through \"Add or Remove Programs\", found \"Microsoft Visual Studio Code\" and uninstalled it.\r\n2. I then went to https://code.visualstudio.com/ and downloaded the Stable version for windows.\r\n3. I followed all installation steps, then went to the path you mentioned. Here is what I see:\r\n\r\n![image](https://user-images.githubusercontent.com/2807766/40843004-9b83e54c-657d-11e8-934d-cae84306a900.png)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14119", "user": "joaomoreno", "root": "ROOT141", "reply_to": "COM14118", "timestamp": "2018-06-01T14:21:39Z", "text": "Oh man, sorry about that. It's in `resources\\app`. I've updated the original post.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14120", "user": "abmagil", "root": "ROOT141", "reply_to": "COM14119", "timestamp": "2018-06-01T14:51:08Z", "text": "I updated the json file and reopened code, but the update flow didn't kick in automatically.  I kicked off an update flow from the gear in the lower left which went through successfully.  I am currently running 1.23.1\r\n\r\nI will keep an eye on this ticket and, if the problem rears its head again, return to the steps you listed.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14121", "user": "joaomoreno", "root": "ROOT141", "reply_to": "COM14120", "timestamp": "2018-06-04T10:03:42Z", "text": "@abmagil That's great to know, looking forward to it!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14122", "user": "OfficerHalf", "root": "ROOT141", "reply_to": "COM14121", "timestamp": "2018-06-04T14:14:59Z", "text": "I was able to repro this again. Guess it working was a fluke.\r\n\r\n- inno_updater.exe *is* elevated\r\n- inno_updater.exe Command Line: `\"C:\\DevTools\\VSCodeStable\\tools\\inno_updater.exe\" \"C:\\DevTools\\VSCodeStable\\Code.exe\" false`\r\n- There are no Code.exe (or Code-Insiders.exe) processes.\r\n\r\nI can't check 'Integrity' as I'm not able to run Process Hacker due to the security suite my company has running on my machine. This info is all from the bog-standard Task Manager.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14123", "user": "joaomoreno", "root": "ROOT141", "reply_to": "COM14122", "timestamp": "2018-06-05T07:02:26Z", "text": "> security suite my company has running on my machine\r\n\r\nThe problem could very well be related to this.\r\n\r\n@scragly @amitesh-gaurav @Clarkey @azarc3 @abmagil @Austen-Oberheu @DeltaIndiana @nickdeppe @maddes @alvarofelipe12 @ojintoad @LouieK22\r\n\r\nGuys/gals, are your machines also managed by a corporation?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14124", "user": "maddes", "root": "ROOT141", "reply_to": "COM14123", "timestamp": "2018-06-05T07:55:11Z", "text": "Mine is, yes.\n\nOn Tue, Jun 5, 2018 at 4:03 AM Jo\u00e3o Moreno <notifications@github.com> wrote:\n\n> security suite my company has running on my machine\n>\n> The problem could very well be related to this.\n>\n> @scragly <https://github.com/scragly> @amitesh-gaurav\n> <https://github.com/amitesh-gaurav> @Clarkey <https://github.com/Clarkey>\n> @azarc3 <https://github.com/azarc3> @abmagil <https://github.com/abmagil>\n> @Austen-Oberheu <https://github.com/Austen-Oberheu> @DeltaIndiana\n> <https://github.com/DeltaIndiana> @nickdeppe\n> <https://github.com/nickdeppe> @maddes <https://github.com/maddes>\n> @alvarofelipe12 <https://github.com/alvarofelipe12> @ojintoad\n> <https://github.com/ojintoad> @LouieK22 <https://github.com/LouieK22>\n>\n> Guys/gals, are your machines also managed by a corporation?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/Microsoft/vscode/issues/47841#issuecomment-394603217>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABY2am8zMCEy_VUN9RlABFcjCa5EGleDks5t5i1egaJpZM4TTz7T>\n> .\n>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14125", "user": "mcleary", "root": "ROOT141", "reply_to": "COM14124", "timestamp": "2018-06-05T09:01:38Z", "text": "Mine as well, I managed to solve this by manually running the installer.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14126", "user": "LouieK22", "root": "ROOT141", "reply_to": "COM14125", "timestamp": "2018-06-05T11:20:58Z", "text": "Mine is not", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14127", "user": "alvarofelipe12", "root": "ROOT141", "reply_to": "COM14126", "timestamp": "2018-06-06T01:52:38Z", "text": "Hello, i'm sorry but that PC is property of my company and the technic support guy say thats not possible to do that procedure.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14128", "user": "joaomoreno", "root": "ROOT141", "reply_to": "COM14127", "timestamp": "2018-06-06T10:09:31Z", "text": "You can still use the old update mechanism with the following setting:\r\n\r\n```\r\n\"update.enableWindowsBackgroundUpdates\": false\r\n```\r\n\r\nThough it would be pretty cool if we could make the background updates work on your machines... I would need some more feedback, like what I mentioned above in https://github.com/Microsoft/vscode/issues/47841#issuecomment-393101777", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14129", "user": "scragly", "root": "ROOT141", "reply_to": "COM14128", "timestamp": "2018-06-07T09:59:35Z", "text": "Just updated to 1.24.0 without issue this time with the in-client updater. My PC is not managed by a corporation. \r\n\r\nJust as a note though, which could be unrelated, I'm not sure; I actually had seemingly the exact same issue as before with a Git for Windows update recently. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT142", "user": "SaintPeter", "root": "ROOT142", "reply_to": null, "timestamp": "2018-06-01T21:19:32Z", "text": "ES6 - Write Higher Order Arrow Functions - About Chaining, Needs Clarification #### Describe your problem and - if possible - how to reproduce it\r Challenge ES6 - Write Higher Order Arrow Functions \r The examples show moving from normal `function` to the ES6 arrow function.  However, the challenge is about \"chaining\" multiple functions together.  It is super unclear how the example code would lead one to chaining a filter and map function together.  This is really a better discussion for the functional programming section.\r \r Additionally, the filter function requires that users understand how to determine if a number is an integer or not.  There is nothing in the prior curriculum which would make it clear to a new coder how to do this.  While you do talk about the \"parseInt\" function, it's never used in the context of comparing a number to itself.  A better filter function might be \"positive numbers\" instead, which is a much simpler comparison.\r \r I was attempting to help someone understand this one today and I was initially flummoxed as to how to solve it.\r \r Once I realized it was about chaining, I was able to write a solution like this:\r ```js\r const squaredIntegers = arr\r     .filter(elem => elem == parseInt(elem))\r     .map(elem => elem * elem);\r ```\r \r I don't believe that there is another way to solve this using higher order functions and arrow functions.  There is no solution in the seed file, so I'm not sure exactly what the authors had in mind.\r \r In short, this challenge badly needs clarification and simplification.  It may be entirely inappropriate for this section of challenges.  I could see it after a new challenge called \"How to Chain Higher Order functions\" or something like that.\r \r #### Add a Link to the page with the problem\r https://learn.freecodecamp.org/javascript-algorithms-and-data-structures/es6/write-higher-order-arrow-functions/\r ", "meta": {"posReactions": "14", "negReactions": "0"}}
{"id": "COM1420", "user": "raisedadead", "root": "ROOT142", "reply_to": "ROOT142", "timestamp": "2018-06-01T22:47:35Z", "text": "Look who is here..! I know this tracker is strictly for issue related discussion, but its awesome to see you here. \r\n\r\nThanks for the report.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1421", "user": "SaintPeter", "root": "ROOT142", "reply_to": "COM1420", "timestamp": "2018-06-04T15:35:27Z", "text": "Are these no longer being tagged/assigned?  Is someone responsible for the new curriculum?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1422", "user": "raisedadead", "root": "ROOT142", "reply_to": "COM1421", "timestamp": "2018-06-05T09:00:47Z", "text": "Hi Rex, sorry about the delay in getting back to you. \r\n\r\nYup.. you are right at the moment we do not have anyone to actively oversee the curriculum's quality. We would love some help though. Its been a little while since the new curriculum was first brought in (I mean added to the beta) by the contributors, so yeah it could use the polishing up.\r\n\r\nI know of a lot of contributors who have done some great work like @ahmadabdolsaheb @mstellaluna and @scissorsneedfoodtoo recently, just to name a few off the top of my head.\r\n\r\nThe other thing is that us shipping the platform (splitting up the curriculum infra and the user backend) has broken the contributing pipeline. The new challenge infra is supper snappy and powerful BTW. So some real potential there, that we did not have previously. No more monkey patching `console.log` !!\r\n\r\nThe challenge and user schema has changed, the tooling has changed (for good though, which we will see in a few days hopefully, when we fix things for the local setup).\r\n\r\nWe are working toward improving to the DX for contributors, as soon as we have the production really stable for us to focus on the contributions. There has been a great surge in people wanting to contribute. We are just a little swamped the moment with the support and user priority issues.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1423", "user": "raisedadead", "root": "ROOT142", "reply_to": "COM1422", "timestamp": "2018-06-05T09:03:41Z", "text": "P.S: Your baby [Contributors Chat room](https://gitter.im/FreeCodeCamp/Contributors) is still the place where everyone hangs out, so if you would like to catch up, you know where to find us.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1424", "user": "moT01", "root": "ROOT142", "reply_to": "COM1423", "timestamp": "2018-06-07T17:13:17Z", "text": "I would agree with this issue - I got real stuck on it knowing quite well how to use the array methods - it doesn't say anything about using `.map` and it is not used or taught at all up to this point - same with testing if it's an integer - that's not too tough to figure out I don't think, but it does complicate things - the challenge description only talks about using `.filter` and the instructions say...\r\n```\r\nUse arrow function syntax to compute the square of only the positive integers (fractions are not integers) in the array realNumberArray and store the new array in the variable squaredIntegers.\r\n```\r\nFrom those instructions it seems like the challenge wants you to use just `.filter` to accomplish this - challenges are supposed to teach a single thing, this one introduces too much and feels way too complicated - and it isn't clear to me what we are even supposed to be learning on this one", "meta": {"posReactions": "8", "negReactions": "0"}}
{"id": "COM1425", "user": "SaintPeter", "root": "ROOT142", "reply_to": "COM1424", "timestamp": "2018-06-07T20:03:20Z", "text": "I just reviewed the curriculum leading up to this challenge.\r\n1. There doesn't appear to be an introduction to the concept of a callback function or functions as first class object.\r\n2. No introduction to anonymous functions (except two challenges prior)\r\n3. No mention of either map or filter\r\n\r\nAll told, I think this challenge should just be removed or moved to the functional programming section.", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM1426", "user": "moT01", "root": "ROOT142", "reply_to": "COM1425", "timestamp": "2018-06-07T21:17:58Z", "text": "in general the whole es6 section seems to too advanced and/or complexly written (or at least some of it), and the javascript section as a whole seems a little scattered and not simple enough for beginners, or maybe just doesn't progress gradually enough or something - I want to suggest some rearranging of some sections/challenges but Im not sure on a better way yet - there's more than a few forum posts from campers struggling in this area of the curriculum\r\n\r\nhttps://forum.freecodecamp.org/t/best-order-to-follow-js-modules/197705", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1427", "user": "Maarondesigns", "root": "ROOT142", "reply_to": "COM1426", "timestamp": "2018-06-19T02:48:54Z", "text": "Thanks for this post!\r\nI was super confused trying to solve this as well and I've even been exposed to .map() and higher order functions previously. I thought for sure there would be a way to solve it with only .filter() because they haven't even said what the other functions do when you get to this exercise, or that it's possible to chain them together. I managed to solve it with a really ugly workaround, still using .map() but forgot about .parseInt() and that you can chain the functions...\r\n\r\n```\r\nconst filteredIntegers = arr.filter(n => n > 0 && n%2 == 1|| n%2 == 0); \r\nconst squaredIntegers = filteredIntegers.map(x => Math.pow(x,2));\r\n```\r\n\r\nCheers!", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1428", "user": "RenaudGagne", "root": "ROOT142", "reply_to": "COM1427", "timestamp": "2018-06-19T19:42:45Z", "text": "Glad that I'm not alone. Please add more steps leading to that exercise. In the meanwhile, I'm going to leave ES6 module, move ahead and come back to it when I'll be able to understand. It's the very first time since I got started that I genuinely can say something negative about the curriculum...all the previous exercises made sense in the linear progression...not this one.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1429", "user": "nathanhannig", "root": "ROOT142", "reply_to": "COM1428", "timestamp": "2018-08-02T05:36:24Z", "text": "Maybe map, filter, reduce need to be explained beforehand. But chaining is not required and there are multiple solutions I suppose.\r\n\r\n```\r\nconst squaredIntegers = arr.reduce((accumulator, currentValue) => {\r\n  if(currentValue > 0 && currentValue % 1 === 0) {\r\n    accumulator.push(currentValue * currentValue);\r\n  }\r\n\r\n  return accumulator;\r\n}, []);\r\n```", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM14210", "user": "quinn-codes-synthesis", "root": "ROOT142", "reply_to": "COM1429", "timestamp": "2018-09-10T08:00:22Z", "text": "Hi! I'm a new coder who just got to this point in the challenges. It definitely took some serious google searching to figure out a solution, since .map(), .filter(), and .reduce() had not been previously mentioned. I also only really grasped that I could chain and nest functions like:\r\n\r\n`const squaredIntegers = arr.filter((num) => num > 0 && num == Math.floor(num)).map((num) => num * num);`\r\n\r\ndue to having learned some through Grasshopper before I started with FCC. I think some challenge on that concept before this one would've been useful, as well as challenges on filter, map, and reduce.\r\n\r\nI know the chaining isn't necessarily required... but at this point in the challenges where the theme seems to be on condensing code, IMO it's the perfect time to bring it up.\r\n\r\nOr in the meantime, maybe we could just point the text for the map, filter, and reduce to their relevant challenges later on, or to relevant tutorials elsewhere on the internet if FCC doesn't currently have challenges for those concepts?", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM14211", "user": "chiliphrosting", "root": "ROOT142", "reply_to": "COM14210", "timestamp": "2018-09-11T14:35:15Z", "text": "Hi All, \r\nThis one was a little fun to figure it out... Here are the steps I took to get the answer. I know it's a slower approach but I had to make sure that I could isolate each step before getting to the next one. I hope this helps! \r\n`<ol>\r\n<li>Bring all the code into a dev console. I use chrome (I always do this first).</li>\r\n<li>Change all the 'const' into 'var'. The reason for this is to keep copying and pasting the code to test it otherwise you will need to open a new tab to run it</li>\r\n<li>*Keep in mind that realNumberArray is what is being filtered!</li>\r\n<li>Only test that one value passes. Eg. - Test to make sure that the 4 goes through</li>\r\n<li>Once known that a value can be passed parseInt(arr) can be used</li>\r\n<li>Before using .filter with .map I isolated .map to pass a value, in order to make sure that the value does pass</li>\r\n<li>Combine .filter and .map</li>\r\n</ol>\r\n`\r\n/***************************************************SPOILER ALERT*****************************************/\r\n<br>\r\n<br>\r\nnumbers in here correspond to the list above: \r\n<br><br>\r\n____________________________________________________________________________________\r\n<br>\r\n4. <br><br>\r\nvar realNumberArray = [4, 5.6, -9.8, 3.14, 42, 6, 8.34];\r\n<br>\r\nvar squareList = (arr) => {\r\n<br>\r\n  \"use strict\";\r\n  // change code below this line\r\n<br>\r\n  var squaredIntegers = \r\n<strong><em>realNumberArray</em></strong>\r\n<br>\r\n\t.filter((arr) => arr === 4)//arr;\r\n<br>\r\n  // change code above this line\r\n<br>\r\n  return squaredIntegers;\r\n<br>\r\n};\r\n<br>\r\n\r\n<br>\r\nvar squaredIntegers = squareList(realNumberArray);\r\nconsole.log(squaredIntegers); /***answer will return 4**/\r\n\r\n<br>\r\n<br>\r\n___________________________________________________________________________<br>\r\n5.\r\n<br>\r\n<br>\r\n  var squaredIntegers = \r\n<br>\r\n<strong><em>realNumberArray</em></strong>\r\n<br>\r\n.filter((arr) => arr == parseInt(arr)) // value will return [4, 42, 6] once it's executed\r\n\r\n<br>\r\n<br>\r\n________________________________________________________________________<br>\r\n7.\r\n<br>\r\n<br>\r\n  var squaredIntegers = \r\n<br>\r\n<strong><em>realNumberArray</em></strong>\r\n<br>\r\n\t.filter((arr) => arr == parseInt(arr))//arr;\r\n<br>\r\n\t.map((arr) => arr*arr);\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14212", "user": "kunzler", "root": "ROOT142", "reply_to": "COM14211", "timestamp": "2018-09-25T05:05:26Z", "text": "I had to just skip it for now.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14213", "user": "75cent", "root": "ROOT142", "reply_to": "COM14212", "timestamp": "2018-10-02T00:38:20Z", "text": "Agreed, I was chugging along fine and then hit this one which felt like a massive leap in difficulty from any of the previous.  Mostly due that a lot of the concepts required to complete it were completely foreign as they had not been explained in prior lessons.\r\n\r\nSkipping for now also.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14214", "user": "Darrenliiu", "root": "ROOT142", "reply_to": "COM14213", "timestamp": "2018-10-04T09:09:11Z", "text": "here's my answer, i modified @Maarondesigns answer by chaining the functions but had to add the Math.sign(num) !== -1 to get rid of the -2\r\n\r\nconst realNumberArray = [4, 5.6, -9.8, 3.14, 42, 6, 8.34, -2];\r\nconst squareList = (arr) => {\r\n  \"use strict\";\r\n  // change code below this line\r\n  const squaredIntegers = arr.filter((num) => num > 0 && num%2 === 1 || num%2 === 0 && Math.sign(num) !== -1 ).map( (num) => Math.pow(num, 2));\r\n  // change code above this line\r\n  return squaredIntegers;\r\n};\r\n// test your code\r\nconst squaredIntegers = squareList(realNumberArray);\r\nconsole.log(squaredIntegers);", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14215", "user": "afefdrissi", "root": "ROOT142", "reply_to": "COM14214", "timestamp": "2018-10-15T20:58:55Z", "text": "**This is my solution:**\r\n// change code below this line\r\n const squaredIntegers = arr.filter((int) => Number.isInteger(int) && int >=0).map(x => x * x);\r\n// change code above this line\r\n**And this can work as well:**\r\n// change code below this line\r\nconst squaredIntegers = arr.filter((int) => int >=0 && int == parseInt(int)).map(x => x * x);\r\n// change code above this line", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14216", "user": "ziaongit", "root": "ROOT142", "reply_to": "COM14215", "timestamp": "2018-10-18T09:35:43Z", "text": "`const squaredIntegers = arr.filter((arr) => Number.isInteger(arr) && arr > 0).map((arr) => arr = arr * arr);`", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM14217", "user": "tommyprevatt", "root": "ROOT142", "reply_to": "COM14216", "timestamp": "2018-10-26T00:24:14Z", "text": "Just came to put my two cents in. I agree with the initial assessment of SaintPeter. I got totally lost on this one and I'm not new to programming, just new to JavaScript. I quickly realized there was a knowledge gap between what I know about these methods and what is expected to solve the problem. ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM14218", "user": "scissorsneedfoodtoo", "root": "ROOT142", "reply_to": "COM14217", "timestamp": "2018-10-26T03:08:11Z", "text": "@tommyprevatt, I agree, several more challenges need to be added to the ES6 section to fill in said knowledge gaps. @SaintPeter had some really great suggestions for possible challenge topics that could be added before this one, but I haven't taken the time to write them up yet.\r\n\r\nIf you have any suggestions for possible challenges you'd like to see before this one, please leave a comment. Or even better, please help us make a new challenge! There's still some time left in Hacktoberfest :+1: ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14219", "user": "bartlomiej-przymus", "root": "ROOT142", "reply_to": "COM14218", "timestamp": "2018-10-27T22:12:08Z", "text": "im really feeling stupid for not being able to figure this one out :(", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14220", "user": "chrisdel101", "root": "ROOT142", "reply_to": "COM14219", "timestamp": "2018-11-08T21:05:25Z", "text": "Is this still an issue? If so, then if I understand the problem correctly, the solution will be creating a text base explanation of how arrow functions work over ES5, emphasizing the chaining of arrow functions, right? I am pretty green PR-wise so not sure if I should just start, I don't want to do it wrong, etc. \r\nIf the above is correct I'll do this.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14221", "user": "SaintPeter", "root": "ROOT142", "reply_to": "COM14220", "timestamp": "2018-11-08T21:53:11Z", "text": "@chrisdel101 My suggestion would be to greatly simplify the problem such that it can be solved by changing a normal function definition into an arrow function definition.  It's not even important that the output of the function be checked, just the syntax.  Just make sure that the instructions line up and that the tests check for the correct syntax.\r\n\r\nI think that would be the most direct solution.\r\n\r\nI'd say go for it!  Making these types of changes was how I got started.  It's great experience!", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14222", "user": "chrisdel101", "root": "ROOT142", "reply_to": "COM14221", "timestamp": "2018-11-12T01:07:41Z", "text": "I started on this. 2 problems: \r\n\r\n1. I can't see my changes in local dev. I posted about it here. It must be something like I am looking at the wrong file https://www.freecodecamp.org/forum/t/not-seeing-changes-in-local-dev-env/239352/3 \r\n2. Where is the code for the tests? The YAML has this:\r\n`testString: getUserInput => assert(getUserInput('index').match(/const\\s+squaredIntegers/g), '<code>squaredIntegers</code> should be a constant variable (by using <code>const</code>).');`\r\nIs this the actual test? What runs this? It's hard to read. What is the best way to work on functions inside a file like this?\r\n\r\nI was going to re-write the problem a bit to check for syntax and change the tests. Not really sure how these tests within a markdown file work.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14223", "user": "scissorsneedfoodtoo", "root": "ROOT142", "reply_to": "COM14222", "timestamp": "2018-11-12T03:58:26Z", "text": "@chrisdel101, great that you started on this!\r\n\r\nSeeing local changes is a bit of a process. First you need to reseed the db with `npm run seed`, then enter `npm run bootstrap`. When the last command is finished, enter `npm run develop`, then refresh the page when that's ready. You should be able to see your changes after that.\r\n\r\nAs for number 2, yes, that's the test. Tests come in pairs with a string for text and another for the testString. Text is what the user will see on the left side of the page before tests are run. The test string itself is made up of two parts--the first is the actual test, then the string after the comma which is shown in the console if the test fails.\r\n\r\nAs for the actual test suite, I believe we're using Chai. There's a cheat sheet that might help you write your tests here: https://github.com/freeCodeCamp/freeCodeCamp/blob/da0df12ab7b3bae46c2a376da246a6c499afd88b/guide/english/miscellaneous/chaijs-cheatsheet/index.md\r\n\r\nThere are a number of ways you could work with functions here. How were you thinking of rewriting the challenge? A lot of the times the tests look at the return value of the function. The third test currently does this: \r\n\r\n```\r\n- text: <code>squaredIntegers</code> should be <code>[16, 1764, 36]</code>\r\n    testString: assert.deepStrictEqual(squaredIntegers, [16, 1764, 36], '<code>squaredIntegers</code> should be <code>[16, 1764, 36]</code>');\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14224", "user": "chrisdel101", "root": "ROOT142", "reply_to": "COM14223", "timestamp": "2018-11-12T15:08:35Z", "text": "@scissorsneedfoodtoo Reran all the npm scripts and my changes are reflected after a seed, but my changes are still not reflected on save. I need to run `npm run bootstrap` to see them. Is there a way around this?\r\n\r\n I'm familiar with Chai but will have to play around with the tests to fully get what is going on.\r\n\r\nAs for what I was going to re-write, just going to focus more on the syntax and remove the need for the function to be written in a particular way, i.e. it has to have an array named a certain way inside of it. This kind of change is what @SaintPeter suggested I do above.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14225", "user": "MoonCWang", "root": "ROOT142", "reply_to": "COM14224", "timestamp": "2019-01-11T12:30:57Z", "text": "Learning arrow functions is very similar to learning regex (which was excellent btw, kudos to the creators).  One needs to slow down, have lots of practice runs of increasing complexity and then you'll get it.  I am still quite far away from playing with Chai but if no one is actively working on this I'll give it a try.   It can be broken up into three successively difficult challenges if that's OK...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14226", "user": "chrisdel101", "root": "ROOT142", "reply_to": "COM14225", "timestamp": "2019-01-16T22:49:48Z", "text": "@MoonCWang I've got a PR for this that's been there for already since November.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14227", "user": "Mr-Henderson", "root": "ROOT142", "reply_to": "COM14226", "timestamp": "2019-01-24T12:34:47Z", "text": "> const squaredIntegers = arr.reduce((accumulator, currentValue) => { if(currentValue > 0 && currentValue % 1 === 0) { accumulator.push(currentValue * currentValue); } return accumulator; }, []);\r\n\r\nYes I UNDERSTAND most of this yet for the life of me I cannot understand why we truncate the decimal numbers or also current value % 1 === 0 so I have been looking at this problem for 1 hour at least... I do have strong math skills and understanding yet really modulus is just remainder yet what 1===0 so does this represent NAN I seem to be confused by word definitions relative to programming. I try to run the numbers through the function in my head yet this throws me off how am I filtering the decimal numbers.... I thought what if I can just pop that -2 of and make it not exist with pop() to no avail. Moving on now to much time on this.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14228", "user": "imburtonh", "root": "ROOT142", "reply_to": "COM14227", "timestamp": "2019-03-14T14:14:08Z", "text": "I had lots of trouble with this too, until finding this post.  I even tried to copy and paste the solution under \"get a hint\" so that I could work backwards and the hint doesn't pass the test.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14229", "user": "IssamAth", "root": "ROOT142", "reply_to": "COM14228", "timestamp": "2019-10-04T22:55:00Z", "text": "people are just making it too complicated . here is my Solution it's very simple\r\n```\r\nconst squaredIntegers = arr\r\n  .filter(n => n % 1 == 0 && n>0)\r\n  .map(n => n*n);\r\n```\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT143", "user": "salar90", "root": "ROOT143", "reply_to": null, "timestamp": "2015-12-20T14:52:31Z", "text": "RTL text selection When trying to select a RTL substring, the highlighted text seems to be current but if you just press delete button, It will delete another part of the text instead of highlighted.  also double clicking on the text will highlight another word/part of text.   It behaves like the position of the mouse is horizontally invert on the RTL text.  Simulate it: First Test: \u0627\u06cc\u0646 \u06cc\u06a9 \u0645\u062a\u0646 \u0641\u0627\u0631\u0633\u06cc \u0627\u0633\u062a Select \u0627\u06cc\u0646 With mouse down and mouse up and Press Delete button, and it will delete \u0627\u0633\u062a instead of \u0627\u06cc\u0646: \u0627\u06cc\u0646 \u06cc\u06a9 \u0645\u062a\u0646 \u0641\u0627\u0631\u0633\u06cc   Second Test: \u0627\u06cc\u0646 \u06cc\u06a9 \u0645\u062a\u0646 \u0641\u0627\u0631\u0633\u06cc \u0627\u0633\u062a Double click on \u0631\u0633\u06cc \u0631\u0633\u06cc will be Highlighted but if you press delete, \u0627\u06cc\u0646 will be deleted. ", "meta": {"posReactions": "20", "negReactions": "0"}}
{"id": "COM1430", "user": "ebraminio", "root": "ROOT143", "reply_to": "ROOT143", "timestamp": "2016-06-01T09:52:35Z", "text": "To devs, consider reading [1](https://github.com/atom/atom/issues/1849#issuecomment-158680023) and [2](https://github.com/atom/atom/issues/1849#issuecomment-102712443) for getting some context.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1431", "user": "mohataher", "root": "ROOT143", "reply_to": "COM1430", "timestamp": "2016-07-17T13:06:25Z", "text": "Any updates on this issue? \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1432", "user": "salar90", "root": "ROOT143", "reply_to": "COM1431", "timestamp": "2016-08-04T05:07:34Z", "text": "@mohataher I Installed yesterday and problem still exists.\n\n@Majid-Kaffash I think its not a good idea to change the Editors entire direction for every time you want to edit a none English word or sentence. even with text-align:left\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1433", "user": "Majidkn", "root": "ROOT143", "reply_to": "COM1432", "timestamp": "2016-08-04T13:57:31Z", "text": "@salar90 I'm agree with you . But in this situation the only thing that you can do is this :)\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1434", "user": "AbdelrahmanHafez", "root": "ROOT143", "reply_to": "COM1433", "timestamp": "2016-09-06T14:02:19Z", "text": "Although @Majid-Kaffash solution isn't perfect, but it works until there's a better solution. Is there anyway I can make a keybind that toggles this edit in the stylesheet?\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1435", "user": "salar90", "root": "ROOT143", "reply_to": "COM1434", "timestamp": "2016-09-07T05:44:02Z", "text": "Microsoft's Visual Studio Code works perfectly in this case. Maybe Developers can inspire from its opensource codes?\n\nhttps://github.com/Microsoft/vscode\n", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM1436", "user": "abumalick", "root": "ROOT143", "reply_to": "COM1435", "timestamp": "2016-11-03T20:47:10Z", "text": "Brackets works too with RTL language. I think atom and brackets are based on electron ?\nMaybe it can help developers : \n[https://github.com/adobe/brackets/](https://github.com/adobe/brackets/)\nI really want this feature in atom \ud83d\udc4d \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1437", "user": "cben", "root": "ROOT143", "reply_to": "COM1436", "timestamp": "2016-11-04T00:12:48Z", "text": "Brackets is based on CodeMirror.\nCodeMirror has bidi support with mild bugs; the main constraint is all\nlines are left-aligned with LTR base direction:\nhttps://codemirror.net/demo/bidi.html\nThere was a GSoC leading to experimental branch improving things,\nincluding per-line direction, but it hasn't landed:\nhttps://discuss.codemirror.net/t/two-new-experimental-branches-open-for-testing-mobile-and-direction/74\nhttps://rawgit.com/codemirror/CodeMirror/direction/demo/bidi.html\n\nAtom does not use CodeMirror, IIUC atom implemented their own editor\nusing electron.\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1438", "user": "timwienk", "root": "ROOT143", "reply_to": "COM1437", "timestamp": "2016-12-19T16:19:52Z", "text": "Not a solution for \"actual\" RTL support (it probably even makes it very hard to read RTL text), but this way at least bidirectionality doesn't destroy the text (and selection) flow, so it's at least possible to work with files with bidirectional text:\r\n\r\n~~`/* Bidirectional text is broken, so let's pretend it doesn't exist. */`~~\r\n~~`atom-text-editor::shadow {`~~\r\n~~`\t.line {`~~\r\n~~`\t\tunicode-bidi: bidi-override;`~~\r\n~~`\t}`~~\r\n~~`}`~~\r\n\r\n**Edit 2017-01-12:**\r\nSmall update, because of the shadow DOM changes in 1.13.0, the following code should be added to the atom stylesheet instead:\r\n\r\n```less\r\n/* Bidirectional text is broken, so let's pretend it doesn't exist. */\r\natom-text-editor .line {\r\n\tunicode-bidi: bidi-override;\r\n}\r\n```", "meta": {"posReactions": "4", "negReactions": "2"}}
{"id": "COM1439", "user": "amraei", "root": "ROOT143", "reply_to": "COM1438", "timestamp": "2016-12-27T21:52:19Z", "text": "Every update is making it even worse. I was solving this problem in a tricking way by inverse selecting words. For example, previously to select `\u0627\u06cc\u0646` in `\u0627\u06cc\u0646 \u06cc\u06a9 \u0645\u062a\u0646 \u0641\u0627\u0631\u0633\u06cc \u0627\u0633\u062a`, I double-clicked on `\u0627\u0633\u062a` and `\u0627\u06cc\u0646` was being selected.\r\n\r\nBut now in latest version `1.12.7`, even this trick isn't working.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14310", "user": "abumalick", "root": "ROOT143", "reply_to": "COM1439", "timestamp": "2016-12-28T04:28:30Z", "text": "@timwienk Thanks, at least we can edit lines containing Arabic text when adding your code to atom stylesheet", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14311", "user": "jalal246", "root": "ROOT143", "reply_to": "COM14310", "timestamp": "2017-02-04T02:29:04Z", "text": "I have the same problem when I try to write in Arabic, it's really confusing for highlighted text. \r\nAny solutions?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14312", "user": "abumalick", "root": "ROOT143", "reply_to": "COM14311", "timestamp": "2017-02-04T05:10:03Z", "text": "I switched to vscode  because of\r\nthis issue. It supports arabic very well, is open source,  have a lot of\r\nplugins too and is very fast.\r\n\r\nhttps://github.com/Microsoft/vscode\r\n\r\nI did love atom but I really need arabic\r\n\r\n", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM14313", "user": "amraei", "root": "ROOT143", "reply_to": "COM14312", "timestamp": "2017-04-14T13:16:35Z", "text": "Fortunately version 1.15 optimized it. Now updated to 1.16 and this bug still is annoying. I'm really thinking to switch to VSCode. Is there any plan to work on this issue?\r\n\r\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14314", "user": "50Wliu", "root": "ROOT143", "reply_to": "COM14313", "timestamp": "2017-04-15T02:30:14Z", "text": "I can ask around and try to get back to you.\r\n(If I don't respond in a week, ping me again)", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM14315", "user": "abumalick", "root": "ROOT143", "reply_to": "COM14314", "timestamp": "2017-04-27T21:24:32Z", "text": "@50Wliu ping", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14316", "user": "lee-dohm", "root": "ROOT143", "reply_to": "COM14315", "timestamp": "2017-04-28T02:45:34Z", "text": "We do plan to work on this issue but we don't have an ETA for when we'll be able to get to it. If people would like to help this happen sooner than we can get to it, we would be very interested in a well-written pull request.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14317", "user": "abumalick", "root": "ROOT143", "reply_to": "COM14316", "timestamp": "2017-04-28T05:31:19Z", "text": "Can you give indications on where the changes should happen and other\nindications?\nI am a bit lost in the source code\n\nOn Apr 28, 2017 05:46, \"Lee Dohm\" <notifications@github.com> wrote:\n\n> We do plan to work on this issue but we don't have an ETA for when we'll\n> be able to get to it. If people would like to help this happen sooner than\n> we can get to it, we would be very interested in a well-written pull\n> request.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/atom/atom/issues/10132#issuecomment-297892801>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AH_TYeucefckiO-Zo6EF4Rabkiuwbbi_ks5r0VL0gaJpZM4G41pi>\n> .\n>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14318", "user": "lee-dohm", "root": "ROOT143", "reply_to": "COM14317", "timestamp": "2017-04-28T16:31:17Z", "text": "@abumalick I would start with the code governing selections and drill in from there: https://github.com/atom/atom/blob/master/src/selection.coffee", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14319", "user": "mostafamemariani", "root": "ROOT143", "reply_to": "COM14318", "timestamp": "2017-07-31T14:56:41Z", "text": "please fix the problemmm", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14320", "user": "yeganemehr", "root": "ROOT143", "reply_to": "COM14319", "timestamp": "2017-07-31T15:40:29Z", "text": "just use [vs code](https://code.visualstudio.com/)", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14321", "user": "Canon0223", "root": "ROOT143", "reply_to": "COM14320", "timestamp": "2017-08-01T06:04:09Z", "text": "@yeganemehr  Did VS code support RTL label now?  But I didn't  find the way in it's home  page", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14322", "user": "yeganemehr", "root": "ROOT143", "reply_to": "COM14321", "timestamp": "2017-08-01T06:22:46Z", "text": "@Canon0223 We used in VS code in past 6 months and now I can say It's better than atom even if Microsoft developing it.\r\nIt's have way way more efficiency about typescript and tslint and as I can tell uses less resource in my ubuntu in compare to atom.\r\nAnd finally as a Persian we have much better experience with VS code.\r\n\r\nI hope atom's team don't mind about my comment, they have good product and I used it over a year but It's good for themselves (LTR languages runs on computers with giant resources) not for me!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14323", "user": "mostafamemariani", "root": "ROOT143", "reply_to": "COM14322", "timestamp": "2017-08-01T06:36:43Z", "text": "vscode is good but i think its ftp plugins are not efficient in the comparison of atom...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14324", "user": "lee-dohm", "root": "ROOT143", "reply_to": "COM14323", "timestamp": "2017-08-01T13:53:55Z", "text": "In general, we don't mind the odd comment about other tools that might be better for some people's uses. The back-and-forth conversation about things that aren't Atom is off-topic though and should be taken elsewhere.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM14325", "user": "WISTFUL12", "root": "ROOT143", "reply_to": "COM14324", "timestamp": "2017-08-20T09:10:03Z", "text": "When this ability will be added to Atom?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14326", "user": "lajmikhalil", "root": "ROOT143", "reply_to": "COM14325", "timestamp": "2017-11-03T20:08:54Z", "text": "We need this to be fixed, coding shouldn't be just for ltr languages. I'm just surprised that this is overlooked still after 4 years.\r\n\r\n<img width=\"109\" alt=\"screen shot 2017-11-03 at 4 03 20 pm\" src=\"https://user-images.githubusercontent.com/9424637/32393678-dd3c2d04-c0b0-11e7-81b2-d4b51f138821.png\">\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14327", "user": "lee-dohm", "root": "ROOT143", "reply_to": "COM14326", "timestamp": "2017-11-03T20:36:41Z", "text": "@lajmikhalil as [I stated above](https://github.com/atom/atom/issues/10132#issuecomment-297892801), if people want to help speed up the process we would definitely welcome the help. The reality is that our resources are finite and there will be things that we can't get to as quickly as some would want. The awesome part about open source is that everyone can work on the bits of functionality that are important to them and the whole system gets better.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM14328", "user": "iamsoorena", "root": "ROOT143", "reply_to": "COM14327", "timestamp": "2017-11-17T14:04:11Z", "text": "does anyone know which source files are related to this issue? If someone wants to help, he/she will need some context.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14329", "user": "50Wliu", "root": "ROOT143", "reply_to": "COM14328", "timestamp": "2017-11-17T14:11:51Z", "text": "@iamsoorena since this is happening in text editors, I would start by looking at [text-editor-component.js](https://github.com/atom/atom/blob/master/src/text-editor-component.js) and [text-editor.js](https://github.com/atom/atom/blob/master/src/text-editor.js).", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "ROOT144", "user": "samtstern", "root": "ROOT144", "reply_to": null, "timestamp": "2017-01-31T21:11:42Z", "text": "Add an AuthUI.reauthenticate() function There are some Firebase Auth actions that require a recent (~5mins) sign-in to succeed:\r \r   * Delete account (#478)\r   * Change email\r   * Etc\r \r We should offer a simple method to launch into a re-authentication flow that allows the user to sign in choosing from any of their linked providers.\r \r Considerations:\r \r   * This would likely have to be a method that returns an `Intent` similar to the sign-in intent\r   * The developer will probably want to provide a reason for the re-authentication, maybe passed in\r   * This would be similar to the normal sign-in flow with a few alterations:\r     * Account creation disabled\r     * Account picker screen lists only methods the user has already linked to the `FirebaseUser`", "meta": {"posReactions": "12", "negReactions": "0"}}
{"id": "COM1440", "user": "amandle", "root": "ROOT144", "reply_to": "ROOT144", "timestamp": "2017-02-06T22:33:02Z", "text": "Unless there are objections I'm going to start taking a crack at this.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1441", "user": "samtstern", "root": "ROOT144", "reply_to": "COM1440", "timestamp": "2017-02-06T22:35:06Z", "text": "Go for it, thanks!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1442", "user": "nikahmadz", "root": "ROOT144", "reply_to": "COM1441", "timestamp": "2018-02-22T14:52:15Z", "text": "May I know , what is the current status of this implementation?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1443", "user": "samtstern", "root": "ROOT144", "reply_to": "COM1442", "timestamp": "2018-02-22T16:25:56Z", "text": "@nikahmadz this is indefinitely on hold ... @amandle left the project and we are focusing on some other priorities for now.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1444", "user": "maillouxc", "root": "ROOT144", "reply_to": "COM1443", "timestamp": "2018-05-18T18:18:47Z", "text": "FWIW, I'd really love to see this implemented. If I'm reading the comments here correctly, it seems like the work was already done for Android, but never released because it wasn't available on the other platforms. Is it possible to just push the release out for android?  I would implement the other devices myself if I had the time, but it seems like a shame to have this stuff ready to go but just waiting on other implementations.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1445", "user": "TeunVR", "root": "ROOT144", "reply_to": "COM1444", "timestamp": "2018-06-07T14:48:23Z", "text": "This is really a necessary feature. \r\nI am currently using the unreleased/unsupported iOS FUIAccountSettingsViewController, and it seems to be working for me.\r\nBut it should be officially released and also available for Android.\r\n\r\nAt the moment FirebaseAuthUI is a 80% solution for iOS and even less for Android. To be able to change email/password etc i still need to build everything myself and i really start to doubt our decision to use FirebaseAuthUI in the first place.\r\n\r\nFrom the website:\r\n\"Easily add sign-in to your Android app with FirebaseUI\r\nFirebaseUI is a library built on top of the Firebase Authentication SDK that provides drop-in UI flows for use in your app.\"\r\n\r\nNo it's not. Not if there is no support to do basic operations like email/password change.\r\n\r\nWe need either documentation how to handle reauthentication (besides email/password which is documented) or even better, release the FUIAccountSettingsViewController and an Android-port of it.", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM1446", "user": "jackz314", "root": "ROOT144", "reply_to": "COM1445", "timestamp": "2019-05-24T07:50:24Z", "text": "It's been more than 2 years from its initial progress and more than a year from the last update, did you guys abandon this key feature?", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM1447", "user": "Heldenkrieger01", "root": "ROOT144", "reply_to": "COM1446", "timestamp": "2020-04-14T21:51:54Z", "text": "When can we expect the release of this necessary feature? @samtstern ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1448", "user": "katowulf", "root": "ROOT144", "reply_to": "COM1447", "timestamp": "2020-04-14T22:54:47Z", "text": "Closing this conversation to prevent more \"ETA requested\" responses (which actually take time from feature work). \r\n\r\nLatest status update: [#issuecomment-367736441](https://github.com/firebase/FirebaseUI-Android/issues/563#issuecomment-367736441)\r\n\r\nFirebase team will update here and potentially unlock thread if/when there is an update.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT145", "user": "shengxinjing", "root": "ROOT145", "reply_to": null, "timestamp": "2020-06-09T06:11:53Z", "text": "use allowlist instead of whitelist <!--\r   Thanks for submitting a pull request!\r   We appreciate you spending the time to work on these changes. Please provide enough information so that others can review your pull request. The three fields below are mandatory.\r \r   Before submitting a pull request, please make sure the following is done:\r \r   1. Fork [the repository](https://github.com/facebook/react) and create your branch from `master`.\r   2. Run `yarn` in the repository root.\r   3. If you've fixed a bug or added code that should be tested, add tests!\r   4. Ensure the test suite passes (`yarn test`). Tip: `yarn test --watch TestName` is helpful in development.\r   5. Run `yarn test-prod` to test in the production environment. It supports the same options as `yarn test`.\r   6. If you need a debugger, run `yarn debug-test --watch TestName`, open `chrome://inspect`, and press \"Inspect\".\r   7. Format your code with [prettier](https://github.com/prettier/prettier) (`yarn prettier`).\r   8. Make sure your code lints (`yarn lint`). Tip: `yarn linc` to only check changed files.\r   9. Run the [Flow](https://flowtype.org/) typechecks (`yarn flow`).\r   10. If you haven't already, complete the CLA.\r \r   Learn more about contributing: https://reactjs.org/docs/how-to-contribute.html\r -->\r \r ## Summary\r \r <!-- Explain the **motivation** for making this change. What existing problem does the pull request solve? -->\r \r ## Test Plan\r \r <!-- Demonstrate the code is solid. Example: The exact commands you ran and their output, screenshots / videos if the pull request changes the user interface. -->\r \r use allowlist instead of whitelist for some reason\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1450", "user": "facebook-github-bot", "root": "ROOT145", "reply_to": "ROOT145", "timestamp": "2020-06-09T06:12:03Z", "text": "Hi @shengxinjing! \n\nThank you for your pull request and welcome to our community.We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file.\n\nIn order for us to review and merge your code, please sign at <https://code.facebook.com/cla>. **If you are contributing on behalf of someone else (eg your employer)**, the individual CLA may not be sufficient and your employer may need to sign the corporate CLA.\n\nIf you have received this in error or have any questions, please contact us at [cla@fb.com](mailto:cla@fb.com?subject=CLA%20for%20facebook%2Freact%20%2319102). Thanks!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1451", "user": "codesandbox-ci[bot]", "root": "ROOT145", "reply_to": "COM1450", "timestamp": "2020-06-09T06:14:02Z", "text": "This pull request is automatically built and testable in [CodeSandbox](https://codesandbox.io).\n\n  To see build info of the built libraries, click [here](https://ci.codesandbox.io/status/facebook/react/pr/19102/builds/31450) or the icon next to each commit SHA.\n\nLatest deployment of this branch, based on commit e35dddb53718c6c2da61458518d1a6bb785ad1ad:\n\n|Sandbox| Source |\n|--|--|\n|[gracious-bas-02j6v](https://codesandbox.io/s/gracious-bas-02j6v)| Configuration |\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1452", "user": "sizebot", "root": "ROOT145", "reply_to": "COM1451", "timestamp": "2020-06-09T06:19:18Z", "text": "\n<!--\n  0 failure: \n  0 warning: \n  \n  2 markdown notices\n  DangerID: danger-id-stable;\n-->\n\n\n\nNo significant bundle size changes to report.\n\n## Size changes (stable)\n<p align=\"right\">\n  Generated by :no_entry_sign: <a href=\"https://danger.systems/js\">dangerJS</a> against e35dddb53718c6c2da61458518d1a6bb785ad1ad\n</p>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1453", "user": "sizebot", "root": "ROOT145", "reply_to": "COM1452", "timestamp": "2020-06-09T06:19:30Z", "text": "\n<!--\n  0 failure: \n  0 warning: \n  \n  2 markdown notices\n  DangerID: danger-id-experimental;\n-->\n\n\n\nNo significant bundle size changes to report.\n\n## Size changes (experimental)\n<p align=\"right\">\n  Generated by :no_entry_sign: <a href=\"https://danger.systems/js\">dangerJS</a> against e35dddb53718c6c2da61458518d1a6bb785ad1ad\n</p>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1454", "user": "pingfengafei", "root": "ROOT145", "reply_to": "COM1453", "timestamp": "2020-06-09T12:18:31Z", "text": "**I REALLY DISAGREE WITH THIS PR**\r\n\r\nI worry about the racial discrimination have happened in US from long time ago to recent as a human being, while I also insist to regard `blacklist, whitelist, blackbox testing, whitebox testing, master, slave, etc` to be neutral nouns in `IT area` as a software engineer. They just info to opposite or relevant methods in computer science without any emotion. The more one tries to hide, the more one is exposed.\r\n\r\nMy voice may seem to be sharp on this rename PR. Indeed, that shows my attitude about racial discrimination and mercy about people who suffer from brutality all around the world.   As a Chinese, we know the eval history of `Negro Slaves` and experienced `Literary Inquisition` about 400 years ago. We should show really action instead of showing shows.\r\n\r\n", "meta": {"posReactions": "1", "negReactions": "6"}}
{"id": "COM1455", "user": "shengxinjing", "root": "ROOT145", "reply_to": "COM1454", "timestamp": "2020-06-09T12:27:34Z", "text": "it's for fun  beacuse google use replace blacklist with blocklist in chrome and [go](https://github.com/golang/go/blob/6bf2eea62a3425c57f3d908ec32047a9ae41c025/src/cmd/compile/internal/gc/plive.go#L905)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1456", "user": "facebook-github-bot", "root": "ROOT145", "reply_to": "COM1455", "timestamp": "2020-06-09T15:39:42Z", "text": "Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1457", "user": "facebook-github-bot", "root": "ROOT145", "reply_to": "COM1456", "timestamp": "2020-06-09T15:39:59Z", "text": "Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1458", "user": "vsTianhao", "root": "ROOT145", "reply_to": "COM1457", "timestamp": "2020-06-11T01:59:59Z", "text": "Agree @pingfengafei .\r\nDon't let word game anesthetize us, If everyone pays attention, discrimination will slowly disappear, but if we pretend that it has disappeared now, it may exist forever, The more one tries to hide, the more one is exposed.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1459", "user": "acdlite", "root": "ROOT145", "reply_to": "COM1458", "timestamp": "2020-06-13T01:11:44Z", "text": "Thanks for the PR! Landed in 655affa302437208e6f03c9ca6d170ea1707ace3", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT146", "user": "SIkebe", "root": "ROOT146", "reply_to": null, "timestamp": "2020-10-01T13:40:47Z", "text": "The Future of IdentityServer >The current version (IdentityServer4 v4.x) will be the last version we work on as free open source. We will keep supporting IdentityServer4 until the end of life of .NET Core 3.1 in November 2022.\r >\r >To continue our work, we have formed a new company Duende Software, and IdentityServer4 will be rebranded as Duende IdentityServer. Duende IdentityServer will contain all new feature work and will target .NET Core 3.1 and .NET 5 (and all versions beyond).\r https://leastprivilege.com/2020/10/01/the-future-of-identityserver/\r \r Currently, some of the ASP.NET Core templates use IdentityServer4. How the above announcement affect? ASP.NET Core 5.0 will be shipped with IdentityServer4?", "meta": {"posReactions": "13", "negReactions": "0"}}
{"id": "COM1460", "user": "blowdart", "root": "ROOT146", "reply_to": "ROOT146", "timestamp": "2020-10-01T15:22:12Z", "text": ".NET 5.0 will ship with IdentityServer 4 in some ASP.NET templates. As the IS folks have stated\r\n\r\n> We will keep supporting IdentityServer4 until the end of life of .NET Core 3.1 in November 2022.\r\n\r\nPlanning has begun for .NET 6.0 and we'll make an announcement when ready.", "meta": {"posReactions": "20", "negReactions": "1"}}
{"id": "COM1461", "user": "Aaronontheweb", "root": "ROOT146", "reply_to": "COM1460", "timestamp": "2020-10-01T17:38:37Z", "text": "I don't see why this is a big deal - still fine for ASP.NET Core to ship OSS templates that include IdentityServer4 under this license. If companies want great tools for solving problems as complicated and critical as identity management they should have no problem paying for it.", "meta": {"posReactions": "20", "negReactions": "5"}}
{"id": "COM1462", "user": "weedkiller", "root": "ROOT146", "reply_to": "COM1461", "timestamp": "2020-10-01T17:40:59Z", "text": "We need a new free option, this is a core component and cannot be outsourced to 3rd party companies.\r\n\r\n**THIS IS TOO CRITICAL**", "meta": {"posReactions": "10", "negReactions": "55"}}
{"id": "COM1463", "user": "Aaronontheweb", "root": "ROOT146", "reply_to": "COM1462", "timestamp": "2020-10-01T17:46:30Z", "text": "> We need a new free option, this is a core component and cannot be outsourced to 3rd party companies.\r\n\r\nIf you've been using IdentityServer all this time, you've already been depending on a 3rd party company. OSS software isn't about other people doing things for you for free - either roll your own, pick another technology, or pay the bill. \r\n\r\nIf you can't afford $1500 a year for IdentityServer4 to manage something as critical as identity for your business applications, drop them a line and let them know - pricing software products is a complicated business.", "meta": {"posReactions": "46", "negReactions": "2"}}
{"id": "COM1464", "user": "isaacabraham", "root": "ROOT146", "reply_to": "COM1463", "timestamp": "2020-10-01T17:57:30Z", "text": "IS4 will actually remain free and will be supported in line with .NET Core 3.1. It's only IS5 (as far as I'm aware) that will be commercial.\r\n\r\nBut the main point is right - if you don't want to pay for the future version of IS, just use the out of the box solution or roll your own. If you would rather not take on that responsibility and / or it'll be quicker to use a third-party package written by experts, then you can pay for them to do it for you.\r\n\r\nI don't see the problem.", "meta": {"posReactions": "21", "negReactions": "6"}}
{"id": "COM1465", "user": "citizenmatt", "root": "ROOT146", "reply_to": "COM1464", "timestamp": "2020-10-01T18:13:07Z", "text": "> .NET 5.0 will ship with IdentityServer 4 in some ASP.NET templates. As the IS folks have stated\r\n> \r\n> > We will keep supporting IdentityServer4 until the end of life of .NET Core 3.1 in November 2022.\r\n> \r\n> Planning has begun for .NET 6.0 and we'll make an announcement when ready.\r\n\r\nCan you link to the issue where this is being discussed, please?", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM1466", "user": "hhariri", "root": "ROOT146", "reply_to": "COM1465", "timestamp": "2020-10-01T18:13:10Z", "text": "@weedkiller Funny how while it's been free, depending on 3rd parties has never been a problem...", "meta": {"posReactions": "33", "negReactions": "3"}}
{"id": "COM1467", "user": "blowdart", "root": "ROOT146", "reply_to": "COM1466", "timestamp": "2020-10-01T19:49:01Z", "text": "@citizenmatt \"we'll make an announcement when ready\"", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1468", "user": "SIkebe", "root": "ROOT146", "reply_to": "COM1467", "timestamp": "2020-10-02T01:04:50Z", "text": "@blowdart Thank you for your clarification!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1469", "user": "citizenmatt", "root": "ROOT146", "reply_to": "COM1468", "timestamp": "2020-10-02T08:00:50Z", "text": "> @citizenmatt \"we'll make an announcement when ready\"\r\n\r\nDoes \"we\" mean Microsoft, the .NET Foundation or the open source community?", "meta": {"posReactions": "11", "negReactions": "0"}}
{"id": "COM14610", "user": "weedkiller", "root": "ROOT146", "reply_to": "COM1469", "timestamp": "2020-10-02T19:51:05Z", "text": "@hhariri It used to be core part of the MS Stack back in early webforms/MVC time frames. However MS did not release the comparable component with an admin/UI, in the new ASP stack. So people gravitated towards that as a viable and that it was a free option.\r\n\r\n**From a financial point** 1500$ in countries where they make less than 3$/day is not an option and a pain of the smaller business that you should personally exp. to understand. Many of these sites just have basic features enabled, with a large community\r\n\r\nAlso with this kind of a mindset other competing products like Wordpress on PHP have gained huge ground on ASP. Some day PHP and its frameworks are going to catch up.\r\n\r\nLook at the search results, there are several several questions and issues just on this topic which are closed or unanswered with a heavy hammer. for e.g. 57 votes ASP identity  -- https://github.com/dotnet/aspnetcore/issues/16534 https://github.com/dotnet/aspnetcore/issues/973 \r\n\r\n_________________________\r\nLooking through the issues..\r\n\r\n**there are several pertinent questions that are core to the stack, that are simply too hard for a developer to tackle on his own**, and too crucial for any one to monopolize.\r\n\r\n### Multi tenancy, Dynamic Roles with claims, Federation, SSO, ASP Identity Core is DB facing more that anything, Open ID integration and more\r\n\r\n@citizenmatt _please_ give us an option that's doesn't burn a hole! ", "meta": {"posReactions": "11", "negReactions": "0"}}
{"id": "COM14611", "user": "weedkiller", "root": "ROOT146", "reply_to": "COM14610", "timestamp": "2020-10-02T19:57:01Z", "text": "> IS4 will actually remain free and will be supported in line with .NET Core 3.1. It's only IS5 (as far as I'm aware) that will be commercial.\r\n> \r\n> But the main point is right - if you don't want to pay for the future version of IS, just use the out of the box solution or roll your own. If you would rather not take on that responsibility and / or it'll be quicker to use a third-party package written by experts, then you can pay for them to do it for you.\r\n> \r\n> I don't see the problem.\r\n\r\nFrom what I gathered their site earlier this week, its free only till IS 4.x (current version). Everything going forward is Duende or something software and costs money from October, so they way I understand any development from here.. is commercial including bug fixes etc.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14612", "user": "bladefist", "root": "ROOT146", "reply_to": "COM14611", "timestamp": "2020-10-02T20:15:24Z", "text": "IS4 will work until 2022 at that point you won't able to get security fixes, etc.  They went enterprise pricing, there is no hobby pricing or \"starter\".   They went from 0 to 60.  It's ok, it's their choice, but we have a choice too.  Before we migrate to one of the other FOSS systems we're waiting for Microsofts response to this.  Surely this is a pivot moment to solve this internally  for the framework.  MVC1-5 came with auth solutions so I expect they will continue that tradition. \r\n\r\nJson parsing used require 3rd party (at least if you wanted performance).  That's internal now and far better.  We'll see what they do. ", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM14613", "user": "adamhathcock", "root": "ROOT146", "reply_to": "COM14612", "timestamp": "2020-10-02T20:25:15Z", "text": "A full OpenID Provider has been built in.  Not sure why it's considered necessary to have it now.\n\nI get that IdentityServer going non-free sucks for some users but there are alternatives like OpenIDdict.\n\nBegging Microsoft to make things like this distracts them from improving core functionality.  Microsoft doesn't have to own everything dotnet.", "meta": {"posReactions": "11", "negReactions": "2"}}
{"id": "COM14614", "user": "pollumi", "root": "ROOT146", "reply_to": "COM14613", "timestamp": "2020-10-03T08:34:09Z", "text": "I get it that the creators need money so it is their decision whatever they want to do.\r\n\r\nFor the .net ecosystem it is a rather disastrous event. As a small company that has chosen IdentityServer because it is the \"official\" framework of choice, both according to Microsoft and the general community, you are now facing a lot of not needed and not wanted problems. Sure you can say, yes $1500 is not much in the business environment. But this is not true for all of them. For us it is a lot of money and also a lot of time that we have already invested. We now have to migrate to something different.\r\nIn a healthy ecosystem, it should not happen that a pillar on which so many have built, changes the license so negatively. \r\n\r\nYes, open source is not about \"free work\" but you clearly want to have a .net ecosystem with all the basic tools that keep steady and have a very open license. It would have been better if they did the license change back then when they converted IdentityServer to .net core.", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM14615", "user": "robertwt7", "root": "ROOT146", "reply_to": "COM14614", "timestamp": "2020-10-03T11:38:06Z", "text": "> Begging Microsoft to make things like this distracts them from improving core functionality. Microsoft doesn't have to own everything dotnet.\r\n\r\nMost of full stack framework out there has official package for crucial things like this (say laravel). Coming from other communities like php, node, etc, dev can build and experiment with everything totally free. This makes it harder for newcomers to learn aspnet core without the support from the community or microsoft officially\r\n\r\nEdit: and yes its totally up to the creators if that's their decision\r\n", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM14616", "user": "isaacabraham", "root": "ROOT146", "reply_to": "COM14615", "timestamp": "2020-10-03T11:48:47Z", "text": "> For the .net ecosystem it is a rather disastrous event.\n\n> In a healthy ecosystem, it should not happen that a pillar on which so many have built, changes the license so negatively. \n\nHere are some alternatives that may have come to pass without this move :\n\n1. They stop developing identity server completely as it's not financially viable for them to continue it. \n\n2. Support and ongoing changes dry up. You have a live issue and there's no one to help you out.\n\nAlso consider the difference now : The team may have more funds to invest in making the API and docs even better, saving you time and money.\n\nIn other words, positioning this as a negative move is perhaps a little short sighted. The current situation was probably unsustainable and this was no surprise to me when I saw the news.\n\nYou have until the end of life of netcore 31 which is next year, to plan for a migration strategy. As I understand it, IS4 will continue to work, it's simply not going to be updated.\n\nI suspect that the time saving of paying the money will outweigh the cost of moving but you will undoubtedly know better.\n\n", "meta": {"posReactions": "6", "negReactions": "3"}}
{"id": "COM14617", "user": "adamhathcock", "root": "ROOT146", "reply_to": "COM14616", "timestamp": "2020-10-03T12:19:02Z", "text": "> > Begging Microsoft to make things like this distracts them from improving core functionality. Microsoft doesn't have to own everything dotnet.\n> \n> \n> \n> Most of full stack framework out there has official package for crucial things like this (say laravel). Coming from other communities like php, node, etc, dev can build and experiment with everything totally free. This makes it harder for newcomers to learn aspnet core without the support from the community or microsoft officially\n> \n> \n> \n\nIt's just one project changing a license.  Yes, it's popular but there are alternatives.  This happens in all ecosystems. They also have paid for things too.\n\nThe sky isn't falling.", "meta": {"posReactions": "8", "negReactions": "5"}}
{"id": "COM14618", "user": "Aaronontheweb", "root": "ROOT146", "reply_to": "COM14617", "timestamp": "2020-10-03T16:18:08Z", "text": "> Sure you can say, yes $1500 is not much in the business environment. But this is not true for all of them. For us it is a lot of money and also a lot of time that we have already invested. We now have to migrate to something different.\r\n> In a healthy ecosystem, it should not happen that a pillar on which so many have built, changes the license so negatively.\r\n\r\nHaving sustainable OSS projects _is_ part of a healthy ecosystem. If not $1500, what amount would you pay?\r\n\r\nIf the answer is \"none\" then _you're the problem_.", "meta": {"posReactions": "25", "negReactions": "8"}}
{"id": "COM14619", "user": "jbogard", "root": "ROOT146", "reply_to": "COM14618", "timestamp": "2020-10-03T17:08:23Z", "text": "If you're hosting on Azure, you might look at its [Easy Auth feature for App Services](https://docs.microsoft.com/en-us/azure/app-service/overview-authentication-authorization). That's free, too. We use that quite a lot for the \"easy\" scenarios. If your situation is complex, that's when you need something more powerful, and I don't see why it must be free.", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM14620", "user": "isaacabraham", "root": "ROOT146", "reply_to": "COM14619", "timestamp": "2020-10-03T17:25:43Z", "text": "In fact you have until end of 2022 to move over. That's two years. ", "meta": {"posReactions": "2", "negReactions": "3"}}
{"id": "COM14621", "user": "leastprivilege", "root": "ROOT146", "reply_to": "COM14620", "timestamp": "2020-10-03T17:52:58Z", "text": "@weedkiller @bladefist (and everyone else)\r\n\r\nAs @Aaronontheweb says, pricing a product is hard. If you want to give us feedback on the pricing and explain your situation, this is not the right place to do that.\r\n\r\nPlease contact us directly\r\nhttps://duendesoftware.com/contact\r\n\r\nthanks!", "meta": {"posReactions": "20", "negReactions": "2"}}
{"id": "COM14622", "user": "HassanHashemi", "root": "ROOT146", "reply_to": "COM14621", "timestamp": "2020-10-03T21:32:58Z", "text": "> Most of full stack framework out there has official package for crucial things like this (say laravel). Coming from other communities like php, node, etc, dev can build and experiment with everything totally free. This makes it harder for newcomers to learn aspnet core without the support from the community or microsoft officially.\r\n\r\nTotally true, identity and access management should be baked into the framework as it is needed in almost any serious app.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM14623", "user": "pollumi", "root": "ROOT146", "reply_to": "COM14622", "timestamp": "2020-10-03T21:42:44Z", "text": "> > Sure you can say, yes $1500 is not much in the business environment. But this is not true for all of them. For us it is a lot of money and also a lot of time that we have already invested. We now have to migrate to something different.\r\n> > In a healthy ecosystem, it should not happen that a pillar on which so many have built, changes the license so negatively.\r\n> \r\n> Having sustainable OSS projects _is_ part of a healthy ecosystem. If not $1500, what amount would you pay?\r\n> \r\n> If the answer is \"none\" then _you're the problem_.\r\n\r\nSorry, but this is just an arrogant statement by you.\r\nI absolutely don't want to pay anything extra (yearly!!) for such a **very basic** thing like identity in my framework. \r\nAgain, I completely get that the IS devs neeed more money and want to be paid. But I (and a lot of other not so high profile devs like you) invested a lot of time into using this product since MS declared it the defacto standard. \r\nI don't expect some - again VERY BASIC - functionality in my tech stack to change the licence 180\u00b0. This is an absolutely not planned change that cost a lot of time and money. If this was a framework that helps solving some black magic math issues, I wouldn't have such problems. But we absolutely need fully FOSS solutions for the very basic things in every day life. And I don't agree that MS should't fill this gap here. It was their mistake to promote IS in the first place without making sure that it keeps the same license **forever**.", "meta": {"posReactions": "4", "negReactions": "9"}}
{"id": "COM14624", "user": "Aaronontheweb", "root": "ROOT146", "reply_to": "COM14623", "timestamp": "2020-10-03T21:55:34Z", "text": "> I absolutely don't want to pay anything extra (yearly!!) for such a very basic thing like identity in my framework.\r\n\r\nYou don't need something as sophisticated as IS4/5 for simple use cases - there are numerous other libraries that are free. We're using `Microsoft.AspNetCore.Identity` in our application, which is already built in and matches your requirements exactly.", "meta": {"posReactions": "7", "negReactions": "5"}}
{"id": "COM14625", "user": "poke", "root": "ROOT146", "reply_to": "COM14624", "timestamp": "2020-10-03T22:00:32Z", "text": "> I absolutely don't want to pay anything extra (yearly!!) for such a very basic thing like identity in my framework.\r\n\r\n1. You're not paying anything right now to begin with. The framework and platform is already free to use. And you're likely making money from it.\r\n2. IdentityServer is only tangentially related to Identity management. It's an identity provider which is still a special thing you likely don't want to put into every other app.\r\n3. Identity management itself is built into the framework with ASP.NET Identity. That is completely unrelated to what IdentityServer offers though except that it integrates well into ASP.NET Identity.\r\n4. Other platforms actually often don't have solutions like IdentityServer, especially not built-in. A common alternative that I know of is Keycloak (which you can easily use for your .NET apps as well).\r\n5. There are other alternatives to building your own identity provider. In Azure, you could use Azure AD. On-premise you have ADFS. And you can also use free third-party services like Auth0 or just integrate other identity providers directly.\r\n5. If you absolutely need to ship your own identity provider, realize the complexity this involves (auth is a complex thing to master!) and consider paying for a license.\r\n6. You can also check out OpenIddict if you need an open (free) implementation. But who knows whether that will always stay free to use. ", "meta": {"posReactions": "5", "negReactions": "4"}}
{"id": "COM14626", "user": "pollumi", "root": "ROOT146", "reply_to": "COM14625", "timestamp": "2020-10-03T22:49:53Z", "text": "> > I absolutely don't want to pay anything extra (yearly!!) for such a very basic thing like identity in my framework.\r\n> \r\n> You don't need something as sophisticated as IS4/5 for simple use cases - there are numerous other libraries that are free. We're using `Microsoft.AspNetCore.Identity` in our application, which is already built in and matches your requirements exactly.\r\n\r\nWe have 2020 and those features should be something that should be absolutely solved **in a standardized way** and freely available in a famework:\r\n- Access token creation with including custom claims\r\n- Refreshtoken creation and presistence\r\n- Everything needs to be easily scalable to multiple instances. \r\n- Storage of credentials should be easily customizable.\r\n\r\nAgain, the point here is that we invested time and money in solutions using IS for those things. Because MS said this is the way to go. \r\n\r\nWe are still in a crucial situation with .net and hoping that it gain more ppl using it. Also if Blazor should gain traction something like this just doesn't help. ", "meta": {"posReactions": "5", "negReactions": "1"}}
{"id": "COM14627", "user": "clooge", "root": "ROOT146", "reply_to": "COM14626", "timestamp": "2020-10-03T22:55:58Z", "text": "> \r\n> \r\n> I get it that the creators need money so it is their decision whatever they want to do.\r\n> \r\n> For the .net ecosystem it is a rather disastrous event. As a small company that has chosen IdentityServer because it is the \"official\" framework of choice, both according to Microsoft and the general community, you are now facing a lot of not needed and not wanted problems. Sure you can say, yes $1500 is not much in the business environment. But this is not true for all of them. For us it is a lot of money and also a lot of time that we have already invested. We now have to migrate to something different.\r\n> In a healthy ecosystem, it should not happen that a pillar on which so many have built, changes the license so negatively.\r\n> \r\n> Yes, open source is not about \"free work\" but you clearly want to have a .net ecosystem with all the basic tools that keep steady and have a very open license. It would have been better if they did the license change back then when they converted IdentityServer to .net core.\r\n\r\n@pollumi I agree with everything you said \ud83d\udcaf this is a pretty core function to the Microsoft Stack, had they done it right in the first place it would have never been issue today.\r\n\r\nAlso @Aaronontheweb is out of line with personal comments like that. What an idi0t, not ok, just because he dont agree with someone else view.\r\n\r\nWhy is this closed?!", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM14628", "user": "jbogard", "root": "ROOT146", "reply_to": "COM14627", "timestamp": "2020-10-03T23:18:20Z", "text": "If folks wanted this to be free, perhaps they should petition MS to sponsor the project at a level that would ensure that?", "meta": {"posReactions": "10", "negReactions": "0"}}
{"id": "COM14629", "user": "hallidev", "root": "ROOT146", "reply_to": "COM14628", "timestamp": "2020-10-04T00:02:17Z", "text": "I just want to throw my hat in because I keep seeing the $1500 number over and over in this and other threads, but I can't see how this would apply to anything but the absolute most basic IS4 implementation.\r\n\r\nI'm putting together a solution that uses IdentityServer4 for a relatively small startup. We don't have a problem paying to support the project, which is what we thought we were doing when we paid for the Enterprise AdminUI license at $8400 / year:\r\n\r\nhttps://www.identityserver.com/products/adminui\r\n\r\nThis was a stretch for us, but we chose it over similar open source projects like https://github.com/skoruba/IdentityServer4.Admin to financially support the IS4 project.\r\n\r\nThe per-client licensing model of Duende IdentityServer is what's going to make this untenable for us going forward. Let me describe our clients:\r\n\r\n1: AdminUI (which alone is $8400 / year)\r\n2: AdminUI Webhooks\r\n3: Delegation gateway 1 (https://docs.identityserver.io/en/dev/topics/extension_grants.html)\r\n4: Delegation gateway 2 (different use case, same idea. Can't be the same client)\r\n5: Worker service 1\r\n6: Worker service 2\r\n7: Worker service 3\r\n\r\n...\r\n\r\nAs you can see, we've used 7 clients (2 of which are required by the IS4-affiliated product we're already paying thousands a year for) before even getting to the part where a single actual website or mobile app exists. \r\n\r\nWorker services (client credentials grants) come online at an alarming rate, and they're generally dead-simple pieces of code, sometimes the entire service is 100 lines of code.\r\n\r\nI don't know how other shops are handling IS4 clients, but using Duende IdentityServer will immediately put us in the Enterprise tier at $12,000 / year, putting our total cost at over $20k / year. \r\n\r\nI wanted to point all of this out since people may read these threads thinking \"I can swing $1500 / year\". I'd be shocked to find out that our setup was unique in the number of clients that end up being created. This client based pricing model is going to immediately price out many startups like the one I'm working with.\r\n\r\nThe IS4 authors deserve to be well compensated and I hope Duende IdentityServer is a success for their sake, but I'm also hoping they introduce something like a per-user pricing model.", "meta": {"posReactions": "10", "negReactions": "0"}}
{"id": "ROOT147", "user": "Skoti", "root": "ROOT147", "reply_to": null, "timestamp": "2018-11-25T00:45:52Z", "text": "Support Pluginfile in \"import_from_git\" ### Feature Request\r I know this has been requested many times but the status of it is a bit unclear to me.\r \r 1. Is it possible to do this? In #8682 @KrauseFx mentioned that:\r > Mh, I don't think that's gonna work, as all Ruby files are already loaded at that point by bundler. You'd have to run bundle update after importing the file, which is not something fastlane can do on its own as far as I know.\r \r What about `fastlane_require`? It could be used to install a plugin gem - not sure whether it contradicts a _Gemfile_ or what other steps are needed.\r \r Anyway, if this is not possible, can we add a note in `import_from_git` [description](https://docs.fastlane.tools/actions/import_from_git/) with reasoning if any?\r Maybe it would be great to add a warning when `import_from_git` detects a _Pluginfile_ to remind that plugins should be installed/updated. I think it would follow _fastlane philosophy_.\r \r Or _fastlane_require_plugin_ could be added in order to fail if there is no entry with a provided plugin name in a project _Pluginfile_?\r \r 2. If this can be done then maybe someone is already working on it? Maybe _fastlane community_ could help?\r In #7636 @lacostej tried to discuss an idea to solve this but with no answer. Any chance to do this in this thread?\r \r #### Motivation Behind Feature\r <!-- Why should this feature be implemented? What problem does it solve? -->\r Updating a _shared Fastfile_ with usage of a plugin requires an update in a _Pluginfile_ in each project importing this _Fastfile_ (or also in a _Gemfile_ if plugins were not used before). This is a bit inconvenient and not a safe way of introducing changes.\r \r `import_from_git` should import a fully configured, standalone _shared Fastfile_ with all dependencies defined there and/or other files.\r \r #### Alternatives or Workarounds\r <!-- Describe alternatives or workarounds you are currently using -->\r <!-- Are there ways to do this with existing actions and plugins? -->\r In #11112 @NiklasWebnuts proposed an interesting workaround.\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1470", "user": "fastlane-bot", "root": "ROOT147", "reply_to": "ROOT147", "timestamp": "2018-11-25T17:30:21Z", "text": "It seems like you have not included the output of `fastlane env`\n\nTo make it easier for us help you resolve this issue, please update the issue to include the output of `fastlane env` :+1:", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1471", "user": "janpio", "root": "ROOT147", "reply_to": "COM1470", "timestamp": "2018-11-26T16:05:52Z", "text": ">  1. Is it possible to do this? In #8682 @KrauseFx mentioned that:\r\n> \r\n> > Mh, I don't think that's gonna work, as all Ruby files are already loaded at that point by bundler. You'd have to run bundle update after importing the file, which is not something fastlane can do on its own as far as I know.\r\n> \r\n> What about `fastlane_require`? It could be used to install a plugin gem - not sure whether it contradicts a _Gemfile_ or what other steps are needed.\r\n\r\nI can give some insight on that:\r\n\r\n`Pluginfile` is not similar to `Deliverfile` and other configuration files: When you add a plugin, some code is added to your `Gemfile` that includes `Pluginfile` there. `Gemfile` (and the included information from your `Pluginfile`) is used to define which gems to install when you run `bundle install` on your project. \r\n\r\nSo to implement a method like the one you want, at runtime in fastlane, you would then have to change both the `Gemfile` to include the new imported data, and run `bundle install`. It would change files on the file system and also \r\n\r\n> Anyway, if this is not possible, can we add a note in `import_from_git` [description](https://docs.fastlane.tools/actions/import_from_git/) with reasoning if any?\r\n\r\nDocumentation of that actions says:\r\n\r\n> Import another Fastfile from a remote git repository to use its lanes\r\n\r\nThat is pretty clear that this action is for importing `Fastfile`s.\r\n\r\n> Maybe it would be great to add a warning when `import_from_git` detects a _Pluginfile_ to remind that plugins should be installed/updated. I think it would follow _fastlane philosophy_.\r\n\r\nWhat do you mean by that? How should this work?\r\n\r\n> Or _fastlane_require_plugin_ could be added in order to fail if there is no entry with a provided plugin name in a project _Pluginfile_?\r\n\r\nDoesn't this already happen when you use an action of a plugin, that is not installed?\r\n\r\nThat being said: You can of course create an action in your shared `Fastfile` that does exactly what I described above. Download some file, edit `Pluginfile` (or create it if it doesn'T exist) or add it additionally to `Gemfile`, then run `bundle install` using the `sh()` action. That would effectively \"force-install\" a plugin when your imported `Fastfile` is used. Would that solve your problem?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1472", "user": "Skoti", "root": "ROOT147", "reply_to": "COM1471", "timestamp": "2018-11-26T21:14:06Z", "text": "<details>\r\n\r\n> `Pluginfile` is not similar to `Deliverfile` and other configuration files: When you add a plugin, some code is added to your `Gemfile` that includes `Pluginfile` there. `Gemfile` (and the included information from your `Pluginfile`) is used to define which gems to install when you run `bundle install` on your project.\r\n\r\n> So to implement a method like the one you want, at runtime in fastlane, you would then have to change both the `Gemfile` to include the new imported data, and run `bundle install`. It would change files on the file system and also\r\n\r\nProbably that would still not work? When running fastlane command via `bundle exec` no other gem can be loaded as _bundler_ disallows loading gems that are not in the bundle. So when `import_from_git` is called in _fastlane_ runtime, _bundler_ runtime environment has already been created and won't allow any other gems to be loaded.\r\n\r\nHowever, the only solution that comes to my mind, to make it work with _bundler_, would be to nest another call to `bundle exec` but with a temporary _Gemfile_ (it can be passed like that: `BUNDLE_GEMFILE=PATH_TO_TEMP/Gemfile bundle exec some_command`). This temporary _Gemfile_ would include all the entries from a _project_ _Gemfile_/_Pluginfile_ and all the entries from an _imported_ _Gemfile_/_Pluginfile_ (as _Gemfile_ is actually calling `eval_gemfile` on a _Pluginfile_ so it is like those entries would be in a _Gemfile_). No modification of a current _Gemfile_ or any other file is needed.\r\n\r\nBut this is  **not a good** idea ;), and it would only work if `import_from_git` was at the beginning of a _Fastfile_ - it would be the most convenient to just call `bundle_exec` with the same command and parameters as the original one.\r\nOne caveat of it is that it nests with each `import_from_git` call over and over again...\r\nThe other one is that if `import_from_git` is not placed at the top of a _Fastfile_ it means some lanes or anything else might already been executed and would require to somehow reuse this _fastlane_ state in a new `bundle exec` call...\r\nTerrible idea that is why I am hiding it in the details \ud83d\ude03 \r\n</details>\r\n\r\nSo I guess it **cannot** be done due to usage of _bundler_.\r\n**But** if one is **not using** _bundler_ in a project (and hence both _Gemfile_ and _Pluginfile_), then they could just add plugins via `fastlane_require` action in a project _Fastfile_ or in an imported _Fastfile_.\r\nThis can be done in the current version of _fastlane_ and it works.\r\n<br/>\r\n\r\n> > Anyway, if this is not possible, can we add a note in `import_from_git` [description](https://docs.fastlane.tools/actions/import_from_git/) with reasoning if any?\r\n> \r\n> Documentation of that actions says:\r\n> \r\n> > Import another Fastfile from a remote git repository to use its lanes\r\n> \r\n> That is pretty clear that this action is for importing `Fastfile`s.\r\n\r\nExactly, that is why I was surprised that it imports all the files of custom actions as well and not only a _Fastfile_ ;). It is not even mentioned. And as plugins are just actions this is probably why people think that remote plugins should be imported or actually expect them to be imported implicitly like in a case of custom actions.\r\nBesides, searching for issues regarding `import_from_git` and _Pluginfile_ yields a lot of results so it seems like it is not so obvious for people and they constantly ask to support _Pluginfile_ in `import_from_git`.\r\nHence, I think an explanation with a good reasoning would be welcomed.\r\n<br/>\r\n\r\n> > Maybe it would be great to add a warning when `import_from_git` detects a _Pluginfile_ to remind that plugins should be installed/updated. I think it would follow _fastlane philosophy_.\r\n> \r\n> What do you mean by that? How should this work?\r\n> \r\nWhat I meant is that when `import_from_git` detects a _remote_ _Pluginfile_ (meaning in the same directory as the _Fastfile_ it tries to import) it could print a warning listing the plugin names and saying that in order to use this _remote_ _Fastfile_ these plugins are required to be in a _local_ _Pluginfile_.\r\nIt could even compare a _local_ _Pluginfile_ with a remote one and throw an error when it detects that plugins from a remote are not included in the local one. It would be very informative and helpful.\r\n<br/>\r\n\r\n> > Or _fastlane_require_plugin_ could be added in order to fail if there is no entry with a provided plugin name in a project _Pluginfile_?\r\n> \r\n> Doesn't this already happen when you use an action of a plugin, that is not installed?\r\n> \r\nYes I know that calling a plugin action would end up with an error but a usage of such an action might be somewhere far down the lanes \ud83d\ude04  i.e. after a long build or anything else.\r\nI think it is better to prevent such a _Fastfile_ from running at all as it will almost certainly finish with an error - so why wait for that?\r\nThis is just another way of prevention I have described above. This time using a `fastlane_require_plugin` as an action in a _remote_ _Fastfile_.\r\nInstead of adding a _remote_ _Pluginfile_ (like in a case above and handle that _Pluginfile_ in `import_from_git`) you could specify directly in a _remote_ _Fastfile_ that some plugins are required via `fastlane_require_plugin` action - this would work like in a case above - check if these plugins are in a _local_ _Pluginfile_ and then throw an error if missing.\r\n\r\nBoth of these preventions of course make sense if one is using _bundler_, _Gemfile_ and _Pluginfile_. Otherwise it is enough to use the current `fastlane_require` action and it will install a particular plugin gem (if necessary) upon running any lane from such a _Fastfile_.\r\nSo now both usages are handled.\r\n\r\n<br/>\r\n\r\n> That being said: You can of course create an action in your shared `Fastfile` that does exactly what I described above. Download some file, edit `Pluginfile` (or create it if it doesn'T exist) or add it additionally to `Gemfile`, then run `bundle install` using the `sh()` action. That would effectively \"force-install\" a plugin when your imported `Fastfile` is used. Would that solve your problem?\r\n\r\nLike I said above, if I use _bundler_ it is almost impossible (see details at the top). If I don't use _bundler_ (and thus neither _Gemfile_ nor _Pluginfile_) I can just require my plugins via `fastlane_require` and they will be installed if necessary.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1473", "user": "janpio", "root": "ROOT147", "reply_to": "COM1472", "timestamp": "2018-11-26T21:35:30Z", "text": "> **But** if one is **not using** _bundler_ in a project (and hence both _Gemfile_ and _Pluginfile_), then they could just add plugins via `fastlane_require` action in a project _Fastfile_ or in an imported _Fastfile_.\r\n\r\nIf you install a plugin, you always configure fastlane to use bundler: https://docs.fastlane.tools/plugins/create-plugin/#add-a-plugin-to-your-project Plugins are (by definition) gems loaded from rubygems. That is the difference to a local custom action.\r\n\r\nBesides that I honestly don't follow any more. Maybe create a new issue with just the actual _problem_ you want to solve, and not suggestion for the solution.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1474", "user": "Skoti", "root": "ROOT147", "reply_to": "COM1473", "timestamp": "2018-11-26T23:21:39Z", "text": "> > **But** if one is **not using** _bundler_ in a project (and hence both _Gemfile_ and _Pluginfile_), then they could just add plugins via `fastlane_require` action in a project _Fastfile_ or in an imported _Fastfile_.\r\n> \r\n> If you install a plugin, you always configure fastlane to use bundler: https://docs.fastlane.tools/plugins/create-plugin/#add-a-plugin-to-your-project Plugins are (by definition) gems loaded from rubygems. That is the difference to a local custom action.\r\n> \r\nCome on, I know they are gems and normally you use _bundler_ for plugins.\r\n**One thing** is that I am providing a **workaround** for `import_from_git` to work with plugins but without _bundler_. As _Pluginfile_ requires _bundler_ and such a usage cannot be supported in `import_from_git` action.\r\n\r\nPut this in a remote _Fastfile_:\r\n`fastlane_require \"fastlane-plugin-clubmate\"`\r\nand you can just use this action in a lane like that:\r\n```\r\nlane :custom_lane do\r\n    clubmate\r\nend\r\n```\r\nwhen you **import** this _Fastfile_ in another one it will also **work**, providing that you do not use _bundler_.\r\n\r\n**The second** thing is that in my previous comment I have suggested adding some **improvements** (prevention steps) either in a form of a new action `fastlane_require_plugin` or additional safety-checks in `import_from_git` action to help mitigate issues when using plugins in a _remote_ _Fastfile_ (in a normal way with _bundler_).\r\n\r\nAs this issue is a _Feature_ _Request_ I was hoping to discuss all that and at the same time be proactive and bring up some ideas.\r\nBy looking at _fastlane_ issues I can see that using a _shared_ _Fastfile_ where one would like to use some plugins, is a problem raised many times and it probably needs some support.\r\n\r\nSo when using _bundler_ and importing a _remote_ _Fastfile_ it **cannot** be **guaranteed** that all the plugins used in this _remote_ _Fastfile_ are installed **locally**.\r\nWhat is more, it can be even unknown what plugins are required (without looking at the source of the _remote_ _Fastfile_) as there is no need to create (although it would be reasonable) a _Pluginfile_ for this _remote_ _Fastfile_.\r\nAnd as you can have multiple projects using a _shared_ _Fastfile_ and/or multiple _shared_ _Fastfiles_ it is easy to lose track of which plugins are required where - hence I wanted to improve that by giving some hints when importing a _shared/remote Fastfile_.\r\n<br/>\r\n\r\n> Besides that I honestly don't follow any more. Maybe create a new issue with just the actual _problem_ you want to solve, and not suggestion for the solution.\r\n\r\nSorry to hear that, but what is causing here an issue for you? It supposed to be a discussion so you can ask questions too. \ud83d\ude04 Otherwise, I cannot help you understand. If you do not follow - can you ask other collaborators for help?\r\n\r\nBy the way, I do not think spawning yet another issue on the same subject is going to help solve anything. Even more, I do not think that \"the actual problem\" I want to solve and \"a suggestion for the solution\" of this problem should be in separate threads?! \ud83d\ude31 What are you saying?\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1475", "user": "Skoti", "root": "ROOT147", "reply_to": "COM1474", "timestamp": "2018-11-27T14:06:07Z", "text": "> Well, now I am wishing you good luck in your search for a solution. I am not interested in spending more time on this.\r\n\r\nGreat attitude @janpio, especially as a _fastlane_ collaborator. Why not say it in here publicly?\r\nSo instead of having a discussion and providing a counter example or presenting **any** reasoning why something would not be implemented, you are just discouraging people from helping _fastlane_...\r\nIs that what you guys do in here?\r\n@joshdholtz, @mfurtak, @hjanuschka, @AliSoftware @milch @revolter ", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM1476", "user": "janpio", "root": "ROOT147", "reply_to": "COM1475", "timestamp": "2018-11-27T14:13:47Z", "text": "I posted a reply in the heat of a discussion. Then I quickly deleted it, as I recognized that it was not a helpful reaction and wouldn't help advance the conversation. Now you post a selected part of that deleted comment again. This is highly inappropriate.\r\n\r\nDo you really wonder why I don't want to spend any more time helping you?\r\n\r\nMentioning other contributors that have not participated in the discussion is inappropriate as well, by the way.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1477", "user": "revolter", "root": "ROOT147", "reply_to": "COM1476", "timestamp": "2018-11-27T14:29:43Z", "text": "Personally, I understand both sides.\r\n\r\nOne thinks it would be obvious for plugins to \"just work\" too, while I clearly understand why is not feasible, and I'd argue that it's actually incorrect. You use a dependency manager to install the required dependencies and then run something that uses them, it would be weird for the thing you run to install dependencies for you.\r\n\r\nKnowing this, another way to improve this is what @Skoti already mentioned, and which I always love: automatically prevent incorrect usages. So the current options seems to be:\r\n1. Warn users (`UI.important`) when they `import_from_git` and a `Pluginfile` also exists in that remote.\r\n2. Create a separate action (`ensure_plugins`?) that ensures that all the required plugins (defined in the local and in the remote `Pluginfile`s) are available (could be \"harder\" because of [this](https://docs.fastlane.tools/create-action/#submitting-the-action-to-the-fastlane-main-repo))\r\n\r\nAnd as always, PRs welcome! \ud83d\ude03", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1478", "user": "Skoti", "root": "ROOT147", "reply_to": "COM1477", "timestamp": "2018-11-27T14:37:39Z", "text": "Well I didn't feel of this as being a heated discussion. So excuse me if this is how you felt.\r\nAnyway, it is nice to know now that you have realized it was a bad move and deleted the comment. However, I quoted the whole part not a selected one as you suggest.\r\n\r\nAnd I do not think that looking for help in other contributors was inappropriate in that case as you clearly didn't want to take care of this issue.\r\n\r\nAnd now you make another comment in a similar style \ud83d\ude1e :\r\n> Do you really wonder why I don't want to spend any more time helping you?\r\n\r\nSeriously, have I done something to you?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1479", "user": "Skoti", "root": "ROOT147", "reply_to": "COM1478", "timestamp": "2018-11-27T14:39:53Z", "text": "@revolter \r\nThanks for a great reply!\r\nAnd the issue starts to go somewhere immediately.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14710", "user": "revolter", "root": "ROOT147", "reply_to": "COM1479", "timestamp": "2018-11-27T14:43:45Z", "text": "I think the warning could be added somewhere here:\r\n\r\nhttps://github.com/fastlane/fastlane/blob/4e04d9310e339ad8d57a977a7e9c6db1903312d4/fastlane/lib/fastlane/fast_file.rb#L263-L273\r\n\r\n@Skoti, Would you be up to create a PR for us to review? \ud83d\ude80", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14711", "user": "KrauseFx", "root": "ROOT147", "reply_to": "COM14710", "timestamp": "2018-11-27T15:24:13Z", "text": "Hey @Skoti, I locked this issue for now. Even though maybe a comment by @janpio might have come across as rude, every fastlane contributor here does this in their free time to help other people. Time is limited, and spending time on other developer's issues is usually hard to justify. It's not cool you mentioned and tried to include a random set of other contributors in the hope they'd help out. As you can see, _fastlane_ is a highly active, and widely used open source project, and there is no possible way to reply to every single issue. I wrote about the problems of how difficult it is to scale open source communities over here https://krausefx.com/blog/scaling-open-source-communities", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14712", "user": "fastlane-bot", "root": "ROOT147", "reply_to": "COM14711", "timestamp": "2018-12-27T17:32:14Z", "text": "There hasn't been any activity on this issue recently. Due to the high number of incoming GitHub notifications, we have to clean some of the old issues, as many of them have already been resolved with the latest updates.\n\nPlease make sure to update to the latest `fastlane` version and check if that solves the issue. Let us know if that works for you by adding a comment :+1:", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14713", "user": "fastlane-bot", "root": "ROOT147", "reply_to": "COM14712", "timestamp": "2019-01-04T17:32:16Z", "text": "This issue will be auto-closed because there hasn't been any activity for a few months. Feel free to [open a new one](https://github.com/fastlane/fastlane/issues/new) if you still experience this problem :+1:", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT148", "user": "sneak", "root": "ROOT148", "reply_to": null, "timestamp": "2019-11-26T18:33:42Z", "text": "Atom still spies on the user even prior to consent request ### Description\r \r Atom is contacting Microsoft/GitHub processes running on Amazon servers on first launch **without consent**, and leaking my IP address and timestamp to the manufacturer, as well as transmitting the fact that I use Atom (via outbound request) to thousands of other people and organizations.\r \r ### Steps to Reproduce\r \r 1. Launch Atom for the first time\r \r **Expected behavior:**\r \r No telemetry is sent.\r \r **Actual behavior:**\r \r Telemetry is sent.\r \r Atom transmits my IP address (and implicit timestamp) to the manufacturer and thousands of other people.\r \r At no point am I prompted for consent prior to this happening.  This happens *silently*.\r \r Only **after** this information has been sent out of my machine does the main application window open with the consent dialog (which has its own issues).\r \r <img width=\"548\" alt=\"Screen Shot 2019-11-26 at 10 22 52\" src=\"https://user-images.githubusercontent.com/408977/69661425-395f1600-1037-11ea-9cfd-64f6959d4f60.png\">\r <img width=\"577\" alt=\"Screen Shot 2019-11-26 at 10 22 56\" src=\"https://user-images.githubusercontent.com/408977/69661427-395f1600-1037-11ea-9246-c93edb428562.png\">\r \r **Reproduces how often:**  100% of the time on first launch\r \r ### Versions\r \r 1.41.0 x64 osx\r \r ### Additional Information\r \r A user's IP address, as well as the tracking/telemetry/analytics/autoupdate target host IP are both transmitted from the user's machine at time of first launch (adding a timestamp to these first two pieces of data).\r \r This tuple of (user source IP, atom.io destination ip, TCP port, TLS SNI hostname, timestamp) **leaks usage information** to thousands of different people when it is sent from the user's computer: ISP, hosting providers, network interchanges, intelligence services (hi Ed!), Microsoft internal systems administrators, GitHub systems administrators, and Amazon network administrators.  The user is given **no opportunity** to opt out of this, to prevent it, and is **not even made aware of it happening**.\r \r This means that the work on #12281 is *incomplete*.  The software is still **transmitting user data without consent** before the consent dialog even appears.\r \r Wikipedia defines spyware as:\r \r > Spyware is a software that aims to gather information about a person or organization, sometimes without their knowledge, and send such information to another entity without the consumer's consent. \r \r ## Required Elements\r \r 1. software :white_check_mark: atom is software\r 1. *gathers information about a person* :white_check_mark: information that the user is launching Atom for the first time\r 1. *without their knowledge* :white_check_mark: no information is displayed to the user when the request is made, or any time thereafter\r 1. *send information to another entity* :white_check_mark: sends data to ISP, routers, hosting companies and staff, GitHub, Microsoft, Amazon, and NSA\r 1. *without the user's consent* :white_check_mark: no consent was asked or provided, and indeed, did not exist\r \r Presently, Atom does *all of these* on first launch.", "meta": {"posReactions": "14", "negReactions": "2"}}
{"id": "COM1480", "user": "sneak", "root": "ROOT148", "reply_to": "ROOT148", "timestamp": "2019-11-26T18:57:28Z", "text": "You'll know that the work is done on #12281 when the app can be first-time launched on a fresh system, opt-out of metrics/telemetry/reporting selected by the user, a file created, typed into, saved, and the application quit, without a single network request being made (meaning that the usage of Atom is not leaked to the LAN, the ISP, the intermediate networks, anyone monitoring those networks, or any staff member of Microsoft/GitHub (including network administrators or network security monitoring devices)).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1481", "user": "Arcanemagus", "root": "ROOT148", "reply_to": "COM1480", "timestamp": "2019-11-26T20:09:30Z", "text": "Atom is designed to run in an internet connected environment, doing things such as checking for updates (your first dialog) without prompting the user. The second dialog you show is from the telemetry package which clearly states that if you opt out it will send an anonymous report of an opt out and then ignore future data:\r\n![image](https://user-images.githubusercontent.com/427137/69666892-de7eec00-1041-11ea-8448-d6585f6b7471.png)\r\n\r\nYou are certainly free to block the network access and Atom will work in an offline mode if that is your preference, if that is not what you desire though there are plenty of other editors out there that may fit your needs better. Atom is fully open source so you are welcome to build your own version that fits your requirements, note that the _branding_ is copyrighted so if you do that and decide to publish it you can't call it Atom \ud83d\ude09.\r\n\r\nThanks for reaching out!\r\n\r\n----\r\n\r\nWe have passed along the information to the maintainers team. Because we treat our issues list as [the Atom team's backlog](https://en.wikipedia.org/wiki/Scrum_(software_development)#Product_backlog), we close feedback issues after passing along the information to the maintainers to keep our backlog clean and focused. In the future, if you want to send feedback to the maintainers you can do so more directly by sending email to atom@github.com.", "meta": {"posReactions": "0", "negReactions": "7"}}
{"id": "COM1482", "user": "sneak", "root": "ROOT148", "reply_to": "COM1481", "timestamp": "2019-11-26T20:10:56Z", "text": "> Atom is designed to run in an internet connected environment\r\n\r\nNobody's saying it shouldn't use the network.  It just shouldn't use the network *before the user has given it permission*, because otherwise it is a **data leak**.  That's *why the consent dialog exists*.\r\n\r\nVery obviously this is a bug: the auto-update mechanism, which is itself a form of telemetry so long as it uses the network (transmitting to the manufacturer that the user has installed Atom), must be serialized to occur *only after* their consent (or lack thereof) to telemetry is indicated.  Doing it beforehand renders the telemetry opt-out entirely ineffective, as you *still end up sending telemetry* to the \"what version is current\" service, even when the user doesn't want it sent.\r\n\r\nThat seems to be a recurring issue, as well: #20185 elaborates on that.", "meta": {"posReactions": "22", "negReactions": "2"}}
{"id": "COM1483", "user": "sneak", "root": "ROOT148", "reply_to": "COM1482", "timestamp": "2019-11-26T23:19:43Z", "text": "> *The second dialog you show is from the telemetry package which clearly states that if you opt out it will send an anonymous report of an opt out and then ignore future data*\r\n\r\nFYI that `central.github.com` connection happens *before* I click *anything* in the consent dialog (including the opt out button), so it's clearly sending something in advance of knowing whether it is permitted to or not.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM1484", "user": "Arcanemagus", "root": "ROOT148", "reply_to": "COM1483", "timestamp": "2019-11-26T23:35:09Z", "text": "> FYI that central.github.com connection happens before I click anything in the consent dialog (including the opt out button), so it's clearly sending something in advance of knowing whether it is permitted to or not.\r\n\r\nCan you report that over in https://github.com/atom/telemetry/issues/33? Thanks!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1485", "user": "sneak", "root": "ROOT148", "reply_to": "COM1484", "timestamp": "2019-11-26T23:37:00Z", "text": "I did so.  You need to reopen this one too, because, inconvenient or not, autoupdate checks are also an inadvertent form of telemetry *whether the project uses them for the purpose or not*.  The data (user with IP X has opened Atom at time Y) is transmitted to third parties regardless of whether or not Microsoft is collecting or using this information as telemetry.\r\n\r\nIt doesn't matter if the telemetry is coming from \"the telemetry package\" or not.  It's still useful as telemetry, and is sent without consent.", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM1486", "user": "Arcanemagus", "root": "ROOT148", "reply_to": "COM1485", "timestamp": "2019-11-26T23:39:42Z", "text": "As already stated, if that form of \"telemetry\" is an issue for you feel free to block the network access or create a version of Atom that doesn't check for updates. This isn't something the Atom team is currently interested in changing though.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM1487", "user": "sneak", "root": "ROOT148", "reply_to": "COM1486", "timestamp": "2019-11-26T23:40:31Z", "text": "I've already done so, naturally.\r\n\r\nWhat about the thousands of other users who haven't spent time and money on things like Little Snitch, who nevertheless don't want to be tracked and explicitly opt out of telemetry that still get telemetry sent (and logged by their government forever) against their wishes?  How is that good UX?  How is that showing respect for your userbase?\r\n\r\nForks don't benefit anyone.  Look at the VSCodium mess that was created; let's not repeat that.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1488", "user": "sneak", "root": "ROOT148", "reply_to": "COM1487", "timestamp": "2019-11-27T00:03:29Z", "text": "If you're going to insist on the autoupdate thing, couldn't you just do it once per month, at a random number of cumulative hours delay (say, 1-12) after startup, so that it doesn't function as an ad hoc \"user has launched the app\" telemetry event to everyone watching and logging the network?  It would still work just fine, and wouldn't be transmitting user activity on every launch.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1489", "user": "ryanisnan", "root": "ROOT148", "reply_to": "COM1488", "timestamp": "2019-11-27T00:13:38Z", "text": "If you bundled auto-update consent in with telemetry consent, that seems like an unfortunate decision for the user.\r\n\r\nAuto-updates, while they are revealing, are different than pure telemetry by most definitions.\r\n\r\nIt's probably to be expected that a) most people turn off telemetry when given an option and b) most people want auto-updates turned on.\r\n\r\nI'm not sure how it would A/B test, but my guess is that having auto-updates default to off would result in a lot less automatically updated Atom clients.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14810", "user": "blordpluto", "root": "ROOT148", "reply_to": "COM1489", "timestamp": "2019-11-27T00:23:40Z", "text": "> As already stated, if that form of \"telemetry\" is an issue for you feel free to block the network access or create a version of Atom that doesn't check for updates. This isn't something the Atom team is currently interested in changing though.\r\n\r\nFolks can reasonably disagree about the privacy impact of something like this, and/or the feasibility of personal workarounds. But I fail to see how anyone fairminded could accept that an identifying outgoing connection is sent before the user presented with an opt-in/out. That's a dark pattern. Any organization that practices it is staining its own credibility. It's just a falsehood, and a bad precedent on every level.\r\n\r\n> Atom is designed to run in an internet connected environment\r\n\r\nIs this documented somewhere? And why is this a design constraint? Speaking generally, I would propose the opposite, that a text editor be designed to be fully capable in all respects when offline. When I look at your home page bullet points, none of them relate to having an internet connection. And when I look at the \"short version\" of your unequivocal privacy statement:\r\n\r\n> We only collect the information you choose to give us\r\n\r\nit's pretty hard to square with the current behavior. _You're collecting something users haven't chosen to give you._\r\n", "meta": {"posReactions": "3", "negReactions": "1"}}
{"id": "COM14811", "user": "sneak", "root": "ROOT148", "reply_to": "COM14810", "timestamp": "2019-11-27T00:25:42Z", "text": "> Auto-updates, while they are revealing, are different than pure telemetry by most definitions.\r\n\r\nIt doesn't matter how we define them, *practically*, immediate auto update checks on launch *amount to telemetry*.  It's a rose by any other name.  It sends out a launch event across the network, regardless of what the person who implemented the feature intended it to accomplish.  It must be treated as such, regardless of intent, because that is the *effect*.\r\n\r\n> I'm not sure how it would A/B test, but my guess is that having auto-updates default to off would result in a lot less automatically updated Atom clients.\r\n\r\nIs this a worse thing than every single Atom user reporting to their ISP and national governments and Microsoft for permanent logging exactly when and where they open their text editor every single time?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14812", "user": "Arcanemagus", "root": "ROOT148", "reply_to": "COM14811", "timestamp": "2019-11-27T00:30:02Z", "text": "> > Atom is designed to run in an internet connected environment\r\n>\r\n> Is this documented somewhere? And why is this a design constraint? Speaking generally, I would propose the opposite, that a text editor be designed to be fully capable in all respects when offline.\r\n\r\nIt's an expected scenario to check for updates, it's not a _constraint_ though. As I have stated multiple times you can definitely work with Atom while offline (or with network requests blocked). You can even turn off checking for updates in the settings if you want, although that wouldn't prevent the first run connection this issue is about.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14813", "user": "neilpanchal", "root": "ROOT148", "reply_to": "COM14812", "timestamp": "2019-11-27T00:45:05Z", "text": "@Arcanemagus This whole issue is extremely simple: Atom should not send data out to the world without asking the user. Period. \r\n\r\nAsking the user to block network access is tangential and does not inspire confidence in the Atom. Internet \"connected\" app means that the App can connect to the internet if needed and invoked by the user. Not willy-nilly send out telemetry data to the world.\r\n\r\nAtom should also ask the user if it can check for updates.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14814", "user": "blordpluto", "root": "ROOT148", "reply_to": "COM14813", "timestamp": "2019-11-27T00:51:14Z", "text": "> It's an expected scenario to check for updates, it's not a constraint though.\r\n\r\n**It is not an expected scenario from the user's perspective.** With great respect, you're just wildly mistaken. Consider the following flow: User looks at your privacy policy. User reads the first sentence and thinks that consent will be requested for outbound connections. User obtains an installer. User launches app and app immediately phones home without consent.\r\n\r\nI think we all understand that there are strong Business Intelligence incentives to want to collect  installation data. Those incentives only get answered by pushback, in micro-processes like this thread. Would it persuade the BI audience if they sat back and contemplated a legal review of this under the CCPA? Just a reminder that enforcement starts July 1, 2020.\r\n\r\n> You can even turn off checking for updates in the settings if you want, although that wouldn't prevent the first run connection this issue is about.\r\n\r\nYou've simply restated the problem.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14815", "user": "ryanisnan", "root": "ROOT148", "reply_to": "COM14814", "timestamp": "2019-11-27T00:54:41Z", "text": "> > Auto-updates, while they are revealing, are different than pure telemetry by most definitions.\r\n> \r\n> It doesn't matter how we define them, _practically_, immediate auto update checks on launch _amount to telemetry_. It's a rose by any other name. It sends out a launch event across the network, regardless of what the person who implemented the feature intended it to accomplish. It must be treated as such, regardless of intent, because that is the _effect_.\r\n\r\nI don't disagree with you, just trying to play devil's advocate a bit. There's clearly a reason Atom's team believes auto-updates on by default is of high importance. Imploring maintainers of an open source software is not going to yield the best results, I think. Nor is telling users to fork your app if they don't like it.\r\n\r\nI do think that while delivered in a dictatorial manner, @neilpanchal's comment is worth discussing more.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14816", "user": "sneak", "root": "ROOT148", "reply_to": "COM14815", "timestamp": "2019-11-27T00:57:49Z", "text": "It's not dictatorial, it's principled.  Using a user's computer to do things against them, silently, without their consent, is unethical.  He's speaking plainly about the ethics of the matter, which comes across as pretty harsh, but ultimately it's no more harsh than asserting 1 as true and zero as false.  It's the simple result of the principle \"the computer belongs to the user and should respect the user's wishes and not silently obey those of a remote party instead\".", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14817", "user": "lee-dohm", "root": "ROOT148", "reply_to": "COM14816", "timestamp": "2019-11-27T00:59:56Z", "text": "Thanks to everyone for the feedback and for sharing your concerns.\r\n\r\nWe obviously disagree over some core definitions here. It appears that the core idea being asserted is that making any network connection is, in essence, sharing private information with whomever might have access to sniffing the network at any point between the source and the destination. Secondarily, that Atom has a responsibility to prevent any network access that the user doesn't explicitly grant consent to.\r\n\r\nWhether we agree on the first point or not, the way that Atom is designed, it _cannot_ prevent all network access in all circumstances. If you install a package that opens a network connection, there's nothing that the core Atom code can do currently to prevent that and that ability isn't something that the Atom maintainer team is going to spend time investigating or implementing. So, if you want an editor that will work completely offline with no network connections whatsoever, Atom is not going to be the appropriate editor for you.\r\n\r\nWe agree that the telemetry package shouldn't send information before a button is clicked, so we're definitely going to investigate premature connections to `central.github.com` before the user has explicitly clicked a button and we are tracking that in https://github.com/atom/telemetry/issues/33.\r\n\r\nWe can appreciate that different people make different tradeoffs when it comes to network exposure versus functionality. We've made choices that we feel strike a good balance for the majority of users, so we'll be leaving the rest, specifically auto-update checking, the way it currently is designed.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT149", "user": "spkane", "root": "ROOT149", "reply_to": null, "timestamp": "2015-02-11T00:12:16Z", "text": "Vagrant box downloads extremely slow When relying on vagrant to download a box I frequently see connection speeds like this:  ``` default: Downloading: http://boxes.example.com/vagrant/boxes/c6/packer_c6_2.5.2_virtualbox.box default: Progress: 20% (Rate: 179k/s, Estimated time remaining: 0:41:37) ```  (Rate: **179k/s**)  Yet when I use wget to the same URL:  ``` wget http://boxes.example.com/vagrant/boxes/c6/packer_c6_2.5.2_virtualbox.box --2015-02-10 09:52:12--  http://boxes.example.com/vagrant/boxes/c6/packer_c6_2.5.2_virtualbox.box Resolving boxes.example.com... 10.1.0.17 Connecting to boxes.example.com|10.1.0.17|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 830674320 (792M) [text/plain] Saving to: 'packer_c6_2.5.2_virtualbox.box'  packer_c6_2.5.2_virtualbox.bo   0%[                                                         ]   7.12M   696KB/s   eta 19m 50s ```  (Rate: **696KB/s**) or often higher.  This particular example was pulled when on Wifi and connected to an IPSEC VPN. ", "meta": {"posReactions": "14", "negReactions": "0"}}
{"id": "COM1490", "user": "sethvargo", "root": "ROOT149", "reply_to": "ROOT149", "timestamp": "2015-02-11T01:16:30Z", "text": "Hi @spkane \n\nSome boxes are hosted on Atlas and sometimes Atlas is just acting as a proxy to a user-hosted box. If you give more information on the specific box(es) you're downloading, we can do some research.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1491", "user": "spkane", "root": "ROOT149", "reply_to": "COM1490", "timestamp": "2015-02-12T03:17:26Z", "text": "@sethvargo This box is actually a box I built using packer and it is hosted on a remote server. I'm trying to understand why the download in significantly slower using vagrant then using wget to the exact same URL.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1492", "user": "sethvargo", "root": "ROOT149", "reply_to": "COM1491", "timestamp": "2015-02-12T15:22:55Z", "text": "@spkane sorry - I misread your original issue.\n\nI would suspect (and maybe @mitchellh could elaborate more) a few things:\n1. Ruby is slow and somehow throttling the subprocess\n2. Wget is faster than curl (which is what Vagrant is using)\n3. Vagrant is also allocating time to unpack the box\n4. Wget is allowing for some type of compressed download\n\nIt would be helpful if you could benchmark this with curl for reference.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1493", "user": "mitchellh", "root": "ROOT149", "reply_to": "COM1492", "timestamp": "2015-02-24T18:40:57Z", "text": "I really can't explain this. Vagrant doesn't do anything during the subprocess Ruby-wise: it subprocesses to `curl`. It doesn't even do the download in Ruby. Perhaps wget is using multiple connections to download multiple parts? I really don't know, but unless we get more information I have to assume that Vagrant is fine here. \n\nIs `curl` just as slow? Vagrant is just subprocessing to curl until it completes.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1494", "user": "keeprock", "root": "ROOT149", "reply_to": "COM1493", "timestamp": "2015-12-01T20:52:31Z", "text": "I'm experience the same slow experience. Anyone can try aria - http://aria2.sourceforge.net/ and http://stackoverflow.com/questions/3430810/wget-download-with-multiple-simultaneous-connections\n\nIt's seems a little bit faster, but, man, you can set this up using default vagrant download mechanism and take a walk or make yourself a sandwich. Get way from screen for a little bit.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1495", "user": "karlkfi", "root": "ROOT149", "reply_to": "COM1494", "timestamp": "2016-01-26T20:31:56Z", "text": "Having the same problem here:\n1. Upload a box manually to atlas\n2. Create a new Vagrantfile with just `vm_cfg.vm.box_url = <user>/box-name`\n3. `vagrant up` - box downloads slowly\n4. wget box url from atlas (see `vagrant up` output) - box downloads lightening fast\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1496", "user": "clakeb", "root": "ROOT149", "reply_to": "COM1495", "timestamp": "2016-02-01T18:26:29Z", "text": "I wish there was just a +1 for this. Me too. Same connection for all 3 attempts. VPN turned off.\n- `vagrant up` took 25+ minutes.\n- `wget` took 3 minutes.\n- `curl` took 4 minutes. \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1497", "user": "milhaus", "root": "ROOT149", "reply_to": "COM1496", "timestamp": "2016-02-02T21:13:55Z", "text": "Ubuntu vivid64 is downloading at ~56kbps. I'm on a 100mbit symmetric connection.\nedit: it timed out before it could finish.\nedit2: I can confirm that https://atlas.hashicorp.com/ubuntu/boxes/vivid64/versions/20160128.0.0/providers/virtualbox.box downloads dramatically faster over wget than via \"vagrant up\".\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1498", "user": "ghost", "root": "ROOT149", "reply_to": "COM1497", "timestamp": "2016-02-06T07:41:08Z", "text": "I'm trying to download the scotch/box and current download speeds using vagrant are less than 10kbps.\n\ndefault: Progress: 0% (Rate: 2603/s, Estimated time remaining: 33:17:38)\n\nHowever just as bad using wget.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1499", "user": "tehmaspc", "root": "ROOT149", "reply_to": "COM1498", "timestamp": "2016-02-15T16:28:42Z", "text": "ditto; some popular boxes are very slow to download - i'm updating ubuntu/trusty64 as we speak and it's dropping below 1Kb/s. Been seeing this for a couple wks now.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14910", "user": "JasonTheAdams", "root": "ROOT149", "reply_to": "COM1499", "timestamp": "2016-03-07T17:54:37Z", "text": "+1 -- exact same as last comment\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14911", "user": "winni2k", "root": "ROOT149", "reply_to": "COM14910", "timestamp": "2016-03-09T02:25:51Z", "text": "Same here:\n\n```\n$ vagrant box add lazygray/heroku-cedar-14\n==> box: Loading metadata for box 'lazygray/heroku-cedar-14'\n    box: URL: https://atlas.hashicorp.com/lazygray/heroku-cedar-14\n==> box: Adding box 'lazygray/heroku-cedar-14' (v1.0.6) for provider: virtualbox\n    box: Downloading: https://atlas.hashicorp.com/lazygray/boxes/heroku-cedar-14/versions/1.0.6/providers/virtualbox.box\n==> box: Box download is resuming from prior download progress\n    box: Progress: 3% (Rate: 281k/s, ...\n```\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14912", "user": "k1ng440", "root": "ROOT149", "reply_to": "COM14911", "timestamp": "2016-03-13T21:57:57Z", "text": "same here\n\n```\nvagrant box update\n==> default: Checking for updates to 'laravel/homestead'\n    default: Latest installed version: 0.4.1\n    default: Version constraints: >= 0\n    default: Provider: vmware_desktop\n==> default: Updating 'laravel/homestead' with provider 'vmware_desktop' from version\n==> default: '0.4.1' to '0.4.2'...\n==> default: Loading metadata for box 'https://atlas.hashicorp.com/laravel/homestead'\n==> default: Adding box 'laravel/homestead' (v0.4.2) for provider: vmware_desktop\n    default: Downloading: https://atlas.hashicorp.com/laravel/boxes/homestead/versions/0.4.2/providers/vmware_desktop.box\n    default: Progress: 0% (Rate: 42210/s, Estimated time remaining: 6:10:54))\n```\n", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM14913", "user": "richard-scott", "root": "ROOT149", "reply_to": "COM14912", "timestamp": "2016-03-14T10:23:23Z", "text": "Is there any way to use something like axel to stream downloads in quicker?\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14914", "user": "winni2k", "root": "ROOT149", "reply_to": "COM14913", "timestamp": "2016-03-16T10:32:10Z", "text": "I guess there's nothing preventing people from sharing boxes via torrent.  For example, below is a magnet link for the heroku-cedar-14 box:\n\n> magnet:?xt=urn:btih:5bb1480d5316f229bb71be55b56b06278de41a67&dn=heroku-cedar-14.box&tr=http%3A%2F%2F9.rarbg.com%3A2710%2Fannounce&tr=http%3A%2F%2Fannounce.torrentsmd.com%3A6969%2Fannounce&tr=http%3A%2F%2Fbt.careland.com.cn%3A6969%2Fannounce&tr=http%3A%2F%2Fexplodie.org%3A6969%2Fannounce&tr=http%3A%2F%2Fmgtracker.org%3A2710%2Fannounce&tr=http%3A%2F%2Ftracker.tfile.me%2Fannounce&tr=http%3A%2F%2Ftracker.torrenty.org%3A6969%2Fannounce&tr=http%3A%2F%2Ftracker.trackerfix.com%2Fannounce&tr=http%3A%2F%2Fwww.mvgroup.org%3A2710%2Fannounce&tr=udp%3A%2F%2F9.rarbg.com%3A2710%2Fannounce&tr=udp%3A%2F%2F9.rarbg.me%3A2710%2Fannounce&tr=udp%3A%2F%2F9.rarbg.to%3A2710%2Fannounce&tr=udp%3A%2F%2Fcoppersurfer.tk%3A6969%2Fannounce&tr=udp%3A%2F%2Fexodus.desync.com%3A6969%2Fannounce&tr=udp%3A%2F%2Fglotorrents.pw%3A6969%2Fannounce&tr=udp%3A%2F%2Fopen.demonii.com%3A1337%2Fannounce&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.glotorrents.com%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=udp%3A%2F%2Ftracker.publicbt.com%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker4.piratux.com%3A6969%2Fannounce\n\nAnyone know a good website where one can search for torrents of vagrant boxes?\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14915", "user": "tehmaspc", "root": "ROOT149", "reply_to": "COM14914", "timestamp": "2016-03-16T15:03:39Z", "text": "@wkretzsch - I personally don't know at the moment about any torrent sites - but for me I wouldn't want to trust torrent links as the source for my infrastructure testing. It's a possible option but security is also important. For me official vagrant boxes from folks like puppetlabs hosted on Atlas are so slow to download at times that I wish this issue could be resolved. For internal vagrant boxes that I build for my company we have the option to host on S3 or Artifactory or private Atlas org.\n\n@mitchellh - yes - curl is just as slow (for me). I don't think it is a Vagrant issue - but a backed server hosting issue. Granted - not a Vagrant issue per se. \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14916", "user": "faddat", "root": "ROOT149", "reply_to": "COM14915", "timestamp": "2016-03-17T07:06:42Z", "text": "![screenshot from 2016-03-17 14-04-58](https://cloud.githubusercontent.com/assets/7142025/13838783/486408ba-ec49-11e5-9903-19cc1e031395.png)\n\nYes, this is because curl can only use one of my 3 connections at the same time.  No, that's not the connection's rated speed.  The rated speed is 45mbps.  Yes, bittorrent does perform better.  Just sayin-- your rationale for not supporting bittorrent is kinda thin here.  \n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14917", "user": "winni2k", "root": "ROOT149", "reply_to": "COM14916", "timestamp": "2016-03-17T12:01:38Z", "text": "@tehmaspc surely there must be a way for a website to publish the hash of their box along with a torrent link?  \n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14918", "user": "darkn3rd", "root": "ROOT149", "reply_to": "COM14917", "timestamp": "2016-03-21T22:28:33Z", "text": "I wish in general, there was a way to have incremental images, like docker images, with vagrant boxes.  For the provisioners, which bootstrap (cfengine, chef, salt, puppet, docker, etc) by downloading their platform, I wish there was a way to download a packaged up installer, so that other fresh images that use that provisioner, e.g. ubuntu + docker, would not need to download the goods again.  Box updates and provisioner downloads were already painful, but recently, have been beyond notoriously slow.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14919", "user": "PorterBytes", "root": "ROOT149", "reply_to": "COM14918", "timestamp": "2016-04-09T23:31:46Z", "text": "Just went to update my box for the first time (trusty64 - noticed the warning on my vagrant up command output), and it's going to take my 1.5 hours on a 150MBps connection - pathetic. It's 2016 - I don't know the specifics of what's going on here, but surely we can fix this, like, by the end of next week? The tech that goes into modern technologies like vagrant is amazing, something this basic should be overcome in mere hours.\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14920", "user": "faddat", "root": "ROOT149", "reply_to": "COM14919", "timestamp": "2016-04-10T01:53:28Z", "text": "Amen, Matt, Amen.  This is about UX.\n\nThere should be a recognition that line speed != line speed and practical\nsteps can be taken to overcome the daunting issue of line speed != line\nspeed.\n\nJacob Gadikian\nE-mail: faddat@gmail.com\nSKYPE: faddat\nPhone/SMS: +84 167 789 6421\n\nOn Sun, Apr 10, 2016 at 6:32 AM, Matt Porter notifications@github.com\nwrote:\n\n> Just went to update my box for the first time (noticed the warning on my\n> vagrant up command output), and it's going to take my 1.5 hours on a\n> 150MBps connection - pathetic. It's 2016 - I don't know the specifics of\n> what's going on here, but surely we can fix this, like, by the end of next\n> week? The tech that goes into modern technologies like vagrant is amazing,\n> something this basic should be overcome in mere hours.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly or view it on GitHub\n> https://github.com/mitchellh/vagrant/issues/5319#issuecomment-207881297\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14921", "user": "briancline", "root": "ROOT149", "reply_to": "COM14920", "timestamp": "2016-04-12T04:58:02Z", "text": "I just tried asking Vagrant to download ubuntu/trusty64, and was getting speeds of <= 5 KiB/sec. I killed it and tried again using the exact same command, and got 29 MiB/sec. \n\nI think @mitchellh is correct in that this doesn't really seem like a Vagrant issue. If anything, it seems more like an Atlas issue (so possibly the ELB and/or whatever's sitting behind it). I highly doubt it has anything to do with the routes or hops between end-users and the ELB VIPs -- you wouldn't typically see such a polarizing set of speeds in that case, especially considering both VIPs terminate in us-east-1.\n\nIf for no other reason, it'd be highly desirable to see these made available through a CDN rather than a centrally-located ELB. Then again, I'm just one guy (who isn't paying for this service), so take that for what it's worth. Pretty thankful it's there either way.\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14922", "user": "karlkfi", "root": "ROOT149", "reply_to": "COM14921", "timestamp": "2016-04-14T14:36:16Z", "text": "It's not just an Atlas issue. I have boxes and metadata.json on S3, with a Fastly CDN in front and regularly have the exact same issue: sometimes vagrant downloads at 100kbps and sometimes it downloads at > 5mbps. You can cancel a slow download and half the time a retry gets you the faster speeds. \n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14923", "user": "milhaus", "root": "ROOT149", "reply_to": "COM14922", "timestamp": "2016-04-15T18:29:28Z", "text": "I contacted support about this around the same time I chimed in here initially. Their response is that Vagrant uses curl to download things so they don't see this as a Vagrant problem. IMO that's an unprofessional cop-out because they chose to use curl, know that there are problems and aren't considering swapping out with an alternative to eliminate the problem for their users.\n", "meta": {"posReactions": "21", "negReactions": "0"}}
{"id": "COM14924", "user": "Haroenv", "root": "ROOT149", "reply_to": "COM14923", "timestamp": "2016-04-22T06:41:30Z", "text": "I can confirm that this is still an issue. All my peers also report times of >1h, while the connection here for other connections is around 200MB/s.\n\n```\nvagrant up\nBringing machine 'default' up with 'virtualbox' provider...\n==> default: Box 'ubuntu/trusty32' could not be found. Attempting to find and install...\n    default: Box Provider: virtualbox\n    default: Box Version: >= 0\n==> default: Loading metadata for box 'ubuntu/trusty32'\n    default: URL: https://atlas.hashicorp.com/ubuntu/trusty32\n==> default: Adding box 'ubuntu/trusty32' (v20160406.0.0) for provider: virtualbox\n    default: Downloading: https://atlas.hashicorp.com/ubuntu/boxes/trusty32/versions/20160406.0.0/providers/virtualbox.box\n    default: Progress: 11% (Rate: 43801/s, Estimated time remaining: 1:36:50)\n```\n", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM14925", "user": "faddat", "root": "ROOT149", "reply_to": "COM14924", "timestamp": "2016-04-22T23:03:20Z", "text": "While I am unsure of the origin of the problem, I really do wish that Hashicorp would get back to its unrelenting focus on user experience with this one.  **Muli-hour downloads (that should take 1-10 minutes)==bad ux.**\n", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM14926", "user": "dacodekid", "root": "ROOT149", "reply_to": "COM14925", "timestamp": "2016-04-25T20:34:51Z", "text": "Currently downloading an image for the 5th time (@13Xk/s, even with `wget`). Keep disconnecting me while around 50-90%. But it ALWAYS downloads at full speed either early morning / late night EST.  Assuming it is a traffic  issue, but regardless very bad UX.\n\n```\n    box: Progress: 47% (Rate: 106k/s, Estimated time remaining: 0:14:50)\n```\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14927", "user": "brazitech", "root": "ROOT149", "reply_to": "COM14926", "timestamp": "2016-04-29T18:04:31Z", "text": "I have been trying for 2 day's now and still can not get it to download... its a shame.. it is really not impressing new comers to  laravel .. i can only get 34ks speed.........\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14928", "user": "richard-scott", "root": "ROOT149", "reply_to": "COM14927", "timestamp": "2016-05-03T11:42:46Z", "text": "Speeds ok from the UK:\n\n```\nBringing machine 'default' up with 'virtualbox' provider...\n==> default: Box 'bento/centos-7.2' could not be found. Attempting to find and install...\n    default: Box Provider: virtualbox\n    default: Box Version: >= 0\n==> default: Loading metadata for box 'bento/centos-7.2'\n    default: URL: https://atlas.hashicorp.com/bento/centos-7.2\n==> default: Adding box 'bento/centos-7.2' (v2.2.6) for provider: virtualbox\n    default: Downloading: https://atlas.hashicorp.com/bento/boxes/centos-7.2/versions/2.2.6/providers/virtualbox.box\n    default: Progress: 11% (Rate: 7728k/s, Estimated time remaining: 0:01:19)\n```\n\nWhat is your location?\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM14929", "user": "richard-scott", "root": "ROOT149", "reply_to": "COM14928", "timestamp": "2016-05-03T11:47:35Z", "text": "Also, https://atlas.hashicorp.com/ URL's are delivered from Amazon Web Services (atlas-frontend-atlas-230110478.us-east-1.elb.amazonaws.com) so I doubt they are tight for bandwidth ;-)\n\nAre the slow downloads being made from locations a long distance away from the AWS us-east-1 DC, perhaps thats the root cause of the issue?\n\nMaybe the AWS CDN could be used to cache files around the world?\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT150", "user": "splincode", "root": "ROOT150", "reply_to": null, "timestamp": "2018-04-12T13:01:13Z", "text": "Why Angular can be overcomplicated? ## I'm submitting a...\r <!-- Check one of the following options with \"x\" -->\r <pre><code>[ ] Regression (a behavior that used to work and stopped working in a new release)\r [ ] Bug report  <!-- Please search GitHub for a similar issue or PR before submitting -->\r [ ] Performance issue\r [ ] Feature request\r [ ] Documentation issue or request\r [ ] Support request\r [x] Other... Please describe:  message to the developers of Angular for feedback\r </code></pre>\r \r ## Current behavior\r \r I have been working with Angular since 2013 (I started with AngularJS). I also write articles on habrahabr.ru and medium.com about Angular. So I have been collecting a lot of statistics and feedback from most people over those years.\r \r And what did I find out in 5 years of working with Angular?\r \r AngularJS was considered to be too high-level language and therefore everyone who already had experience with jQuery or other things that work as a simple JavaScript could quickly understand it. Angular 2+ has become too low-level and no longer resembles Java, and it feels like working with C++, when you have to do everything with your hands, keep track of everything and grasp on time things that seem to occasionally drift away. Angular 2+ can also be understood, but not immediately.\r \r 1. You forgot to make an unsubscribe in the components when they are destroyed - you get a memory leak. \r \r 2. You work with large data streams in the application and did not find out how to optimize your application, and/or did not change components on OnPush \u2013 you get severe performance drop. \r \r 3. The customer changed the business requirement, he wants dynamic components, and a small bandle \u2013 say goodbye to the technological stack of Angular. Because it is unreal to do it by hand, when you do not even have the experience, especially while time is running out. Even the original ng-component-outlet did not work as it should, and to write your own solution you must have skills on a Senior level at least. I hope Angular Elements will save the day for us. \r \r 4. Junior developer included setInterval in the component and did not wrap the start outside the zone \u2013 again, performance decline for you. \r \r 5. In AngularJS there was such property at the directive, as setValidate (or something of that kind), I actively used it, everything was cool. When creating a custom validator, you need to ensure that you do not overwrite existing ones, for what? In doing so, you create more than one validator, and all at once. That is, you cannot simply add a validator if you already have required, for example: firstly, you specify the required validator, and then - your own. And still you have to keep in mind whether he is active, or maybe there is already a field filled. Currently there is no such thing and you have to create custom validator as a whole in a separate class with accessories, and even then you can\u2019t be sure if you\u2019re doing fine. \r \r 6. To create your custom ngModel, you have to rewrite a ton of code, a whole class with ControlValueAccesor and a stock full of methods. But even if you use your own banana-box attribute on the component, if you forgot to make emit from the component of the event, you will not even be warned about it.\r \r 7. In Angular CLI, since 1.6.5 strange bugs began to appear and something fails all the time, making it necessary to restart the dev-server. When my project was written on pure Webpack and Angular, I had not experienced such problems before.\r \r 8. If I want to use the web-worker platform, I have to do an eject, and on the whole Internet there is only a couple of articles on how to further run web-riches. \r \r 9. There are declarative and reactive forms. But when I'm working with one enormous entity, I have to do a lot of work to map fields in both the class and the template. Moreover, if I use declarative forms, I lose the advantage in future, where jet forms could do better. \r \r 10. Tests are painful. Angular is the only framework with Dependency Injection built-in, but it brings a lot of pain as well. All these mandatory dependencies for the DI component do not let you live happily while writing tests. Writing tests in Angular is as tedious as nowhere else. The component designer requires you to include everything at all. Even if you're not going to test it. \r \r 11. Routing is completely untyped; should I switch the module directories, not even the Webstorm IDEA or VSC will not help me in putting those paths correctly.\r \r Angular is overcomplicated. And at first sight in many cases this is not justified. There are not enough \"convenient\" things. Well, take the router, he has a directive for adding an active class. But why is there no such directive for checking the current route? Not the URL, but the very route. As it is made in UI-router, where you can check individually all the segments at the template level. This is a simple thing, I needed it in all projects, on the first and second Angular both. Without exception. When on one page you show one top hat, and other top hat on the other one. Same thing with background pictures. In general, the range of tasks for this thing is diverse and huge. The day before yesterday, I once again had to make up something with this. But I did it.\r \r Now let\u2019s take a person who just wants to study Angular and tries to find out what is frequently asked on an interview, what should he study and in which way? And so, most of the beginning developers, they do not find a one-step solution, they start making their own solution, they see it over-complicated and they switch to Vue. Not because it's simpler, but because of the total number of complications and the lack of detail in Angular. Which, seems, is a framework for robots.\r \r At first it seemed that Angular was poorly designed. But in fact, no, it\u2019s not.You get tired very quickly while using it, however, and there are no alternatives yet. Neither Vue nor React seem to suit me, and I do not want to write jQuery any more. Angular does not make it simpler for the developer, not for a single moment. From the very first line, you are doomed to seek solutions, something to redefine and make yourself comfortable with your \u201cbare hands\u201d.\r \r It's cool when you can do it, when there is such an opportunity, but not when you are forced to do this through all the work process. Modern front-end developers have to solve problems, not to engage in academic research, which framework is better or faster scaled in the first place. It is necessary for it to be easy and reliable. React is easy, but it is not reliable, Angular is reliable, but is not easy. Many people now see the balance in Vue, but it's not balanced as they see it. This is a hellish mixture of 80% React and 20% AngularJS. By reliability, I mean, first of all, the probability of code getting \u201csmelly\u201d, if you know what I mean. JSX itself is a shitty code, to be fair. Regarding React - statistics confirm that the amount of such poor-quality code is just off-scale.\r \r Continuous complaints. And all companies only seek Seniors, who can fix poor-written code.\r \r About the state of the application. Redux - this is also not a good implementation, I'm getting more and more convinced in this opinion. It actually tends more to the ideology of Angular, where you have to describe the elementary things like it\u2019s some kind of multi-volume advanced research study. And it does not protect you against unforeseen changes, plus it forces its architecture upon you. It just appeared before Mobx and Dan Abramov speaks for it, and Dan\u2019s opinion influences not very experienced programmers, which are a big group among the React developers\r \r ## Expected behavior\r \r I want to know if there are any plans to reduce complexity and simplify the framework. To make it easier to start developing any projects on Angular at any level of preparation, so that the project can easily be increased, while being based on the technological stack of Angular.\r \r If we had something simple as StencilJS out of the box and could easily scale to full components and modules, I think many would be happy. I would like Angular to be more popular and inquired on all markets, not only more popular or better than AngularJS only.\r \r I like Angular and I want everything to be\u00a0fine (pin medium [publish](https://medium.com/@splincode/why-is-angular-can-be-over-complicated-eda09933cb2a)).", "meta": {"posReactions": "25", "negReactions": "12"}}
{"id": "COM1500", "user": "AckerApple", "root": "ROOT150", "reply_to": "ROOT150", "timestamp": "2018-04-12T13:59:20Z", "text": "I read you... I am a Software Engineer, I am that senior level guy you speak of... I have cried out Angular pains in the past. Currently, I'm crying out about ng-content multiple projections. And I cant nor wont argue your individual points but I do come to bring my success to the table:\r\n\r\nIt has proven well worth the pains of \"extra\" setup and the \"extra\" jumping through hoops (depending on how you look at it). In so many ways, you do have to change your approach, and your past knowledge may work against you. I'm so thankful that Angular took it's giant leaps and they make sense to me now and I wouldn't do REACT or any things else but Angular.\r\n\r\nI've now trained two people on Angular, who knew nothing of Angular before and also are Junior developers. It was and is sooooooooooooooo easy for me to stick them in Angular projects because they only have to concern themselves with the limited scope of just the small components they touch. Angular makes my life easier to work with other people, it does.\r\n\r\nSo, sorry I don't have small debate points and I don't blame you for having your point of view. However, I do see much evidence that you are trying to crash through head first through Angular and I see it as you feel it should just work the way you want it to... You also want some Angular Elements to make things easier, and you want Angular to just be easier so maybe you'll have to figure less out........... MY OPINION: it's called computer science and this job takes GREAT amounts of attention to details and great amounts of learning. A lot of reading, a lot of separating symptoms from causes, and you cant just stay junior at it....... You either consume it all OR you will be \"wingin' it\" and fighting the current of how things actually work versus how you want them to work.\r\n\r\nThat all said, I too have written \"why does Angular suck now\" entries BUT I have since edit every comment. I just about have to hold myself back from saying how much I love Angular now... You think of someone in your head that lent you a great deal of free knowledge and how humble it made you feel, and thats how I feel about Angular, they done right for all of us in the BIG choices they have made for us all.\r\n\r\nGood luck. Farewell.", "meta": {"posReactions": "15", "negReactions": "0"}}
{"id": "COM1501", "user": "sod", "root": "ROOT150", "reply_to": "COM1500", "timestamp": "2018-04-12T14:17:43Z", "text": "I feel your points. They burn us, too. \r\n\r\nMy guess is, the angular team is very occupied with big topics (elements, ivy, bazel, documentation, ng-conf). The ivy renderer in particular targets some of the pain points you mentioned.\r\n\r\nWe have two projects running in parallel, one angularjs and one angular5. And nobody here likes to touch the angularjs codebase. angular5 and the ecosystem around it is just wonderful (full template typecheck and linting, clean component interface, typescript by default, the template syntax and one way data flow). So we admire the work the team is doing with the framework. Also that there is always an upgrade path (and not a hard cut like angularjs=>angular2).\r\n\r\nMy hope is that the team gets back to productive boosting features as soon as the dirty plumbing is done. And no need for another major rewrite (Router4? \ud83d\ude31)", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM1502", "user": "splincode", "root": "ROOT150", "reply_to": "COM1501", "timestamp": "2018-04-12T14:25:25Z", "text": "@AckerApple I like Angular. It is quite easy to understand when moving from project to project. \r\nBut the number of people who are new, who would like to learn it for some reason, is decreasing. \r\nI popularize only Angular in Russia, but it becomes difficult every day. While other frameworks have the same number of functional functions, and the number of libraries is increasing every day. \r\n\r\nIn Russia, I wanted to work in a large company in Yandex, but they write only on React. I wanted to work in Vkontakte, there too on React.  Large companies are opposed to the use of Angular. My friends in mid-level companies, mostly one full-stack developers, and they say that the quicker to sketch the layouts and start using Vue, without going into and diving. \r\n\r\nEspecially many front-end developers in Russia do not understand the benefits of RxJS. Allegedly they only want to use Promise.  For example, in our company, a component library is already tied to Primeng, it is badly written (if you open source), people do not even write tests. And half the time you have to kill for cutting styles. But when it is no longer possible to cut styles and is strongly tied to a component, \r\neven very difficult somehow without crutches to redefine the internal logic of the third-party component. \r\n\r\nOverall, I like Angular, I really grew up as a programmer. However, I still feel like a weak expert, since Angular is huge.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1503", "user": "mlc-mlapis", "root": "ROOT150", "reply_to": "COM1502", "timestamp": "2018-04-12T14:34:41Z", "text": "It is necessary to say that the whole web environment is not the easy world, and it'll be harder, not easier in a year or two. If I look at some JS code which was written 5 or more years back it is hard to believe where we are today. Angular as is today, it's not the simplest tool for a standalone beginner because of abstractions and new concepts (especially on the edge it means that when you analyze any design then the best is to think that all is async as the real world is in fact) but it is the very easy and super efficient tool when such beginners have a good teacher.\r\n", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1504", "user": "AlexDaSoul", "root": "ROOT150", "reply_to": "COM1503", "timestamp": "2018-04-12T14:34:59Z", "text": "@AckerApple i'm Software Engineer too and i like angular. \r\n\r\nBut now he wants to become a robot framework. It is good to use for academic purposes, like a barbell that helps build muscle. But in production with it is more difficult than with react or vue. It does not help to solve problems, it simply does what it does.\r\n\r\nI really hope that in the future it will be what the framework for an engineer should be - a tool in production, not a bar in the gym\r\n\r\n", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM1505", "user": "AckerApple", "root": "ROOT150", "reply_to": "COM1504", "timestamp": "2018-04-12T14:37:04Z", "text": "@splincode \r\n\r\nYour last comment mostly speaks to popularity.... And I'm sure you can agree NOT always the most popular packages on NPM are the best ones.\r\n\r\nI hear ya man... I choose Angular for my own sanity, not others. I will deal with the less jobs and packages, nor now.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1506", "user": "AckerApple", "root": "ROOT150", "reply_to": "COM1505", "timestamp": "2018-04-12T14:41:33Z", "text": "@AlexDaSoul you don't think Angular is for production?\r\n\r\nI got a Golf Cart, a 1978 Joker Poker pinball machine, a 2017 Wizard of Pinball machine, and a Baby PAC man pinball machine on the way THAT WERE ALLL paid for by Angular production code produced at the following companies:\r\n\r\n- http://www.tap2.care/\r\n- https://caringpeopleinc.com/\r\n- http://www.caringondemand.com/", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1507", "user": "AlexDaSoul", "root": "ROOT150", "reply_to": "COM1506", "timestamp": "2018-04-12T14:48:32Z", "text": "@AckerApple 50/50. I'm writing production on Angular. Angular allows you not to write bad code. But almost always forces you to write a lot of low-level code, which takes away a monstrous amount of time", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM1508", "user": "AckerApple", "root": "ROOT150", "reply_to": "COM1507", "timestamp": "2018-04-12T14:52:12Z", "text": "Well said. Agreed. I'm just banging it out of the park here in South Florida in the Healthcare app industry.... Rocking Cordova back to life with \"PWAs\" cause web-apps got a bad taste so now we gotta call doing it right a PWA", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1509", "user": "splincode", "root": "ROOT150", "reply_to": "COM1508", "timestamp": "2018-04-12T14:59:21Z", "text": "@AckerApple Yes, the Angular team makes a tool for developers. But I would like to pay attention to the little things, because of which it sometimes hurts.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15010", "user": "AckerApple", "root": "ROOT150", "reply_to": "COM1509", "timestamp": "2018-04-12T15:02:00Z", "text": "AWWWWWWWWWwwwwwwww\r\n\r\nAlright I'm often full of sassy comments and I don't have troubles any more cause I mastering this shit!\r\n\r\nHere, try my code:\r\n- https://www.npmjs.com/package/angular-file\r\n- https://www.npmjs.com/package/ack-angular-webcam\r\n- https://www.npmjs.com/package/ack-angular-fx\r\n- https://www.npmjs.com/package/ack-angular\r\n\r\nDemos and docs at all... I love this Angular.... Sorry you're having such a tough time making the cash rain from Angular. I be milking the sucker ova her!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15011", "user": "AckerApple", "root": "ROOT150", "reply_to": "COM15010", "timestamp": "2018-04-12T15:39:44Z", "text": "When the title of this issue was grammatically incorrect, it was evidence of the sheer agitation you have with Angular. But your body comments were well typed and thought out.\r\n\r\nAngular makes me feel on a high like the Beck WoW song: https://www.youtube.com/watch?v=pyCkhPTU13w", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM15012", "user": "StephenFluin", "root": "ROOT150", "reply_to": "COM15011", "timestamp": "2018-04-12T16:31:39Z", "text": "@splincode Thanks so much for creating this issue. I don't have any concrete reactions to the above yet (there's a lot to unpack, and we're already working on some of it), but I want you to know that we are listening and thinking about these problems deeply. We care a lot, and we spend a lot of time reflecting on issues like this.\r\n\r\nWe've shared several times our goals about making Angular simpler, but still helping developers build state of the art applications that are scalable (teams, code, etc), correct (you can understand what's going on under the hood), with a learning journey that adds complexity at the right times, etc. Thanks for sharing your hopes around these things.", "meta": {"posReactions": "6", "negReactions": "0"}}
{"id": "COM15013", "user": "splincode", "root": "ROOT150", "reply_to": "COM15012", "timestamp": "2018-04-12T16:44:55Z", "text": "@StephenFluin Thank you, Stephen. I hope in the future Angular will become even better and easier to understand. However, first of all, I am grateful to Angular for making me grow as a developer.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM15014", "user": "splincode", "root": "ROOT150", "reply_to": "COM15013", "timestamp": "2018-04-12T17:35:41Z", "text": "@StephenFluin How often do you collect feedback from community developers?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15015", "user": "StephenFluin", "root": "ROOT150", "reply_to": "COM15014", "timestamp": "2018-04-12T17:37:07Z", "text": "@splincode we talk to developers about Angular every day. But maybe I'm misunderstanding your question?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15016", "user": "AlexDaSoul", "root": "ROOT150", "reply_to": "COM15015", "timestamp": "2018-04-12T18:01:37Z", "text": "@StephenFluin splincode says that in our daily work with Angular we solve about the same problems time after time. Almost always there is not enough definition of URL or rout name of at the level of the directive of the type routerLinkActive. Very often there is a lack of a setValidator and a removalValidator. Very much hampered by the need for DI all and everything in the tests. There is not enough opportunity to redefine. There is not enough opportunity to override the concrete method without defining the whole class. In general, all that is needed for daily work in production. This is cool, when we have the opportunity to redefine and adjust everything to our own needs, but not when you are forced to do this in almost every new task.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM15017", "user": "mlc-mlapis", "root": "ROOT150", "reply_to": "COM15016", "timestamp": "2018-04-12T18:55:27Z", "text": "@splincode ... a small notice ... what do you mean by ...\r\n> You can not inject the same pipe into two different modules.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15018", "user": "mlc-mlapis", "root": "ROOT150", "reply_to": "COM15017", "timestamp": "2018-04-12T20:38:16Z", "text": "@splincode ... ah, thanks for your explanation. I have to say that this factor of modules architecture is absolutely fine for me and I don't feel it as limitation from any point of view. Maybe it is my personal feeling, maybe affected by my professional historical background.\r\n\r\nHere are some points as I see it:\r\n\r\n* You always have one shared module at least, usually more ... so it is a natural thing to place such a thing to a correct module. A simple app is just one module usually.\r\n* If it is something extra then it is a part of that custom eager or lazy loaded module.\r\n* There are exact rules ... and I think very simple in fact ... how modules architecture is structured. I never understand what are the reasons why some developers don't understand them.\r\n* Usually the similar discussion is about the topic ... one component / one module. The fact is that the simple module for just one component is only 5 simple lines of code ... possible to place into just one TS file.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15019", "user": "splincode", "root": "ROOT150", "reply_to": "COM15018", "timestamp": "2018-04-13T05:50:24Z", "text": "@mlc-mlapis I just want to say that I've seen a lot of projects where people come from React. They do not understand the modular architecture to the end, and all the components, pipes, services are shoved into the module or the shared module. And then on the way out we have a huge bundle. For example, I do not have such a feature as lazy components (maybe Angular Elements is it).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15020", "user": "jotatoledo", "root": "ROOT150", "reply_to": "COM15019", "timestamp": "2018-04-13T11:01:15Z", "text": "Its complex? yeah.\r\nImpossible to learn? nope.\r\nBeginner friendly? Only if you invest some time reading/doing tutorials.", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM15021", "user": "AckerApple", "root": "ROOT150", "reply_to": "COM15020", "timestamp": "2018-04-13T11:04:17Z", "text": "Lazy loading in Angular is super dope. You can do by component or entire routes.\r\n\r\n@splincode, are you using some Angular that a crack dealer sold you? That or you\u2019re not reading enough because several things you mention you can do and I\u2019m doing it with ease. Don\u2019t bother to ask how cause I feel this chat is compacted with complaining newbies that just need to read and learn how to do things outside React", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15022", "user": "andremarcondesteixeira", "root": "ROOT150", "reply_to": "COM15021", "timestamp": "2018-04-13T19:01:16Z", "text": "Learning takes time. Lots of time. That's all. Bye.", "meta": {"posReactions": "7", "negReactions": "0"}}
{"id": "COM15023", "user": "djleonskennedy", "root": "ROOT150", "reply_to": "COM15022", "timestamp": "2018-04-16T09:05:03Z", "text": "Our team learned **ng** as well, the problem is two things for now:\r\n  1) router lazy loading doesn't work with relative path (problem leaves since angular 2 - wtf?);\r\nhttps://github.com/angular/angular/issues/17957\r\n  2) unstable **angular/cli** (every time something doesn't work since 1.6.x);\r\n\r\nP.S. documentation covers not a lot i'd say, if you want to learn angular, read material's code, it's more convenient than angular's documentation\r\n\r\ni just feel that **angular team doesn't care about users feedback at all**", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM15024", "user": "AckerApple", "root": "ROOT150", "reply_to": "COM15023", "timestamp": "2018-04-16T11:55:49Z", "text": "@djleonskennedy\r\n\r\nI didn\u2019t graduate with my high school class. I had to take extra classes in the summer and even then i only graduated with a 2.1\r\n\r\nY\u2019all are making me feel like a scientist though!!!!!\r\n\r\nI learned Angular all on my own. No teacher. Y\u2019all suck at learning. Angular team will put it more politely but nah me: Y\u2019all are being out smarted by this D student.\r\n\r\nMake money money! Angular taking me places daily", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM15025", "user": "splincode", "root": "ROOT150", "reply_to": "COM15024", "timestamp": "2018-04-16T12:03:09Z", "text": "@AckerApple I just think he wanted to say that the project got out of control", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15026", "user": "AckerApple", "root": "ROOT150", "reply_to": "COM15025", "timestamp": "2018-04-16T12:11:37Z", "text": "Noooooo. Lazy loading works, the cli works too great. I know they work, everyday I know it\r\n\r\nAnd the Angular team talks allllllllllll the time (it\u2019s just scheduled)\r\n\r\nNot gonna argue with flat earthers nor am I gonna debate with y\u2019all\r\n\r\nI\u2019ll make the money. You write the complaints", "meta": {"posReactions": "2", "negReactions": "1"}}
{"id": "COM15027", "user": "splincode", "root": "ROOT150", "reply_to": "COM15026", "timestamp": "2018-04-16T12:16:52Z", "text": "@AckerApple I do not argue, I'm fine, I just wanted to note the observed phenomena", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15028", "user": "AckerApple", "root": "ROOT150", "reply_to": "COM15027", "timestamp": "2018-04-16T12:40:36Z", "text": "Electromagnetism is a phenomena\r\n\r\nI wouldn\u2019t put complainers in that category.\r\n\r\nIt\u2019s just complaining cause this Angular works the way you say it don\u2019t ", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM15029", "user": "djleonskennedy", "root": "ROOT150", "reply_to": "COM15028", "timestamp": "2018-04-16T13:54:59Z", "text": "@AckerApple\r\n\r\nYou want to say that you cannot reproduce it ? https://github.com/angular/angular/issues/17957\r\n\r\nDon't say that it works man", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT151", "user": "taoso", "root": "ROOT151", "reply_to": null, "timestamp": "2019-06-10T02:00:35Z", "text": "So many issues and pull requests with only one contributor? _Instructions: Replace the template text and remove irrelevant text (including this line)_\r \r **Describe the bug**\r A clear and concise description of what the bug is.\r (Issues related to the runtime files should be reported to their maintainer, check the file header.)\r \r **To Reproduce**\r Detailed steps to reproduce the behavior:\r 1. Run `vim --clean` (or `gvim --clean`, etc.)\r 2. Edit `filename`\r 3. Type '....'\r 4. Describe the error\r \r **Expected behavior**\r A clear and concise description of what you expected to happen.\r \r **Screenshots**\r If applicable, copy/paste the text or add screenshots to help explain your problem.\r \r **Environment (please complete the following information):**\r  - Vim version [e.g. 8.1.1234] (Or paste the result of `vim --version`.)\r  - OS: [e.g. Ubuntu 18.04, Windows 10 1809, macOS 10.14]\r  - Terminal: [e.g. GNOME Terminal, mintty, iTerm2, tmux, GNU screen] (Use GUI if you use the GUI.)\r \r **Additional context**\r Add any other context about the problem here.\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1510", "user": "nickspoons", "root": "ROOT151", "reply_to": "ROOT151", "timestamp": "2019-06-10T02:13:00Z", "text": "When a project pre-dates github, don't be surprised to see a non-github workflow", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1511", "user": "k-takata", "root": "ROOT151", "reply_to": "COM1510", "timestamp": "2019-06-10T02:20:55Z", "text": "First, please use the issue template properly. Replace the template text and remove irrelevant text as the instruction says.\r\n\r\nIf you talking about that you can see only one person (Bram) in https://github.com/vim/vim/graphs/contributors, check each commit. Each contributor name is written in each commit log.\r\nThere are several hundreds of contributors in Vim.\r\n\r\nAnyway, this is not a place to ask a question and this is not an issue of Vim. So closing.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1512", "user": "k-takata", "root": "ROOT151", "reply_to": "COM1511", "timestamp": "2019-06-10T04:25:21Z", "text": "See also: #1554", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1513", "user": "trusktr", "root": "ROOT151", "reply_to": "COM1512", "timestamp": "2020-12-30T02:06:35Z", "text": "Seems more like Bram enjoys taking all the credit.\r\n\r\nVim has been on GitHub for a while now, and there has been plenty of opportunity for the right thing to be done.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1514", "user": "trusktr", "root": "ROOT151", "reply_to": "COM1513", "timestamp": "2020-12-30T02:11:57Z", "text": "Note, I said _seems_. That's important.\r\n\r\nAlso, people on GitHub may enjoy their stats being visible in various GitHub pages, like the contributor graph, so that people may click on them and see their profiles, etc.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1515", "user": "chrisbra", "root": "ROOT151", "reply_to": "COM1514", "timestamp": "2020-12-30T07:58:06Z", "text": "> Also, people on GitHub may enjoy their stats being visible in various GitHub pages, like the contributor graph, so that people may click on them and see their profiles, etc.\r\n\r\nYes, people may enjoy it, but for me, I contribute because I want to make Vim better and not to have a nice contribution graph. Also I think it is more important that the main developer of Vim can concentrate on enhancing and improving Vim instead of having to change a workflow, that has been proven to be working well for the past 30 years. Thanks for understanding.", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM1516", "user": "Shane-XB-Qian", "root": "ROOT151", "reply_to": "COM1515", "timestamp": "2021-01-05T14:06:01Z", "text": "> but for me, I contribute because I want to make Vim better\r\n\r\nwould not doubt that;\r\njust some people thought they joined to discuss or gave patch/advice was a help too.. i think..\r\nespecially sometime were treated as 'asking', (though some was), but some actually were 'giving' report/improvement to vim..\r\n\r\nas for 'workflow', to do some adjust to fit some perhaps was necessary too\r\ne.g . recording the 'commiter' name as some formal/fixed format even in the commits msg, then some stupid shell script can generate it or list it to somewhere, then everyone happy!\r\ne.g . some runtime files owners perhaps disappeared long time / some classic plugins were not update-2-date long time, then setup a heartbeat check to confirm their alive (sorry but that's) or willing, perhaps was necessary too..\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1517", "user": "Shane-XB-Qian", "root": "ROOT151", "reply_to": "COM1516", "timestamp": "2021-01-05T15:37:35Z", "text": "https://github.com/vim/vim/issues/7624", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1518", "user": "felipec", "root": "ROOT151", "reply_to": "COM1517", "timestamp": "2021-04-18T23:34:31Z", "text": "> Thanks for understanding.\r\n\r\nNo, I don't understand.\r\n\r\nAny software developer doing things exactly the same as 10 years ago is a **bad** software developer, let alone 30 years ago.\r\n\r\nIt literally takes less than 30 minutes to learn git. That's no excuse.\r\n\r\n30 minutes for one person so that thousands others don't have to run through loops is a no-brainer.", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM1519", "user": "vim-ml", "root": "ROOT151", "reply_to": "COM1518", "timestamp": "2021-04-19T01:06:41Z", "text": "On 2021-04-18, Felipe Contreras wrote:\n>     Thanks for understanding.\n> \n> No, I don't understand.\n> \n> Any software developer doing things exactly the same as 10 years ago is a bad\n> software developer, let alone 30 years ago.\n\nThat's just plain not true.  A idea that was good 10 or even 30\nyears ago may be just as good today.  Ideas are good or bad because\nthey're good or bad, not because they're new or old.  To think that\na new idea is better than an old one simply because it is new is\nfoolish.\n\n> It literally takes less than 30 minutes to learn git. That's no excuse.\n\nThat's not true, either.  While basic git operations are reasonably\nstraightforward, anything beyond the basics is horribly obscure and\ninconsistent.  To paraphrase Jamie Zawinski's comment about regular\nexpressions:\n\n    Some people, when confronted with a problem, think \"I know,\n    I'll use git.\"  Now they have two problems.\n\nAnd of course:  https://xkcd.com/1597/\n\nRegards,\nGary\n\n", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM15110", "user": "vim-ml", "root": "ROOT151", "reply_to": "COM1519", "timestamp": "2021-04-19T16:00:39Z", "text": "\u5415\u6d77\u6d9b : When looking for information about Vim, the place to look is\nalways the built-in help. Not Google, not the manpages, not the github\nmetadata, just the help. In this case: :help credits\n\nBest regards,\nTony.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT152", "user": "Thaina", "root": "ROOT152", "reply_to": null, "timestamp": "2020-02-20T10:58:17Z", "text": "Firebase Realtime Database don't get update from wifi <!-- DO NOT DELETE \r validate_template=true\r template_path=.github/ISSUE_TEMPLATE/bug.md\r -->\r \r ### [REQUIRED] Step 2: Describe your environment\r \r   * Firebase Component: Database\r   * Component version: 19.2.0, but I think it has been problem since 2018\r \r ### [REQUIRED] Step 3: Describe the problem\r \r Using realtime database change listener normally in android mobile with wifi connection. It work perfectly for most of the times. But it would eventually (2-3 days to 2-3 weeks) not be able to connect to firebase realtime database and get the realtime update, even if the PC of the same router still able to connect. I need to shut the wifi of my android to use mobile 4g network, or reset the router. Resetting router make it usable but eventually after a while it will fail again\r \r I myself using unity. But there was already some people happen to face the same problem so I think it could be common to many people\r \r https://stackoverflow.com/questions/52609349/couldnt-connect-to-firebase-database-via-wifi-but-connects-fine-with-4g-mobile\r https://stackoverflow.com/questions/48340327/firebase-database-listeners-dont-work-on-android-with-wifi\r \r Also, surprisingly, the web that use firebase still work in the same network state. So I think this problem is because native network library\r \r I think the actual source of problem could be a problem of router setting. But that might be critical. Because realtime update could be fail for anyone in misconfig router (in workplace for instance) but it result in the whole app failed unknowingly to us. It could also be a critical feature of that app. Isn't it possible to have firebase native to have failsafe to fallback?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1520", "user": "aguatno", "root": "ROOT152", "reply_to": "ROOT152", "timestamp": "2020-02-20T13:10:34Z", "text": "Thanks for reporting, @Thaina. From what I understand, Realtime Database works on mobile/cellular connection properly, but not on Wi-Fi connection. \r\n\r\nWe usually mention to developers that the issue may be isolated to certain network providers that possibly blocks access to certain services. However, if this isn't the case, then there may be something else that is causing it. With that, I would like to ask for the following details in order for me to understand the issue further:\r\n\r\n- A set of verbose logs captured upon running your app through your IDE (can be found in your Logcat)\r\n\r\n     - To capture them, you need to enable the [debug logging](https://firebase.google.com/docs/reference/android/com/google/firebase/database/FirebaseDatabase.html#setLogLevel(com.google.firebase.database.Logger.Level)) after getting an instance by using the following line:\r\n     - rtdbInstance.setLoggingLevel(Logger.Level.DEBUG);\r\n\r\n- Any other information that would be helpful", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1521", "user": "Thaina", "root": "ROOT152", "reply_to": "COM1520", "timestamp": "2020-02-27T14:10:36Z", "text": "@aguatno On monday I try to build and find the log but cannot see anything related to firebase database. It just silence\r\n\r\nI have upgrade to 6.11 yesterday and will try to log and search for problem again soon\r\n\r\nBut one thing I would like to report is, while realtime database face the problem from wifi. Firestore (I have alpha privilege) can listen to change from that wifi normally. Is there anything related to network connection system difference between these two library?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1522", "user": "Thaina", "root": "ROOT152", "reply_to": "COM1521", "timestamp": "2020-03-03T04:11:58Z", "text": "```\r\n03-03 11:09:45.842 20590 21583 D WebSocket: ws_17 - WebSocket error.\r\n03-03 11:09:45.842 20590 21583 D WebSocket: com.google.firebase.database.tubesock.WebSocketException: IO Error\r\n03-03 11:09:45.842 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocketReceiver.run(com.google.firebase:firebase-database@@19.2.1:92)\r\n03-03 11:09:45.842 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocket.runReader(com.google.firebase:firebase-database@@19.2.1:427)\r\n03-03 11:09:45.842 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocket.access$000(com.google.firebase:firebase-database@@19.2.1:48)\r\n03-03 11:09:45.842 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocket$2.run(com.google.firebase:firebase-database@@19.2.1:144)\r\n03-03 11:09:45.842 20590 21583 D WebSocket: \tat java.lang.Thread.run(Thread.java:919)\r\n03-03 11:09:45.842 20590 21583 D WebSocket: Caused by: javax.net.ssl.SSLException: Read error: ssl=0x7a5e049a08: I/O error during system call, Software caused connection abort\r\n03-03 11:09:45.842 20590 21583 D WebSocket: \tat com.android.org.conscrypt.NativeCrypto.SSL_read(Native Method)\r\n03-03 11:09:45.842 20590 21583 D WebSocket: \tat com.android.org.conscrypt.NativeSsl.read(NativeSsl.java:411)\r\n03-03 11:09:45.842 20590 21583 D WebSocket: \tat com.android.org.conscrypt.ConscryptFileDescriptorSocket$SSLInputStream.read(ConscryptFileDescriptorSocket.java:549)\r\n03-03 11:09:45.842 20590 21583 D WebSocket: \tat java.io.DataInputStream.readFully(DataInputStream.java:198)\r\n03-03 11:09:45.842 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocketReceiver.read(com.google.firebase:firebase-database@@19.2.1:155)\r\n03-03 11:09:45.842 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocketReceiver.run(com.google.firebase:firebase-database@@19.2.1:48)\r\n03-03 11:09:45.842 20590 21583 D WebSocket: \t... 4 more\r\n03-03 11:09:45.842 20590 21583 D WebSocket: ws_17 - closing itself\r\n03-03 11:09:45.842 20590 21583 D Connection: conn_17 - Realtime connection lost\r\n03-03 11:09:45.842 20590 21583 D Connection: conn_17 - closing realtime connection\r\n03-03 11:09:45.842 20590 21583 D PersistentConnection: pc_0 - Got on disconnect due to OTHER\r\n03-03 11:09:45.843 20590 21583 D PersistentConnection: pc_0 - Scheduling connection attempt\r\n03-03 11:09:45.843 20590 21583 D ConnectionRetryHelper: Scheduling retry in 0ms\r\n03-03 11:09:45.843 20590 21583 D WebSocket: ws_17 - WebSocket error.\r\n03-03 11:09:45.843 20590 21583 D WebSocket: com.google.firebase.database.tubesock.WebSocketException: IO Exception\r\n03-03 11:09:45.843 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocketWriter.runWriter(com.google.firebase:firebase-database@@19.2.1:159)\r\n03-03 11:09:45.843 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocketWriter.access$000(com.google.firebase:firebase-database@@19.2.1:30)\r\n03-03 11:09:45.843 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocketWriter$1.run(com.google.firebase:firebase-database@@19.2.1:47)\r\n03-03 11:09:45.843 20590 21583 D WebSocket: \tat java.lang.Thread.run(Thread.java:919)\r\n03-03 11:09:45.843 20590 21583 D WebSocket: Caused by: java.net.SocketException: socket is closed\r\n03-03 11:09:45.843 20590 21583 D WebSocket: \tat com.android.org.conscrypt.ConscryptFileDescriptorSocket$SSLOutputStream.write(ConscryptFileDescriptorSocket.java:618)\r\n03-03 11:09:45.843 20590 21583 D WebSocket: \tat java.nio.channels.Channels$WritableByteChannelImpl.write(Channels.java:453)\r\n03-03 11:09:45.843 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocketWriter.writeMessage(com.google.firebase:firebase-database@@19.2.1:138)\r\n03-03 11:09:45.843 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocketWriter.runWriter(com.google.firebase:firebase-database@@19.2.1:152)\r\n03-03 11:09:45.843 20590 21583 D WebSocket: \t... 3 more\r\n03-03 11:09:45.843 20590 21583 D WebSocket: ws_17 - closed\r\n03-03 11:09:45.843 20590 21583 D PersistentConnection: pc_0 - Trying to fetch auth token\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: readPacket error: \r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: android.system.ErrnoException: read failed: ENETDOWN (Network is down)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat libcore.io.Linux.readBytes(Native Method)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat libcore.io.Linux.read(Linux.java:190)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat libcore.io.ForwardingOs.read(ForwardingOs.java:177)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat libcore.io.BlockGuardOs.read(BlockGuardOs.java:303)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat android.system.Os.read(Os.java:468)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat android.net.util.PacketReader.readPacket(PacketReader.java:59)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat android.net.util.PacketReader.readPacket(PacketReader.java:34)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat android.net.util.FdEventsReader.handleInput(FdEventsReader.java:220)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat android.net.util.FdEventsReader.lambda$createAndRegisterFd$2$FdEventsReader(FdEventsReader.java:201)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat android.net.util.-$$Lambda$FdEventsReader$MJGveJiu3TqatZaBXlmIyD8DwEE.onFileDescriptorEvents(Unknown Source:2)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat android.os.MessageQueue.dispatchEvents(MessageQueue.java:294)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat android.os.MessageQueue.nativePollOnce(Native Method)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat android.os.MessageQueue.next(MessageQueue.java:336)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat android.os.Looper.loop(Looper.java:174)\r\n03-03 11:09:45.844  1758 19520 E ConnectivityPacketTracker.wlan0: \tat android.os.HandlerThread.run(HandlerThread.java:67)\r\n03-03 11:09:45.845 20590 21583 D PersistentConnection: pc_0 - Successfully fetched token, opening connection\r\n03-03 11:09:45.845 20590 21583 D Connection: conn_18 - Opening a connection\r\n03-03 11:09:45.851  3291 28814 V NativeCrypto: SSL shutdown failed: ssl=0x79ddc18c48: I/O error during system call, Broken pipe\r\n03-03 11:09:45.851  3291 28814 E WakeLock: GCM_HB_ALARM release without a matched acquire!\r\n03-03 11:09:45.851  3291 28814 W WakeLock: GCM_HB_ALARM counter does not exist\r\n03-03 11:09:45.853 20590 21583 D WebSocket: ws_18 - WebSocket error.\r\n03-03 11:09:45.853 20590 21583 D WebSocket: com.google.firebase.database.tubesock.WebSocketException: unknown host: s-usc1c-nss-246.firebaseio.com\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocket.createSocket(com.google.firebase:firebase-database@@19.2.1:331)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocket.runReader(com.google.firebase:firebase-database@@19.2.1:359)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocket.access$000(com.google.firebase:firebase-database@@19.2.1:48)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocket$2.run(com.google.firebase:firebase-database@@19.2.1:144)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat java.lang.Thread.run(Thread.java:919)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: Caused by: java.net.UnknownHostException: Unable to resolve host \"s-usc1c-nss-246.firebaseio.com\": No address associated with hostname\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat java.net.Inet6AddressImpl.lookupHostByName(Inet6AddressImpl.java:156)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat java.net.Inet6AddressImpl.lookupAllHostAddr(Inet6AddressImpl.java:103)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat java.net.InetAddress.getAllByName(InetAddress.java:1152)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat java.net.Socket.<init>(Socket.java:218)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat javax.net.ssl.SSLSocket.<init>(SSLSocket.java:931)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat com.android.org.conscrypt.AbstractConscryptSocket.<init>(AbstractConscryptSocket.java:97)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat com.android.org.conscrypt.OpenSSLSocketImpl.<init>(OpenSSLSocketImpl.java:41)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat com.android.org.conscrypt.ConscryptFileDescriptorSocket.<init>(ConscryptFileDescriptorSocket.java:131)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat com.android.org.conscrypt.Java8FileDescriptorSocket.<init>(Java8FileDescriptorSocket.java:42)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat com.android.org.conscrypt.Platform.createFileDescriptorSocket(Platform.java:332)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat com.android.org.conscrypt.OpenSSLSocketFactoryImpl.createSocket(OpenSSLSocketFactoryImpl.java:106)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat android.net.SSLCertificateSocketFactory.createSocket(SSLCertificateSocketFactory.java:597)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat com.google.firebase.database.tubesock.WebSocket.createSocket(com.google.firebase:firebase-database@@19.2.1:319)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \t... 4 more\r\n03-03 11:09:45.853 20590 21583 D WebSocket: Caused by: android.system.GaiException: android_getaddrinfo failed: EAI_NODATA (No address associated with hostname)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat libcore.io.Linux.android_getaddrinfo(Native Method)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat libcore.io.ForwardingOs.android_getaddrinfo(ForwardingOs.java:74)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat libcore.io.BlockGuardOs.android_getaddrinfo(BlockGuardOs.java:200)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat libcore.io.ForwardingOs.android_getaddrinfo(ForwardingOs.java:74)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \tat java.net.Inet6AddressImpl.lookupHostByName(Inet6AddressImpl.java:135)\r\n03-03 11:09:45.853 20590 21583 D WebSocket: \t... 16 more\r\n03-03 11:09:45.853 20590 21583 D WebSocket: ws_18 - closing itself\r\n03-03 11:09:45.853 20590 21583 D Connection: conn_18 - Realtime connection failed\r\n03-03 11:09:45.853 20590 21583 D Connection: conn_18 - closing realtime connection\r\n03-03 11:09:45.853 20590 21583 D PersistentConnection: pc_0 - Got on disconnect due to OTHER\r\n03-03 11:09:45.854 20590 21583 D PersistentConnection: pc_0 - Scheduling connection attempt\r\n03-03 11:09:45.854 20590 21583 D ConnectionRetryHelper: Scheduling retry in 589ms\r\n03-03 11:09:45.854 20590 21583 D WebSocket: ws_18 - closed\r\n```\r\n\r\nThis is the log that might be related", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1523", "user": "schmidt-sebastian", "root": "ROOT152", "reply_to": "COM1522", "timestamp": "2020-03-04T00:44:57Z", "text": "@Thaina Thank you for sharing the logs. It looks like the error might be a fundamental issue with the device's network (`Unable to resolve host \"s-usc1c-nss-246.firebaseio.com\": No address associated with hostname`).\r\n\r\nCan you let us know if this problem occurs on multiple devices? If so, would it be possible to share a reproduction for us that we could run on Emulator?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1524", "user": "Thaina", "root": "ROOT152", "reply_to": "COM1523", "timestamp": "2020-03-04T03:58:54Z", "text": "@schmidt-sebastian I don't know which specific device have this problem except one samsung of my acquaintance I don't know detail about. And my own Nokia 7 plus\r\n\r\nThis problem could occur in many router setting even though it could use internet normally and the most disturbingly confusion is, in the same wifi that cause problem to android, realtime database in ios of the same app still work under it properly\r\n\r\nAnd while RTDB won't work, at the same time in the same device that RTDB can't load anything, firestore could work properly\r\n\r\nSo this issue is really specifically a problem of only RTDB android library in wifi", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1525", "user": "schmidt-sebastian", "root": "ROOT152", "reply_to": "COM1524", "timestamp": "2020-03-07T03:41:04Z", "text": "Firestore and RTDB uses a very different networking stack. Firestore uses GRPC, whereas the RTDB used WebChannel which more heavily relies on Android's built in networking. \r\n\r\nIf you are able to reproduce this somewhat reliable in an emulator, then we could probably come up with a reproduction. It's a bit tough to diagnose issues that point to issues with the DNS resolver from afar.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1526", "user": "Thaina", "root": "ROOT152", "reply_to": "COM1525", "timestamp": "2020-03-07T05:00:52Z", "text": "Thank you for your information. Sadly I don't have times, so I would switch to firestore instead as of now it release unity SDK", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1527", "user": "augusto-nc", "root": "ROOT152", "reply_to": "COM1526", "timestamp": "2020-03-07T23:58:04Z", "text": "Is there any alternative to solve this problem?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1528", "user": "schmidt-sebastian", "root": "ROOT152", "reply_to": "COM1527", "timestamp": "2020-03-09T19:00:20Z", "text": "At this point, I don't see an obvious fix since this happens very low in the network stack.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1529", "user": "honorianos", "root": "ROOT152", "reply_to": "COM1528", "timestamp": "2020-03-28T00:33:37Z", "text": " same problem help :(\r\nuse MODEM WIFI  :   https://articulo.mercadolibre.com.pe/MPE-435156300-modem-router-huawei-b612s-4g-nuevo-movistar-claro-entel-_JM\r\nLOGS:\r\nD/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/Surface: Surface::setBuffersDimensions(this=0xb847e3f0,w=720,h=1480)\r\n D/MALI: _egl_make_current:857: [MALI] make current with display 0x1, context 0x40000001, state 0xb846edb8\r\n D/MALI: _egl_make_current:872: [MALI] Map __dpy 0x1 to dpy 0xb84011b0\r\n D/MALI: _egl_make_current:906: [MALI] Map __ctx 0x40000001 to ctx 0xb84835d8\r\n D/OpenGLRenderer: Flushing caches (mode 0)\r\n D/Surface: Surface::disconnect(this=0xb84e9c68,api=1)\r\n D/GraphicBuffer: unregister, handle(0xb845f0e0) (w:412 h:88 s:416 f:0x1 u:0x000f02)\r\n D/OpenGLRenderer: Flushing caches (mode 0)\r\n D/ViewRootImpl: hardware acceleration is enabled, this = ViewRoot{35cf9e9b Toast,ident = 2}\r\n D/OpenGLRenderer: CanvasContext() 0xb84896a0 initialize 0xb85146f0\r\n D/Surface: Surface::connect(this=0xb85146e8,api=1)\r\n D/GraphicBuffer: register, handle(0xb8517b30) (w:390 h:88 s:400 f:0x1 u:0x000f02)\r\n I/MaliEGL: [Mali]window_type=1, is_framebuffer=0, errnum = 0\r\n I/MaliEGL: [Mali]surface->num_buffers=4, surface->num_frames=3, win_min_undequeued=1\r\n I/MaliEGL: [Mali]max_allowed_dequeued_buffers=3\r\n D/Surface: Surface::setBufferCount(this=0xb85146e8,bufferCount=4)\r\n D/GraphicBuffer: unregister, handle(0xb8517b30) (w:390 h:88 s:400 f:0x1 u:0x000f02)\r\n D/MALI: _egl_make_current:857: [MALI] make current with display 0x1, context 0x40000001, state 0xb846edb8\r\n D/MALI: _egl_make_current:872: [MALI] Map __dpy 0x1 to dpy 0xb84011b0\r\n D/MALI: _egl_make_current:906: [MALI] Map __ctx 0x40000001 to ctx 0xb84835d8\r\n D/Surface: Surface::setBuffersDimensions(this=0xb85146e8,w=390,h=88)\r\n D/GraphicBuffer: register, handle(0xb8517b30) (w:390 h:88 s:400 f:0x1 u:0x000f02)\r\n D/Surface: Surface::allocateBuffers(this=0xb85146e8)\r\n D/MALI: _egl_make_current:857: [MALI] make current with display 0x1, context 0x40000001, state 0xb846edb8\r\n D/MALI: _egl_make_current:872: [MALI] Map __dpy 0x1 to dpy 0xb84011b0\r\n D/MALI: _egl_make_current:906: [MALI] Map __ctx 0x40000001 to ctx 0xb84835d8\r\n D/OpenGLRenderer: Flushing caches (mode 0)\r\n D/Surface: Surface::disconnect(this=0xb85146e8,api=1)\r\n D/GraphicBuffer: unregister, handle(0xb8517b30) (w:390 h:88 s:400 f:0x1 u:0x000f02)\r\n D/OpenGLRenderer: Flushing caches (mode 0)\r\n V/FA: Inactivity, disconnecting from the service\r\n I/System.out: [socket][1:41386] exception\r\n I/System.out: [CDS]close[41386]\r\n I/System.out: Close in OkHttp\r\n I/System.out: [CDS]rx timeout:0\r\n I/System.out: [socket][1] connection settings.crashlytics.com/216.58.192.35:443;LocalPort=58048(10000)\r\n I/System.out: [CDS]connect[settings.crashlytics.com/216.58.192.35:443] tm:10\r\n D/Posix: [Posix_connect Debug]Process com.solucionesonline.tcompraempresa :443 \r\n I/System.out: [socket][/192.168.1.100:58048] connected\r\n D/libc-netbsd: [getaddrinfo]: mtk hostname=settings.crashlytics.com; servname=(null); cache_mode=(null), netid=0; mark=0\r\n D/libc-netbsd: getaddrinfo( app_uid:10129\r\n D/libc-netbsd: getaddrinfo() uid prop:\r\n D/libc-netbsd: getaddrinfo() getuid():10129\r\n D/libc-netbsd: [getaddrinfo]: mtk ai_addrlen=0; ai_canonname=(null); ai_flags=4; ai_family=0\r\n D/NativeCrypto: ssl=0xb85196a0 NativeCrypto_SSL_do_handshake fd=0xa2bb82f0 shc=0xa2bb82f4 timeout_millis=0 client_mode=1 npn=0x0\r\n D/NativeCrypto: doing handshake ++\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x10 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 handshake start in UNKWN  before/connect initialization\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback calling handshakeCompleted\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback completed\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1001 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:UNKWN  before/connect initialization\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1001 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:23WCHA SSLv2/v3 write client hello A\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1002 ret=-1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:error exit in 23RSHA SSLv2/v3 read server hello A\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: doing handshake -- ret=-1\r\n D/NativeCrypto: ssl=0xb85196a0 NativeCrypto_SSL_do_handshake ret=-1 errno=11 sslError=2 timeout_millis=0\r\n D/NativeCrypto: doing handshake ++\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1001 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:3RSH_A SSLv3 read server hello A\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1002 ret=-1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:error exit in 3RSC_A SSLv3 read server certificate A\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1002 ret=-1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:error exit in 3RSC_A SSLv3 read server certificate A\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: doing handshake -- ret=-1\r\n D/NativeCrypto: ssl=0xb85196a0 NativeCrypto_SSL_do_handshake ret=-1 errno=11 sslError=2 timeout_millis=0\r\n D/NativeCrypto: doing handshake ++\r\n E/NativeCrypto: ssl=0xb85196a0 cert_verify_callback x509_store_ctx=0xa2bb8138 arg=0x0\r\n E/NativeCrypto: ssl=0xb85196a0 cert_verify_callback calling verifyCertificateChain authMethod=ECDHE_RSA\r\n D/NativeCrypto: ssl=0xb85196a0 cert_verify_callback => 1\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1001 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:3RSC_A SSLv3 read server certificate A\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1001 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:3RSKEA SSLv3 read server key exchange A\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1001 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:3RSD_A SSLv3 read server done A\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1001 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:3WCKEA SSLv3 write client key exchange A\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1001 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:3WCCSA SSLv3 write change cipher spec A\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1001 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:3WFINA SSLv3 write finished A\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1001 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:3FLUSH SSLv3 flush data\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1002 ret=-1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:error exit in UNKWN  SSLv3 read server session ticket A\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: doing handshake -- ret=-1\r\n D/NativeCrypto: ssl=0xb85196a0 NativeCrypto_SSL_do_handshake ret=-1 errno=11 sslError=2 timeout_millis=0\r\n D/NativeCrypto: doing handshake ++\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1001 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:UNKWN  SSLv3 read server session ticket A\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1001 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:3RFINA SSLv3 read finished A\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x20 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 handshake done in SSLOK  SSL negotiation finished successfully\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback calling handshakeCompleted\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback completed\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback where=0x1002 ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 SSL_connect:ok exit in SSLOK  SSL negotiation finished successfully\r\n D/NativeCrypto: ssl=0xb85196a0 info_callback ignored\r\n D/NativeCrypto: doing handshake -- ret=1\r\n D/NativeCrypto: ssl=0xb85196a0 NativeCrypto_SSL_get_certificate => NULL\r\n I/System.out: gba_cipher_suite:TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\r\n I/System.out: [OkHttp] sendRequest>>\r\n I/System.out: [OkHttp] sendRequest<<\r\n D/NativeCrypto: ssl=0xb85196a0 sslWrite buf=0xb84dc348 len=816 write_timeout_millis=0\r\n D/NativeCrypto: ssl=0xb85196a0 sslRead buf=0xb8531ae0 len=2048,timeo=0\r\n E/Fabric: Failed to retrieve settings from https://settings.crashlytics.com/spi/v2/platforms/android/apps/com.solucionesonline.tcompraempresa/settings\r\n E/Answers: Failed to retrieve settings\r\n W/CrashlyticsCore: Received null settings, skipping report submission!\r\n I/System.out: [CDS][DNS] getAllByNameImpl netId = 0\r\n D/libc-netbsd: [getaddrinfo]: mtk hostname=tcompra-7dc35.firebaseio.com; servname=(null); cache_mode=(null), netid=0; mark=0\r\n D/libc-netbsd: getaddrinfo( app_uid:10129\r\n D/libc-netbsd: getaddrinfo() uid prop:\r\n D/libc-netbsd: getaddrinfo() getuid():10129\r\n D/libc-netbsd: [getaddrinfo]: mtk ai_addrlen=0; ai_canonname=(null); ai_flags=4; ai_family=0\r\n D/libc-netbsd: [getaddrinfo]: mtk hostname=tcompra-7dc35.firebaseio.com; servname=(null); cache_mode=(null), netid=0; mark=0\r\n D/libc-netbsd: getaddrinfo( app_uid:10129\r\n D/libc-netbsd: getaddrinfo() uid prop:\r\n D/libc-netbsd: getaddrinfo() getuid():10129\r\n D/libc-netbsd: [getaddrinfo]: mtk ai_addrlen=0; ai_canonname=(null); ai_flags=1024; ai_family=0\r\n D/libc-netbsd: getaddrinfo: tcompra-7dc35.firebaseio.com get result from proxy >>\r\n I/System.out: propertyValue:true\r\n I/System.out: [CDS]connect[tcompra-7dc35.firebaseio.com/2600:1901:0:94b6:::443] tm:90\r\n D/Posix: [Posix_connect Debug]Process com.solucionesonline.tcompraempresa :443 \r\n I/art: System.exit called, status: 1\r\n I/AndroidRuntime: VM exiting with result code 1, cleanup skipped.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15210", "user": "derrickrc", "root": "ROOT152", "reply_to": "COM1529", "timestamp": "2020-04-18T00:45:15Z", "text": "I've also encountered this problem before and only resetting the customer's router ended up working. Writes over wifi to another REST API were working during this period, but setValue() to my Firebase RTDB were not. I unfortunately don't have the logs from that period.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15211", "user": "korva", "root": "ROOT152", "reply_to": "COM15210", "timestamp": "2020-04-21T12:07:48Z", "text": "Chiming in since this seems to be an issue in our usage of Realtime Database too. For years already, we have received support requests from Android app users who are not receiving data from RTDB. I've tried many things over the years to mitigate this, but never have found a way to fix the issue completely. Switching away from wifi usually fixes the situation. It's not a very widespread issue, but one that has been very hard to reproduce. Common symptoms include:\r\n- Only affects our Android app, not iOS (which is accessing the exact same database)\r\n- Other apps / internet connection in general works on the phone, it's just RTDB things that fail\r\n- Seems to affect devices from many manufacturers (Samsung, OnePlus, Huawei, Nokia)\r\n- Has been a consistent problem over many Android versions (7-10)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15212", "user": "derrickrc", "root": "ROOT152", "reply_to": "COM15211", "timestamp": "2020-04-21T14:50:07Z", "text": "One thing I am going to try (which I already do in another version of my app, for different reasons) is to create a dummy keep-alive setValue() write to my RTDB every 5 minutes or so. I've never gotten a report from that version of my app that the connection has broken, so I am wondering if it has something to do with it. \r\n\r\n**Update:**\r\n\r\nI was actually able to reproduce this, or some version of this, it seems. I connected my test device to my phone's hotspot wifi connection and then turned off the LTE mobile data. I sent my setValue() request with an onComplete listener and the connection hangs. DatabaseError is never thrown. I then re-enable the mobile LTE data on my hotspot device - subsequent attempts also fail, DatabaseError is never thrown so the else statement never runs. I opened a browser and confirmed internet connection is present. Restarting the activity in the reconnected state did not help as well. \r\n\r\nThe fix was to disable and re-enable wifi on the device.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15213", "user": "katowulf", "root": "ROOT152", "reply_to": "COM15212", "timestamp": "2020-04-21T21:56:46Z", "text": "How long did you wait for the connections to recover? This would be useful for comparing to the socket connection timeouts.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15214", "user": "derrickrc", "root": "ROOT152", "reply_to": "COM15213", "timestamp": "2020-04-21T22:51:41Z", "text": "Hi Kato,\r\n\r\nI let the setValue() run twice and both times it recovered after around 18 minutes. I'm happy to email you the entire stacktrace if that's helpful, it looks like there's some relevant stuff going on there. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15215", "user": "derrickrc", "root": "ROOT152", "reply_to": "COM15214", "timestamp": "2020-04-22T20:20:38Z", "text": "@katowulf and I connected offline and this is expected behavior due to the Android OS basically neglecting to informing apps when the connection is restored. I can't say if this is the same exact issue the original poster and others faced, but in my case (Nexus 10 tablet, Android 5.1.1) it took around 18 minutes to reconnect to the socket and for the setValue() request to complete after an initial internet disconnect (when no change in wifi network connection occurs). \r\n\r\nRestarting the app or disabling and re-enabling wifi appears to fix it.  ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15216", "user": "korva", "root": "ROOT152", "reply_to": "COM15215", "timestamp": "2020-04-24T06:59:16Z", "text": "I managed to get some additional info about this issue from one of our users: sees like that using an Android device on wifi over a certain wifi router/modem (Sagemcom F-3686ACv2) from a certain Finnish mobile carrier (DNA) caused Firebase's websocket connection to wss://s-usc1c-nss-256.firebaseio.com to not work. HTTP traffic worked normally through the same wifi. This issue was \"solved\" by rebooting or resetting the router. Unfortunately I don't have logs about this case.\r\n\r\nWhile the blame in this case falls to the router and/or carrier, it's very unfortunate that this happens for Realtime Database usage only. And it's weird that this seems to affect Android only. I wish I could even get an error from Firebase SDK in these cases (currently no callbacks are fired when connection does not work). Our usage of Realtime database is read-only.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15217", "user": "Thaina", "root": "ROOT152", "reply_to": "COM15216", "timestamp": "2020-04-24T07:51:40Z", "text": "@korva The glimpse of the cause is in this comment https://github.com/firebase/firebase-android-sdk/issues/1258#issuecomment-596042114\r\n\r\n \"The network stack\" that rely on underlying android network library is the root cause, there was many bug about networking in android OS itself, not only firebase but facebook SDK also suffer from another android networking library bug and google themselves never ever had publicly announcement to fix them\r\n\r\nFireStore use GRPC instead and they avoid those android bug", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15218", "user": "giovanny1307", "root": "ROOT152", "reply_to": "COM15217", "timestamp": "2020-05-07T16:18:44Z", "text": "I happen to have the same issue, after reading this thread I contact our clients experimenting this issue, I suggested to them to use their mobile data instead of their wifi and the app loaded the info.\r\nOn my research I found that the problem could be even more complex.\r\n\r\nOne of our clients have two phones, Samsung A30s and Huawei P20 pro, the 2 devices were connected to the same wifi router. The samsung is having the issue, the Huawei is not. \r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15219", "user": "derrickrc", "root": "ROOT152", "reply_to": "COM15218", "timestamp": "2020-05-22T17:15:26Z", "text": "Firebase support got back to me and in my case, after an initial internet connectivity disconnect occurs with device wifi remaining connected, the correct approach is to simply call `goOffline()` followed by `goOnline()`. I verified this immediately restores connection to the Firebase database, though not sure if it's the same wifi issue others are facing. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15220", "user": "katowulf", "root": "ROOT152", "reply_to": "COM15219", "timestamp": "2020-05-26T17:01:42Z", "text": "Current status:\r\nSeems to recover in about 18 minutes (when the OS informs the app the connection is recovered, most likely). \r\n\r\nWorkaround: Call goOffline() followed by goOnline(). \r\n\r\nWhile calling goOffline/goOnline is a reasonable workaround until there's a fix, doesn't feel like clients should have to monitor and manage the connectivity; our SDKs should handle this. \r\n\r\nLocking discussion to save eng time answering ETA requests, but keeping this open as a bug for discussion and resolution. We'll update here when there is a status update or news of a fix. Until then, please use the workaround and assume there's no release date available.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT153", "user": "The-Fireplace", "root": "ROOT153", "reply_to": null, "timestamp": "2020-01-15T06:46:47Z", "text": "[1.15.1] Add event for when a chat packet is about to be sent from the server to a client This event allows the monitoring, modification, and cancellation of chat packets before they get sent to the client.\r An example use case for this is in a server-side chat censorship mod - *I removed this link for a reason, do not repost it* was previously needed to ensure that all chat messages, whether sent by the player or sent by some other system which the player can control, were properly censored before being sent to the client. This event addresses that.\r I'm open to suggestions if anyone has any better names for anything I've added, or any other changes they'd like to be made to this event.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1530", "user": "LexManos", "root": "ROOT153", "reply_to": "ROOT153", "timestamp": "2020-01-15T07:33:17Z", "text": "Don't hack things with coremods, this has never been needed. Netty allows you control of direct packets if you want to be that annoying and screw with the raw data.\r\nWe also have a crapload of hook related to the chat system already so you can use any one of those.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1531", "user": "The-Fireplace", "root": "ROOT153", "reply_to": "COM1530", "timestamp": "2020-01-15T08:05:48Z", "text": "Ok, so first of all, I wasn't aware that Netty allowed directly modifying the packets. Thank you for telling me about it, I'll look into that when I get the chance. Secondly, literally none of the hooks related to the chat system cover my mod's use case, where:\r\n* The mod does not have to be installed on the client\r\n* Users can individually choose to opt out of the chat censor using a command\r\n* The censor also censors messages sent by systems that the user can type input to, such as the names of claimed territories in Clans, Towny, Factions, etc, to help ensure there is no way around it\r\n\r\nI would not have put in the effort to make a coremod in the first place if any of the hooks were able to do this.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1532", "user": "LexManos", "root": "ROOT153", "reply_to": "COM1531", "timestamp": "2020-01-15T08:18:41Z", "text": "There is both a ServerChatEvent and a ClientChatEvent, they should address the bulk of what you need.\r\nA 10 second look would of shown you that.\r\nAnd do not readd links in which I have removed, do it again and you'll be blocked.\r\nI have instructed you on two paths on how to achieve your goal now.\r\n\r\nAlso this PR would never be accepted because we do not encourage people to directly screw with packets at the  raw level like this.\r\nIF it was to EVER be entertained it would have to be hooked in the correct places where the data is actually sent like ServerChatEvent is and have the proper context.\r\nIf you're just going to hack around with low level packets, then just use netty and don't bother us when things break.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1533", "user": "The-Fireplace", "root": "ROOT153", "reply_to": "COM1532", "timestamp": "2020-01-15T08:32:04Z", "text": "ServerChatEvent controls the message being sent to all players, not allowing me to exclude the players who have opted out of the censor. ClientChatEvent modifies the message before it gets sent from the client to the server, which is not what I want.\nI understand that it won't be accepted, I'm not contesting that. Again, I wasn't aware that Netty allowed messing with low level packets like this, and I intend to look into that as an alternative to using a coremod.\nLastly, I wouldn't have edited that link back in if you had simply put _link removed_ or something along those lines in the first place. I don't appreciate you basically calling me an idiot in all caps when you didn't bother to even consider that maybe I had a good reason for doing it the way I did.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1534", "user": "LexManos", "root": "ROOT153", "reply_to": "COM1533", "timestamp": "2020-01-15T08:35:37Z", "text": "Except, you don't have a good reason, if you would of worked with anyone in the community to figure things out before resorting to hacking things with a coremod then we would be having a different conversation.\r\nBut for now, locking this as i'm done arguing, and you've been given all the information you need to NOT ASM hack things and still achieve what you want.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT154", "user": "thesmalleyes", "root": "ROOT154", "reply_to": null, "timestamp": "2019-07-24T09:27:51Z", "text": "Crash on Android 6.0 Xiaomi devices after release on PlayStore **Canonical issue: https://issuetracker.google.com/issues/147096055**\r -----\r \r I have launched my app in playstore, but i have found so many crash after the app is opened.\r And according my data on playstore, all crash happened in android 6.0. \r I have tried to testing in debug and released mode and everything is work. So this is strange for me.\r So this crash decreases my rating on playstore. Flutter team please help me.\r \r This is my data\r \r <img width=\"968\" alt=\"Screen Shot 2019-07-24 at 16 24 59\" src=\"https://user-images.githubusercontent.com/32892647/61782084-a8312600-ae2f-11e9-9cb3-827072e6c436.png\">\r \r This is error messages:\r <img width=\"973\" alt=\"Screen Shot 2019-07-24 at 16 25 14\" src=\"https://user-images.githubusercontent.com/32892647/61782106-b121f780-ae2f-11e9-9b92-72d1e52e0847.png\">\r \r And this is the log while app crash\r \r > 07-24 15:58:02.066 377-386/? E/cutils: Failed to openat(/storage/0403-0201): Permission denied\r 07-24 15:58:02.071 377-386/? E/cutils: Failed to openat(/storage/0403-0201): Permission denied\r 07-24 15:58:02.161 11382-11382/? A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x8 in tid 11382 (pkarir.topkarir)\r 07-24 15:58:02.214 520-520/? A/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\r 07-24 15:58:02.215 520-520/? A/DEBUG: Build fingerprint: 'Xiaomi/helium/helium:6.0.1/MMB29M/V7.3.14.0.MBDCNDE:user/release-keys'\r 07-24 15:58:02.215 520-520/? A/DEBUG: Revision: '0'\r 07-24 15:58:02.215 520-520/? A/DEBUG: ABI: 'arm64'\r 07-24 15:58:02.215 520-520/? A/DEBUG: pid: 11382, tid: 11382, name: pkarir.topkarir  >>> com.topkarir.topkarir <<<\r 07-24 15:58:02.215 520-520/? A/DEBUG: signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x8\r 07-24 15:58:02.224 520-520/? A/DEBUG:     x0   0000007fed6aefd8  x1   0000007f7a03453f  x2   0000000000000006  x3   0000000000007472\r 07-24 15:58:02.224 520-520/? A/DEBUG:     x4   0000000000000000  x5   0000000000000001  x6   00000055b4fca658  x7   0000007f7a034539\r 07-24 15:58:02.224 520-520/? A/DEBUG:     x8   0000000000000021  x9   00000055b4fca640  x10  0000000051511100  x11  0000000000000033\r 07-24 15:58:02.224 520-520/? A/DEBUG:     x12  0000007f94d5ba70  x13  00000055b4fca660  x14  00000055b4fca650  x15  000000000000af60\r 07-24 15:58:02.224 520-520/? A/DEBUG:     x16  0000007f7a7afa78  x17  0000007f94cc5c08  x18  c000000000000000  x19  0000007fed6af178\r 07-24 15:58:02.224 520-520/? A/DEBUG:     x20  0000007fed6af180  x21  0000007fed6af190  x22  0000000000000000  x23  0000007fed6aefd8\r 07-24 15:58:02.224 520-520/? A/DEBUG:     x24  0000007f7a7c00d0  x25  0000000000000008  x26  0000000012c59080  x27  0000000071584b40\r 07-24 15:58:02.224 520-520/? A/DEBUG:     x28  00000000724b5dd4  x29  0000000012caeca0  x30  0000007f7a229320\r 07-24 15:58:02.224 520-520/? A/DEBUG:     sp   0000007fed6aefd0  pc   0000007f7a229320  pstate 0000000080000000\r 07-24 15:58:02.225 520-520/? A/DEBUG: backtrace:\r 07-24 15:58:02.225 520-520/? A/DEBUG:     #00 pc 000000000004d320  /data/app/com.topkarir.topkarir-1/split_config.arm64_v8a.apk (offset 0x715000)\r 07-24 15:58:02.560 520-520/? A/DEBUG: Tombstone written to: /data/tombstones/tombstone_07\r 07-24 15:58:02.560 520-520/? E/DEBUG: AM write failed: Broken pipe\r 07-24 15:58:02.578 1287-11433/? E/ActivityManager: Invalid thumbnail dimensions: 0x0\r \r =====================================================================\r \r **Edit by @xster:**\r \r  We're closing this bug since it's an issue in the Xiaomi OS and we can't fix it. See more info in https://github.com/flutter/flutter/issues/36822#issuecomment-591173690", "meta": {"posReactions": "25", "negReactions": "0"}}
{"id": "COM1540", "user": "thesmalleyes", "root": "ROOT154", "reply_to": "ROOT154", "timestamp": "2019-07-24T09:53:17Z", "text": "cc @tvolkert ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1541", "user": "jason-simmons", "root": "ROOT154", "reply_to": "COM1540", "timestamp": "2019-07-24T18:02:24Z", "text": "The device codenames in the third graph are Xiaomi devices\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1542", "user": "tvolkert", "root": "ROOT154", "reply_to": "COM1541", "timestamp": "2019-07-24T18:29:24Z", "text": "The top device (santoni), for instance, is the Xiaomi Redmi 4X", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1543", "user": "thesmalleyes", "root": "ROOT154", "reply_to": "COM1542", "timestamp": "2019-07-25T07:23:38Z", "text": "yeah, it happens in every xiaomi devices who used android 6.0, and the most of my user use xiaomi devices", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1544", "user": "timsneath", "root": "ROOT154", "reply_to": "COM1543", "timestamp": "2019-07-31T02:47:02Z", "text": "Sorry to hear about the crashes. \r\n\r\nCouple of questions, @bayuramadeza -- is this a regression from previous versions, or can you reproduce it on older builds? \r\n\r\nAnd are you able to narrow this down to a reproducible crash with a small sample? I'm not aware that we're seeing general issues with these devices, so it would be nice to know the source of this (could be Flutter itself, a plug-in, or something else, of course). ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1545", "user": "thesmalleyes", "root": "ROOT154", "reply_to": "COM1544", "timestamp": "2019-07-31T03:04:11Z", "text": "@timsneath yes this regression happened since i used appbundle in playstore. when i tried to remove any plugin and all code, then i uploaded it to playstore it's still happened. So, i rechecked anything but there is no something wrong. \r\ni just confused, why it's running in release mode with apk, but it crashed after internal teesting with appbundle?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1546", "user": "timsneath", "root": "ROOT154", "reply_to": "COM1545", "timestamp": "2019-07-31T03:10:05Z", "text": "Hmm, that's interesting. And you're using `Flutter 1.7.4+hotfix.4`? (Check with `flutter doctor -v`, if you wouldn't mind -- I want to make sure you're running the very latest hotfix revision.)\r\n\r\nSo to confirm:\r\n\r\n- Uploaded as an APK with Flutter 1.7.4+hotfix.4, the app does not crash on these devices\r\n- Uploaded as an APPBUNDLE with Flutter 1.7.4+hotfix.4, the app crashes on the same devices?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1547", "user": "thesmalleyes", "root": "ROOT154", "reply_to": "COM1546", "timestamp": "2019-07-31T03:54:19Z", "text": "i used the latest beta.\r\n\r\n[\u2713] Flutter (Channel beta, v1.7.8+hotfix.4, on Mac OS X 10.14.5 18F132, locale en-ID)\r\n    \u2022 Flutter version 1.7.8+hotfix.4 at /Users/topkarir/Documents/developments/flutter\r\n    \u2022 Framework revision 20e59316b8 (12 days ago), 2019-07-18 20:04:33 -0700\r\n    \u2022 Engine revision fee001c93f\r\n    \u2022 Dart version 2.4.0\r\n\r\n \r\n[\u2713] Android toolchain - develop for Android devices (Android SDK version 28.0.3)\r\n    \u2022 Android SDK at /Users/topkarir/Library/Android/sdk\r\n    \u2022 Android NDK location not configured (optional; useful for native profiling support)\r\n    \u2022 Platform android-29, build-tools 28.0.3\r\n    \u2022 Java binary at: /Applications/Android Studio.app/Contents/jre/jdk/Contents/Home/bin/java\r\n    \u2022 Java version OpenJDK Runtime Environment (build 1.8.0_152-release-1343-b01)\r\n    \u2022 All Android licenses accepted.\r\n\r\n[\u2713] Xcode - develop for iOS and macOS (Xcode 10.2.1)\r\n    \u2022 Xcode at /Applications/Xcode.app/Contents/Developer\r\n    \u2022 Xcode 10.2.1, Build version 10E1001\r\n    \u2022 CocoaPods version 1.6.1\r\n\r\n[\u2713] iOS tools - develop for iOS devices\r\n    \u2022 ios-deploy 1.9.4\r\n\r\n[\u2713] Android Studio (version 3.4)\r\n    \u2022 Android Studio at /Applications/Android Studio.app/Contents\r\n    \u2022 Flutter plugin version 37.1.1\r\n    \u2022 Dart plugin version 183.6270\r\n    \u2022 Java version OpenJDK Runtime Environment (build 1.8.0_152-release-1343-b01)\r\n\r\n[\u2713] VS Code (version 1.36.1)\r\n    \u2022 VS Code at /Applications/Visual Studio Code.app/Contents\r\n    \u2022 Flutter extension version 3.2.0\r\n\r\n[!] Connected device\r\n    ! No devices available\r\n\r\n! Doctor found issues in 1 category.\r\n\r\nAnd when i uploaded only apk in playstore it's running well in android 6.0 but when i uploaded appbundle the crash appears ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1548", "user": "blasten", "root": "ROOT154", "reply_to": "COM1547", "timestamp": "2019-07-31T21:20:23Z", "text": "We have requested a device to test this issue. It's expected to arrive between Aug 19 and Sep 30.\r\n\r\nIn the meanwhile, would it be possible to access the app's source code? If yes, feel free to send the link via Gitter.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1549", "user": "tvolkert", "root": "ROOT154", "reply_to": "COM1548", "timestamp": "2019-07-31T22:11:37Z", "text": "Please sign the CLA at https://cla.developers.google.com/ before sending us any source code, or we can't look at it \ud83d\ude42 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15410", "user": "thesmalleyes", "root": "ROOT154", "reply_to": "COM1549", "timestamp": "2019-08-02T09:31:32Z", "text": "i'm sorry, i didn't get permission to share my code, ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15411", "user": "ajinasokan", "root": "ROOT154", "reply_to": "COM15410", "timestamp": "2019-08-03T08:03:27Z", "text": "@tvolkert @timsneath Is it possible to expedite fix for this issue? Around 30% of our users are on these devices and we already reached 2,500 crashes.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15412", "user": "bpillon", "root": "ROOT154", "reply_to": "COM15411", "timestamp": "2019-08-03T13:16:49Z", "text": "Same for me. Have crash on redmi 4 since 1.2, 1.0 is working so I have to keep using it. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15413", "user": "tvolkert", "root": "ROOT154", "reply_to": "COM15412", "timestamp": "2019-08-08T19:43:49Z", "text": "@ajinasokan see https://github.com/flutter/flutter/issues/36822#issuecomment-517025572 -- once we receive devices to try to reproduce the crashes on, we will have a look.  In the meantime, if you can send us symbolicated stack traces, that would be helpful.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15414", "user": "gofur", "root": "ROOT154", "reply_to": "COM15413", "timestamp": "2019-08-09T09:29:23Z", "text": "i got the same problem... any solutions??? @bayuramadeza ?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15415", "user": "ajinasokan", "root": "ROOT154", "reply_to": "COM15414", "timestamp": "2019-08-09T14:23:58Z", "text": "We had to upload APKs with split ABIs to solve this issue.\r\n\r\n@tvolkert I tried to reproduce this issue in a Redmi Note 4 (mido). But it is only causing in Android 6.0 and I'm unable to find the stock images for it because it is too old.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15416", "user": "HeorhiiKhrushch", "root": "ROOT154", "reply_to": "COM15415", "timestamp": "2019-08-12T13:26:29Z", "text": "same problem here, tested release build on Xiaomi Redmi Note4, android 6.0, my logs:\r\n\r\n08-12 16:20:30.419 2297-2438/com.miui.whetstone E/Whetstone-JNI: set process [index 0](addres 0x7f6f9c55c0), pid(24518), uid(0), processName(<MY_PACKAGE_NAME>), property(0)\r\n08-12 16:20:30.586 24518-24518/? A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x8 in tid 24518 (<MY_PACKAGE_NAME>)\r\n08-12 16:20:30.670 2297-2438/com.miui.whetstone E/Whetstone-JNI: set process [index 0](addres 0x7f6f9c55c0), pid(24606), uid(0), processName(<MY_PACKAGE_NAME>), property(0)\r\n08-12 16:20:30.863 24606-24606/? A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x8 in tid 24606 (<MY_PACKAGE_NAME>)\r\n08-12 16:20:30.954 2297-2438/com.miui.whetstone E/Whetstone-JNI: set process [index 0](addres 0x7f6f9c55c0), pid(24677), uid(0), processName(<MY_PACKAGE_NAME>), property(0)\r\n08-12 16:20:31.110 24677-24677/? A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x8 in tid 24677 (<MY_PACKAGE_NAME>)\r\n\r\n[\u2713] Flutter (Channel stable, v1.7.8+hotfix.4, on Mac OS X 10.14.6 18G84, locale en-UA)\r\n    \u2022 Flutter version 1.7.8+hotfix.4 at /Users/admin908/flutter\r\n    \u2022 Framework revision 20e59316b8 (3 weeks ago), 2019-07-18 20:04:33 -0700\r\n    \u2022 Engine revision fee001c93f\r\n    \u2022 Dart version 2.4.0\r\n\r\n \r\n[\u2713] Android toolchain - develop for Android devices (Android SDK version 28.0.3)\r\n    \u2022 Android SDK at /Users/admin908/Library/Android/sdk\r\n    \u2022 Android NDK location not configured (optional; useful for native profiling support)\r\n    \u2022 Platform android-28, build-tools 28.0.3\r\n    \u2022 ANDROID_HOME = /Users/admin908/Library/Android/sdk\r\n    \u2022 Java binary at: /Applications/Android Studio.app/Contents/jre/jdk/Contents/Home/bin/java\r\n    \u2022 Java version OpenJDK Runtime Environment (build 1.8.0_152-release-1343-b01)\r\n    \u2022 All Android licenses accepted.\r\n\r\n[\u2713] Xcode - develop for iOS and macOS (Xcode 10.3)\r\n    \u2022 Xcode at /Applications/Xcode.app/Contents/Developer\r\n    \u2022 Xcode 10.3, Build version 10G8\r\n    \u2022 CocoaPods version 1.6.1\r\n\r\n[\u2713] iOS tools - develop for iOS devices\r\n    \u2022 ios-deploy 1.9.4\r\n\r\n[\u2713] Android Studio (version 3.4)\r\n    \u2022 Android Studio at /Applications/Android Studio.app/Contents\r\n    \u2022 Flutter plugin version 37.1.1\r\n    \u2022 Dart plugin version 183.6270\r\n    \u2022 Java version OpenJDK Runtime Environment (build 1.8.0_152-release-1343-b01)\r\n\r\n[\u2713] VS Code (version 1.36.1)\r\n    \u2022 VS Code at /Applications/Visual Studio Code.app/Contents\r\n    \u2022 Flutter extension version 3.3.0\r\n\r\n[\u2713] Connected device (1 available)\r\n    \u2022 Redmi Note 4 \u2022 UOK7GY89LNSOSWEI \u2022 android-arm64 \u2022 Android 6.0 (API 23)\r\n\r\nBuilding app using 'flutter build appbundle', installing using bundletool.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM15417", "user": "psovit", "root": "ROOT154", "reply_to": "COM15416", "timestamp": "2019-08-28T07:06:28Z", "text": "@ajinasokan did you solve the issue by splitting apk:\r\n`flutter build apk --target-platform android-arm,android-arm64 --split-per-abi`\r\nor  by splitting bundle:\r\n`flutter build appbundle --target-platform android-arm,android-arm64` ?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15418", "user": "psovit", "root": "ROOT154", "reply_to": "COM15417", "timestamp": "2019-08-30T07:52:47Z", "text": "--removing my comment here as it was a different issue which was specific to Redmi developer options configuration...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15419", "user": "ajinasokan", "root": "ROOT154", "reply_to": "COM15418", "timestamp": "2019-08-30T08:00:11Z", "text": "@psovit Second approach doesn't work. I'm not sure about the first approach. We are building APKs separately like this \r\n\r\n```\r\nflutter build apk --target-platform android-arm --build-name=$(BUILD_NAME) --build-number $(BUILD_NUMBER_32)\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15420", "user": "codxse", "root": "ROOT154", "reply_to": "COM15419", "timestamp": "2019-08-30T08:59:55Z", "text": "Guys, I am following this issue too. We have major incident after release appbundle. A lot of android 6 device crash.\r\n\r\nWell, after move to split-apk approach ([described here](https://stackoverflow.com/questions/56607075/could-not-find-an-option-named-split-per-abi)), I finally can install the app on Android 6.0. Still I need more tests to ensure not happening on other device.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15421", "user": "HeorhiiKhrushch", "root": "ROOT154", "reply_to": "COM15420", "timestamp": "2019-08-30T09:26:39Z", "text": "@codxse I'm now using same approach (split-per-abi)\r\n\r\nNoticing, in case of building using appbundle, the device i'm using (Redmi Note 4 \u2022 android-arm64 \u2022 Android 6.0 (API 23)) gets strange apk of bundletool. Installed app is **much smaller** (installed app normal size is about 20Mb, while this app - about 3Mb), definitely missing native libs!\r\n![device-2019-08-30-122337](https://user-images.githubusercontent.com/23216320/64009853-54e27f80-cb21-11e9-8188-87ca7f881aec.png)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15422", "user": "thesmalleyes", "root": "ROOT154", "reply_to": "COM15421", "timestamp": "2019-09-23T02:29:56Z", "text": "Hai @tvolkert , is there a new update for this issue? because i used to build apk command rather than build appbundle since this issue makes problem to my users. Thanks", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15423", "user": "blasten", "root": "ROOT154", "reply_to": "COM15422", "timestamp": "2019-09-23T04:37:34Z", "text": "@bayuramadeza I received the phone, but it came with Android 7.0 instead of 6.0. The crash doesn\u2019t occur on 7.0. To install 6.0, the phone needs to be rooted first... I will try that when I get a chance. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15424", "user": "blasten", "root": "ROOT154", "reply_to": "COM15423", "timestamp": "2019-10-03T15:05:50Z", "text": "The stacktrace you posted is very similar to this one https://github.com/flutter/flutter/issues/37234#issuecomment-536893636.\r\n\r\nThe Android App Bundle team is looking into this issue and I will update as I find out more. In the meanwhile, have you tried to upload two APKs to the Play Store instead of an app bundle? \r\n\r\nYou can use `flutter build apk --split-per-abi` to generate two APKs for 32 and 64bit.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM15425", "user": "blasten", "root": "ROOT154", "reply_to": "COM15424", "timestamp": "2019-10-03T17:35:07Z", "text": "The workaround is to use `flutter build apk --split-per-abi` to generate two APKs for 32 and 64bit.  \r\n\r\nI'm closing the issue, but feel free to reopen if the problem persists after uploading the two APKs.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15426", "user": "thesmalleyes", "root": "ROOT154", "reply_to": "COM15425", "timestamp": "2019-10-04T02:30:10Z", "text": "Yeah since this issue was opened, i have built apk --split, not appbundle anymore. I hope the issue can fix in appbundle, to optimize the app like playstore recommendation", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15427", "user": "sroddy", "root": "ROOT154", "reply_to": "COM15426", "timestamp": "2019-10-04T12:08:38Z", "text": "@blasten as appbundle is the Play Store recommendation, I think this issue should be kept open until a proper fix is found and if it not found, it should be underlined extremely well in the docs (or even by the tool during a build) that appbundle builds are currently unstable and not recommended by Flutter", "meta": {"posReactions": "9", "negReactions": "0"}}
{"id": "COM15428", "user": "blasten", "root": "ROOT154", "reply_to": "COM15427", "timestamp": "2019-10-04T14:03:18Z", "text": "Just to clarify. This isn\u2019t a Flutter bug. I forwarded this issue to the Android team, and they are currently looking into ways to mitigate the problem at the Play Store level.\r\n\r\nI can keep the issue open and close once the upstream issue is fixed. ", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM15429", "user": "sroddy", "root": "ROOT154", "reply_to": "COM15428", "timestamp": "2019-10-04T23:03:55Z", "text": "Thank you for the clarification.\r\nIf I understood correctly splitting per ABI with the current flutter build script is done by adding 1000/2000/3000/4000/5000 to the base build number.\r\nThis means it would start causing potential issues with a base build number above 1000. Even if it seems a relatively high number, it is currently not that high (we are already at build number 200 after 18 months of release cycles).\r\nIt's also important to pay attention when switching back to appbundle, as the build number needs to go above the highest build number already released.\r\nSwitching back and forth multiple times between these two modes is not trivial.\r\nFor this reason we have currently decided to release fat apks with binary code for both architectures, accepting a 8MB overhead in the size, hoping to see this bug solved soon.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "ROOT155", "user": "thisandagain", "root": "ROOT155", "reply_to": null, "timestamp": "2018-05-01T16:22:20Z", "text": "Adjust colors for \"control\" and \"events\" In Scratch 2.0 the colors for \"control\" and \"events\" are an orange-ish brown and an orange-ish yellow respectively. As part of our initial color explorations for Scratch 3.0 we strived to normalize the block category palettes between Scratch 2.0 and ScratchJr as well as resolve design issues with the \"muddy\" brown color that was being used for the \"events\" category. The result of this was to shift the \"events\" category to yellow and keep the \"control\" category with a similar orange to what it has today.\r \r An unfortunately side-effect of this change that we have observed is that users who are familiar with the Scratch 2.0 category colors sometimes mistakenly select the \"control\" category when they intend to select the \"events\" category. We have observed that this issue goes away after continuous use of Scratch 3.0 (it appears to be temporary / transitional), but nonetheless we should discuss if corrective action should be taken.\r \r ### Scratch 2.0\r ![image](https://user-images.githubusercontent.com/747641/39480947-cb4495aa-4d37-11e8-9b26-38514f37a6a8.png)\r \r ### ScratchJr\r ![image](https://user-images.githubusercontent.com/747641/39480978-e2b12d20-4d37-11e8-8bd6-58899c237b58.png)\r \r ### Scratch 3.0 (Vertical Grammar)\r ![image](https://user-images.githubusercontent.com/747641/39481623-189f23b8-4d3a-11e8-87ff-36bdc105a1e0.png)\r \r ### Scratch 3.0 (Horizontal Grammar)\r ![image](https://user-images.githubusercontent.com/747641/39481659-31f6e710-4d3a-11e8-812b-845b238b082a.png)\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1550", "user": "thisandagain", "root": "ROOT155", "reply_to": "ROOT155", "timestamp": "2018-05-01T16:26:44Z", "text": "/cc @ntlrsk ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1551", "user": "carljbowman", "root": "ROOT155", "reply_to": "COM1550", "timestamp": "2018-05-01T18:16:09Z", "text": "## Events and Control Color Swap\r\n\r\n### Blocks (Vertical & Horizontal)\r\n![r1_events-and-control-swap](https://user-images.githubusercontent.com/3409578/39486412-00801840-4d4a-11e8-9aae-e378f49a951b.png)\r\n\r\n### Blocks in Context\r\n![empty editor](https://user-images.githubusercontent.com/3409578/39486434-18aea9ae-4d4a-11e8-9a48-4b7a48f3c915.png)\r\n\r\n### Color Palette\r\n![r4_vertical-colors](https://user-images.githubusercontent.com/3409578/39486441-248d007c-4d4a-11e8-87e5-c2167c9750f9.png)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1552", "user": "thisandagain", "root": "ROOT155", "reply_to": "COM1551", "timestamp": "2018-05-31T12:58:47Z", "text": "After further discussion we have decided to keep these color relationships as-is in an effort to unify colors / grammars across ScratchJr and Scratch.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT156", "user": "tifDev", "root": "ROOT156", "reply_to": null, "timestamp": "2020-05-24T18:59:42Z", "text": "Focus on Terminal View on mouse hover <!-- \u26a0\ufe0f\u26a0\ufe0f Do Not Delete This! feature_request_template \u26a0\ufe0f\u26a0\ufe0f -->\r <!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->\r <!-- Please search existing issues to avoid creating duplicates. -->\r \r I'm not sure if vscode already allows this or if it is already possible to focus on terminal view on mouse hover? And it would be nice to, **when you have multiple splitted terminals, you just change focus by hovering over them with the mouse.**\r \r [Tilix](https://github.com/gnunn1/tilix) terminal has this feature.\r \r Here are the settings for keybindings:\r \r ``` \r {\r   \"key\": \"\",\r   \"command\": \"workbench.panel.terminal.focus\"\r }\r \r {\r   \"key\": \"\",\r   \"command\": \"workbench.action.terminal.focus\"\r }\r \r ```\r \r Can i add something like a \"mouse-hover\" instead of \"key\"? \r \r ", "meta": {"posReactions": "22", "negReactions": "0"}}
{"id": "COM1560", "user": "vscode-triage-bot", "root": "ROOT156", "reply_to": "ROOT156", "timestamp": "2020-11-05T02:26:04Z", "text": "<!-- 6d457af9-96bd-47a8-a0e8-ecf120dfffc1 -->\nThis feature request is now a candidate for our backlog. The community has 60 days to [upvote](https://github.com/microsoft/vscode/wiki/Issues-Triaging#up-voting-a-feature-request) the issue. If it receives 20 upvotes we will move it to our backlog. If not, we will close it. To learn more about how we handle feature requests, please see our [documentation](https://aka.ms/vscode-issue-lifecycle).\n\nHappy Coding!", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1561", "user": "vscode-triage-bot", "root": "ROOT156", "reply_to": "COM1560", "timestamp": "2020-11-21T02:27:45Z", "text": "<!-- 9078ab2c-c9e0-7adb-d31b-1f23430222f4 -->\n:slightly_smiling_face: This feature request received a sufficient number of community upvotes and we moved it to our backlog. To learn more about how we handle feature requests, please see our [documentation](https://aka.ms/vscode-issue-lifecycle).\n\nHappy Coding!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1562", "user": "Tyriar", "root": "ROOT156", "reply_to": "COM1561", "timestamp": "2021-02-02T15:05:46Z", "text": "The bot mishaved, it took 9 months to reach 20 upvotes whereas it's meant to only allow 2 months. Sorry to disappoint but I'm going to close the issue as it didn't reach that bar fast enough.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1563", "user": "phil-opp", "root": "ROOT156", "reply_to": "COM1562", "timestamp": "2021-02-02T15:55:20Z", "text": "@Tyriar Why do you think that it took 9 months? The announcement that 20 upvotes are needed was [made on Nov 5, 2020](https://github.com/microsoft/vscode/issues/98475#issuecomment-722085036) and less than three weeks later (on Nov 21, 2020) the [required number of upvotes was reached](https://github.com/microsoft/vscode/issues/98475#issuecomment-731493169). Or am I missing something?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1564", "user": "tifDev", "root": "ROOT156", "reply_to": "COM1563", "timestamp": "2021-02-02T22:30:01Z", "text": "> The bot mishaved, it took 9 months to reach 20 upvotes whereas it's meant to only allow 2 months. Sorry to disappoint but I'm going to close the issue as it didn't reach that bar fast enough.\r\n\r\n\r\n\r\nTyriar, we have reached the 20 upvotes well within the 2 months. I've been monitoring this close and there is also reddit to prove this.\r\n\r\n\r\nPls re-check this  @Tyriar \r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1565", "user": "Tyriar", "root": "ROOT156", "reply_to": "COM1564", "timestamp": "2021-02-02T22:37:01Z", "text": "This actually duplicates https://github.com/microsoft/vscode/issues/44214, which was attempted and reverted in https://github.com/microsoft/vscode/pull/53963. We would only consider this as a workbench level feature, not just the terminal and it's closed as out of scope on that issue. Closing as duplicate.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1566", "user": "tifDev", "root": "ROOT156", "reply_to": "COM1565", "timestamp": "2021-02-02T23:55:36Z", "text": "> This actually duplicates #44214\r\n\r\n\r\nSorry but the justification that the bot gave for closing [#44214](https://github.com/microsoft/vscode/issues/44214) , for me it's not clear and valid (no wonder that it received 17 downvotes). \r\n\r\n> which was attempted and reverted in #53963\r\n\r\n\r\nOn that attempt that @alexdima  tried and reverted, was focus on hover for the **EditorGroup** not for the **terminal**.\r\n\r\nAlso, those references are from 2 years ago. Until now, what has been done taking into account this? Was there a change plan created for this or something? Because it looks like the community want this (not only from 2018, but also nowadays since my request received > 20 upvotes).\r\n\r\nCan you pls re-check this and reopen **or** provide a more clear and valid justification?\r\n\r\n\r\nIf you need any help, pls tell me. \r\n\r\n@Tyriar \r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1567", "user": "Tyriar", "root": "ROOT156", "reply_to": "COM1566", "timestamp": "2021-02-03T12:55:24Z", "text": "I get you care about this but it's already been considered in https://github.com/microsoft/vscode/issues/44214#issue-299400073:\r\n\r\n> Now that we can split editors and terminals I think it would be a good idea to have the ability to activate **editors/terminals** on mouse over.\r\n\r\nAs the owner of the terminal component I reject the idea that this should be a terminal only feature, it should apply to the editors as well at the very least. The PR revealed some usability issues with the feature and it was marked as out of scope by someone intimately familiar with the editor.\r\n\r\nRealistically this would also not get prioritized for the team to work on so it would only come in via a PR, and we've already attempted and spent a bunch of time on it reviewing, testing and fixing in https://github.com/microsoft/vscode/pull/53963. It would also be a major feature in terms of work required to implement and maintain, but it would very rarely get used because it's an opt-in.\r\n\r\nThe bot helps us manage issues and it messed up here by not applying the feature request label and starting the timer in May, if it did maybe it would have reached 20 upvotes in time but I also made a mistake by not closing it out as a duplicate of https://github.com/microsoft/vscode/issues/44214 to begin with.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT157", "user": "tn", "root": "ROOT157", "reply_to": null, "timestamp": "2019-12-19T13:37:30Z", "text": "Please create Offensive build of VSCode Also add SantaHat icon", "meta": {"posReactions": "25", "negReactions": "1"}}
{"id": "COM1570", "user": "vscodebot[bot]", "root": "ROOT157", "reply_to": "ROOT157", "timestamp": "2019-12-19T13:37:36Z", "text": "(Experimental duplicate detection)\nThanks for submitting this issue. Please also check if it is already covered by an existing one, like:\n- [The code, that is written in vscode is offensive (#87373)](https://www.github.com/microsoft/vscode/issues/87373) <!-- score: 0.517 -->\n<!-- potential_duplicates_comment -->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1571", "user": "nkkollaw", "root": "ROOT157", "reply_to": "COM1570", "timestamp": "2019-12-19T13:38:07Z", "text": "\ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM1572", "user": "galimba", "root": "ROOT157", "reply_to": "COM1571", "timestamp": "2019-12-19T13:52:29Z", "text": "add a Satan Hat!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1573", "user": "CoachGodzup", "root": "ROOT157", "reply_to": "COM1572", "timestamp": "2019-12-19T13:58:28Z", "text": "Please add also an ultra-offensive debugger that shitstorms you on every error", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1574", "user": "egamma", "root": "ROOT157", "reply_to": "COM1573", "timestamp": "2019-12-19T19:42:58Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.\r\n\r\nHappy Coding!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT158", "user": "tom-adsfund", "root": "ROOT158", "reply_to": null, "timestamp": "2018-05-30T22:52:04Z", "text": "Deprecate DL4J Word2Vec for fastText? I've seen several people asking questions about w2v on chat, and there are many open issues, and I wonder whether you should deprecate w2v and point people in the direction of fastText.\r \r fastText has many benefits above w2v: subword correlations, generate vectors for new words, generate vectors for sentences, extremely fast implementation.\r \r Just seems pointless to continue supporting something that uses so much developer time.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1580", "user": "raver119", "root": "ROOT158", "reply_to": "ROOT158", "timestamp": "2018-05-30T22:53:28Z", "text": "You're welcome to send us PR.\r\n\r\nQuestions about w2v are usually not related to w2v itself, but memory and loaders related.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1581", "user": "tom-adsfund", "root": "ROOT158", "reply_to": "COM1580", "timestamp": "2018-05-30T22:56:22Z", "text": "fastText produces word2vec style vector files, so it's more a documentation thing?\r\n\r\nBeyond that it's something that keeps coming to mind that I wanted to share, rather than go further submitting pull requests etc.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1582", "user": "raver119", "root": "ROOT158", "reply_to": "COM1581", "timestamp": "2018-05-30T23:00:05Z", "text": "Sorry, what do you mean by \"documentation thing\"?\r\n\r\nHow users are supposed to build their models, if they want specific model? They should be sent to facebook for generally the same skip-gram model called fastText? \r\n\r\nHow exactly \"documentation thing\" is supposed to generate vectors for unseen-before words, without actual implementation code?\r\n\r\nSorry, i'm really not sure, what do you mean by \"documentation thing\" in this case.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1583", "user": "tom-adsfund", "root": "ROOT158", "reply_to": "COM1582", "timestamp": "2018-05-30T23:05:44Z", "text": "fastText is a tool to create word vectors, but also sentence vectors, and many other things to do with word vectors.\r\n\r\nThe point is I suggest it's better to let fastText handle word vector generation, and just remove that functionality from dl4j. Because fastText does it to a much higher level -- because they specialize in it.\r\n\r\nSo the \"documentation thing\" is to deprecate the Word2Vec generation examples and code in DL4J, and say \"see fastText [with link] for generation of word vectors\".", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1584", "user": "raver119", "root": "ROOT158", "reply_to": "COM1583", "timestamp": "2018-05-30T23:08:12Z", "text": "Good point. I hope one day Google will get the same idea, and deprecate Android. \r\n\r\nApple does it to a much higher level - because they specialize in it. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1585", "user": "tom-adsfund", "root": "ROOT158", "reply_to": "COM1584", "timestamp": "2018-05-30T23:13:50Z", "text": "That analogy makes no sense.\r\n\r\nHere's a better analogy: fastText vectors are superior to w2v vectors in the same way Darknet is superior to VGG.\r\n\r\n(Android and iOS aren't comparable because they have different use cases.)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1586", "user": "tom-adsfund", "root": "ROOT158", "reply_to": "COM1585", "timestamp": "2018-05-30T23:20:07Z", "text": "@AlexDBlack Please look at this, because @raver119 is still angry I said C wasn't a good language.\r\n\r\n(Btw, C is a fine language, just not something I use much or personally gain much utility from.)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1587", "user": "raver119", "root": "ROOT158", "reply_to": "COM1586", "timestamp": "2018-05-30T23:20:23Z", "text": "In any way - it's not a way of solving problems. Differences should drive competition. With this logic everything out there can be deprecated: dl4j, keras, chainer, pytorch - we should just all use TF and be happy.\r\n \r\nProgramming languages should be all deprecated too, in favor of C++.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1588", "user": "raver119", "root": "ROOT158", "reply_to": "COM1587", "timestamp": "2018-05-30T23:21:30Z", "text": "> Please look at this, because @raver119 is still angry I said C wasn't a good language.\r\n\r\nThat's a bit of surprising statement. I don't even remember who you are.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1589", "user": "raver119", "root": "ROOT158", "reply_to": "COM1588", "timestamp": "2018-05-30T23:21:53Z", "text": "P.s. sorry. Just too many people around.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15810", "user": "tom-adsfund", "root": "ROOT158", "reply_to": "COM1589", "timestamp": "2018-05-30T23:26:24Z", "text": "@raver119 Things that are superceded *in their use case* should be deprecated.\r\n\r\nAnd of course you remember me. It's not a big deal.\r\n\r\nC and C++ are great. For their use case! Otherwise why wouldn't DL4J just use Java throughout?? Java doesn't give access to AVX for important matrix math... doesn't give access to many useful things. So Java is useless for that.\r\n\r\nBut w2v is worse than fastText. That I won't change my mind about!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15811", "user": "agibsonccc", "root": "ROOT158", "reply_to": "COM15810", "timestamp": "2018-05-30T23:37:55Z", "text": "Hey folks - I'm locking this. @tom-adsfund I agree with @raver119 - the proper solution would be for us to add support for fast text, not \"deprecate\" word2vec.  We can definitely add it. As of right now it would have to be a pull request though. We can maybe look adding support for adding that file format. I'll keep this issue open as the point stands.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15812", "user": "AlexDBlack", "root": "ROOT158", "reply_to": "COM15811", "timestamp": "2018-05-30T23:38:06Z", "text": "@tom-adsfund \r\n> @AlexDBlack Please look at this, because @raver119 is still angry I said C wasn't a good language.\r\n\r\nKeep it professional or I won't hesitate to ban you from interacting with this repository.\r\n\r\nNow, as for the question of FastText - that's an internal roadmap question and question of priorities. Deprecating W2V is a moot point until we have support for it. Even then, I don't see why we should deprecate something functional just because something better is around.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15813", "user": "saudet", "root": "ROOT158", "reply_to": "COM15812", "timestamp": "2018-05-31T01:24:53Z", "text": "@tom-adsfund FWIW, we can use fastText from Java and I would be happy to maintain them as part of the JavaCPP Presets, contributions welcome: https://github.com/bytedeco/javacpp-presets/issues/346", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT159", "user": "tovine", "root": "ROOT159", "reply_to": null, "timestamp": "2019-12-11T14:58:35Z", "text": "Terminal windows are closed whenever updated from the store <!-- \r \ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8\r \r I ACKNOWLEDGE THE FOLLOWING BEFORE PROCEEDING:\r 1. If I delete this entire template and go my own path, the core team may close my issue without further explanation or engagement.\r 2. If I list multiple bugs/concerns in this one issue, the core team may close my issue without further explanation or engagement.\r 3. If I write an issue that has many duplicates, the core team may close my issue without further explanation or engagement (and without necessarily spending time to find the exact duplicate ID number).\r 4. If I leave the title incomplete when filing the issue, the core team may close my issue without further explanation or engagement.\r 5. If I file something completely blank in the body, the core team may close my issue without further explanation or engagement.\r \r All good? Then proceed!\r -->\r On several occasions I've experienced that when I leave my computer for a while and come back, all my terminal windows are gone.\r After some investigation I've reached the conclusion that this happens because the app was installed through the Microsoft store, and just received an update.\r \r This is probably fine for your average note taking app or Candy Crush game, but for a terminal with several tabs open that do actual work (and perhaps even long-running (like several days) processes open in remote SSH sessions) this is completely unacceptable.\r \r Is there a way to avoid the terminal being restarted after receiving an update through the Store? A notification would be fine to let me know that I should restart it on the earliest convenient moment, but having it just disappear can in the worst case scenario cost me days of work that will need to be restarted, and in the best case some inconvenience and a few minutes to get back to where I was before...\r \r Luckily a workaround exists: disable apps auto-updating (https://support.microsoft.com/en-us/help/15081/windows-turn-on-automatic-app-updates), but is there really no better way of handling this?\r <!--\r This bug tracker is monitored by Windows Terminal development team and other technical folks.\r \r **Important: When reporting BSODs or security issues, DO NOT attach memory dumps, logs, or traces to Github issues**.\r Instead, send dumps/traces to secure@microsoft.com, referencing this GitHub issue.\r \r If this is an application crash, please also provide a Feedback Hub submission link so we can find your diagnostic data on the backend. Use the category \"Apps > Windows Terminal (Preview)\" and choose \"Share My Feedback\" after submission to get the link.\r \r Please use this form and describe your issue, concisely but precisely, with as much detail as possible.\r \r -->\r \r # Environment\r \r ```none\r Windows build number: [Version 10.0.18362.418]\r Windows Terminal version (if applicable): 0.7.3382.0\r ```\r \r # Steps to reproduce\r \r Do normal everyday work in terminal, wait for an update to arrive.\r \r # Expected behavior\r \r A notification to restart the app at my earliest convenience, or that the app continues to run with the old version, and that all new instances are started as the new version (like in Linux, where executables linger on in RAM until closed regardless of whether the file they started from still exist).\r Or at the very least that it would notify me that new updates were available, but not install them.\r \r # Actual behavior\r \r Terminal windows suddenly disappear with no explanation whatsoever, before I open the Store app and see that it was just now updated...\r \r Sorry if this issue seems a bit salty, but it's really annoying - right up there with getting to the office in the morning to continue where you left off yesterday, only to find out that the PC rebooted automatically to install Windows updates (hint: not cool).", "meta": {"posReactions": "23", "negReactions": "0"}}
{"id": "COM1590", "user": "tovine", "root": "ROOT159", "reply_to": "ROOT159", "timestamp": "2019-12-11T15:03:54Z", "text": "Actually, the way you're doing it for Visual Studio Code is perfect - why not use the same approach here if possible? :)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1591", "user": "mg-christian-axelsson", "root": "ROOT159", "reply_to": "COM1590", "timestamp": "2019-12-13T08:32:07Z", "text": "+1 I just lost hours worth of state because of this behavior.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM1592", "user": "int3l", "root": "ROOT159", "reply_to": "COM1591", "timestamp": "2020-01-09T14:57:50Z", "text": "The other way around is also not good.\r\nPreviously I had a lot of errors in my Event Viewer from Windows Update about the fact that Windows Terminal can't be updated, because the executable is running.\r\nWe need a better process of updating the app. And it would be nice if we have some kind of configuration options like: automatic restart after update - on/off and so on :)", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1593", "user": "mg-christian-axelsson", "root": "ROOT159", "reply_to": "COM1592", "timestamp": "2020-01-14T08:11:22Z", "text": "Just having automatic updates install upon next launch would be a perfectly fine behavior.", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM1594", "user": "CaptFrankSolo", "root": "ROOT159", "reply_to": "COM1593", "timestamp": "2020-02-15T18:21:25Z", "text": "Also note, there is a massive difference in these experiences:\r\n1) windows restarts while my console apps are running and all my terminal state is lost AND my enqueued commands for long-running operations to finish while i am sleeping are in an unknown state\r\n2) windows restarts for updates after my enqueued commands finish and all my terminal state is lost\r\n3) windows waits to restart before my enqueued commands finish and restarts terminals with the same windows open\r\n4) windows waits to restart before my enqueued commands finish, and upon restart, terminal relaunches to to the exact same display state\r\n5) windows waits to restart before my enqueued commands finish, and upon restart, terminal relaunches to to the exact same display state including command history\r\n\r\nplease, on behalf of developers everywhere with long build times, consider moving us more and more to #5 ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1595", "user": "emusgrave", "root": "ROOT159", "reply_to": "COM1594", "timestamp": "2020-05-18T15:17:54Z", "text": "@DHowett-MSFT I see that you've mentioned this issue from other closed issues but you have not actually commented here regarding the problem or the intention to fix it. I was about to open a new report because this issue also doesn't capture the entire story. But instead I'll post some findings here and hope that you can shed some more light on what the plans are.\r\n\r\nFirst, the problem is not just that the console sessions are silently closed when the program automatically updates. I haven't been able to fully trace what set of circumstances causes this, but I've had processes just get orphaned. The only reason I even realize this is that when I go to re-open one of my command line processes, I see that the listening port is still in use and I can't open it. I've then had to go searching through TCPView and Process Explorer to find the orphaned process and kill it.\r\n\r\nSecond, I tried to circumvent all of this by installing the Terminal app via Chocolatey. However, it still gets updated via the Windows Store!? I'm not sure why that would happen if I did not install via the Store.\r\n\r\nAt the very least I would _LOVE_ an option to disable automatic updates. Another solution might be to tie _all_ updates to Terminal to the next Windows reboot cycle? But I think from your comments on other threads this is what you aren't able to do when distributing via the Store. \r\n\r\nI would also make the recommendation to just not distribute this application on the Windows Store. This is not really an ideal app for that delivery mechanism. This is a power user / developer targeted app, so I would think it would be distributed more like Visual Studio or Visual Studio Code, or even Power Toys.\r\n\r\nThanks for your teams work on this app. Unfortunately I am going to have to abandon it until this issue is fixed because I'm losing a lot of time and work every other week when an update is pushed and my long-running processes are lost.\r\n", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1596", "user": "DHowett", "root": "ROOT159", "reply_to": "COM1595", "timestamp": "2020-05-18T15:36:03Z", "text": "You've got the critical points down pat.\r\n\r\nFor right now, it's possible to extract the msixbundle (and the architecture-specific msix inside it) and run WindowsTerminal.exe directly. We're not intending on breaking this. \ud83e\udd1e ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1597", "user": "emusgrave", "root": "ROOT159", "reply_to": "COM1596", "timestamp": "2020-05-18T18:29:57Z", "text": "@DHowett Thank you for the quick response!\r\n\r\nI went ahead and uninstalled my existing copy of Terminal (thereby unlinking it from the Windows Store), and am now running it directly from the exe extracted from the package you referred to. Appears to work the same, although the version number in the about box is listed as 0.11.200512003-release1.0. \r\n\r\nHopefully this helps some others who are struggling with the automatic updates. I will keep an eye on the repo so that I can perform my own updates manually.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1598", "user": "sba923", "root": "ROOT159", "reply_to": "COM1597", "timestamp": "2020-07-27T19:42:52Z", "text": "> @DHowett Thank you for the quick response!\r\n> \r\n> I went ahead and uninstalled my existing copy of Terminal (thereby unlinking it from the Windows Store), and am now running it directly from the exe extracted from the package you referred to. Appears to work the same, although the version number in the about box is listed as 0.11.200512003-release1.0.\r\n> \r\n> Hopefully this helps some others who are struggling with the automatic updates. I will keep an eye on the repo so that I can perform my own updates manually.\r\n\r\nSo you did _not_ install from the msixbundle available from the 'Releases' page?\r\n\r\nThat's what I just did, and how Store reports the app is 'installed'... so I expect it will still be subject to (auto)updates. Correct?\r\n\r\nCan you please elaborate on how you got a runnable instance deployed without Store considering it's installed (and thus needs updating)?\r\n\r\nTIA", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1599", "user": "emusgrave", "root": "ROOT159", "reply_to": "COM1598", "timestamp": "2020-07-28T01:08:04Z", "text": "@sba923 You can \"unzip\" the msixbundle, and then just run the exe from there. I copied the folder to Program Files and added it to my PATH env for extra convenience.\r\n\r\nI have had no problems with auto-updates since doing it this way. I watch the github project for any releases that have fixes/features that I want.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15910", "user": "sba923", "root": "ROOT159", "reply_to": "COM1599", "timestamp": "2020-07-28T07:29:55Z", "text": "> @sba923 You can \"unzip\" the msixbundle, and then just run the exe from there. I copied the folder to Program Files and added it to my PATH env for extra convenience.\r\n> \r\n> I have had no problems with auto-updates since doing it this way. I watch the github project for any releases that have fixes/features that I want.\r\n\r\nThanks for the tip!\r\n\r\nI chose _not_ to add the folder to the PATH, because that's not absolutely required (and I have a theory where adding tons of app folders to the PATH would slow down the system...).\r\n\r\nSomething worth mentioning: uninstalling will delete ``%LOCALAPPDATA%\\Packages\\Microsoft.WindowsTerminal_8wekyb3d8bbwe\\LocalState`` where the ``settings.json`` file is located (I know, that's part of the \"good\" sandboxing idea beyond store app deployment), so you'll lose your settings if you don't make a copy first.\r\n\r\nIn the \"XCOPY-deployed\" instance, the ``settings.json`` file resides at ``%LOCALAPPDATA%\\Microsoft\\Windows Terminal``.\r\n\r\nHTH\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15911", "user": "jsejcksn", "root": "ROOT159", "reply_to": "COM15910", "timestamp": "2020-07-28T09:04:54Z", "text": "> I have a theory where adding tons of app folders to the PATH would slow down the system\r\n\r\nA bit of research can help you get the info you need in order to be able to perform the necessary tests to confirm/deny your theory so you can start acting on knowledge. Don't act on theories!\r\n\r\n  - [Bash PATH length restrictions](https://stackoverflow.com/a/4599911)\r\n  - [Duplicate entries in $PATH a problem?\r\n](https://unix.stackexchange.com/a/14898)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15912", "user": "sba923", "root": "ROOT159", "reply_to": "COM15911", "timestamp": "2020-07-28T09:37:16Z", "text": "> > I have a theory where adding tons of app folders to the PATH would slow down the system\r\n> \r\n> A bit of research can help you get the info you need in order to be able to perform the necessary tests to confirm/deny your theory so you can start acting on knowledge. Don't act on theories!\r\n> \r\n> * [Bash PATH length restrictions](https://stackoverflow.com/a/4599911)\r\n> * [Duplicate entries in $PATH a problem?\r\n>   ](https://unix.stackexchange.com/a/14898)\r\n\r\nI support your reasoning, but a simple model proves that the more folders you have on the PATH, and the more items therein, the more time it takes to search for a specified EXE or DLL.\r\n\r\nOf course, the actual measurable impact depends on how much optimization (e.g. caching) has been put into that search algorithm, and of the platform's performance.\r\n\r\nAnd that is context and OS-dependent (the articles you refer to pertain to searches done by the bash shell on Unix, my use case is the Windows APIs that rely on EXE/DLL searches on the PATH).\r\n\r\nMy plan is to start a discussion [there](https://msft.it/6013TWaxd,) hoping that some Microsoft people with knowledge about those internals will react to my \"theory.\"", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15913", "user": "RowdyChildren", "root": "ROOT159", "reply_to": "COM15912", "timestamp": "2021-02-13T20:39:58Z", "text": "Seeing this issue as well, its very annoying. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15914", "user": "aaroneg", "root": "ROOT159", "reply_to": "COM15913", "timestamp": "2021-02-14T04:48:48Z", "text": "What's the point of swooping in like a hawk to close other reports of this problem if this issue is just going to sit here, stale? ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15915", "user": "DHowett", "root": "ROOT159", "reply_to": "COM15914", "timestamp": "2021-02-14T04:50:47Z", "text": "@aaroneg because having six copies of an issue is harder on us, and harder to present to our leadership, than one issue with a robust single discussion thread in it? This issue isn\u2019t stale insomuch as it has to move at the speed of Windows, rather than the speed of our open-source project.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM15916", "user": "DHowett", "root": "ROOT159", "reply_to": "COM15915", "timestamp": "2021-02-14T04:52:46Z", "text": "Now: it seems like the discussion here _has_ reached its terminus, so there isn\u2019t value in leaving it unlocked for angry people to get their digs in. It\u2019s on our radar\u2013just as much as it has been since our first update\u2013and we only have as much sway with the store folks as we can get.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT160", "user": "trivikr", "root": "ROOT160", "reply_to": null, "timestamp": "2020-06-13T17:41:50Z", "text": "Rename default branch from \"master\" to \"main\" **Is your feature request related to a problem? Please describe.**\r Lot of software developers are discussing on twitter to rename default branches for their projects from \"master\" to \"main\" or equivalent https://twitter.com/search?q=master%20branch&src=typed_query\r \r The primary reason being master-slave an oppressive metaphor.\r \r **Describe the solution you'd like**\r Node.js core follows the trend to change the industry standard, and renames default branch from \"master\" to \"main\" or similar\r \r **Describe alternatives you've considered**\r Sticking with existing master branch name for the default\r \r EDIT: Updated \"renaming master to main\" to \"renaming default branch name from 'master' to 'main'\"", "meta": {"posReactions": "4", "negReactions": "16"}}
{"id": "COM1600", "user": "devsnek", "root": "ROOT160", "reply_to": "ROOT160", "timestamp": "2020-06-13T17:52:45Z", "text": "This is not a technically difficult task (https://www.hanselman.com/blog/EasilyRenameYourGitDefaultBranchFromMasterToMain.aspx) but it might break some things. I definitely think we should try to change it.", "meta": {"posReactions": "5", "negReactions": "2"}}
{"id": "COM1601", "user": "ronag", "root": "ROOT160", "reply_to": "COM1600", "timestamp": "2020-06-13T18:41:38Z", "text": "Does this mean we would have to change the cluster API (which includes master in its vocabulary) as well in a semver-major?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1602", "user": "Gallardo994", "root": "ROOT160", "reply_to": "COM1601", "timestamp": "2020-06-13T18:52:36Z", "text": "This is getting silly already. No way it makes any sense.\r\n\r\nUPD: How is this offtopic? Please stop bringing politics into development world. That's just mindblowingly silly.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1603", "user": "ghost", "root": "ROOT160", "reply_to": "COM1602", "timestamp": "2020-06-13T18:52:43Z", "text": "That is hilarious. From defacing nodejs.org with blm propaganda, to renaming master branch to avoid similarity with master-slave metaphor. What is the next requirement OpenJS will ask for? To remove the **test** directory to avoid similarity with **test**icles? Please keep technical aspects of the software free of politics and globalistic propaganda.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1604", "user": "devsnek", "root": "ROOT160", "reply_to": "COM1603", "timestamp": "2020-06-13T19:01:09Z", "text": "@ronag i don't think that cluster was brought up in this thread, though it has been discussed on other occasions.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1605", "user": "ronag", "root": "ROOT160", "reply_to": "COM1604", "timestamp": "2020-06-13T19:06:17Z", "text": "I'm -0 to the change itself. I don't think that changing it because it is \"industry standard\" is a valid argument, at least not yet. If we are changing it because we think it is a loaded/inappropriate word, then I think we should remove all occurrences to remain consistent with that decision.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1606", "user": "benjamingr", "root": "ROOT160", "reply_to": "COM1605", "timestamp": "2020-06-13T19:20:15Z", "text": "I don't feel like this is something people have actually complained about. When we've made these changes in the past (for example in child_worker.suicide) it was guided by someone acting in good faith feeling strongly about the terminology. \r\n\r\nIf someone from the project's base does feel strongly about it - I suggest we rename it, though `master` is the default git branch name so I would caution we pick our battles.\r\n\r\nI vote we:\r\n - Don't change the name from master to something else currently.\r\n - Change it when a contributor/collaborator feels strongly enough about this.\r\n\r\nOf course, if you @trivikr personally feel strongly about this then I support you :]", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM1607", "user": "trivikr", "root": "ROOT160", "reply_to": "COM1606", "timestamp": "2020-06-13T19:28:22Z", "text": "> Of course, if you @trivikr personally feel strongly about this then I support you :]\r\n\r\nI don't feel strongly against using master branch name. I proposed it as I plan to follow it in my personal projects and work projects, and wanted to ask Node.js community.\r\n\r\nShould we add this to tsc-agenda?\r\n\r\n> though `master` is the default git branch name so I would caution we pick our battles.\r\n\r\nIs there an equivalent ask in git repo?\r\nIf not, we should create one.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1608", "user": "benjamingr", "root": "ROOT160", "reply_to": "COM1607", "timestamp": "2020-06-13T19:28:42Z", "text": "Also, to all the people making the drive by comments: please keep discussion civil and remember Node.js has a [code of conduct](https://github.com/nodejs/admin/blob/master/CODE_OF_CONDUCT.md). If you can't be polite here you really don't have to comment. It's fine to either support or object to the proposed change (or any proposed change) as long as you are [civil](https://github.com/nodejs/admin/blob/master/CODE_OF_CONDUCT.md#our-standards) - **we do not tolerate abuse** towards the project and its members here.\r\n\r\nTo collaborators: kind reminder that you are [allowed to ban users](https://github.com/nodejs/admin/blob/master/Moderation-Policy.md#non-collaborator-posts) that make these sort of comments and to hide said comments - but please update the project (as explained there) with what actions you took so that any moderation actions taken are done in full transparency.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1609", "user": "benjamingr", "root": "ROOT160", "reply_to": "COM1608", "timestamp": "2020-06-13T19:33:23Z", "text": "> Is there an equivalent ask in git repo?\r\n\r\nI'm not sure where the git repo is - but I recommend trying the mailing list and asking there https://git-scm.com/community \r\n\r\nI think \"doing whatever git does and bringing the issue to their attention\" is a viable strategy - but again, I don't feel particularly strongly about the use of \"master\" and if someone else does - sure.\r\n\r\n> Should we add this to tsc-agenda?\r\n\r\nI'm not entirely sure why? ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16010", "user": "trivikr", "root": "ROOT160", "reply_to": "COM1609", "timestamp": "2020-06-13T19:36:54Z", "text": "> > Should we add this to tsc-agenda?\r\n>\r\n> I'm not entirely sure why?\r\n\r\nTo let tsc make a call on this request.\r\n\r\nOther option would be to keep this issue open for a week or so, and see if it gathers more feedback or support.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16011", "user": "benjamingr", "root": "ROOT160", "reply_to": "COM16010", "timestamp": "2020-06-13T19:44:39Z", "text": "> To let tsc make a call on this request.\r\n\r\nAs far as I understand it that's not how our governance works. Any collaborator may add the `tsc-agenda` label for an issue so it gets TSC eyes on it - but that should only be done if consensus seeking fails. It's an escape hatch for when we need to _force a vote_ which is pretty rare. At least that is my understanding of [the process](https://github.com/nodejs/node/blob/master/GOVERNANCE.md).\r\n\r\nSo far everyone here seems to be pretty in sync (no one is opposed but no one is particularly in favor). We're not even in disagreement \ud83d\ude05", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM16012", "user": "trivikr", "root": "ROOT160", "reply_to": "COM16011", "timestamp": "2020-06-13T20:04:38Z", "text": "> I'm not sure where the git repo is - but I recommend trying the mailing list and asking there git-scm.com/community\r\n\r\nI've sent an email to Git Community mailing list, and will update here once they come up with a decision.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16013", "user": "ljharb", "root": "ROOT160", "reply_to": "COM16012", "timestamp": "2020-06-13T20:14:47Z", "text": "Bear in mind that URLs linking to `master` will not redirect to the new default branch name (and for repos where it matters, which isn't this one, github-pages only works on the default branch when it's named `master`). It may be worth waiting for Github to fix these discrepancies before making the switch.\r\n\r\n(to be clear; i'm in favor of making the change, and \"main\" seems as good as anything else, but the disruption caused by Github's incomplete support for a non-master default branch are significant)", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM16014", "user": "jasnell", "root": "ROOT160", "reply_to": "COM16013", "timestamp": "2020-06-13T20:27:02Z", "text": "+1 to main but I do want to see what lead GitHub takes in making this easier", "meta": {"posReactions": "2", "negReactions": "1"}}
{"id": "COM16015", "user": "MylesBorins", "root": "ROOT160", "reply_to": "COM16014", "timestamp": "2020-06-13T20:27:30Z", "text": "I personally feel very strongly that we should change this.\r\n\r\n+1 to `main`", "meta": {"posReactions": "3", "negReactions": "1"}}
{"id": "COM16016", "user": "AshCripps", "root": "ROOT160", "reply_to": "COM16015", "timestamp": "2020-06-13T20:32:39Z", "text": "I would be -1 untill a plan is drawn for the changes. This could cause a lot of issues with our build ci which would need to be accounted for.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16017", "user": "benjamingr", "root": "ROOT160", "reply_to": "COM16016", "timestamp": "2020-06-13T20:37:21Z", "text": "Ok, it looks like there are people in favor in the org who feel strongly that we should change this. So far no objections and everyone in the conversation is +0 -0 or +1.\r\n\r\nDoes anyone object to changing this (just the main branch name from `master` to `main`)?\r\n\r\nIt looks like it's [not particularly hard](https://github.com/nodejs/node/issues/33864#issuecomment-643656288) technically (+ an update to the collaborator guide and policy). We probably need to address [the links](https://github.com/nodejs/node/issues/33864#issuecomment-643672588) as well.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16018", "user": "ronag", "root": "ROOT160", "reply_to": "COM16017", "timestamp": "2020-06-13T20:39:17Z", "text": "> So far no objections and everyone in the conversation is +0 -0 or +1.\r\n\r\nWhat about https://github.com/nodejs/node/issues/33864#issuecomment-643674646?\r\n\r\nAlso, I think GitHub might pick `trunk` instead of `main`. https://github.com/cli/cli/issues/929...\r\n\r\n> Does anyone object to changing this (just the main branch name from master to main)?\r\n\r\nI don't object... but I don't think it's a good idea to rush this...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16019", "user": "MylesBorins", "root": "ROOT160", "reply_to": "COM16018", "timestamp": "2020-06-13T20:40:58Z", "text": "Fwiw there is quite a lot of work for us to do in order to make sure we do this in a way that is not disruptive.\r\n\r\nTo @AshCripps point, we definitely need to do a large audit and preparation before moving forward.\r\n\r\nI was putting together some notes yesterday outlining steps to take and what to consider before making a change like this\r\n\r\nI'd like to suggest that we pause discussion until Monday and I can come back with a suggestion of what we should audit and steps to follow to do this in a way that would minimize disruption", "meta": {"posReactions": "4", "negReactions": "0"}}
{"id": "COM16020", "user": "benjamingr", "root": "ROOT160", "reply_to": "COM16019", "timestamp": "2020-06-13T20:42:13Z", "text": "@ronag that message was posted after I started writing mine so I did not see it. Sorry for the (timing) confusion. Fwiw https://github.com/nodejs/node/issues/33864#issuecomment-643674646 isn't a conceptual -1 it's a -1 until a plan is drawn for how we make the changes. I thought that not making the change quickly without discussing this or laying out how (clearly) is a given.", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM16021", "user": "ARitz-Cracker", "root": "ROOT160", "reply_to": "COM16020", "timestamp": "2020-06-13T22:38:46Z", "text": "Needlessly censoring words does nothing to resolve the social issues surrounding them. The reasoning behind this is the same used when changing the gun emoji to a squirt gun. But in the end, such efforts only take away words and symbols we can use to easily describe concepts, such as the hierarchical and control structures we work with every day. It's destructive at worst and pointless virtue signalling at best.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM16022", "user": "ARitz-Cracker", "root": "ROOT160", "reply_to": "COM16021", "timestamp": "2020-06-13T22:44:46Z", "text": "Anyway, -1 to this. Not worth the effort.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16023", "user": "mscdex", "root": "ROOT160", "reply_to": "COM16022", "timestamp": "2020-06-13T22:52:06Z", "text": "I am -1 on renaming/changing the branch.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16024", "user": "gabrieledarrigo", "root": "ROOT160", "reply_to": "COM16023", "timestamp": "2020-06-13T23:32:41Z", "text": "-1 on this.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16025", "user": "jasnell", "root": "ROOT160", "reply_to": "COM16024", "timestamp": "2020-06-14T00:26:59Z", "text": "Putting this on the tsc agenda for discussion", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16026", "user": "gireeshpunathil", "root": "ROOT160", "reply_to": "COM16025", "timestamp": "2020-06-14T10:28:52Z", "text": "-1 on renaming the branch", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16027", "user": "benjamingr", "root": "ROOT160", "reply_to": "COM16026", "timestamp": "2020-06-14T10:43:43Z", "text": "I would recommend we escalate this (to a vote for example) when:\r\n - We have a clear plan on how to make this change addressing the raised issues (GH links, build infrastructure etc).\r\n - We have an individual or group willing to champion those changes.\r\n\r\nCan either of the collaborators -1ing (@gireeshpunathil / @mscdex ) speak up regarding what in particular they are objecting to? (The process of changing it? the name `main` itself?)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16028", "user": "benjamingr", "root": "ROOT160", "reply_to": "COM16027", "timestamp": "2020-06-14T10:47:35Z", "text": "Also, this issue is locked because it has received a large number of abuse comments. Like the website change - changes with this flavor tend to get a lot of attention.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16029", "user": "bnoordhuis", "root": "ROOT160", "reply_to": "COM16028", "timestamp": "2020-06-14T11:02:20Z", "text": "> I can come back with a suggestion of what we should audit and steps to follow to do this in a way that would minimize disruption\r\n\r\n@MylesBorins Also think about how to roll back when things go wrong. Auditing Jenkins jobs is the kind of mind-numbing tedium that makes human error more likely than not.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT161", "user": "uncleramsay", "root": "ROOT161", "reply_to": null, "timestamp": "2019-10-17T10:23:50Z", "text": "no-git-push not working after 3.18.0 ```\r 15:41:24 $ lerna publish prerelease --canary --exact --yes --no-git-tag-version --no-git-push --no-git-reset --no-changelog --dist-tag=pr-157 --preid=alpha-52b7893\r 15:41:24 ERR! lerna Unknown arguments: git-push, gitPush\r 15:41:24 error Command failed with exit code 1.\r ```\r \r ## Expected Behavior\r Prior to 3.18.0, this does not error out, and publishes without pushing to git.\r \r ## Current Behavior\r Errors out as in above example\r \r ## Steps to Reproduce (for bugs)\r \r <details><summary>lerna.json</summary><p>\r <!-- browsers demand the next line be empty -->\r \r ```json\r {\r   \"version\": \"independent\",\r   \"npmClient\": \"yarn\",\r   \"useWorkspaces\": true,\r   \"conventionalCommits\": true,\r   \"registry\": <enterprise artifactory url>,\r   \"verifyAccess\": false,\r   \"verifyRegistry\": false,\r }\r ```\r </p></details>\r \r ## Context\r I'm currently unable to publish alphas without locking to a lower version of lerna.\r \r ## Your Environment\r Running on jenkins\r \r | Executable | Version |\r | ---: | :--- |\r | `lerna --version` | 3.18.1 |\r | `npm --version`  | 6.10.1 |\r | `yarn --version` | 1.15.2 |\r | `node --version` | 8.9.0 |\r \r | OS | Version |\r | --- | --- |\r | NAME | VERSION |\r <!-- For example:\r | Red Hat Enterprise Linux | 7 |\r -->\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1610", "user": "tkissing-work", "root": "ROOT161", "reply_to": "ROOT161", "timestamp": "2019-10-17T21:32:58Z", "text": "Other options are also affected:\r\n\r\n> ERR! lerna Unknown arguments: git-reset, gitReset, verify-access, verifyAccess, npm-client, npmClient", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1611", "user": "evocateur", "root": "ROOT161", "reply_to": "COM1610", "timestamp": "2019-10-18T16:50:56Z", "text": "@uncleramsay There is no `--no-git-push` option, it's called [`--no-push`](https://github.com/lerna/lerna/blob/master/commands/version/README.md#--no-push).\r\n\r\n@tkissing-work Which command elicited that error?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1612", "user": "uncleramsay", "root": "ROOT161", "reply_to": "COM1611", "timestamp": "2019-10-18T17:50:31Z", "text": "That's very odd. Prior to 3.18.0 --no-git-push definitely works", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1613", "user": "tkissing-work", "root": "ROOT161", "reply_to": "COM1612", "timestamp": "2019-10-18T17:52:46Z", "text": "`lerna version --exact --force-publish --loglevel=verbose --no-git-reset --no-push --no-verify-access --npm-client=npm --yes --no-git-tag-version --preid=20191018175119.master.gitish-7d39735d40 prerelease`\r\n\r\nWorks fine with 3.17.0, breaks with 3.18.0 and 3.18.1", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1614", "user": "mlavina", "root": "ROOT161", "reply_to": "COM1613", "timestamp": "2019-10-21T12:40:18Z", "text": "Hey @evocateur thanks for the quick response, but this still feels like something is wrong. If @uncleramsay had the wrong command and it was working fine and then all they upgraded was to `3.18` wouldn't that same wrong command still work.\r\n\r\nSure it would git push when he didn't want it to, but clearly it was working before. Unless, Lerna added some better error checking and this is an error that the command specified doesn't exist and it just didn't error out before, but that's probably still a break if bad commands worked before. \r\n\r\nEDIT -\r\n\r\nRemoving the `git` in `--no-git-push` fixed the above command, but I still think it might be worth having somewhere in the release notes that bad commands will now error out instead of just being ignored. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1615", "user": "evocateur", "root": "ROOT161", "reply_to": "COM1614", "timestamp": "2019-10-21T17:25:32Z", "text": "@tkissing-work \r\n* `--npm-client` only applies to `lerna bootstrap` and `lerna run`.\r\n* `--no-git-reset` and `--no-verify-access` only apply to `lerna publish`, not `lerna version`.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1616", "user": "evocateur", "root": "ROOT161", "reply_to": "COM1615", "timestamp": "2019-10-21T17:25:37Z", "text": "@mlavina Yargs has been configured with [`.strict()`](https://github.com/yargs/yargs/blob/master/docs/api.md#strictenabledtrue) for [almost two years now](https://github.com/lerna/lerna/blob/0687939004910186a7f2d78373bca3701d84fa5a/src/cli.js#L41). It appears Yargs 14 fixes some bugs that were previously obscuring it.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1617", "user": "tkissing-work", "root": "ROOT161", "reply_to": "COM1616", "timestamp": "2019-10-21T21:08:11Z", "text": "For every version prior to 3.18.x \"only applies to\" meant \"is ignored otherwise\". Now it means \"breaks your build\". That's not SemVer minor. I don't even care if that is directly in your code or was pulled in via a dependency bump. Minor versions of lerna should not break my build.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1618", "user": "evocateur", "root": "ROOT161", "reply_to": "COM1617", "timestamp": "2019-10-21T21:19:04Z", "text": "Your build had silent errors before. I'd say that's much worse than a temporarily broken build.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1619", "user": "tkissing-work", "root": "ROOT161", "reply_to": "COM1618", "timestamp": "2019-10-21T21:20:48Z", "text": "my build updated the package.json files and a later `lerna publish` pushed them to npm. That's exactly what I expected it to do. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16110", "user": "tkissing-work", "root": "ROOT161", "reply_to": "COM1619", "timestamp": "2019-10-21T21:27:42Z", "text": "And SemVer doesn't care if breaking my build now is \"better\" than silent errors, it only cares about compatibility. lerna 3.18.x is not compatible to 3.17.x.\r\nIf lerna does not want to do SemVer, than at the very least you should put a warning into your readme and possibly switch to version numbers that do not suggest SemVer, so consumers know not to let renovate auto-update this dependency.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM16111", "user": "evocateur", "root": "ROOT161", "reply_to": "COM16110", "timestamp": "2019-10-21T21:35:51Z", "text": "I'm sorry my fuckups have caused you pain. Please stop berating me, now.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16112", "user": "mlavina", "root": "ROOT161", "reply_to": "COM16111", "timestamp": "2019-10-21T22:14:37Z", "text": "@tkissing-work while I agree in principle clearly this was not @evocateur fault but an underlying package.\r\n\r\nIt's not fair to put the blame on him. And even if you do feel there is responsibility, you should not be so rude. \r\n\r\nRelax, I get the frustration, but let's be civil. Let's not make the person who runs a massive open source project almost by himself job harder than it needs to be. ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM16113", "user": "tkissing-work", "root": "ROOT161", "reply_to": "COM16112", "timestamp": "2019-10-22T19:56:42Z", "text": "I was quite polite until I was asked to be thankful for my builds breaking without warning. Unintended breaking changes happen, but blaming it on the consumers is not an appropriate response. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16114", "user": "evocateur", "root": "ROOT161", "reply_to": "COM16113", "timestamp": "2019-10-25T22:06:59Z", "text": "> [...] until I was asked to be thankful for my builds breaking without warning.\r\n\r\nWhen exactly did I say that, @tkissing-work?\r\n\r\n* If you're not using a lockfile, then the only one to blame for your builds breaking \"without warning\" is yourself.\r\n* If you _are_ using a lockfile, then it was an explicit change you made (upgrading `lerna`) that caused the breakage, not a dastardly plan on my part to cause you pain.\r\n\r\nThe fact remains that the long-standing _intention_ of `lerna`'s argument parsing was to be strict, throwing errors when unrecognized options were passed. There was a bug in yargs 12 that silently perverted this intention, and yargs 14 fixed it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16115", "user": "tkissing-work", "root": "ROOT161", "reply_to": "COM16114", "timestamp": "2019-10-29T16:49:12Z", "text": "> Your build had silent errors before. I'd say that's much worse than a temporarily broken build.\r\n\r\n\"I'd say that's much worse than\" sounds like you did me a favor, but all I got was extra work.\r\n\r\n> If you are using a lockfile, then it was an explicit change you made (upgrading lerna) that caused the breakage\r\n\r\nThe whole point of SemVer is that this \"explicit change\" can be made by a machine. The author of a library categorized upgrades into breaking and non-breaking. Software like renovate can then pick certain updates and apply them automatically based on this categorization.\r\n\r\n> If you're not using a lockfile, then the only one to blame for your builds breaking \"without warning\" is yourself.\r\n\r\nThe condescending attitude aside, a lockfile alone does not help here. Updating lerna necessarily means my lockfile changes. My direct usage of yargs was \"protected\" by the lockfile, because the selector `yargs@^12.0.1` still gave me 12.0.5 at `node_modules/yargs/`. But without forced hoisting (and thus forced conflict resolutions) that has no impact on what is in `node_modules/lerna/node_modules/yargs/`\r\n\r\n> not a dastardly plan on my part to cause you pain\r\n\r\nI am not saying you planned this.\r\nYour update broke something for some consumers without being SemVer major. That is unfortunate, but it's a mistake that can happen. \r\nHowever, your reaction to the mistake being brought to your intention is somewhere between condescending and hostile.\r\nYou could have said \"sorry, this was not intended, let me roll back and re-release as 4.0.0\" and it would be fine.\r\nYou could have said \"sorry, I didn't consider that the yargs API practically becomes part of the lerna API, I will make sure that future SemVer major updates of yargs only happen in SemVer major updates of lerna\"\r\nInstead you said that it's good that your mistake broke my build.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT162", "user": "varun-av", "root": "ROOT162", "reply_to": null, "timestamp": "2020-07-04T12:52:10Z", "text": "Nice, the only notable contribution you've ever made anywhere on Github is making sure everyone at Google knows you're a racist. Nice, the only notable contribution you've ever made anywhere on Github is making sure everyone at Google knows you're a racist.\r \r _Originally posted by @ncrawlins in https://github.com/angular/angular/issues/37771#issuecomment-650169764_", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1620", "user": "varun-av", "root": "ROOT162", "reply_to": "ROOT162", "timestamp": "2020-07-04T12:55:38Z", "text": "Why are you using this platform for displaying your political agenda. You have other platforms to do that. No one wants this here. Stop whining about that and remove the BLM from the site. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1621", "user": "gkalpak", "root": "ROOT162", "reply_to": "COM1620", "timestamp": "2020-07-04T13:00:40Z", "text": "See https://github.com/angular/angular/issues/37771#issuecomment-650294204.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1622", "user": "petebacondarwin", "root": "ROOT162", "reply_to": "COM1621", "timestamp": "2020-07-04T13:29:46Z", "text": "Note that @varun-av only created the account to post this.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT163", "user": "veganaize", "root": "ROOT163", "reply_to": null, "timestamp": "2019-01-05T00:10:49Z", "text": "UTF-8 no BOM Specify that no byte order mark should be used (when applicable) for source files.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1630", "user": "googlebot", "root": "ROOT163", "reply_to": "ROOT163", "timestamp": "2019-01-05T00:10:52Z", "text": "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1631", "user": "veganaize", "root": "ROOT163", "reply_to": "COM1630", "timestamp": "2019-01-06T20:30:02Z", "text": "I signed it!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1632", "user": "googlebot", "root": "ROOT163", "reply_to": "COM1631", "timestamp": "2019-01-06T20:30:05Z", "text": "CLAs look good, thanks!\n\n<!-- ok -->", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1633", "user": "veganaize", "root": "ROOT163", "reply_to": "COM1632", "timestamp": "2020-05-21T00:07:03Z", "text": "The purpose of this commit is to avoid potential problems associated with BOMs, since they have been known to halt some script interpreters and compilers in their tracks.\r\n\r\nPersonally speaking, I have never experienced any problems by omitting the BOM.  But I write/code primarily in English.  If non-English writing/coding doesn't necessitate a BOM then it seems that the appropriate option would be to forgo its use, by default.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1634", "user": "dimo414", "root": "ROOT163", "reply_to": "COM1633", "timestamp": "2020-05-21T01:27:36Z", "text": "This doesn't really seem worth stipulating; the [BOM has no meaning for UTF-8](https://en.wikipedia.org/wiki/Byte_order_mark#UTF-8):\r\n\r\n> The Unicode Standard permits the BOM in UTF-8,[3] but does not require or recommend its use.[4] Byte order has no meaning in UTF-8,[5] so its only use in UTF-8 is to signal at the start that the text stream is encoded in UTF-8, or that it was converted to UTF-8 from a stream that contained an optional BOM. The standard also does not recommend removing a BOM when it is there, so that round-tripping between encodings does not lose information, and so that code that relies on it continues to work.\r\n\r\nWhat's the motivation for calling this out? Interpreters that don't handle BOMs sound like they aren't properly implementing the UTF-8 spec and should be fixed.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1635", "user": "veganaize", "root": "ROOT163", "reply_to": "COM1634", "timestamp": "2020-05-21T03:40:23Z", "text": "The reason is that back-compatibility with ASCII is a major benefit of UTF-8.\r\n\r\nFor instance a Windows `.bat`/batch file saved as UTF-8 + BOM will crash when run because the command interpreter doesn't understand the BOM (ie. `\u2229\u2557\u2510`) prefix -- It's just garbage, which also displays in some text editors; which could easily confuse one as to whether to let this _mysterious garbage_ persist, or should they remove it?\r\n\r\nThe following Unicode laced `.bat` file, saved as UTF-8, will work properly only when saved _**without**_ a BOM:\r\n```\r\necho \"\u263a \u0141\" >textfile.txt\r\n```\r\n\r\nAs the standard itself states, it neither requires nor recommends the use of a BOM, with UTF-8.\r\n\r\nThe so-called \"round-tripping\" scenario is really only appropriate when dealing with (pre-existing / external) text files, input into a program --not to the (Google) source code to be executed.\r\n\r\nSo ideally one shouldn't erase existing BOMs, willy-nilly, because they may be processed by another system which, against the standard's recommendation, expects their presence.  However, when fresh source files are created, the BOM is probably best avoided, in accordance with the Unicode/UTF-8 recommendation.\r\n\r\nIt follows the programming principle: \"Be liberal in what you accept and conservative in what you send.\"\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1636", "user": "dimo414", "root": "ROOT163", "reply_to": "COM1635", "timestamp": "2020-05-21T06:40:48Z", "text": "I don't think this is worth adding. As you say, the UTF-8 spec already discourages using a BOM when feasible, and I don't see any reason why it being a Java source file introduces further complexity that merits calling this out in the style guide. I'm not certain I've ever even seen a UTF-8 file with a BOM...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1637", "user": "veganaize", "root": "ROOT163", "reply_to": "COM1636", "timestamp": "2020-05-21T12:30:45Z", "text": "If it's worth stating that the file should be in UTF-8 format then it's worth mentioning the avoidance of a BOM.\r\n\r\nBut that's just my little ol' opinion.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1638", "user": "veganaize", "root": "ROOT163", "reply_to": "COM1637", "timestamp": "2020-05-21T16:30:55Z", "text": "![utf-8_bom](https://user-images.githubusercontent.com/7102064/82581650-bdf1a380-9b45-11ea-8d43-d772c79befde.png)\r\n[ What if my editor is dumb and pre-checks the BOM box, for UTF-8 files, or just includes it without giving me any option? ]", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1639", "user": "dimo414", "root": "ROOT163", "reply_to": "COM1638", "timestamp": "2020-05-21T20:45:44Z", "text": "It's not the goal of the Java Style Guide to address all possible configuration issues; we require Java source code to be UTF-8 for numerous reasons, but the presence or absence of a BOM is not something we need to make a ruling on. Leave it off when possible, as the UTF-8 spec already says.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16310", "user": "veganaize", "root": "ROOT163", "reply_to": "COM1639", "timestamp": "2020-05-21T21:11:52Z", "text": "So as long as everyone reads through at least the first 39 pages of the Unicode standard then there shouldn't be any problem.  Why would anyone even consider using `.BAT` files to automate Java code compilation or execution?  I'm such an idiot.  I'm so sorry for wasting your precious time with a totally realistic scenario; and providing examples to support it.\r\n\r\nMeanwhile, you've provided zero evidence to support your claim, which is based solely on your personal experience.  The Wikipedia snippet, a somewhat pathetic and non-authoritative source, in all honesty, actually supports my argument.\r\n\r\nIf I ever make a contribution to Google I will be sure to include that BOM.\r\n\r\nIt's no wonder that even Google's own engineers could care less about the company's style guides.\r\n\r\nAnd here I'd thought that Google workers were above mansplaining.  Stupid me.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16311", "user": "dimo414", "root": "ROOT163", "reply_to": "COM16310", "timestamp": "2020-05-22T01:02:15Z", "text": "Hi veganaize, first, let me say thank you for sending this PR; I should have done so in an earlier comment. Rejecting the PR is in no way a statement about you, nor your qualifications. Although it's true that Google's public style guides are under-curated (a situation we all lament, but no one has stepped up to address) we care very deeply about the contents of our style guides, and therefore are very conservative in what we add to it. My intent here was to bring closure to this issue, since it had unfortunately sat unaddressed for some time.\r\n\r\nYou are absolutely right that there are situations where a BOM can matter, and it is reasonable to discourage their use. In our experience at Google this has not been a major issue (admittedly, most internal development happens on Linux, so issues related to `.bat` scripting are indeed something we don't typically run into). Looking into historical internal discussions around BOMs affecting Google Java developers I can find very little, and nothing related to BOMs in the `.java` source files themselves. None of which invalidates your concern, but in our opinion it doesn't rise to a level of severity to merit calling out in the Style Guide. Many best practices are intentionally not included in the guide simply because we don't want to make a ruling we don't have to. We trust teams to identify their own best practices where we don't make stipulations.\r\n\r\nOf note, this doesn't appear to be a Java-specific issue, and I notice only the HTML/CSS guide makes any mention of it. Perhaps we should consistently discourage BOMs across all our style guides, but I don't believe it's necessary to make the Java guide an outlier in this regard.\r\n\r\n> If I ever make a contribution to Google I will be sure to include that BOM.\r\n\r\nI would ask that you do so with good-faith, but *please do* include a BOM if you believe it is relevant. We put a lot of faith in our tooling, and count on developers both internally and externally to help catch places where our tooling falls short. If a BOM breaks something we rely on, we will want to fix it. You might even [get paid](https://www.google.com/about/appsecurity/reward-program/) if you are able to find an exploit related to mishandling of BOMs.\r\n\r\n> And here I'd thought that Google workers were above mansplaining. Stupid me.\r\n\r\nOne of the things I have deeply, deeply valued about my time at Google has been the candid and open discussions around issues of identity, gender inequality, and respect. We continue to fall short in many ways, but I am proud of the effort my peers have made to create a culture that is welcoming and inclusive. I don't believe anything I've said could fairly be labeled mansplaining, but I am sorry that I was curt. Again, thank you for raising this issue.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT164", "user": "votdev", "root": "ROOT164", "reply_to": null, "timestamp": "2019-09-17T08:58:08Z", "text": "mount.mounted does not handle blanks properly Currently it is not possible to mount a filesystem to a mount point that contains blanks.\r \r There are many problems in the ``states.mount.mounted`` code path, e.g. the mount command arguments are not quoted in the ``modules.mount.mount`` function, see \r https://github.com/saltstack/salt/blob/develop/salt/modules/mount.py#L1237. \r \r Code should look like this IMO:\r ```\r cmd = 'mount {0} {1} {2} '.format(args, device, shlex.quote(name))\r ```\r But this will fix only a small piece of the whole problem.\r \r Another one is that ``states.mount.mounted`` does not detect correctly that the filesystem might be mounted already, i think it's because the key in the active table is not unquoted, so a comparison between\r ``/srv/dev-disk-by-label-My\\040Passport\\040Blue`` and the specified ``/srv/dev-disk-by-label-My Passport Blue`` fails.\r \r To me it looks like the whole mount state and module is not able to handle blanks in device names and mount points properly.\r \r Example SLS:\r ```\r mount_fs_with_label:\r   mount.mounted:\r     - name: \"/srv/dev-disk-by-label-My Passport Blue\"\r     - device: \"/dev/disk/by-label/My\\\\x20Passport\\\\x20Blue\"\r     - fstype: ext4\r     - mkmnt: True\r     - persist: False\r     - mount: True\r ```\r \r Result:\r ```\r           ID: mount_fs_with_label\r     Function: mount.mounted\r         Name: /srv/dev-disk-by-label-My Passport Blue\r       Result: False\r      Comment: mount: bad usage\r               Try 'mount --help' for more information.\r      Started: 08:31:10.286521\r     Duration: 181.307 ms\r      Changes: \r ```\r \r ```\r # salt-call mount.active\r ...\r  /srv/dev-disk-by-label-My\\040Passport\\040Blue:\r         ----------\r         alt_device:\r             None\r         device:\r             /dev/sda1\r         fstype:\r             ext4\r         opts:\r             - rw\r             - noexec\r             - relatime\r             - jqfmt=vfsv0\r             - usrjquota=aquota.user\r             - grpjquota=aquota.group\r ...\r ```\r \r ```\r # ls -alh /dev/disk/by-label/\r total 0\r drwxr-xr-x 2 root root  60 Sep 17 08:29  .\r drwxr-xr-x 7 root root 140 Sep 17 08:29  ..\r lrwxrwxrwx 1 root root  10 Sep 17 08:29 'My\\x20Passport\\x20Blue' -> ../../sda1\r ```\r \r ```\r # ls -alh /srv\r total 28K\r drwxr-xr-x  7 root root    4.0K Sep 17 08:07  .\r drwxr-xr-x 21 root root    4.0K Sep 16 16:07  ..\r drwxr-xr-x  4 root root    4.0K Sep 13 13:40  dev-disk-by-id-scsi-0QEMU_QEMU_HARDDISK_drive-scsi0-0-2-part1\r drwxr-xr-x  2 root root    4.0K Sep 16 16:11 'dev-disk-by-label-My Passport Blue'\r drwxr-xr-x  2 ftp  nogroup 4.0K Sep 10 14:23  ftp\r drwxr-xr-x  3 root root    4.0K Sep 16 16:07  pillar\r drwxr-xr-x  5 root root    4.0K Sep 16 16:07  salt\r ```\r \r ```\r # cat /etc/fstab\r proc /proc proc defaults 0 0\r UUID=90ee6298-385f-4841-bfdc-8b1e0e0ae5c1 / ext4 errors=remount-ro 0 1\r # >>> [openmediavault]\r /dev/disk/by-label/My\\x20Passport\\x20Blue\t\t/srv/dev-disk-by-label-My\\040Passport\\040Blue\text4\tdefaults,nofail,user_xattr,noexec,usrjquota=aquota.user,grpjquota=aquota.group,jqfmt=vfsv0,acl\t0 2\r # <<< [openmediavault]\r ```\r \r ```\r # cat /proc/self/mountinfo\r ...\r 265 25 8:1 / /srv/dev-disk-by-label-My\\040Passport\\040Blue rw,noexec,relatime shared:148 - ext4 /dev/sda1 rw,jqfmt=vfsv0,usrjquota=aquota.user,grpjquota=aquota.group\r ...\r ```\r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1640", "user": "the-Arioch", "root": "ROOT164", "reply_to": "ROOT164", "timestamp": "2021-03-28T04:34:34Z", "text": "Hello, @votdev \r\n\r\nI am trying to build myself home NAS with old Atom mini-ITX board... So i install OMV5, i plug in dad's old NTFS drive... and here we go...\r\n\r\nFrankly, i wish Salt guys put the comments inside this source, listing all the bugs related to this module. So any hacker which for whatever reason would change it - would be instantly notifie on old pending bugs.\r\n\r\nSalt seems extremely fragile here, probably no one else except for OMV5 uses it for partitions. Maybe OMV6 could do it outside Salt? Like good old UDEV rules or anything. I mean, before Salt porject might decide to drop this functionality that almost no one use, instead of burden of maintaining it for OMV5 alone....\r\n\r\nWell, ranting aside, i am rather puzzled with your _device: \"/dev/disk/by-label/My\\\\x20Passport\\\\x20Blue\"_\r\nWhere do you even get this hex substitution from???\r\n\r\nThing is, the whole mounting escaping is one uber-ancient legacy mess. Putting it here so maybe someone would use it. I spent like 3 hours googling around and experimenting with Python that i never used before. Tryied to google some standard about Posix/Linux/bash filename mangling/escaping.... and then Python module to undo it. To no avail.\r\n\r\nOkay, so, to document it down.\r\n\r\n- mtab/fstab and friends is one-of-a-kind ancient mess.\r\n- it started with ancient BSD (not FreeBSD) function strunvis, which behaviour  not documented. Probably that was OS-specific function (a la virtual methods). http://manpages.org/strunvis/3\r\n- when Linux was mimicking good old BSd it only made ad hoc substitutions for 4 specific chars. There is no any systematic/generic pattern at all.\r\n\r\n```\r\nstatic inline void mangle(struct seq_file *m, const char *s)\r\n{\r\n\tseq_escape(m, s, \" \\t\\n\\\\\");\r\n}\r\n```\r\nhttps://elixir.bootlin.com/linux/latest/source/fs/proc_namespace.c#L84\r\n\r\n```\r\n\t\t\t\tR(\"\\\\\", '\\\\'),\r\n\t\t\t\tR(\"011\", '\\t'),\r\n\t\t\t\tR(\"012\", '\\n'),\r\n\t\t\t\tR(\"040\", ' '),\r\n\t\t\t\tR(\"134\", '\\\\')\r\n```\r\nhttps://sources.debian.org/src/sysvinit/2.96-6/src/fstab-decode.c/\r\n\r\nSo, whatever comes from Linux mounts information - should be de-mangled for those four special cases.\r\nEvery single space-separated column of every single line.\r\nUgly, and undocumented, but that is what it is. And, frankly, it is not that hard...\r\n\r\nBUT, why do you want to compare with some arbitrary hex-escaped string? what can be a real use-case for that???\r\nLinux kernel just does not have hex-escaping code for disk mounts.\r\n\r\nNow, to be frank, even this would NOT be enough, because i can have multiple disks with the same partition label. Like many USB thumb drives with \"DATA\" partition. I can even have several partitions with the same name on singe disk!\r\n\r\nAgain, it can be fixed by detecting collisions and adding extra data, like counters or GUID or whatever, but...\r\n\r\nWhat gonna OMV do if OMV's user has two drives with partitions having same labels, and then he hotplugs one disk, or another, or both in any order? Is it race condition now? Is it okay for OMV to have race condition?\r\nSeems whatever use cases Salt imagined for them here is very different from what OMV users might face.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1641", "user": "the-Arioch", "root": "ROOT164", "reply_to": "COM1640", "timestamp": "2021-03-28T04:58:15Z", "text": "Output from Linux's mount\r\n`/dev/sdb1 on /media/U:NTFS Disk type fuseblk (rw,relatime,user_id=0,group_id=0,allow_other,blksize=4096)`\r\n\r\nSpaces are NOT escaped there!\r\nDunno how it is done on BSD/Darwin\r\n\r\nAnd then we have this...\r\n```\r\n# salt-call mount.list_mounts\r\nlocal:\r\n    ----------\r\n    /:\r\n        /dev/sda1\r\n......\r\n    /media/U:NTFS:\r\n        /dev/sdb1\r\n    /proc:\r\n        proc\r\n........\r\n```\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1642", "user": "the-Arioch", "root": "ROOT164", "reply_to": "COM1641", "timestamp": "2021-03-28T06:26:46Z", "text": "@votdev  re: escaping names for calling `mount` - i think that is what was intended to do so:\r\n\r\n`\"device\": device_name.replace(\"\\\\040\", \"\\\\ \"),` inside `def _active_mountinfo()`\r\nbut that was only called when from `def active(extended=False)` then Extended is set to True, if ever\r\n\r\nAnd similar code inside `def _resolve_user_group_names(opts):`\r\n\r\nSo it seems Salt prefers to keep space-containing names mangled, but mangled differently.\r\nSo, no escaping when calling `mount` or `umount` is needed,\r\n\r\n---\r\n\r\nI am not even sure that de-escaping mount point likes `xxx\\040yyy` in Salt would be correct way to go.\r\n\r\nThere can be a point: since that module serves as abstraction layer and should hide UNIX-likes peculiarities from generic Salt modules, all IDs better be unmangled. But not sure. \r\n\r\nHowever IF to do this de-mangling, then quoting arguments for calling `mount` becomes required indeed.\r\n\r\nBut anyway, this line i believe  should not had ended in /etc/fstab and whoever added it was at fault...\r\n\r\n```\r\n# >>> [openmediavault]\r\n/dev/disk/by-label/My\\x20Passport\\x20Blue\t\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1643", "user": "the-Arioch", "root": "ROOT164", "reply_to": "COM1642", "timestamp": "2021-03-28T09:38:18Z", "text": "@votdev i made quite many changes in that mounts.py - and now i am thinking about undoing almost all of them... Lack of any documentation...\r\n\r\nI am coming to believe that, while never documented, the intention of that Salt module was to always use fstab-like escaped strings for all their IDs. If not, i would like to see specific calls into other Salt modules, which expect different convention for disk names.\r\n\r\nI really did quite a number of changes to de-escape \\040 and other special chars. And probably that was only breaking things.\r\n\r\nExcept for one place though, which i believe should be patched.\r\n\r\n```\r\nimport pathlib \r\n\r\ndef list_mounts(): # for debug\r\n    return _list_mounts()\r\n\r\ndef _list_mounts():\r\n    ret = {}\r\n    idx_mpoint = 2\r\n    # one cannot trust `mount` with space-containing paths\r\n    # at least on Linux - https://github.com/saltstack/salt/issues/54508\r\n\r\n    if __grains__[\"kernel\"] == \"Linux\":\r\n        idx_mpoint = 1\r\n        mounts = pathlib.Path('/proc/mounts').read_text()\r\n    elif __grains__[\"os\"] in [\"MacOS\", \"Darwin\"]:\r\n        mounts = __salt__[\"cmd.run_stdout\"](\"mount\")\r\n    else:\r\n        mounts = __salt__[\"cmd.run_stdout\"](\"mount -l\")\r\n\r\n    for line in mounts.split(\"\\n\"):\r\n        comps = re.sub(r\"\\s+\", \" \", line).split()\r\n        if len(comps) > idx_mpoint:\r\n##            if __grains__[\"kernel\"] == \"Linux\":\r\n##               comps[0] = _Linux_fstab_unmangle( comps[0] )\r\n##               comps[idx_mpoint] = _Linux_fstab_unmangle( comps[idx_mpoint] )\r\n            ret[comps[idx_mpoint]] = comps[0]\r\n    return ret\r\n```\r\n\r\nWould you keep implementation non-patched and would you call `salt-call mount.list_mounts` - you would see the mount point broken, cut off on the first space. This was probably THE bug.\r\n\r\n----------------\r\n\r\nOkay, keeping my stolen Linux archeologist hat on\r\n\r\nhttps://unix.stackexchange.com/questions/56291/what-causes-dev-disk-by-label-to-be-populated\r\n\r\n```\r\nmount -l \r\n   .....\r\n/dev/sdb1 on /media/U:NTFS Disk type fuseblk (rw,relatime,user_id=0,group_id=0,allow_other,blksize=4096) [U - Arch-2 Hitachi_2Tb_7200]\r\n\r\nroot@diskoteka:/media# ls /dev/disk/by-label/\r\n'U\\x20-\\x20Arch-2\\x20Hitachi_2Tb_7200'\r\n\r\nroot@diskoteka:/media# blkid -o udev -p /dev/sdb1\r\nID_FS_LABEL=U_-_Arch-2_Hitachi_2Tb_7200\r\nID_FS_LABEL_ENC=U\\x20-\\x20Arch-2\\x20Hitachi_2Tb_7200\r\nID_FS_UUID=C6705D84705D7BDD\r\nID_FS_UUID_ENC=C6705D84705D7BDD\r\nID_FS_TYPE=ntfs\r\nID_FS_USAGE=filesystem\r\nID_PART_TABLE_TYPE=atari\r\nID_PART_ENTRY_SCHEME=dos\r\nID_PART_ENTRY_UUID=78fdd16a-01\r\nID_PART_ENTRY_TYPE=0x7\r\nID_PART_ENTRY_NUMBER=1\r\nID_PART_ENTRY_OFFSET=2048\r\nID_PART_ENTRY_SIZE=3907024896\r\nID_PART_ENTRY_DISK=8:16\r\n```\r\n\r\nSo, it is UDEV or SYSTEMD which creates those weird hex-mangled names. Okay. Though putting them into /etc/fstab still feels wrong. `man mount` suggests against it and suggests using `UUID=...` and `LABEL=...` flags instead.\r\n\r\nNow back to your\r\n```\r\nExample SLS:\r\n\r\nmount_fs_with_label:\r\n  mount.mounted:\r\n    - name: \"/srv/dev-disk-by-label-My Passport Blue\"\r\n```\r\n\r\nI don't know what it should mean in specific files/commands terms. But i feel this is the error on OMV part. And perhaps lack of documentation/understanding/forecasting on Salt part.\r\n\r\n```\r\ndef mount(\r\n    name, device=False, mkmnt=False, fstype=\"\", opts=\"defaults\", user=None, util=\"mount\"\r\n):\r\n.....\r\n        salt '*' mount.mount /mnt/foo /dev/sdz1 True\r\n.....\r\n    if device:\r\n        cmd += \"{} {} {} \".format(args, device, name)\r\n    else:\r\n        cmd += \"{} \".format(name)\r\n```\r\n\r\nMy inner archeologist says that the `name` AKA mount point AKA target directory is meant to be in bash-mangled format.\r\nIOW OMV should had created \"\\ \" containing fileneames:\r\n```\r\n  mount.mounted:\r\n    - name: \"/srv/dev-disk-by-label-My\\ Passport\\ Blue\"\r\n```\r\nLinux `man mount` also suggests against the second option due to ambiguity, where the single parameter is mount point name or device file name. I don't know if other UNIX-likes but Linux support those precision keys.\r\n\r\n```\r\n       --source device\r\n              If only one argument for the mount command is given  then  the\r\n              argument might be interpreted as target (mountpoint) or source\r\n              (device).  This option allows to explicitly  define  that  the\r\n              argument is the mount source.\r\n\r\n       --target directory\r\n              If  only  one argument for the mount command is given then the\r\n              argument might be interpreted as target (mountpoint) or source\r\n              (device).   This  option  allows to explicitly define that the\r\n              argument is the mount target.\r\n```\r\n\r\nSo i think that part in `def mount` should better be written as\r\n\r\n```\r\n    if device:\r\n        cmd += \"{} {} {} \".format(args, device, name)\r\n    else:\r\n        if __grains__[\"kernel\"] == \"Linux\":\r\n             cmd += \"--target \"\r\n        cmd += \"{} \".format(name)\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1644", "user": "votdev", "root": "ROOT164", "reply_to": "COM1643", "timestamp": "2021-03-28T09:38:45Z", "text": "@the-Arioch I don't think this is the right place to discuss OMV related things.\r\n\r\n> Well, ranting aside, i am rather puzzled with your device: \"/dev/disk/by-label/My\\x20Passport\\x20Blue\"\r\n> Where do you even get this hex substitution from???\r\n\r\nEscaping blanks is not my idea, it is used by every userland command that processes mount points, e.g. `mount`.\r\nEither `systemd` want to have escaped paths in mount units too, there is a special command to convert\r\npaths for you, see `systemd-escape`.\r\n\r\n> Salt seems extremely fragile here, probably no one else except for OMV5 uses it for partitions. \r\n> Maybe OMV6 could do it outside Salt?\r\n\r\nOMV already workarounds this issue, thus it is not affected by this reported issue here.\r\n\r\n> I mean, before Salt porject might decide to drop this functionality that almost no one use, \r\n> instead of burden of maintaining it for OMV5 alone....\r\n\r\nI don't think Salt will drop `mount.mounted` because it is a somewhat essential functionality of Linux systems.\r\n\r\n> Now, to be frank, even this would NOT be enough, because i can have multiple disks with the \r\n> same partition label. Like many USB thumb drives with \"DATA\" partition. I can even have several \r\n> partitions with the same name on singe disk!\r\n\r\nYou can do that, but don't blame the software then. Using USB devices in a NAS is no good idea, but that's a different thing. IMO devices using in a NAS should be already connected to the NAS, no plug-and-play, this is not how a NAS is intended to work. If devices are always connected, then you will never run into the situation that duplicate labels might harm your system. This issue is user introduced and should be handled by them.\r\n\r\nIf you want to discuss this issue please open an issue in the OMV Git repository.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1645", "user": "votdev", "root": "ROOT164", "reply_to": "COM1644", "timestamp": "2021-03-28T09:46:06Z", "text": "> So, it is UDEV or SYSTEMD which creates those weird hex-mangled names. Okay. Though putting them into /etc/fstab still feels wrong. \r\n\r\nI think it is ok to use systemd escaped paths in `/etc/fstab` since systemd handles filesystem mounting nowadays.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1646", "user": "the-Arioch", "root": "ROOT164", "reply_to": "COM1645", "timestamp": "2021-03-28T10:15:49Z", "text": "@votdev i meantioned systemd because of https://github.com/systemd/systemd/issues/12018\r\n\r\nSee... i know very little about Linux and nothing about Python, so i was googling everything i could think of :-)\r\n\r\nBut i am glad to hear from you.  So, how can we scratch this itch, is Salt team is not with us on it...\r\n\r\nCan you make some scripts demonstrting the alleged Salt bug that i could run from bash ? Also are there some hidden option in OMV5 to re-enable mounting space-containing partitions?\r\n\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1647", "user": "the-Arioch", "root": "ROOT164", "reply_to": "COM1646", "timestamp": "2021-03-28T10:17:44Z", "text": "But i really am worried about potential race conditions in OMV when different partitions would have same label... IF you use label as \"primary key\" as persistent ID for all the other settings (user rights, sharing folders, etc), it might be quite a gotcha...", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1648", "user": "the-Arioch", "root": "ROOT164", "reply_to": "COM1647", "timestamp": "2021-03-28T10:26:46Z", "text": "Some of the \"deep changes\" i mentioned above. I now think those are dead end, but just in case they would be useful to someone, maybe even us later.\r\n\r\nUsing \"Raw\" non-escaped string would probably be more proper design, but might really require deep refactoring of many Salt modules and then testing on many different systems. Horror...\r\n\r\n```\r\ndef _Linux_fstab_unmangle(fs_str):\r\n    # rather ugly ad-hoc substitutions cosplaying ancient BSD's non-documented strunvis(...)\r\n    # https://sources.debian.org/src/sysvinit/2.96-6/src/fstab-decode.c/\r\n    # https://elixir.bootlin.com/linux/latest/source/fs/proc_namespace.c#L84\r\n    fs_str = fs_str.replace(r\"\\011\", \"\\t\").replace(r\"\\012\", \"\\n\")\r\n    fs_str = fs_str.replace(r\"\\040\", r\" \")\r\n    fs_str = fs_str.replace(r\"\\134\", \"\\\\\").replace(r\"\\\\\", \"\\\\\")\r\n    return fs_str\r\n\r\ndef _Str_Nop(text):\r\n    return str(text)\r\n\r\ndef _fsfilter():\r\n    if __grains__[\"kernel\"] == \"Linux\":\r\n        return _Linux_fstab_unmangle\r\n    return _Str_Nop\r\n```\r\n\r\nand then\r\n\r\n```\r\ndef _list_mounts():\r\n    ret = {}\r\n    idx_mpoint = 2\r\n    # one cannot trust `mount` with space-containing paths\r\n    # at least on Linux - https://github.com/saltstack/salt/issues/54508\r\n\r\n    if __grains__[\"kernel\"] == \"Linux\":\r\n        idx_mpoint = 1\r\n        mounts = pathlib.Path('/proc/mounts').read_text()\r\n    elif __grains__[\"os\"] in [\"MacOS\", \"Darwin\"]:\r\n        mounts = __salt__[\"cmd.run_stdout\"](\"mount\")\r\n    else:\r\n        mounts = __salt__[\"cmd.run_stdout\"](\"mount -l\")\r\n\r\n    for line in mounts.split(\"\\n\"):\r\n        comps = re.sub(r\"\\s+\", \" \", line).split()\r\n        if len(comps) > idx_mpoint:\r\n            if __grains__[\"kernel\"] == \"Linux\":\r\n               comps[0] = _Linux_fstab_unmangle( comps[0] )\r\n               comps[idx_mpoint] = _Linux_fstab_unmangle( comps[idx_mpoint] )\r\n            ret[comps[idx_mpoint]] = comps[0]\r\n    return ret\r\n\r\n\r\ndef _active_mountinfo_linux(ret):\r\n    _list = _list_mounts()\r\n    _fi = _fsfilter()\r\n    filename = \"/proc/self/mountinfo\"\r\n    if not os.access(filename, os.R_OK):\r\n        msg = \"File not readable {0}\"\r\n        raise CommandExecutionError(msg.format(filename))\r\n\r\n    if \"disk.blkid\" not in __context__:\r\n        __context__[\"disk.blkid\"] = __salt__[\"disk.blkid\"]()\r\n    blkid_info = __context__[\"disk.blkid\"]\r\n\r\n    with salt.utils.files.fopen(filename) as ifile:\r\n        for line in ifile:\r\n            comps = salt.utils.stringutils.to_unicode(line).split()\r\n            device = comps[2].split(\":\")\r\n            # each line can have any number of\r\n            # optional parameters, we use the\r\n            # location of the separator field to\r\n            # determine the location of the elements\r\n            # after it.\r\n            _sep = comps.index(\"-\")\r\n            device_name = _fi(comps[_sep + 2])\r\n            device_uuid = None\r\n            device_label = None\r\n            if device_name:\r\n                device_uuid = blkid_info.get(device_name, {}).get(\"UUID\")\r\n                device_uuid = device_uuid and device_uuid.lower()\r\n                device_label = blkid_info.get(device_name, {}).get(\"LABEL\")\r\n            ret[_fi(comps[4])] = {\r\n                \"mountid\": comps[0],\r\n                \"parentid\": comps[1],\r\n                \"major\": device[0],\r\n                \"minor\": device[1],\r\n                \"root\": _fi(comps[3]),\r\n                \"opts\": _resolve_user_group_names(comps[5].split(\",\")),\r\n                \"fstype\": comps[_sep + 1],\r\n                \"device\": device_name, ## .replace(\"\\\\040\", \"\\\\ \"),\r\n                \"alt_device\": _list.get(_fi(comps[4]), None),\r\n                \"superopts\": _resolve_user_group_names(comps[_sep + 3].split(\",\")),\r\n                \"device_uuid\": device_uuid,\r\n                \"device_label\": device_label,\r\n            }\r\n    return ret\r\n\r\n\r\ndef _active_mounts_linux(ret):\r\n    \"\"\"\r\n    List active mounts on Linux systems\r\n    \"\"\"\r\n    _list = _list_mounts()\r\n    _fi = _fsfilter()\r\n    filename = \"/proc/self/mounts\"\r\n    if not os.access(filename, os.R_OK):\r\n        msg = \"File not readable {0}\"\r\n        raise CommandExecutionError(msg.format(filename))\r\n\r\n    with salt.utils.files.fopen(filename) as ifile:\r\n        for line in ifile:\r\n            comps = salt.utils.stringutils.to_unicode(line).split()\r\n            ret[_fi(comps[1])] = {\r\n                \"device\": _fi(comps[0]),\r\n                \"alt_device\": _list.get(_fi(comps[1]), None),\r\n                \"fstype\": comps[2],\r\n                \"opts\": _resolve_user_group_names(comps[3].split(\",\")),\r\n            }\r\n    return ret\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1649", "user": "the-Arioch", "root": "ROOT164", "reply_to": "COM1648", "timestamp": "2021-03-28T11:05:59Z", "text": "@votdev  > OMV already workarounds this issue\r\n\r\nby failing to mount the disk? because i can not mount disk in OMV5 or i would never learn about this issue.\r\nfailing to mount disk does not look like work-around at all.\r\n\r\nlet's think what we can do to make space-containing partitions mounted by OMV. It seems to be a kind of \"communication breakdown\" between Salt and OMV5, they expect and provide for mututally incompatible things.\r\n\r\nhere is minimally patched \r\n/usr/lib/python3/dist-packages/salt/modules/mount.py \r\n\r\n[mount.py.gz](https://github.com/saltstack/salt/files/6217180/mount.py.gz)\r\n\r\n\r\nit makes space-containing mount point visible. If there still is something not working - i can not see what it is and how could i test it using `salt-call` scripts\r\n\r\n```\r\n# salt-call mount.list_mounts\r\nlocal:\r\n    ----------\r\n    /:\r\n        /dev/sda1\r\n    /dev:\r\n        udev\r\n    /dev/hugepages:\r\n        hugetlbfs\r\n    /dev/mqueue:\r\n        mqueue\r\n    /dev/pts:\r\n        devpts\r\n    /dev/shm:\r\n        tmpfs\r\n    /media/U:NTFS\\040Disk:\r\n        /dev/sdb1\r\n    /proc:\r\n        proc\r\n......\r\n# salt-call mount.active\r\n....\r\n   /media/U:NTFS\\040Disk:\r\n        ----------\r\n        alt_device:\r\n            /dev/sdb1\r\n        device:\r\n            /dev/sdb1\r\n        fstype:\r\n            fuseblk\r\n        opts:\r\n            - rw\r\n            - relatime\r\n            - user_id=0\r\n            - group_id=0\r\n            - allow_other\r\n            - blksize=4096\r\n..........\r\n# salt-call mount.active extended=true\r\n......\r\n   /media/U:NTFS\\040Disk:\r\n        ----------\r\n        alt_device:\r\n            /dev/sdb1\r\n        device:\r\n            /dev/sdb1\r\n        device_label:\r\n            U - Arch-2 Hitachi_2Tb_7200\r\n        device_uuid:\r\n            c6705d84705d7bdd\r\n        fstype:\r\n            fuseblk\r\n        major:\r\n            8\r\n        minor:\r\n            17\r\n        mountid:\r\n            427\r\n        opts:\r\n            - rw\r\n            - relatime\r\n        parentid:\r\n            26\r\n        root:\r\n            /\r\n        superopts:\r\n            - rw\r\n            - user_id=0\r\n            - group_id=0\r\n            - allow_other\r\n            - blksize=4096\r\n```\r\nand also\r\n```\r\nroot@diskoteka:/media# salt-call mount.is_mounted name=\"/media/U:NTFS Disk\"\r\nlocal:\r\n    False\r\nroot@diskoteka:/media# salt-call mount.is_mounted name=\"/media/U:NTFS\\ Disk\"\r\nlocal:\r\n    False\r\nroot@diskoteka:/media# salt-call mount.is_mounted name=\"/media/U:NTFS\\040Disk\"local:\r\n    True\r\n```", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16410", "user": "the-Arioch", "root": "ROOT164", "reply_to": "COM1649", "timestamp": "2021-03-28T11:41:02Z", "text": "And now the most curious thing to me. I changed the partition label, then i mounted the disk from OMV Web UI and...\r\n\r\n....and there is no any space-containing mountpoint path regardless of partition label.\r\nThe \"workaround\" seems to needlessly shoot down the perfectly working function!\r\n\r\nMaybe it is only with MBR/NTFS disks, maybe GPT or XFS disks would use something else in `fstab`, dunno\r\n\r\n```\r\n# mount -l\r\n    ....\r\n/dev/sdb1 on /srv/dev-disk-by-uuid-C6705D84705D7BDD type fuseblk (rw,relatime,user_id=0,group_id=0,allow_other,blksize=4096) [U_-_Arch-2_Hitachi_2Tb_7200]\r\n```\r\nand\r\n\r\n```\r\n# salt-call mount.active\r\n  . . . .\r\n    /srv/dev-disk-by-uuid-C6705D84705D7BDD:\r\n        ----------\r\n        alt_device:\r\n            /dev/sdb1\r\n        device:\r\n            /dev/sdb1\r\n        fstype:\r\n            fuseblk\r\n        opts:\r\n            - rw\r\n            - relatime\r\n            - user_id=0\r\n            - group_id=0\r\n            - allow_other\r\n            - blksize=4096\r\n    /sys:\r\n        ----------\r\n        alt_device:\r\n            sysfs\r\n```\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16411", "user": "the-Arioch", "root": "ROOT164", "reply_to": "COM16410", "timestamp": "2021-03-29T17:34:41Z", "text": "@votdev it is sad how fast you were to say Salt is all wrong and how protective you fet about OMV.\r\n\r\nYou still try to push Salt to adhere to OMV data format, while common sense says it should be otherwise.\r\n\r\nSalt users would not suffer from it. OMV users would.\r\nDemanding PR from OMV users like me is funny when you did not make any PR to Salt, or maybe i am wrong and you did.\r\n\r\nSo, back to:\r\n\r\nhttps://github.com/openmediavault/openmediavault/issues/566#issuecomment-809541057\r\n\r\nThe intention was and is to make OMV work with disks users insert. \r\nWithout forcing them to go ssh sudo. \r\nSo simple.\r\n\r\nYou make it look that making OMV \"just work\" is bad goal. \r\n\r\n> Why the hell should escapeshellarg be called here?\r\n\r\nBecause that woul be consistent with bash/Salt data format. But i alreeady said it was kneejerk impulse, so you eems to be crashing through door wide open.\r\n\r\n> The function is doing exactly what you are suggesting, keep data raw/verbatim/unescaped within OMV\r\n\r\nSome we are on the same page here. You blaze of ego is called for.\r\n\r\nSince eysterday i was asking you to show me at the se\r\nems between OMV and Salt, the exact borderleines, didn't i?\r\nI am glad you seem to did so above, https://github.com/openmediavault/openmediavault/issues/566#issuecomment-809529126\r\n\r\nAnd when i showed those links, i commented upon them.\r\n\r\n`Salt is based on Python, not PHP. The code you're ranting about never runs in the Salt context.`\r\n\r\nI never said so. Both Salt and OMV are \"black boxes\" with some data exchange. And i was asking you to point me to the raw places of exchange and raw data being exchanged, didn't i?\r\n\r\nYesterday i spent hours looking into Salt code and patching it along your suggestions.\r\nFirst i took your suggestions as correct and thought through. And just followed them. An then had to undo it all.\r\n\r\nNow you imply it was your time wasted not mine.\r\n\r\nThat `Example SLS:` - many times from yesterday i asked you how can i reproduice this activity from bash command line.\r\nFor example above - https://github.com/saltstack/salt/issues/54508#issuecomment-808875885\r\nYou kind of answered by showing PHP code for SLS generation - after many requests and hours.\r\nBut you still not answered how to trigger that action from bash.\r\n\r\nI asked you yesterday how to make OMV code trigger that action of Salt, allegedly buggy Salt.\r\nAnd you refused to help me doing it.\r\nhttps://github.com/openmediavault/openmediavault/issues/566#issuecomment-808955077\r\n\r\n```\r\nWhat can i patch in OMV5 to make this notification gone?\r\nWhy do you want to know that? What do you expect to improve?\r\n```\r\n\r\nYou made me look into Linux kernel i am not familiar with, at the same time you are not very willing to point me to specific OMV code and Salt commands you are familiar with.\r\n\r\nYou are blocking any attempt to debug OMV and Salt interaction - and you demand perfectly polished PRs. \r\nIt is not consistent. And it is would not help anyone. Not me, not you, not OMV users.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16412", "user": "the-Arioch", "root": "ROOT164", "reply_to": "COM16411", "timestamp": "2021-03-29T17:39:39Z", "text": "@garethgreenaway  @waynew  @sagetherage \r\n\r\nPlease consider this fix to `Salt` above\r\n\r\n> here is minimally patched /usr/lib/python3/dist-packages/salt/modules/mount.py\r\n> mount.py.gz\r\n\r\nhttps://github.com/saltstack/salt/issues/54508#issuecomment-808881089\r\n\r\nThat is a clear bug in `Salt` that can be reproduced on Linux box (and probably on other UNIX-likes) independently on OMV", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16413", "user": "votdev", "root": "ROOT164", "reply_to": "COM16412", "timestamp": "2021-03-29T19:38:29Z", "text": "@the-Arioch Please stop blaming and ranting me. This raised issue here has nothing to do with OMV.\n\n@garethgreenaway please set this issue to read-only, I had to do the same on the OMV issues to stop these rants.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT165", "user": "vsfeedback", "root": "ROOT165", "reply_to": null, "timestamp": "2018-01-04T02:05:20Z", "text": "VS2017express C#, tabs replaced with spaces Hello,  under the following circumstances, VS2017express replaces tabs with spaces even though I deactivated that feature in the options: - I am working on a C# file - I am pasting a tab from my clipboard into a line of code, but not at the end, e.g. &quot;int i = 0; // init i&quot;. If I want more space between the command and the comment and I use my tab key, then tabs get inserted properly, but if I put a tab into my clipboard and insert it with Ctrl-V, then ALL tabs get replaced with spaces.  This problem does not occur in C++ files of the same solution, even though I set the tab configuration identical for all languages.  Cheers Peter  _This issue has been moved from https://developercommunity.visualstudio.com/content/problem/154651/vs2017express-c-tabs-replaced-with-spaces.html VSTS ticketId: 528589_ _These are the original issue comments:_  Peter Meier on \u200e11\u200e/\u200e23\u200e/\u200e2017, 02:27 AM (41 days ago): <p>Also I just found out that if I hit the auto format keys (Ctrl-K, Ctrl-D), all the tabs I inserted between the command and the comment are replaced with spaces again. I searched through Tools/Options/Text Editor/C#/Code Style/Formatting, but I found no way to change this annoying behavior. I don't understand why C# won't let me align my comments the way I want them to be when it's no problem for C++.</p>  Jinu Joseph [MSFT] on \u200e12\u200e/\u200e20\u200e/\u200e2017, 02:48 AM (14 days ago): <p>We appreciate you taking the time to report this problem. We are currently prioritizing problems that are impacting a broad set of our customers, so we may not be able to investigate this one immediately. We know this problem is important to you, so we will continue to monitor it.</p>  _These are the original issue solutions:_ (no solutions)", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM1650", "user": "jcoutch", "root": "ROOT165", "reply_to": "ROOT165", "timestamp": "2018-05-16T18:33:37Z", "text": "I'm having a similar problem with Visual Studio 2017 Professional (15.7.0.)  I have my indentation style set using `.editorconfig`:\r\n\r\n```\r\n[*.cs]\r\nindent_style = tab\r\nindent_size = tab\r\ntab_width = 4\r\n```\r\n\r\nIf I add a newline to a C# file, tabs are inserted as expected.  But, if I format the document using Ctrl+K Ctrl+D, any tabs in the file are replaced with spaces.\r\n\r\nIf I use ReSharper to format my document, all indentation is converted to tabs as expected.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1651", "user": "FlorianHaupt", "root": "ROOT165", "reply_to": "COM1650", "timestamp": "2018-06-26T08:10:03Z", "text": "Would be nice to get this fixed, would save much time.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1652", "user": "elliott-beach", "root": "ROOT165", "reply_to": "COM1651", "timestamp": "2018-09-12T00:41:26Z", "text": "I was thinking of submitting a repro, but the OP hits the nail on the head:\r\n>  just found out that if I hit the auto format keys (Ctrl-K, Ctrl-D), all the tabs I inserted between the command and the comment are replaced with spaces again. I searched through Tools/Options/Text Editor/C#/Code Style/Formatting, but I found no way to change this annoying behavior. \r\n\r\nThis creates big whitespace changes after formatting the document as we use tabs at work. Please fix this.\r\n", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1653", "user": "sharwell", "root": "ROOT165", "reply_to": "COM1652", "timestamp": "2018-11-25T23:59:48Z", "text": "\ud83d\udcdd The issue here is hard tabs contained *within* a line of code, i.e. tabs not used for indentation.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1654", "user": "kendrahavens", "root": "ROOT165", "reply_to": "COM1653", "timestamp": "2018-12-03T23:11:40Z", "text": "Design meeting notes:\r\nIn the past we've had conflicting requests on the behavior for tabs within a line of code so we need to add an option for this behavior.\r\n\r\nMy proposal:\r\n* add editorconfig setting that enforces tabs within a line of code. `tab_within_line`\r\n* add new toggle in **Tools > Options > C# > Tabs**: Enforce tabs within lines.\r\n  * It could also go under **Tools > Options > C# > Code Style > Formatting > Spacing** if that is the preferred place to keep editorconfig settings.\r\n\r\n@heejaechang @sharwell ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1655", "user": "FlorianHaupt", "root": "ROOT165", "reply_to": "COM1654", "timestamp": "2018-12-04T09:01:11Z", "text": "@kendrahavens \r\nNice proposal to add an extra option.\r\n> Design meeting notes:\r\nIn the past we've had conflicting requests on the behavior for tabs within a line of code so we need to add an option for this behavior.\r\n\r\nAre there really users that like to keep tabs only on specific parts, like indent?\r\n![tabs-settings](https://user-images.githubusercontent.com/18165738/49427897-d7adf800-f7a4-11e8-9842-6077bbb51952.png)\r\nAs the current option does reflect what it should do, to \"keep tabs\" and do not replace them with spaces - This is the behavior as I know it from previous versions and as it is within the C++ text editor - I would prefer an new option that says \"keep tabs only for indent\" for this new behavior. One saying \"Enforce tabs within lines\" would still confuse and let me wonder why I have to check that extra option in situations I already selected \"Keep tabs\".", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1656", "user": "sharwell", "root": "ROOT165", "reply_to": "COM1655", "timestamp": "2018-12-04T11:27:17Z", "text": "> Are there really users that like to keep tabs only on specific parts, like indent?\r\n\r\nYes, it's actually a primary request for users who indent with tabs.\r\n\r\nThe name of the new option has not been decided, but it would have two options:\r\n\r\n1. Allow tabs whenever <kbd>Tab</kbd> is used (matches the behavior prior to Visual Studio 2015)\r\n2. Use tabs for indentation, but not for alignment\r\n\r\nIn most cases, the second option behaves as you see today. However, the behavior would change in cases where hanging indentation is used for aligning code with code on a previous line. For example:\r\n\r\n```csharp\r\nvoid Method()\r\n{\r\n\u2192   var\u00b7data\u00b7=\u00b7from\u00b7value\u00b7in\u00b7new[]\u00b7{\u00b71,\u00b72\u00b7}\r\n\u2192   \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7select value;\r\n}\r\n```", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1657", "user": "sharwell", "root": "ROOT165", "reply_to": "COM1656", "timestamp": "2018-12-11T14:01:50Z", "text": "The preliminary design discussion is now complete. We will review the final user experience once it is ready.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1658", "user": "levicki", "root": "ROOT165", "reply_to": "COM1657", "timestamp": "2020-04-24T21:27:04Z", "text": "> The issue here is hard tabs contained within a line of code, i.e. tabs not used for indentation.\r\n\r\nI keep hearing people referring to tabs as hard when it's actually the other way around -- tabs are soft (as in you can replace them with any number of spaces on display),, and spaces are hard (as in hard-coded number in the file itself which you can't reformat so easily on display).\r\n\r\nThat said, I would really prefer if Tab key did what it says on the tin -- inserted a Tab character into the editor. Currently in Visual Studio 16.5.4 that doesn't seem to be the case even though I have configured everything to have Tabs instead of spaces.\r\n\r\nI'd like to voice my displeasure towards two trends going on in Visual Studio editor since VS 2015:\r\n\r\n1. Editor trying to be \"smart\" and disregarding user input more and more (i.e. I enter Tab and it enters spaces even though it's clearly configured to use Tabs)\r\n2. Premature code analysis and error checking (i.e. telling you your code is broken and offering to \"fix\" it before you ever get a chance to complete it)\r\n\r\nThose additions waste enormous amounts of developer time and effort on fighting them when they are wrong (and sadly they can be wrong a lot). The least you could do is offer an option to disable both behaviors globally.\r\n\r\nFinally, I'd appreciate if there was some workaround for this spaces instead of tabs issue, it's driving me nuts.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1659", "user": "Edgs", "root": "ROOT165", "reply_to": "COM1658", "timestamp": "2020-12-13T16:31:16Z", "text": "This is still a problem.  The older versions of editors never used to behave like this.  Other editors don't behave like this.  Even Notepad doesn't behave like this.\r\n\r\nI'll explain simply:\r\nWith the option to KEEP TABS selected in the Editor settings, TABs typed within code (so end of line comments line up, for example.) are later changed into spaces by Visual Studio.  When copying & pasting a line, for example.\r\nI NEVER want this to happen.  That's why I select the option to KEEP TABS.\r\nIf I type a TAB in my code, I NEVER want it changed it to spaces.  It's really that simple.\r\n\r\nWhy is this not fixed after 2+ years?\r\nThis is not an enhancement request, but simply a request that the editor behave as editors have always behaved since the dawn of computing.  At some point, someone in Microsoft decided to 'muck' around with users typed code and change it, when not one user asked for that to happen.\r\n\r\n> > Are there really users that like to keep tabs only on specific parts, like indent?\r\n> Yes, it's actually a primary request for users who indent with tabs.\r\nThat's simply not true.  Show us ONE request from ANYONE who asked for their TABs to be changed to spaces within their code when using the option KEEP TABS.\r\n\r\nAlso worth noting that this still happens when the 'Use Adaptive Formatting' option is turned off.  So it is impossible to prevent this from happening.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16510", "user": "sharwell", "root": "ROOT165", "reply_to": "COM1659", "timestamp": "2020-12-14T16:08:36Z", "text": "> Why is this not fixed after 2+ years?\r\n\r\nThere is no one consensus on the definition of correct behavior. The overwhelming majority of users are happy with the current implementation of tabs/spaces handling. Accounting for the remaining ones (in particular, https://github.com/dotnet/roslyn/issues/24031#issuecomment-444067640 and \"always use tabs\") without breaking the experience for users who are happy with the current behavior is a particularly challenging exercise that requires both design and implementation work.\r\n\r\nI'm not sure this will move up on the internal priority list in the near future, but if an external user wanted to spend the time to define and implement the full experience we would be happy to review it. See #23394 for a great example of a feature which shipped because a contributor went through this process. \ud83d\ude04 ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16511", "user": "levicki", "root": "ROOT165", "reply_to": "COM16510", "timestamp": "2021-02-23T00:27:09Z", "text": "@sharwell \r\n> There is no one consensus on the definition of correct behavior.\r\n\r\nHow about you take the same approach as Git does for line endings?\r\n\r\n1. Replace TABs with spaces on reformat\r\n2. Replace spaces with TABs on reformat\r\n3. Leave both as entered on reformat\r\n\r\nShouldn't the above satisfy everyone involved?\r\n\r\nCome on people, this is not rocket science, it's a text editor for $(Deity)'s sake!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16512", "user": "CyrusNajmabadi", "root": "ROOT165", "reply_to": "COM16511", "timestamp": "2021-02-23T04:06:22Z", "text": "I've never seen git do that. ", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM16513", "user": "Edgs", "root": "ROOT165", "reply_to": "COM16512", "timestamp": "2021-02-23T09:52:52Z", "text": "> \r\n> \r\n> I've never seen git do that.\r\n\r\nNo matter, you've never seen any other existing or previous code editor, since text editors first existed, behave the way VS does.\r\nWhen auto-indenting, it ALWAYS changes TABs between code and line comments to SPACES no matter what settings are selected - like the 'always keep TABs' setting.\r\nNobody asked for this behaviour.  It's a bug.\r\nObviously it's more convient to blindly deny it here rather than simply fix it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16514", "user": "levicki", "root": "ROOT165", "reply_to": "COM16513", "timestamp": "2021-02-23T09:59:34Z", "text": "> I've never seen git do that.\r\n\r\nHow about not commenting before understanding what you read? I never said Git does anything with spaces and TABs -- I explicitly mentioned line endings.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16515", "user": "sharwell", "root": "ROOT165", "reply_to": "COM16514", "timestamp": "2021-02-23T15:31:33Z", "text": "> Nobody asked for this behaviour. It's a bug.\r\n\r\nThis is not correct. Some users who use tabs for indenting prefer the current setting, since it allows for variable-width tabs without changing alignment\u00b9. _Most_ users who use tabs for indenting either prefer the current behavior _or_ they are OK with either behavior.\r\n\r\nWe are willing to reconsider the design since some teams still aren't happy with the current behavior, but only if the design provides a comprehensive approach that works for both preferences.\r\n\r\n\u00b9 Some alignment scenarios are still broken; we would expect the change proposal to ensure these are corrected per https://github.com/dotnet/roslyn/issues/24031#issuecomment-444067640.\r\n\r\n> How about not commenting before understanding what you read? I never said Git does anything with spaces and TABs -- I explicitly mentioned line endings.\r\n\r\nGit has the ability to transparently normalize line endings as part of commit/checkout, but there are many reasons why this would not work with tabs/spaces:\r\n\r\n1. Git doesn't have the ability to alter its understanding of normalization to include characters other than end-of-line characters.\r\n2. Git's normalization process is transparent, meaning any given developer never actually sees it take action. From a local perspective, the file only ever existed in the local form.\r\n3. Not all users are working with Git for source control.\r\n4. Tools which operate on files with checksum validation (e.g. debugging) _explicitly_ account for the fact that every text file has two possible forms: one with `\\r\\n` and a second with `\\n`. All of these tools will break if new normalization characters are added.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16516", "user": "CyrusNajmabadi", "root": "ROOT165", "reply_to": "COM16515", "timestamp": "2021-02-23T16:15:05Z", "text": "> How about not commenting before understanding what you read?\r\n\r\nHow can I understand without discussing and talking with people about the topic?", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM16517", "user": "CyrusNajmabadi", "root": "ROOT165", "reply_to": "COM16516", "timestamp": "2021-02-23T16:44:27Z", "text": "So, i would need some strong answers to problems i see arising from changing the representation of the file for different developers.  First, that would violate some of our efforts we have around reproducible builds.  Second, it seems like it would just cause problems for normal situations like:\r\n\r\n```c#\r\nvar v1 = from c in customers\r\n         where c.Age >= 21\r\n         ...\r\n```\r\n\r\nHere, the continuation lines need to be indented 9 columns to maintain alignment.  Replacing these with tabs just breaks this.  Even if it was on some tab multiple for some developers, it might not be for others.\r\n\r\nIn general, I think all developers on the team (including CI) should operate on a bit-for-bit identical version of the code for many important reasons.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM16518", "user": "levicki", "root": "ROOT165", "reply_to": "COM16517", "timestamp": "2021-02-23T18:45:37Z", "text": "@sharwell \r\n> Git has the ability to transparently normalize line endings as part of commit/checkout, but there are many reasons why this would not work with tabs/spaces...\r\n\r\nLet me be absolutely clear that I did not suggest changing Git behavior, but rather emulating their set of options for the particular problem at hand.\r\n\r\nWith that out of the way, can we agree that VS editor already does some sort of \"normalization\" of TABs and spaces?\r\n\r\nThe problem in my opinion is twofold:\r\n\r\n1. The existing settings that govern TAB .vs. space editor behavior are all over the place and totally do not work as described in the UI, much less produce results that are expected.\r\n2. There is no `What You Type Is What You Get` editor setting -- I just want (and I am sure I am not the only one) that when I enter mixed TABs and spaces on a single line of code that they stay exactly like I entered them (save for expression reformatting which is already customizable enough for everyone's taste).\r\n\r\n@CyrusNajmabadi \r\n\r\n> How can I understand without discussing and talking with people about the topic?\r\n\r\nYou butted into the middle of a discussion by putting words in my mouth because you haven't bothered to understand what I wrote. Maybe that is somehow my fault because English is not my primary language and what I wrote is hard to understand, but in all honesty I am not sure what are you arguing for (or against). If you want to keep spaces in your files then rest assured that nobody here wants to take that away from you. I am asking for more options, not less. Therefore, please stop diluting the topic with pointless and/or obvious comments.\r\n\r\n@sharwell \r\n\r\nSo once again, I only want an editor option to not touch beginning of line indentation, variable name indentation, and comment indentation -- it is irrelevant whether those are done with TABs, spaces, or a mixture of the two -- I want it preserved as I typed it.\r\n\r\nI am really surprised to hear that something like that cannot be done while still keeping all current options.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16519", "user": "CyrusNajmabadi", "root": "ROOT165", "reply_to": "COM16518", "timestamp": "2021-02-23T19:00:03Z", "text": "> You butted into the middle of a discussion by putting words in my mouth\r\n\r\nI didn't.  I said i'd never see such behavior.  I have not.  That was me just giving insight that I wasn't familiar with what you are talking about.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM16520", "user": "CyrusNajmabadi", "root": "ROOT165", "reply_to": "COM16519", "timestamp": "2021-02-23T19:00:48Z", "text": "> I am not sure what are you arguing for (or against)\r\n\r\nI'm happy to clarify any of my points.  Def ask questions and I'll get back to you asap.  If you'd like another venue to discuss things (perhaps in realtime) I'm also happy to use gitter or discord to continue the discussion :)", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM16521", "user": "CyrusNajmabadi", "root": "ROOT165", "reply_to": "COM16520", "timestamp": "2021-02-23T19:02:11Z", "text": "> I am asking for more options, not less. \r\n\r\nSure.  However, I'm pointing out that those options are potentially quite problematic.  I would be wary about adding them without fully understanding all the implications here.  And to get there, i need to talk about the topic.\r\n\r\n> Therefore, please stop diluting the topic with pointless and/or obvious comments.\r\n\r\nIt was not obvious to me.  That's the reason i made the comment.  I was unfamiliar with what you were talking about, so i pointed that out to get clarity.  ", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM16522", "user": "CyrusNajmabadi", "root": "ROOT165", "reply_to": "COM16521", "timestamp": "2021-02-23T19:04:33Z", "text": "> I am really surprised to hear that something like that cannot be done while still keeping all current options.\r\n\r\nThe challenge is that you may be asking for X, and we may provide *exactly* X, only to find out soon after that you actually wanted X', and that X is not sufficient for all your cases.  THe purpose of the discussion, and the examination of all the tangential concerns is to try to get as full an understanding as possible so as to provide the best possible solution here.  \r\n\r\nAs you may have noticed, this is actually a fairly complex space with lots of varying concerns.  You may have even noticed that different people have asked for things *in conflict* with other requests.  It's not as simple as just taking one proposal and implementing it and leaving it at taht.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM16523", "user": "levicki", "root": "ROOT165", "reply_to": "COM16522", "timestamp": "2021-02-23T22:39:14Z", "text": "> The challenge is that you may be asking for X, and we may provide exactly X, only to find out soon after that you actually wanted X', and that X is not sufficient for all your cases\r\n\r\nSo now you are implying that I don't even know what I want? What's next, telling me to get used to doing things your way because reasons?\r\n\r\nWell I know one thing for certain -- I do not want an AI or any piece of software to \"think\" instead of me and attempt to interpret my consistent keyboard input in different ways at different times as it pleases.\r\n\r\nHumans are creatures of habit and muscle memory is how we free our brain's capacity so it can perform more complex tasks, contextual controls or behavior are breaking muscle memory and are thus bad UI and software design.\r\n\r\nAgain, all I want is that spaces and tabs are left as I entered them when the line is reformatted. Nothing more, nothing less. All existing indentation and spacing formatting was fine for me before this \"smart\" tab to space conversion on reformat was added. I just want an option to turn it off.\r\n\r\nHow hard can that be?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16524", "user": "CyrusNajmabadi", "root": "ROOT165", "reply_to": "COM16523", "timestamp": "2021-02-23T22:58:45Z", "text": "> So now you are implying that I don't even know what I want?\r\n\r\nYes.  That's always a possibility.  It's happened numerous times in the past with many requests from many customers.  It's always something that needs to be kept in mind.  Furthermore, it may be what you want, but it may be wrong for other users complaining about something similar.  So navigating all the potential requests and constraints here can be tricky and takes a lot of communication and a lot of thought.  Thanks! :)", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM16525", "user": "Edgs", "root": "ROOT165", "reply_to": "COM16524", "timestamp": "2021-02-23T23:00:10Z", "text": "> As you may have noticed, this is actually a fairly complex space with lots of varying concerns...\r\n\r\nThen just concentrate on the **original problem in the first post**.  It's a very straightforward problem.\r\n**Tab characters, between code and double-slashed comments, are changed to space characters when auto-indenting is performed.**\r\nAuto indenting works fine - it uses TAB characters when asked, but TAB characters after the code are changed.\r\nWhy?\r\n\r\nThis is with **Always keep TABs** option selected.\r\nIf this is a feature, and not a bug, then someone please explain why, when **Always keep TABs** is selected, these TABs are being replaced by Spaces?\r\n\r\nThis behaviour does not exist in older versions of VS.  At some point it has been added by someone, for some reason.\r\nThat was the point at which the user experience was broken.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16526", "user": "CyrusNajmabadi", "root": "ROOT165", "reply_to": "COM16525", "timestamp": "2021-02-23T23:00:40Z", "text": "> How hard can that be?\r\n\r\nIt could potentially be very difficult.  The formatting engine is one part of Roslyn that i find the most challenging.  Not \"it's one of the top challenging parts\".  Rather: \"it is literally the most challenging pieces of roslyn\".\r\n\r\nChanges here often have very unexpected effects that are unintended and can break users who have become accustomed to how things work.  We have to be very delicate here as this can be very detrimental to codebases.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM16527", "user": "CyrusNajmabadi", "root": "ROOT165", "reply_to": "COM16526", "timestamp": "2021-02-23T23:01:33Z", "text": "> Auto indenting works fine - it uses TAB characters when asked, but TAB characters after the code are changed.\r\n\r\nI don't think this is the case.  For example, i believe we may choose to align things, and not stick with tabs.  But i would have to go check on that. \r\n", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM16528", "user": "CyrusNajmabadi", "root": "ROOT165", "reply_to": "COM16527", "timestamp": "2021-02-23T23:03:39Z", "text": "> This is with Always keep TABs option selected. If this is a feature, and not a bug, then someone please explain why, when Always keep TABs is selected, these TABs are being replaced by Spaces?\r\n\r\nI believe this may be a bug or a feature depending on ones perspective.  I certain see how it can be a bug.  However, that doesn't mean that just because it's a bug that it is simple to fix or that it is without consequences if changes are made here.  Again, as i mentioned above, the existing formatting system is highly complex (including with likely bugs in it that many have taken dependencies on).  So changes need to be very judiciously made.", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "COM16529", "user": "CyrusNajmabadi", "root": "ROOT165", "reply_to": "COM16528", "timestamp": "2021-02-23T23:05:36Z", "text": "> This behaviour does not exist in older versions of VS. At some point it has been added by someone, for some reason.\r\nThat was the point at which the user experience was broken.\r\n\r\nThat's quite possible.  My guess is that it happened when we did the entire roslyn rewrite.  We tried to preserve a lot of old behavior, but we very likely did not given the huge complexity in the old system and that the new system takes an entirely different approach on things.  Unfortunately though, we've now had this new system a long time, and we are wary about subjecting people to more potential changes in behavior, esp. as it might fix this issue, only to cause problems for others :-/   It's a tricky situation to be sure!", "meta": {"posReactions": "0", "negReactions": "1"}}
{"id": "ROOT166", "user": "vsfeedback", "root": "ROOT166", "reply_to": null, "timestamp": "2018-08-24T00:40:21Z", "text": "Incorrect formatting of C# comments When you want to disable (but not delete) a field etc in a C# class, you comment it out by writing &quot;//&quot; at the start of the line, but this causes VS 15.8.0 to incorrectly format the line when the previous line ends with a comment.  You can understand this much easier when you look at my screenshot attached.\r \r To reproduce this bug, first put this class in a .cs file:\r \r ```csharp\r class ExampleClass1\r {\r     int ExampleField1;\r     int ExampleField2;  // Some comment here.\r     //int ExampleField3;\r     int ExampleField4;\r }\r ```\r \r Then select the text (select the entire class).  Then click menubar -&gt; Edit -&gt; Advanced -&gt; Format Selection.  VS changes the class to:\r \r ```csharp\r class ExampleClass1\r {\r     int ExampleField1;\r     int ExampleField2;  // Some comment here.\r                         //int ExampleField3;\r     int ExampleField4;\r }\r ```\r \r ![image](https://user-images.githubusercontent.com/12449387/44558946-c3655400-a6fb-11e8-9a75-b6960e057a2d.png)\r \r \r The bug also occurs when VS formats the class at other times, not only the &quot;Format Selection&quot; command.  See the &quot;Automatically format when/on XXXXX&quot; options in menubar -&gt; Tools -&gt; Options -&gt; Text Editor -&gt; C# -&gt; Code Style -&gt; Formatting -&gt; General.\r \r Thanks for investigating this!\r \r _This issue has been moved from https://developercommunity.visualstudio.com/content/problem/317225/incorrect-formatting-of-c-comments.html\r VSTS ticketId: 668245_\r _These are the original issue comments:_\r \r Etienne Poirier on 8/21/2018, 04:35 PM (2 days ago): <p>Same issue as </p><p><a target='_blank' href=\"https://developercommunity.visualstudio.com/content/problem/317225/https://developercommunity.visualstudio.com/content/problem/20554/line-comments-unwantedly-align-to-comment-above-in.html\">https://developercommunity.visualstudio.com/content/problem/20554/line-comments-unwantedly-align-to-comment-above-in.html</a></p><p>Thank you to check this.</p>\r \r _These are the original issue solutions:_\r (no solutions)", "meta": {"posReactions": "5", "negReactions": "0"}}
{"id": "COM1660", "user": "CyrusNajmabadi", "root": "ROOT166", "reply_to": "ROOT166", "timestamp": "2018-08-24T01:24:39Z", "text": "This seems by design to me...  it's a common pattern to have multi-line comments at the end of constructs, and to align them across multiple lines.\r\n\r\nIn this case, we don't really have any way to know or believe that this isn't one of those cases, and aligning the comments as shown seems reasonable in terms of respecting the common pattern that is out there.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1661", "user": "jinujoseph", "root": "ROOT166", "reply_to": "COM1660", "timestamp": "2018-09-03T09:15:49Z", "text": "~~Also referred [here](https://developercommunity.visualstudio.com/content/problem/324827/vs2017-undesired-reformatting-when-uncommenting-a.html)~~ (edit: this was moved to #29647)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1662", "user": "verelpode", "root": "ROOT166", "reply_to": "COM1661", "timestamp": "2018-09-05T21:54:01Z", "text": "> This seems by design to me...\r\n\r\nI can't really agree with you because VS 15.8.2 also does it when the first comment is single-line `//` and the second comment is multi-line `/* */`\r\nThe following shows the result after executing the \"Format Document\" command:\r\n```\r\nint ExampleField2;  // Some comment here.\r\n                    /*\r\n                    int ExampleField3;\r\n                    int ExampleField4;\r\n                    int ExampleField5;\r\n                    */\r\n\r\n```\r\n\r\nI don't believe that anyone wants the above formatting.\r\n\r\n>  it's a common pattern to have multi-line comments at the end of constructs, and to align them across multiple lines.\r\n\r\nI never do that, and apparently multiple other people also never do that, therefore I suggest making a checkbox in the Options window, so that people can simply switch this behavior on or off as desired. \r\nHowever, in my opinion, the mixed example above seems to be a bug not a feature.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1663", "user": "dibarbet", "root": "ROOT166", "reply_to": "COM1662", "timestamp": "2019-02-05T18:53:31Z", "text": "@sharwell do you recall if there was an outcome for this in design review, or does it still need to be discussed?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1664", "user": "sharwell", "root": "ROOT166", "reply_to": "COM1663", "timestamp": "2019-02-05T19:28:15Z", "text": "@dibarbet This one is still in the queue", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1665", "user": "dibarbet", "root": "ROOT166", "reply_to": "COM1664", "timestamp": "2019-02-05T19:30:11Z", "text": "Thanks for confirming, wanted to make sure.  I'll park these 2 until the next meeting then.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1666", "user": "sharwell", "root": "ROOT166", "reply_to": "COM1665", "timestamp": "2019-04-08T19:28:45Z", "text": "I'm bringing this to a design review today. My proposal is as follows:\r\n\r\n* The current behavior is generally by design\r\n* We could modify the current behavior in the case where a line comment starting with a space is followed by a line comment _not_ starting with a space:\r\n\r\n    ```csharp\r\n    int x; // This comment starts with a space\r\n           //This comment did not start with a space\r\n    ```\r\n\r\n    For this case, the first line comment not starting with a space would be aligned with `int` instead of the current behavior of aligning it with `//`.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1667", "user": "CyrusNajmabadi", "root": "ROOT166", "reply_to": "COM1666", "timestamp": "2019-04-08T19:29:57Z", "text": "Note that some linters will complain if you don't start your comment without a space.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1668", "user": "sharwell", "root": "ROOT166", "reply_to": "COM1667", "timestamp": "2019-04-08T19:32:35Z", "text": "@CyrusNajmabadi Other linters will complain about comments at the end of a line of code. Most relevant to this issue though is the fact that most cases where I've seen this reported as a bug, including the original example above, do not have a space on the line of code that the user did not want to see indented.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1669", "user": "verelpode", "root": "ROOT166", "reply_to": "COM1668", "timestamp": "2019-04-08T19:45:51Z", "text": "> most cases where I've seen this reported as a bug, including the original example above, do not have a space on the line of code that the user did not want to see indented.\r\n\r\nThat's an interesting pattern observation, but I think you'd like to see this issue fixed and terminated forever, but I fear that if the solution relies upon whether or not that particular space character exists, then it will be precarious and this issue will in future again be reported as a bug, instead of being laid to rest permanently.  Did you dislike the idea of solving it via a tickable option in the Options window?\r\n\r\nAnother case to remember is **mixed** comment types, such as the following example.  The solution for mixed comments appears to be simple and unambiguous and does not require an option in the Options window.  If the second comment is a different type than the first comment, then the second comment should **never** be indented to match the first comment, thus VS should never produce the following:\r\n```\r\nint ExampleField2;  // Some comment here.\r\n                    /*\r\n                    int ExampleField3;\r\n                    int ExampleField4;\r\n                    int ExampleField5;\r\n                    */\r\n```\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16610", "user": "verelpode", "root": "ROOT166", "reply_to": "COM1669", "timestamp": "2019-04-08T20:02:24Z", "text": "If the idea of putting it in the Options window is rejected, then I'm trying to brainstorm an alternative solution, and I thought about _maybe_ making VS look for a tab character in the place marked with \"\\t\" following:\r\n```\r\nint x;\\t// This comment is preceded by one or more tab characters.\r\n// This comment would never be aligned with the previous comment.\r\n\r\nint x; // This comment is preceded by one or more space characters.\r\n       // This comment would be aligned with the previous comment.\r\n```\r\n\r\nOn my computer, I have `Options -> Text Editor -> C# -> Tabs` set to \"Keep tabs\".  I can't stand the \"Insert spaces\" option.  I always use tab in-between \";\" and \"// comment\".  Despite the fact that I have VS set to \"Keep tabs\", when I copy & paste a line or otherwise trigger VS to format the line, VS changes my tabs to spaces.  I wish it wouldn't do that.\r\n\r\nI write it with tabs like this:\r\n```\r\nint x;\\t\\t// Comment. \r\n```\r\n...and VS 2019 changes my tabs to spaces against my wishes:\r\n```\r\nint x;     // Comment. \r\n```\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16611", "user": "CyrusNajmabadi", "root": "ROOT166", "reply_to": "COM16610", "timestamp": "2019-04-08T20:09:54Z", "text": "I thnk i'd much rather have the rule that the `//`s are aligned if they abut.  BUt not if there's a blank line between them.  So, if you have:\r\n\r\n```c#\r\nint foo; //a comment\r\n         //this follow the above\r\n```\r\n\r\nand\r\n\r\n```c#\r\nint foo; //a comment\r\n\r\n//this does not\r\n```\r\n\r\nNeeding to understand that having a space (or not) would affect alignment of comments seems super strange to me.  Whereas, if there's this obvious gap between them, it would make it much more clear if they were intended to *not* be together.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16612", "user": "CyrusNajmabadi", "root": "ROOT166", "reply_to": "COM16611", "timestamp": "2019-04-08T20:10:25Z", "text": "> Another case to remember is mixed comment types,\r\n\r\nYes, i think i would agree that mixed comment types should not align here.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16613", "user": "verelpode", "root": "ROOT166", "reply_to": "COM16612", "timestamp": "2019-04-08T20:13:30Z", "text": "Wait, here is another alternative solution, better than my previous brainstorming.\r\nVS would only increase the indenting of a comment if it is _already_ indented by at least one space or tab char.  Example:\r\n```\r\nint x;  // First comment.\r\n    // VS would align this comment with the first comment because it is already indented.\r\n\r\nint y; // Blah blah.\r\n// This comment would never be aligned with the previous comment.\r\n```\r\n\r\nThus the final result is:\r\n```\r\nint x;  // First comment.\r\n        // VS would align this comment with the first comment because it is already indented.\r\n\r\nint y; // Blah blah.\r\n// This comment would never be aligned with the previous comment.\r\n```\r\n\r\nIn other words, if a comment is aligned with \"int x;\" then it remains at that level, but if it already indented beyond \"int x;\" by one or more space or tabs, then VS aligns it with the previous comment.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16614", "user": "verelpode", "root": "ROOT166", "reply_to": "COM16613", "timestamp": "2019-04-08T20:20:47Z", "text": "> Needing to understand that having a space (or not) would affect alignment of comments seems super strange to me. Whereas, if there's this obvious gap between them, it would make it much more clear if they were intended to not be together.\r\n\r\nI agree, but that's identical to the current behavior of VS 2019, therefore it would continue to trigger bug reports.  So how about making VS only increase the indenting of a comment when it is _already_ indented further right than `int x;` ?    If a comment is currently exactly aligned with `int x;`, then why should VS think that a preexisting exact alignment is incorrect?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16615", "user": "verelpode", "root": "ROOT166", "reply_to": "COM16614", "timestamp": "2019-04-08T20:43:22Z", "text": "Note that if the formatting of comments is influenced by the preexisting formatting/spacing (in the manner as I described above), then this behavior is _not at all_ unusual nor inconsistent with other VS formatting behavior, because VS formatting is _already_ influenced by the preexisting spacing.  For example, when I run the \"Format Selection\" command on the following code in VS 2019 on my own computer, VS doesn't change the code at all.  VS respects the fact that I wrote TestProperty2 on a single line and it leaves it on a single line.\r\n\r\n```\r\nint TestProperty1\r\n{\r\n    get\r\n    {\r\n        return 123;\r\n    }\r\n}\r\n\r\nint TestProperty2 { get { return 456654; } }\r\n```\r\n\r\nIn the same way as VS retains my preexisting formatting of a property, it can retain my preexisting formatting of a comment.\r\n```\r\nint x; // Blah blah.\r\n// This comment is already exactly aligned with \"int x;\" \r\n// thus there is NO reason to think it's wrongly aligned.\r\n\r\nint y;   // another comment\r\n   // this comment does look wrong and should be reformatted.\r\n```\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16616", "user": "CyrusNajmabadi", "root": "ROOT166", "reply_to": "COM16615", "timestamp": "2019-04-08T20:45:36Z", "text": "@verelpode in general we haven't had that concept in the formatting engine yet.  But i'm personally amenable to it.  I think it's a reasonable approach that would give the user some level of control here in a manner that would be reasonably intuitive.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16617", "user": "sharwell", "root": "ROOT166", "reply_to": "COM16616", "timestamp": "2019-04-08T21:05:27Z", "text": "**Design review summary:**\r\n\r\nThe current general recommended approach is to add a blank line before the comment which should not have the extra indentation. However, to address the specific issue here, we would take a pull request which added a conditional formatting rule where comments _already aligned_ where code would be indented on the same line will anchor at that location instead of the current behavior of anchoring to the trailing comment on the preceding line.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16618", "user": "verelpode", "root": "ROOT166", "reply_to": "COM16617", "timestamp": "2019-04-08T21:15:30Z", "text": "Great, I think this solution will successfully prevent this issue being reported in future again as a bug.  To my surprise, it was even possible to satisfy all users automatically without the burden of creating yet another option in the Options window.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16619", "user": "HappyNomad", "root": "ROOT166", "reply_to": "COM16618", "timestamp": "2019-05-09T19:13:27Z", "text": "This horribly annoying behavior in Visual Studio bothered me multiple times today.  It's so unbelievably annoying!  I'll upgrade to VS 2019 just for this improvement once it's available.  I'm anxiously awaiting.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16620", "user": "jcouv", "root": "ROOT166", "reply_to": "COM16619", "timestamp": "2019-07-14T05:10:05Z", "text": "I've encountered this problem in Roslyn as well. The current behavior is annoying. See `CS1720WRN_DotOnDefault02` for an example.\r\n\r\nOriginal code (with formatting warning):\r\n![image](https://user-images.githubusercontent.com/12466233/61179603-87a8d680-a5ba-11e9-8e5e-7f2c7d2e1316.png)\r\n\r\n`1>C:\\repos\\roslyn\\src\\Compilers\\CSharp\\Test\\Semantic\\Semantics\\SemanticErrorTests.cs(21922,17,21922,17): warning IDE0055: Fix formatting`\r\n\r\nCode with formatting fix applied, but undesirable formatting:\r\n![image](https://user-images.githubusercontent.com/12466233/61179606-9e4f2d80-a5ba-11e9-88f9-a880063ea6e2.png)\r\n\r\nThis is using 16.2p3.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16621", "user": "jinujoseph", "root": "ROOT166", "reply_to": "COM16620", "timestamp": "2019-09-10T01:11:25Z", "text": "also reported [DC](https://developercommunity.visualstudio.com/content/problem/719204/comment-code-style.html) ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16622", "user": "HappyNomad", "root": "ROOT166", "reply_to": "COM16621", "timestamp": "2019-10-31T04:27:48Z", "text": "@jinujoseph Why is it moved to the backlog?  This keeps coming up and it is SO ANNOYING.  How about just adding an option to turn this nonsense off?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16623", "user": "CyrusNajmabadi", "root": "ROOT166", "reply_to": "COM16622", "timestamp": "2019-10-31T07:08:33Z", "text": "@ChainReactive as mentioned in this post here: https://github.com/dotnet/roslyn/issues/29482#issuecomment-481007848\r\n\r\n> The current general recommended approach is to add a blank line before the comment which should not have the extra indentation. However, to address the specific issue here, we would take a pull request which added a conditional formatting rule where comments already aligned where code would be indented on the same line will anchor at that location instead of the current behavior of anchoring to the trailing comment on the preceding line.\r\n\r\nIn other words, if a community member wanted to contribute such a PR, roslyn would take it.  however, absent that, the advice would be to just put in a blank line in the code.  \r\n\r\nIf this is something you are passionate about (which seem evidenced by https://github.com/dotnet/roslyn/issues/29482#issuecomment-491030328 and https://github.com/dotnet/roslyn/issues/29482#issuecomment-548212118) perhaps you would be willing to help out here with a PR yourself?  \r\n\r\nNote that there are a couple of good channels to help out people working to contribute toward roslyn (internal and external alike):\r\n\r\ngitter.im/dotnet/roslyn and\r\naka.ms/csharp-discord\r\n\r\nCheers!", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM16624", "user": "HappyNomad", "root": "ROOT166", "reply_to": "COM16623", "timestamp": "2019-10-31T07:39:17Z", "text": "@CyrusNajmabadi, @sharwell  Visual Studio is a commercial product with a dedicated team on staff at Microsoft.  I'm not already familiar with Roslyn, nor do I have time to dive down that rabbit hole.  The people who's job it is to improve Visual Studio's user experience would be better equipped to fix this.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16625", "user": "CyrusNajmabadi", "root": "ROOT166", "reply_to": "COM16624", "timestamp": "2019-10-31T08:10:13Z", "text": "> @CyrusNajmabadi, @sharwell Visual Studio is a commercial product with a dedicated team on staff at Microsoft.\r\n\r\nIt's also an open source project with a community that actively contributes to it and provides PRs when their needs don't align with the priorities of the main team itself.  I'm one of those people and have contributed as an external community member a large number of times.\r\n\r\nAs i've already pointed out, the stated view of the team is that there is an easy workaround if hte current behavior is undesirable to you.  If that workaround is not tenable and you want to see this fixed, it will have to come from a PR from someone willing to view the change as valuable enough to invest their own time.\r\n\r\nI personally don't feel like it's worth fixing myself, but i'd be happy to help you with a PR to change if it is something that is affecting you.\r\n\r\n> The people who's job it is to improve Visual Studio's user experience \r\n\r\nAs an open source project, \"the people\" includes the community (including you, me, and other interested parties).  \r\n\r\n> would be better equipped to fix this.\r\n\r\nYes, that's likely true.  But they're also tasked with work felt to be more important and a more valuable use of their time.  And so here we are. ", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM16626", "user": "HappyNomad", "root": "ROOT166", "reply_to": "COM16625", "timestamp": "2019-10-31T09:07:23Z", "text": "@CyrusNajmabadi I'd welcome your assistance in making up for Microsoft's negligence.  As I've already mentioned, I don't have time to get into Roslyn.  How about I send you my kudos once you fix this bug?  But if your Roslyn skills aren't up to stuff, then don't worry about it.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM16627", "user": "CyrusNajmabadi", "root": "ROOT166", "reply_to": "COM16626", "timestamp": "2019-10-31T09:40:02Z", "text": "> @CyrusNajmabadi I'd welcome your assistance in making up for Microsoft's negligence. \r\n\r\nTeams prioritizing things different from you is not negligence.  There are millions of users and thousands of signals indicating what is valuable and important to actually address with the resources available.  This minor issue simply isn't one of those.  I can imagine you probably have to make similar decisions in your own work when deciding where to allocate your own resources.\r\n\r\n> How about I send you my kudos once you fix this bug? \r\n\r\nI am personally not interesting in contributing a PR here.  Primarily because i don't find the behavior particularly problematic, nor do i feel that the workaround is insufficient.\r\n\r\nStill happy to help you out at any point if you change you mind.  The links to the channels still apply.   Cheers!", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM16628", "user": "CyrusNajmabadi", "root": "ROOT166", "reply_to": "COM16627", "timestamp": "2019-10-31T09:42:25Z", "text": "> But if your Roslyn skills aren't up to stuff, then don't worry about it.\r\n\r\nWhen it comes to this area, they may not be.  Hence why I was offering to work through it with you.  Two minds being better than one and all that :)  \r\n\r\nCheers and good luck!  If you change your mind, just let me know! :)", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM16629", "user": "HappyNomad", "root": "ROOT166", "reply_to": "COM16628", "timestamp": "2019-10-31T10:13:29Z", "text": "> Teams prioritizing things different from you is not negligence\r\n\r\nI disagree with you on this in the current context.  The (ir)responsible team at Microsoft is neglecting a lot of users by not fixing this bug.  Just google \"visual studio c# turn off align comments\" to see.\r\n\r\n> This minor issue simply isn't one of those.\r\n\r\nIt is a \"minor issue\" in that it'd be easy for them to fix, although the choose not to.  It's not a \"minor issue\" in that it is indeed super annoying.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT167", "user": "WangJincheng4869", "root": "ROOT167", "reply_to": null, "timestamp": "2021-02-01T06:44:57Z", "text": "\u5173\u4e8e\u5fae\u8f6f\u5e94\u7528\u5546\u5e97\u8bed\u8a00\u7b80\u6d01\u7684\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u5efa\u8bae\uff0c\u8bf7\u5c06\u3010\u4e2d\u6587\uff08\u53f0\u6e7e\uff09\u3011\u6539\u4e3a\u3010\u4e2d\u6587\uff08\u7e41\u4f53\uff09\u3011\uff0c\u8c22\u8c22\uff01 <!-- Briefly describe which document needs to be corrected and why. -->\r \u53f0\u6e7e\u5c5e\u4e8e\u4e2d\u56fd![image](https://user-images.githubusercontent.com/41162158/106423712-f0f18280-649b-11eb-8104-97003199f862.png)\r \u4fee\u6539\u4e3a\u3010\u4e2d\u6587\uff08\u7e41\u4f53\uff09\u3011\u66f4\u4e3a\u8d34\u5207\r \r ![image](https://user-images.githubusercontent.com/41162158/106423689-e636ed80-649b-11eb-93e7-7c536a332a3b.png)\r ", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM1670", "user": "skyline75489", "root": "ROOT167", "reply_to": "ROOT167", "timestamp": "2021-02-01T15:17:27Z", "text": "Technically \u201c\u7e41\u4f53\u201d is more accurate since it\u2019s used in various regions like HongKong & Taiwan. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1671", "user": "castiel652", "root": "ROOT167", "reply_to": "COM1670", "timestamp": "2021-02-01T16:44:30Z", "text": "> Technically \u201c\u7e41\u4f53\u201d is more accurate since it\u2019s used in various regions like HongKong & Taiwan.\r\n\r\nShould also change \u4e2d\u6587\uff08\u4e2d\u56fd\uff09to \u4e2d\u6587\uff08\u7b80\u4f53\uff09since not only China uses it. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1672", "user": "DHowett", "root": "ROOT167", "reply_to": "COM1671", "timestamp": "2021-02-01T20:47:24Z", "text": "@skyline75489 Mind helping me with a translation? I believe the request is, \"the language list inside the Store is incorrect for Chinese\"\r\n\r\nIf so, I will need to forward this to the Store team; we do not control the specifics of that list -- just checkboxes for \"yes, no\" for each language.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1673", "user": "skyline75489", "root": "ROOT167", "reply_to": "COM1672", "timestamp": "2021-02-02T00:00:08Z", "text": "@DHowett With pleasure. Basically the issue is about the supported language list being misleading by marking Simplified Chinese as \u201c\u4e2d\u6587\uff08\u4e2d\u56fd\uff09\u201d aka Chinese\uff08China\uff09,and marking Traditional Chinese as \u201c\u4e2d\u6587\uff08\u53f0\u6e7e\uff09\u201d aka Chinese(Taiwan). This is technically misleading and incorrect. \r\n\r\nMore commonly we see Simplified Chinese as \u201c\u4e2d\u6587\uff08\u7b80\u4f53\uff09\u201d and Traditional Chinese as \u201c\u4e2d\u6587\uff08\u7e41\u4f53\uff09, which is region-neutral. But if the supported language list is designed to be (language, region) pair, I think we should mark at least Taiwan as a region instead of a country. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1674", "user": "WangJincheng4869", "root": "ROOT167", "reply_to": "COM1673", "timestamp": "2021-02-02T01:34:13Z", "text": "\u6ca1\u9519\u76f4\u63a5\u53eb\u3010\u4e2d\u6587\uff08\u7b80\u4f53\uff09\u3011\u548c\u3010\u4e2d\u6587\uff08\u7e41\u4f53\uff09\u3011\u6bd4\u8f83\u597d\uff0c\u53eb\u6cd5\u4e0a\u6ca1\u6709\u4efb\u4f55\u6b67\u4e49\u3002\r\n\r\n\u5982\u4e0bEdge\u8fd9\u79cd\u53eb\u6cd5\u5c31\u5f88\u597d\uff0c\u8c01\u4e5f\u4e0d\u5f97\u7f6a\u3002\r\n![image](https://user-images.githubusercontent.com/41162158/106540041-17fe9180-653a-11eb-8f9b-bd49fdb350ed.png)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1675", "user": "yhmtsai", "root": "ROOT167", "reply_to": "COM1674", "timestamp": "2021-02-02T07:21:22Z", "text": "I don't think so. and the term is \u7e41\u9ad4 in traditional Chinese.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1676", "user": "KeyuanHuang", "root": "ROOT167", "reply_to": "COM1675", "timestamp": "2021-02-05T14:37:17Z", "text": "\u4f46\u662f\u53f0\u6e7e\u548c\u9999\u6e2f\u7684\u7e41\u4f53\u662f\u6709\u4e9b\u4e0d\u540c\u7684\uff0c\u7279\u522b\u662f\u5728\u8bcd\u6c47\u65b9\u9762\u3002\u6211\u89c9\u5f97\u53eb\u505a\u3010\u4e2d\u6587\uff08\u4e2d\u56fd\u53f0\u6e7e\uff09\u3011\u548c\u3010\u4e2d\u6587\uff08\u4e2d\u56fd\u9999\u6e2f\uff09\u3011\u5c31\u597d\u4e86\u3002", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1677", "user": "castiel652", "root": "ROOT167", "reply_to": "COM1676", "timestamp": "2021-02-06T07:33:55Z", "text": "> \u4f46\u662f\u53f0\u6e7e\u548c\u9999\u6e2f\u7684\u7e41\u4f53\u662f\u6709\u4e9b\u4e0d\u540c\u7684\uff0c\u7279\u522b\u662f\u5728\u8bcd\u6c47\u65b9\u9762\u3002\u6211\u89c9\u5f97\u53eb\u505a\u3010\u4e2d\u6587\uff08\u4e2d\u56fd\u53f0\u6e7e\uff09\u3011\u548c\u3010\u4e2d\u6587\uff08\u4e2d\u56fd\u9999\u6e2f\uff09\u3011\u5c31\u597d\u4e86\u3002\r\n\r\nThere's no \u4e2d\u56fd\u53f0\u6e7e", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1678", "user": "DHowett", "root": "ROOT167", "reply_to": "COM1677", "timestamp": "2021-02-06T07:36:29Z", "text": "This seems like it could become a geopolitical issue, so I am going to lock this thread before it does. I will engage the Store team about the wording here. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT168", "user": "whytewolf", "root": "ROOT168", "reply_to": null, "timestamp": "2018-04-18T17:41:31Z", "text": "pkg.install on Arch upgrades full OS as a default option. ### Description of Issue/Question\r On Arch Linux running `pkg.install vim refresh=true` will upgrade the entire OS instead of just installing the latest version of vim. This does not follow the other package managers and becomes unintuitive when dealing with multiple Linux distros. \r \r This behavior is documented. However, It doesn't follow the standard that other pkg modules use for full os upgrade.\r \r ### Setup\r run `pkg.install vim refresh=true` \r want vim, get os upgrade.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1680", "user": "whytewolf", "root": "ROOT168", "reply_to": "ROOT168", "timestamp": "2018-04-18T17:41:52Z", "text": "ZD-2445", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1681", "user": "gtmanfred", "root": "ROOT168", "reply_to": "COM1680", "timestamp": "2018-04-19T12:25:50Z", "text": "Yes, that is correct That should be the defaults on arch, if you refresh, you need to do an upgrade, otherwise you end up with broken so names because pacman does not resolve upgrades to sonames and force other packages to upgrade.\r\n\r\nIf you want to do only a refresh and install, and not upgrade you can end up with an unbootable system, but you can do this by setting `sysupgrade=False` on the commandline with the `refresh=true`", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1682", "user": "gtmanfred", "root": "ROOT168", "reply_to": "COM1681", "timestamp": "2018-04-19T12:28:25Z", "text": "https://gist.github.com/vodik/5660494  Here is the story that archlinux maintainers and people in #archlinux on freenode give to people that -Sy instead of -Syu.\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1683", "user": "rhaig", "root": "ROOT168", "reply_to": "COM1682", "timestamp": "2018-04-25T18:12:17Z", "text": "By not doing what the command line tools do, you are varying from the expected behavior and breaking convention. THIS IS WRONG.\r\n\r\n\r\nYour belief that you're doing anyone a favor by varying from the expected command line tool behavior, you should turn in your commit per.issions and get a job in management where you don't have access to break things AGAIN.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1684", "user": "terminalmage", "root": "ROOT168", "reply_to": "COM1683", "timestamp": "2018-04-25T18:41:33Z", "text": "We could make `sysupgrade=False` the default, but then we'd have a lot _more_ people complaining about broken systems from unsupported partial upgrades (though, likely with far more tact than you displayed).\r\n\r\nPlease read this [article](https://wiki.archlinux.org/index.php/System_maintenance#Partial_upgrades_are_unsupported) from the ArchWiki so that you can better understand the reason for making `sysupgrade=True` the default.\r\n\r\nHave a nice day!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT169", "user": "worl4125", "root": "ROOT169", "reply_to": null, "timestamp": "2019-10-21T22:27:52Z", "text": "Forum Login Issue When attempting to log into my forum account, I get the error message:\r \r \"You can't log in as <username> from that IP address.\" (see screen shot below)\r \r ![image](https://user-images.githubusercontent.com/19894000/67247366-28ffbe00-f42f-11e9-8612-814071b1a2e4.png)\r \r This occurs across all browsers that I have (Firefox, Chrome, and Edge). All browsers are up to date. Clearing the cache and history sometimes resolves this; sometimes it doesn't. And even if it does resolve the issue, it's a one time thing only. As soon as I log out and attempt to log back in, the same error pops up again.\r \r This issue started several days ago out of the blue. No changes to my system at the time that might account for this. This issue is exclusive to log in attempts to my forum account. I can log into the lessons/project side of freecodecamp without issue and I'm having no issues accessing anything else on the web. \r \r Any thoughts on what I might be dealing with here?\r Thanks in advance. \r ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1690", "user": "raisedadead", "root": "ROOT169", "reply_to": "ROOT169", "timestamp": "2019-10-21T23:05:05Z", "text": "Hi @worl4125 \r\n\r\nThanks for reporting. Yes, you are correct.\r\n\r\n#### TL;DR:\r\n\r\nThis is a known issue, and the dev team is working on it.\r\n\r\n#### Details:\r\n\r\nWe recently moved over our servers to a different infrastructure with the new platform roll out earlier last week. As a consequence, your IP addresses are masked by our CDN servers from the forum.\r\n\r\nDuring peak usage, this means the forum sees this as too many sign in requests from the same IPs which belong to our CDN servers. \r\n\r\nThis is a false positive.\r\n\r\nAs of now this stands as a known issue, we are working with various teams to get this fixed.\r\n\r\nThanks a lot for your patience.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1691", "user": "raisedadead", "root": "ROOT169", "reply_to": "COM1690", "timestamp": "2019-10-21T23:22:46Z", "text": "Temporarily updated the message to be less cryptic for users:\r\n\r\n![image](https://user-images.githubusercontent.com/1884376/67250106-c38beb80-f487-11e9-90fa-01ce3cba749b.png)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1692", "user": "LuosRestil", "root": "ROOT169", "reply_to": "COM1691", "timestamp": "2019-10-21T23:44:33Z", "text": "Just read this with the same issue, and I see that the sign in error message should be changed, but I'm still getting the same \"You can't log in as ****** from that IP address.\"", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1693", "user": "raisedadead", "root": "ROOT169", "reply_to": "COM1692", "timestamp": "2019-10-21T23:56:55Z", "text": "> [...] but I'm still getting the same [...]\r\n\r\nDo you still the message after a reload of the forum? That message could be cached.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1694", "user": "LuosRestil", "root": "ROOT169", "reply_to": "COM1693", "timestamp": "2019-10-22T02:08:27Z", "text": "I just tried again after reloading, and this time I was allowed to log into the forum, so I can\u2019t confirm whether the message has changed. Thanks for following up!\n\n> On Oct 21, 2019, at 19:03, mrugesh <notifications@github.com> wrote:\n> \n> \ufeff\n> [...] but I'm still getting the same [...]\n> \n> Do you still the message after a reload of the forum? That message could be cached.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub, or unsubscribe.\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1695", "user": "mikehaart", "root": "ROOT169", "reply_to": "COM1694", "timestamp": "2019-10-22T10:22:59Z", "text": "I had the same problem 18 hours ago but managed to circumvent the issue by using opera's free VPN. Oddly enough that is also blocked now and I'm getting the same message.\r\n<img width=\"505\" alt=\"Screenshot 2019-10-22 at 11 21 32\" src=\"https://user-images.githubusercontent.com/17619758/67277238-49c32480-f4be-11e9-820c-b7f821b8eeae.png\">\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT170", "user": "WrongBit", "root": "ROOT170", "reply_to": null, "timestamp": "2019-10-31T10:39:25Z", "text": "Too tricky explanation of Win32 support Knowing MS style of \"avoiding inconvenient facts\", I want to see in description of WinUI **explicit declaration** what Windows versions will be supported.\r As everybody knows, Win10 fails in many aspects and TONS of people still sit in Win7x64. I want to know will WinUI work on Win7 and all necessary details if this \"support\" will be limited/tricky some way.", "meta": {"posReactions": "1", "negReactions": "7"}}
{"id": "COM1700", "user": "mdtauk", "root": "ROOT170", "reply_to": "ROOT170", "timestamp": "2019-10-31T10:59:23Z", "text": "WinUI is Windows 10 onwards.\r\n\r\nI think it will support the Creators Update (**15063**) onwards.  But it is possible that as a new version of Windows 10 comes out, the lowest supported version may be dropped.  So that would be roughly 3 years of previous versions supported with each release.\r\n\r\nAs for the details of precise Win32 support - we will learn more during Ignite this coming week.\r\n\r\nWindows 7 goes out of support at the end of the year, so if you use Windows 7, you will need to upgrade.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1701", "user": "WrongBit", "root": "ROOT170", "reply_to": "COM1700", "timestamp": "2019-10-31T11:46:06Z", "text": "@mdtauk : I do NOT need to upgrade, you miss the point. Avoiding Win10 is intentional, because I don't want my PC to have buggy, ugly, spying rubbish.\r\n\r\nTech Q: What \"exciting and unique\" you have in Win10 that your GUI lib(!!!) cannot work on Win7? Obviously if your lib so \"independed\" from platform, there is no any problem to support it on Win7. Moreover: Win10 is FAR from be the dominating OS, at least 50% users have Win7. So your library intentionally abuse millions of Win7 users in favor of... what? Pathetic Win10?", "meta": {"posReactions": "0", "negReactions": "7"}}
{"id": "COM1702", "user": "mdtauk", "root": "ROOT170", "reply_to": "COM1701", "timestamp": "2019-10-31T11:50:18Z", "text": "> @mdtauk : I do NOT need to upgrade, you miss the point. Avoiding Win10 is intentional, because I don't want my PC to have buggy, ugly, spying rubbish.\r\n> \r\n> Tech Q: What \"exciting and unique\" you have in Win10 that your GUI lib(!!!) cannot work on Win7? Obviously if your lib so \"independed\" from platform, there is no any problem to support it on Win7. Moreover: Win10 is FAR from be the dominating OS, at least 50% users have Win7. So your library intentionally abuse millions of Win7 users in favor of... what? Pathetic Win10?\r\n\r\nThe short answer is that WinUI relies on the underlying OS, even in it's decoupled state.  WinUI is the UI framework, and can be updated faster than the OS.\r\n\r\nAs for your views about Windows 10, you are entitled to believe what you like, but Windows 7 is coming to an end, and if you do not wish to remain a Windows user, there is macOS and various forms of Linux, for you to choose from.\r\n\r\nI however suspect your comments are a little disingenuous, but I hope I have provided an accurate answer to your query.", "meta": {"posReactions": "3", "negReactions": "0"}}
{"id": "COM1703", "user": "kmgallahan", "root": "ROOT170", "reply_to": "COM1702", "timestamp": "2019-10-31T11:59:38Z", "text": "@WrongBit Review the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). \r\n\r\n> Be respectful: We are a world-wide community of professionals, and we conduct ourselves professionally. Disagreement is no excuse for poor behavior and poor manners.\r\n\r\nThis isn't some Reddit thread for you to vent.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1704", "user": "WrongBit", "root": "ROOT170", "reply_to": "COM1703", "timestamp": "2019-10-31T12:47:15Z", "text": "@mdtauk : I don't know what exactly you count \"disingenuous\" - don't I look fair in my valuation of Win10?? Shortly, it's THE WORST system MS made (after Millenium). That's why I feel disappointed(angry) that you support Win10 and WITHOUT ANY REASON drop support for Win7.\r\nThe fact I cannot call MS to support Win7 DO NOT means 3rd party products (like your) should drop support too. Actually only MS pushes users to Win10 by intentional \"lack of support for 7\", everybody else do. All my programs still work on Win7 and nobody complain \"ah, we need those features from win10!\".\r\nI say that to discover - do you intentionally cut Win7 from plans or you're really depended from something important in Win10 internals. Believe me, if you cut Win7, you'll fail like .NET Core does.", "meta": {"posReactions": "0", "negReactions": "3"}}
{"id": "COM1705", "user": "WrongBit", "root": "ROOT170", "reply_to": "COM1704", "timestamp": "2019-10-31T12:51:50Z", "text": "@kmgallahan : Sorry, but speaking about \"professionals\" better TO BE professional. I have doubts you are, because you miss absolutely tech question, which I can cite AGAIN:\r\n\r\n> Tech Q: What \"exciting and unique\" you have in Win10 that your GUI lib(!!!) cannot work on Win7?\r\n\r\nAnd funny, but NOT A SINGLE ANSWER were given by... hm... \"professionals\". Maybe you will?", "meta": {"posReactions": "0", "negReactions": "2"}}
{"id": "COM1706", "user": "maxkatz6", "root": "ROOT170", "reply_to": "COM1705", "timestamp": "2019-10-31T12:57:37Z", "text": "> All my programs still work on Win7 and nobody complain \"ah, we need those features from win10!\".\r\n\r\nSo, that's answer. You just do not need \"features from win10\" like WinUI. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1707", "user": "kmgallahan", "root": "ROOT170", "reply_to": "COM1706", "timestamp": "2019-10-31T12:57:46Z", "text": "@WrongBit I have no desire to provide a professional response based on your attitude. You really need to take a step back and consider how you present yourself publicly. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1708", "user": "mdtauk", "root": "ROOT170", "reply_to": "COM1707", "timestamp": "2019-10-31T14:36:55Z", "text": "@WrongBit  WinUI has dependencies on APIs, code, and systems that were built for Windows 10, and require Windows 10 to function.\r\n\r\nWPF and WinForms frameworks are there and open which support Windows 7 for the time being.  These frameworks were supported when Windows 7 was being developed, and this is why support is being maintained, but WinUI is the WinRT/UWP core that was built for Windows 10, and in the future, will be open sourced  and updated at a faster cadence than the OS.\r\n\r\nIf what you would like to ask for, in a polite and \"professional\" manner, is the back-porting of WinUI 3.0 to allow it to run on Windows 7, that is what you can do.\r\n\r\nHowever as Microsoft is soon to be ending it's support of Windows 7, you should probably expect that request to be turned down.  And in the next 5 years or so, Winforms, WPF, and other Microsoft software will also end support for Windows 7.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1709", "user": "jevansaks", "root": "ROOT170", "reply_to": "COM1708", "timestamp": "2019-10-31T16:14:26Z", "text": "@WrongBit please refer to the [Code of Conduct](https://opensource.microsoft.com/codeofconduct/), specifically the Be Respectful section. This is not the right forum to complain about Windows 10 in general.\r\n\r\nIt is true that Windows 7 is still in use. But it goes out of support soon and so WinUI won't support it either. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT171", "user": "x1024", "root": "ROOT171", "reply_to": null, "timestamp": "2019-12-19T13:04:01Z", "text": "100% Reproducible crash on Mac OS Catalina that happens on projects with more than 1024 files in them. Just kidding, bring the hat back.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1710", "user": "nkkollaw", "root": "ROOT171", "reply_to": "ROOT171", "timestamp": "2019-12-19T13:28:26Z", "text": "\ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85 \ud83c\udf85", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1711", "user": "robertodormepoco", "root": "ROOT171", "reply_to": "COM1710", "timestamp": "2019-12-19T13:39:05Z", "text": "i don't even like christmas, i'm just into cool hats", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1712", "user": "pietrodellanotte", "root": "ROOT171", "reply_to": "COM1711", "timestamp": "2019-12-19T13:45:38Z", "text": "![hat](https://user-images.githubusercontent.com/54886974/71178491-9634a180-226e-11ea-8223-fa99e4f93f68.PNG)\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1713", "user": "kieferrm", "root": "ROOT171", "reply_to": "COM1712", "timestamp": "2019-12-19T22:57:23Z", "text": "Thanks for creating this issue. We think this issue is unactionable or unrelated to the goals of this project. Please follow our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.\r\n\r\nHappy Coding!", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT172", "user": "Xispeo", "root": "ROOT172", "reply_to": null, "timestamp": "2017-08-23T09:53:27Z", "text": "Fail to compile under VS2017 Hello,\r \r Upgraded a couple of days ago Unity to 2017.1, HoloToolkit to MixedRealityToolkit release 1 and Visual Studio to 2017 and cannot compile under VS with the guideline workflow : \r \r 2>CSC : error CS0006: Metadata file '***\\Unity\\WindowsStoreApp\\GeneratedProjects\\UWP\\Assembly-CSharp-firstpass\\bin\\x86\\Debug\\Assembly-CSharp-firstpass.dll' could not be found\r 3>------ Build started: Project: AdB, Configuration: Debug x86 ------\r 3>CSC : error CS0006: Metadata file '***\\Unity\\WindowsStoreApp\\GeneratedProjects\\UWP\\Assembly-CSharp-firstpass\\bin\\x86\\Debug\\Assembly-CSharp-firstpass.dll' could not be found\r 3>CSC : error CS0006: Metadata file '***\\Unity\\WindowsStoreApp\\GeneratedProjects\\UWP\\Assembly-CSharp\\bin\\x86\\Debug\\Assembly-CSharp.dll' could not be found", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1720", "user": "Xispeo", "root": "ROOT172", "reply_to": "ROOT172", "timestamp": "2017-08-23T15:41:16Z", "text": "So after having read workaround solutions I switched back to VS2015 and now have : \r\n***\\HoloToolkit\\Utilities\\Scripts\\ApplicationViewManager.cs(52,62,52,64): error CS1003: Syntax error, ',' expected\r\n***\\HoloToolkit\\Utilities\\Scripts\\ApplicationViewManager.cs(88,17,88,21): error CS1547: Keyword 'void' cannot be used in this context\r\n***\\HoloToolkit\\Utilities\\Scripts\\ApplicationViewManager.cs(88,50,95,85): error CS1528: Expected ; or = (cannot specify constructor arguments in declaration)\r\n***\\HoloToolkit\\Utilities\\Scripts\\ApplicationViewManager.cs(88,50,88,51): error CS1003: Syntax error, '[' expected\r\n***\\HoloToolkit\\Utilities\\Scripts\\ApplicationViewManager.cs(88,102,88,102): error CS1003: Syntax error, '=>' expected\r\n***\\HoloToolkit\\Utilities\\Scripts\\ApplicationViewManager.cs(94,18,94,18): error CS1003: Syntax error, ',' expected\r\n***\\HoloToolkit\\Utilities\\Scripts\\ApplicationViewManager.cs(95,85,95,86): error CS1003: Syntax error, ']' expected\r\n\r\nSo am switching back to previous HoloToolkit packages and will try your MixedRealityToolkit release 2 when it will be available. Lost 2 days ^^", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1721", "user": "StephenHodgson", "root": "ROOT172", "reply_to": "COM1720", "timestamp": "2017-08-23T15:48:59Z", "text": "@Xispeo, what version of Visual Studio are you using? \r\n\r\nAlso for your first issue, did you make sure to switch your build settings back to UWP?  It looks like you're missing/didn't install the windows universal module for unity.\r\n\r\nFor the second issue, Visual Studio 2017 is required for the latest versions of this project.\r\nKeep in mind this [known issue w/Visual Studio 2017.3 and all current Releases of Unity](https://github.com/Microsoft/MixedRealityToolkit-Unity/issues/860).", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1722", "user": "TinyTangS", "root": "ROOT172", "reply_to": "COM1721", "timestamp": "2017-08-24T06:41:54Z", "text": "I also happened with such problem\uff0cit confused me for two days. I had reinstalled VS2017 with 15.3 for many times,but it didn't work. I also tried to update the Unity , but the old project can't be opened without any questions. I had a very long way to find the solution(I also tried VS2015) . At last the VS2017 with 15.0 and the unity 5.6.2 works well in my computer, that is my way to solved this problem. I wish it may be helpful.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1723", "user": "Xispeo", "root": "ROOT172", "reply_to": "COM1722", "timestamp": "2017-08-24T08:02:35Z", "text": "@StephenHodgson as indicated in my previous posts I tried with both VS 2017 and 2015. Universal module is installed, am not a newcomer with Hololens since I develop since a year on it, and have a project to get ready for an incoming demo. Sounds like there are problems with last Unity version and the toolkit.\r\n\r\n@TinyTangS ty for your feedback, will help :)", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1724", "user": "Xispeo", "root": "ROOT172", "reply_to": "COM1723", "timestamp": "2017-08-24T09:12:04Z", "text": "Ok am sorted with Unity 5.6.3, HoloToolkit 1.5.8 and VS 2015.\r\nWill try to update when next iterations of both Unity and MixedRealityToolkit will get released since I don't have the time to betatest atm.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1725", "user": "SinSeitan", "root": "ROOT172", "reply_to": "COM1724", "timestamp": "2018-04-04T14:51:48Z", "text": "I just dont get why is allways so complicated to even do anything with the Hololens. Do you think they will thrive give all this errors and problems? Im just sickk of having to go through thousnads of tutorials, forums, chats, emails and so on every time Unity updates, or the HoloToolkit or the MRDL or visual studio... It is just SUPER UNSTABLE and a serious pain in the *** to do anything. I think Hololens will fail miserably due to all the constant difficulties.\r\nBTW I was compiling no problem this afternoon, until sudenly it started throwing errors ive never seen before. Hope Holelns V.2 never come out. Seriously.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1726", "user": "StephenHodgson", "root": "ROOT172", "reply_to": "COM1725", "timestamp": "2018-04-04T15:10:37Z", "text": "@SinSeitan I def understand how frustrated you are, but every new platform has its shares of issues and stability.  Yeah, there's been issues from the manufacturer, all the way through to the middle ware game engine, and even here in the community trying to solve the problems. (odd thing is that's what keeps me around \ud83d\ude05 ).\r\n\r\nPlease keep in mind this is a Gen1 device, that was never really intended to go beyond developers who wanted to play with it, and companies wanting to do a feasibility test.\r\n\r\n> The only way to grow and learn is to make mistakes, the important thing is that you learn from them.\r\n\r\nThis quote couldn't be any more true, especially when it comes to software. The nice thing is that it's a continuous process to grow and learn, and they only way you really know that it's happening is when you make mistakes.  I'm glad to see the software getting better (and it has!).  Microsoft, Unity, and even the Toolkit have come a long way in the last two years.\r\n\r\n> I'm just sick of having to go through thousands of tutorials, forums, chats, emails and so on.\r\n\r\nI agree it is a pain, but I think the difference here is that you haven't talked to me, or other engineers trying to make your life easier by fixing some of the problems. This is the first time I've heard from you, so **let's open a new issue and try to figure out what's going on**.  Remember to follow the [Code of Conduct](https://opensource.microsoft.com/codeofconduct/faq/).  I understand you're frustrated, but having a positive attitude, even when you're stressed out or frustrated speaks volumes to others who are genuinely trying to help.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT173", "user": "Yara-smurf", "root": "ROOT173", "reply_to": null, "timestamp": "2020-06-05T07:07:35Z", "text": "Replace the refinery with the \"ERCC\" refinery in the standard game ## Issue Summary\r As it has become the standard in RAGL and proven its value, it might be a good idea to replace it everywhere for better balancing.\r \r What is ERCC? \r ERCC provides more exits for harvesters (north exit) which makes harvesting from all sides more balanced. Furthermore, the outline of the refinery got changed to square to alleviate map-inconveniences. \r \r TODO: \r More detailed guide by widow about ERCC.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM1730", "user": "PunkPun", "root": "ROOT173", "reply_to": "ROOT173", "timestamp": "2020-06-05T11:27:22Z", "text": "It this has a footprint\r\n=+x\r\n+=+\r\nx==\r\n\r\nwhile the current one has this\r\n\\_X\\_\r\nxxx\r\nX==\r\n\\===\r\n\r\nit looks like\r\n![Screen Shot 2020-06-05 at 14 18 10](https://user-images.githubusercontent.com/37534529/83871007-ebd70a80-a737-11ea-9e09-6e61d8529322.png)\r\n\r\nwhile the OG looks like\r\n![Screen Shot 2020-06-05 at 14 24 34](https://user-images.githubusercontent.com/37534529/83871195-4f613800-a738-11ea-8ee9-de5d4111230b.png)\r\n\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1731", "user": "PunkPun", "root": "ROOT173", "reply_to": "COM1730", "timestamp": "2020-06-05T11:28:06Z", "text": "ERCC currently suffers from #18232", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1732", "user": "pchote", "root": "ROOT173", "reply_to": "COM1731", "timestamp": "2020-06-05T11:28:56Z", "text": "Please also include screenshots that show how the harvester clips through solid walls and the roof for a fair comparison.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1733", "user": "PunkPun", "root": "ROOT173", "reply_to": "COM1732", "timestamp": "2020-06-05T11:35:07Z", "text": "It works most of the time, but if you do these exact paths it clips\r\n\r\n![ERCC4](https://user-images.githubusercontent.com/37534529/83871616-08c00d80-a739-11ea-9668-d47c2d36851c.gif)\r\n![ERCC1](https://user-images.githubusercontent.com/37534529/83871625-0b226780-a739-11ea-8af6-99c820c4a31d.gif)\r\n![ERCC3](https://user-images.githubusercontent.com/37534529/83871628-0bbafe00-a739-11ea-9f66-a492a9b27f56.gif)\r\n![ERCC2](https://user-images.githubusercontent.com/37534529/83871630-0c539480-a739-11ea-853d-66bd42b7185b.gif)\r\n\r\nOne of the problems is that the harvester art is bigger than once cell\r\n![Harv](https://user-images.githubusercontent.com/37534529/83871836-75d3a300-a739-11ea-93f7-94b332bd69a0.png)\r\nthat also causes problems with the current ref\r\n![REF1](https://user-images.githubusercontent.com/37534529/83871862-88e67300-a739-11ea-9828-d546cd89e71d.png)\r\n![REF3](https://user-images.githubusercontent.com/37534529/83871884-94399e80-a739-11ea-9c23-dc0f8aef6a83.png)\r\nbut these don't exist with ERCC\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1734", "user": "netnazgul", "root": "ROOT173", "reply_to": "COM1733", "timestamp": "2020-06-05T11:43:10Z", "text": "> pchote: it would be much better if it used a new design that was not a space-warping bodge of the original refinery\r\n> pchote: get rid of the overhang completely\r\n> pchote: it is never going to be accepted as a replacement for the original refinery, but if you want to be added as a distinct thing that could be optionally enabled then it needs to make sense as its own thing", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1735", "user": "pchote", "root": "ROOT173", "reply_to": "COM1734", "timestamp": "2020-06-05T12:45:03Z", "text": "One thing that I find the most offensive about this extended trainwreck of a discussion is that it basically boils down to a few competitive players, who already have access to ERCC via map-mods, insisting that everybody else is playing the game wrong and should have the option to use the classic refineries taken away from them. This is not cool, IMO.", "meta": {"posReactions": "1", "negReactions": "0"}}
{"id": "COM1736", "user": "dragunoff", "root": "ROOT173", "reply_to": "COM1735", "timestamp": "2020-06-05T13:15:31Z", "text": "I can get behind what @pchote is saying. I think this already has a nice place in map-mods. And if ruleset-only mods are ever implemented then the ERCC (and other balance mods and tests) could be easily applied to any map.\r\n\r\nAnd even if the ERCC gets accepted to the core game then it should be optional and not the default. ", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1737", "user": "netnazgul", "root": "ROOT173", "reply_to": "COM1736", "timestamp": "2020-06-05T14:58:52Z", "text": "The mutator thing should be mentioned here if it is raised as an issue somewhere.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1738", "user": "abcdefg30", "root": "ROOT173", "reply_to": "COM1737", "timestamp": "2020-06-05T15:03:52Z", "text": "> The mutator thing should be mentioned here if it is raised as an issue somewhere.\r\n\r\n#13629 / #14325 / #9422", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1739", "user": "PunkPun", "root": "ROOT173", "reply_to": "COM1738", "timestamp": "2020-06-05T16:38:43Z", "text": "> One thing that I find the most offensive about this extended trainwreck of a discussion is that it basically boils down to a few competitive players, who already have access to ERCC via map-mods, insisting that everybody else is playing the game wrong and should have the option to use the classic refineries taken away from them. This is not cool, IMO.\r\n\r\nI understand that but it's missleading. Fact is that majority of above avarage skilled players prefer playing with ERCC refineries.  OpenRA supposted to improve gameplay of the originals, so players that who actually understand openra's gameplay are forced to play on a mod map doesn't give it a good look\r\n\r\nI'm not saying that ERCC has to be implemented in its current form, after all it was merelly an experiment to see if refineries could be fixed. I'm just saying that it's a very relevant issue that needs a solution", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM17310", "user": "PunkPun", "root": "ROOT173", "reply_to": "COM1739", "timestamp": "2020-06-05T16:43:42Z", "text": "Additionally the person responsible for ERCC is not interested in refining it further, so it falls on the shoulders of someone else", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM17311", "user": "Mailaender", "root": "ROOT173", "reply_to": "COM17310", "timestamp": "2020-06-05T20:12:12Z", "text": "This could also be solved using `PlaceBuildingVariants` and inverted artwork.", "meta": {"posReactions": "2", "negReactions": "0"}}
{"id": "COM17312", "user": "PunkPun", "root": "ROOT173", "reply_to": "COM17311", "timestamp": "2020-06-06T12:05:31Z", "text": ">  > ERCC currently suffers from #18232\r\n\r\n> I tested it and that problem doe snot (really) exist with ERCC @Punsho . The only thing I observed is that you have to click a bit \"below\" the husk which is probably due to the logical layout/overlay structure. But you can certainly recover husks from the ERCC refinery.\r\n\r\nThere's more than one place where a harvester can die, i had a game where 2 harvesters were dead on a refinery. I was able to revive one by the method you just mentioned, but the other was completelly unclickable. This is how this bug was discovered", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM17313", "user": "MlemandPurrs", "root": "ROOT173", "reply_to": "COM17312", "timestamp": "2020-06-06T20:09:44Z", "text": "This could be in the form of an tickbox at lobby, probably it would be default off.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM17314", "user": "deleted-user-1", "root": "ROOT173", "reply_to": "COM17313", "timestamp": "2020-06-07T09:23:25Z", "text": "> This could be in the form of an tickbox at lobby, probably it would be default off.\r\n\r\nThat's doesn't scale well. A dropdown to choose mutators from would be better.\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM17315", "user": "pchote", "root": "ROOT173", "reply_to": "COM17314", "timestamp": "2020-12-31T22:12:06Z", "text": "I am officially drawing a line under this request. ERCC will never be merged upstream while I remain involved with OpenRA. At this point it has nothing to do with any of the in-game aspects, it is entirely about the behaviour of the people championing it.\r\n\r\nWhile most of the competitive RA community are good people, there is a rotten core of toxic entitlement that manifests as abuse and belittlement, often focused around ERCC, and usually focused personally against me. This behaviour has forever soured ERCC, and integrating it into the upstream RA mod now would validate that behaviour as an effective strategy for influencing OpenRA's development.\r\n\r\nWhy now? Two recent incidents targeting me (from N/A in the community discord, and Longely/Widow in the competitive discord - the two main personalities behind ERCC) were incredibly offensive and belittling, and are the straw that has broken the camels back when added on top of many other generally toxic events this year. People in the competitive community were having fun meming about \"us vs the devs\" earlier this year, but at that time I was seriously considering quitting OpenRA completely due to how unhappy and embarrased the behaviour of some people in the community (and the general tolerance of that behaviour as acceptable by everybody else) was making me. Ultimately, I decided that I enjoy working on the project, and making things better for everybody else in the community. I *do not* enjoy interacting with the assholes, and intend to be increasingly blunt in dismissing their toxic behaviour. This is the first concrete action towards that.\r\n\r\nI can certainly appreciate the desire for solving directional map imbalance, to the point where I fully implemented the code for one solution (rotatable structures) and developed a working prototype for a second (allowing harvesters to dock from any direction, visually jumping docking point). I think there is scope for some ERCC alternative, but I suggest that the competitive community as a whole put some effort into solving its attitude problem before they try to revisit such ideas here.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT174", "user": "youfeed", "root": "ROOT174", "reply_to": null, "timestamp": "2020-09-14T17:32:05Z", "text": "Fuck Flutter Fuck you flutter, if macos adds PATH, it just won\u2019t join, go to hell, you\u2019re so ugly, Google is so big, will the script be configured to die?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1740", "user": "Abhishek01039", "root": "ROOT174", "reply_to": "ROOT174", "timestamp": "2020-09-14T17:51:47Z", "text": "Hey @youfeed \r\ncan you please provide the details of what problem you are facing?\r\nplease send your `flutter run -v` and `flutter doctor -v` and minimal reproduction code?\r\nThanks\r\n\r\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1741", "user": "Abhishek01039", "root": "ROOT174", "reply_to": "COM1740", "timestamp": "2020-09-14T17:55:11Z", "text": "Flutter team is doing the great\r\nFlutter is one of the most popular frameworks for making apps nowadays.\r\nFlutter is so good and Thanks to the Flutter team for making the awesome framework.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1742", "user": "cbracken", "root": "ROOT174", "reply_to": "COM1741", "timestamp": "2020-09-14T18:07:31Z", "text": "Hi @youfeed, I'd remind you that we require that all participants on our issue tracker and mailing lists abide by our [code of conduct](https://github.com/flutter/flutter/blob/master/CODE_OF_CONDUCT.md).\r\n\r\nIt sounds like you've run into an issue with handling of `$PATH` on macOS, but it looks like you may have submitted this issue before filling out the issue template. If you're running into a reproducible issue I'd ask that you file a [new issue](https://github.com/flutter/flutter/issues/new/choose) and fill out the template with a clear statement of the issue you're running into and repro steps.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "ROOT175", "user": "zerocarbthirty", "root": "ROOT175", "reply_to": null, "timestamp": "2021-03-07T04:41:41Z", "text": "Microsoft Safety Scanner shows different results than Test-ProxyLogon.ps1  **Describe the issue**\r I ran Test-ProxyLogon.ps1 it showed that my machine was impacted by the 0day CVEs.\r I ran MSERT and it reported nothing on a full scan.\r **Expected behavior**\r \r I would expect that both of them would show IOCs or neither of them would show IOCs.\r \r How is anyone supposed to know what is going on if two tools from the same company gives two different results?", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1750", "user": "bill-long", "root": "ROOT175", "reply_to": "ROOT175", "timestamp": "2021-03-07T04:51:06Z", "text": "Test-ProxyLogon.ps1 and MSERT scan for two different things. They are not expected to show the same results. Please refer to the blog post for details.", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1751", "user": "zerocarbthirty", "root": "ROOT175", "reply_to": "COM1750", "timestamp": "2021-03-07T05:14:25Z", "text": "Quote the blog post to me one more time.\n\nOn Sat, Mar 6, 2021, 11:51 PM Bill Long <notifications@github.com> wrote:\n\n> Closed #109 <https://github.com/microsoft/CSS-Exchange/issues/109>.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/microsoft/CSS-Exchange/issues/109#event-4417645174>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AD7FNQTM4RXUTTGGOOOQO5TTCMA4LANCNFSM4YXOOVPQ>\n> .\n>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
{"id": "COM1752", "user": "zerocarbthirty", "root": "ROOT175", "reply_to": "COM1751", "timestamp": "2021-03-07T05:28:19Z", "text": "I honestly cannot believe how casual and dismissive you guys at MS are.\nLose more games than the Jets and act like you are a team full of Tom\nBradys. The hubris. I understand it must really difficult to do your job as\na $1.75T company but can you try?\n\nMake some sort of effort. Please? Anything?\n\nOn Sun, Mar 7, 2021, 12:14 AM Drew <zerocarbthirty@gmail.com> wrote:\n\n> Quote the blog post to me one more time.\n>\n> On Sat, Mar 6, 2021, 11:51 PM Bill Long <notifications@github.com> wrote:\n>\n>> Closed #109 <https://github.com/microsoft/CSS-Exchange/issues/109>.\n>>\n>> \u2014\n>> You are receiving this because you authored the thread.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/microsoft/CSS-Exchange/issues/109#event-4417645174>,\n>> or unsubscribe\n>> <https://github.com/notifications/unsubscribe-auth/AD7FNQTM4RXUTTGGOOOQO5TTCMA4LANCNFSM4YXOOVPQ>\n>> .\n>>\n>\n", "meta": {"posReactions": "0", "negReactions": "0"}}
