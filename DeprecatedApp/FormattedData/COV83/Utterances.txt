ROOT +++$+++ SP3934326 +++$+++ ROOT +++$+++ ROOT +++$+++ 2021-05-07T19:17:06Z +++$+++ Indicator of module progress As a user, I constantly return to the module level (multiple courses) to see how far I have progressed in relation to the entire module. It would be nice if I didn't have to go back to this view and scroll up and down it to get an indication of how much I have left.

For me, I think a feature like this would keep me more engaged and therefore reduce the likelihood of me not finishing a module.

**Describe the solution you'd like**
![image](https://user-images.githubusercontent.com/3934326/117497796-c9dc9e00-af2d-11eb-9baf-7097a372b657.png)

**Describe alternatives you've considered**
I think there are many ways this could be done, here a few I could think of:
- Percentage of completion
- Ratio
- Approximation of remaining time. Given FCC has data on average time to completion on each challenge. _Just curious, where does the 300hr estimation come from?_

**Additional context**
There is some useful discussion that has already happened on the FCC forum [here](https://forum.freecodecamp.org/t/new-feature-indicator-of-module-level-progress/459290).

I think it's fair to say that this is a simple feature to experiment with. If users say it's helpful, and it increases engagement, I say keep it. If not, then toss it. I remember being surprised it wasn't included when I first started though. +++$+++ 0 +++$+++ 0
COM0 +++$+++ SP25011573 +++$+++ ROOT +++$+++ ROOT +++$+++ 2021-05-07T19:30:37Z +++$+++ See additional discussion here: https://forum.freecodecamp.org/t/new-feature-indicator-of-module-level-progress/459290

Personally, given the wide range of difficulty between challenges, I think this would be a bad statistic that makes it easy for users to infer incorrect information about their progress, as percent of challenges completed in a certification module is not related to amount of effort or time remaining in such a simple manner.

This would especially be a bad piece of information to display next to the *very* rough estimate of 300 hours, and it would be worse to 'estimate' the time remaining for a user. The variance in time to competition between users is already pretty high and we already have to tell a decent number of users that its ok if they go 'too fast' or 'too slow' wrt the 300 hours.

It is really tempting to provide numbers because of the assumption that more numbers = more information = more better. But aggregating data that is too dissimilar is a common statistical sin that we shouldn't be showing our users.

Also, I think this would add clutter to the simpler UX. +++$+++ 0 +++$+++ 0
COM1 +++$+++ SP3934326 +++$+++ ROOT +++$+++ COM0 +++$+++ 2021-05-07T19:40:44Z +++$+++ Luckily, this is software, it's always changing. If we try it, and it doesn't work, atleast then we have data to re-inforce that the feature doesn't improve the app. +++$+++ 0 +++$+++ 0
COM2 +++$+++ SP25011573 +++$+++ ROOT +++$+++ COM1 +++$+++ 2021-05-07T19:44:43Z +++$+++ "Because we can undo it" is not a good reason to present bad statistics. Data should not only be technically accurate, but meaningful and not lead readers to incorrect assumptions. fCC should strive to follow sound statistical principals and not teach bad habits by example.

I think we understand each other's opinions on the matter. Let's let others chime in. +++$+++ 0 +++$+++ 0
COM3 +++$+++ SP3934326 +++$+++ ROOT +++$+++ COM2 +++$+++ 2021-05-07T19:49:05Z +++$+++ 52/130 (40%) is not inacurrate. That is 100% accurate as _a gauge of percentage of challenges completed_. 

Maybe it's important to clarify that this feature is not an estimate of time remaining, but simply progress through a module. +++$+++ 0 +++$+++ 0
COM4 +++$+++ SP25011573 +++$+++ ROOT +++$+++ COM3 +++$+++ 2021-05-07T19:55:52Z +++$+++ All the percentage or ratio reveals is the percent/ratio of challenges completed. As I said, the data is *technically accurate* but not *meaningful* and *may lead readers to incorrect assumptions*.

The percent of challenges completed is, at best, only roughly correlated with the total time remaining for the user. Given the wide range of learning styles, processes, challenge difficulty, etc, this statistic provides zero *actionable information* to the user. It is just clutter, and possibly demotivating clutter to users that do not understand the limited and misleading statistic we'd be putting on the front page.

Reporting statistics that distill information and strip contextual factors is a statistical bad practice, and we should not show statistical bad practices. +++$+++ 0 +++$+++ 0
COM5 +++$+++ SP53656529 +++$+++ ROOT +++$+++ COM4 +++$+++ 2021-05-07T20:01:49Z +++$+++ I'm not super passionate about it but I agree that this would be a useful feature, as long as it's in the format "number_completed/number_total". It'll be obvious to everyone who goes through the curriculum that the difficulty and the time you need to invest into a challenge increases. Just like it's obvious to everyone who's ever played a video game that the boss level won't be as easy as level 1-10.  +++$+++ 1 +++$+++ 0
COM6 +++$+++ SP3934326 +++$+++ ROOT +++$+++ COM5 +++$+++ 2021-05-07T20:04:25Z +++$+++ To be fair, @jeremylt, the 300hrs estimate was quite demotivating for me when I started. +++$+++ 0 +++$+++ 0
COM7 +++$+++ SP25011573 +++$+++ ROOT +++$+++ COM6 +++$+++ 2021-05-07T20:06:50Z +++$+++ Adding UX clutter should have a purpose. What is the *actionable information* this would give the user? Why is it worth adding the clutter? Reported statistics must help the recipient make better decisions. That's the purpose of statistics. If we 'all know' (bad assumption) this statistic is not useful, then why add it? +++$+++ 0 +++$+++ 0
COM8 +++$+++ SP3934326 +++$+++ ROOT +++$+++ COM7 +++$+++ 2021-05-07T20:08:18Z +++$+++ @jeremylt, @jsdisco just said "I agree that this would be a useful feature" +++$+++ 0 +++$+++ 0
COM9 +++$+++ SP1884376 +++$+++ ROOT +++$+++ COM8 +++$+++ 2021-05-07T20:09:25Z +++$+++ Hi @jeremylt 

Thanks for your candid and honest feedback. We have been thinking about this and in fact we are not against the idea considering it does exist in a form here:

![image](https://user-images.githubusercontent.com/1884376/117502529-42c70e80-af9d-11eb-916a-cc5cbcf3ca12.png)

One of the ways, that users of the curriculum keep coming back is gamification. Does it keep users motivated? Yes - The #100DaysOfCode challenge is one of those initiatives. 

I am 100% in agreement with you that we can never design a program that will give exact report of where a learner stands in terms of knowledge gained. An 80% completion does not mean a user has 80% mastery on the topic. 

@jknapp25 @jeremylt 

Let's keep this thread constructive towards an actual implementation. You should continue to deliberate on the forum thread for pros-cons. Deliberation is a good thing to vet out a feature.

Meanwhile let me check with the team and get back to you, after discussing this more objectively.

Thanks for your patience and comments everyone. +++$+++ 1 +++$+++ 0
COM10 +++$+++ SP25011573 +++$+++ ROOT +++$+++ COM9 +++$+++ 2021-05-07T20:17:27Z +++$+++ I am fine with the fact that we have progress bars for each course. The variance in task difficulty is closer in the individual courses than it is across the entire module, so the statistic is not as bad as an aggregation across all courses in a module. The user can gain actionable information from the percentage of challenges completed in a course - specifically, a reasonable estimate of the time and effort required to complete the course.

A challenge from Basic JavaScript and one from Intermediate Algorithm Scripting are not remotely comparable. Mixing disparate objects and obscuring differences is bad statistics, and we shouldn't show bad statistics. The user cannot derive actionable information from this statistic.

I understand that the *feature* feels useful, but we all seem to be in agreement that the *statistic* is meaningless. I'm trying to use specific words with intentionality to be clear. Please ask for clarification as needed. I really am reading and responding to what others write here. +++$+++ 0 +++$+++ 0
COM11 +++$+++ SP1884376 +++$+++ ROOT +++$+++ COM10 +++$+++ 2021-05-07T20:24:56Z +++$+++ I understand the goal should be able to make the UX more actionable, and like I said:

> Let's keep this thread constructive towards an actual implementation.

We are not inclined in anyway right now.

That could either be proceed with some form of the proposal by the OP or an objective rejection. I would urge to continue the deliberation on the forum thread instead. 

Thanks for your understanding. +++$+++ 0 +++$+++ 0
COM12 +++$+++ SP3934326 +++$+++ ROOT +++$+++ COM11 +++$+++ 2021-05-07T20:26:24Z +++$+++ Thank you all for taking time out of your day to discuss this. Especially, @jeremylt. This _has_ been pretty constructive in my opinion. 

Maybe it would be helpful to step back and discuss the role that metrics play within the app, because I don't necessarily agree that a ratio of completed modules is meaningless.

As a user, from the start I'm assuming variance of time-to-completion within challenges. But maybe the value in a metric like this is that it simply re-inforces that progress is being made. Re-orienting the learner in a way. And maybe, like video games, it's safe to assume users are expecting challenges to get harder or take longer as they go?

Anyways, I'll let the pro's take it from here ðŸ˜Š +++$+++ 0 +++$+++ 0
COM13 +++$+++ SP3934326 +++$+++ ROOT +++$+++ COM12 +++$+++ 2021-05-07T20:42:04Z +++$+++ I think @jeremylt has made good points! It feels like we're at a bit of a stalemate though. 

From experience, when stalemates like this are reached on an idea, the "[Fail fast](https://innolution.com/resources/glossary/fail-fast)" approach can provide value. By trying something, then, at least we can say with greater confidence (and data) if it provided value or not. +++$+++ 0 +++$+++ 0
COM14 +++$+++ SP51722130 +++$+++ ROOT +++$+++ COM13 +++$+++ 2021-05-07T20:51:12Z +++$+++ @jknapp25 Thank you, for opening this feature request. We have spent a lot of time going back-and-forth between ideas. One of the main discussions occurred here: https://github.com/freeCodeCamp/freeCodeCamp/pull/39265

Ultimately, the decision was:
> It looks cool, but there are a few things that prevent visual representation from working well here:

>For each certification, the lessons only constitute about 16% of the cert. The other 84% is the certification projects. This means that on the first certification, a camper could make it through a hundred or more lessons and only be 5 or 6% of the way done with the certification. So all they would see would be a tiny slice of the pie for their first 50 hours of coding.

>This is why I recommended using the (300 hours - 1.03% complete) text. Because we really need that level of granularity in the numbers. Otherwise progress would be virtually invisible from one coding session to the next.

>Also, people may wonder "what is this thing over on the right hand margin"? The "X.XX% complete" text is unambiguous.

>Thus, if you want to implement a text-based version of this, we would be very interested in this.


---

So, there is still scope to implement such a feature, but keeping in mind the discussion had in this issue, and the linked PR.

We welcome PoCs (proof of concepts) - as you have done, or more; visual communication is appreciated. However, it is in your and our best interest to read through the current/past discussion so as to not end up spending hours on something which ultimately might not be used.

Hope this adds to the discussion. +++$+++ 0 +++$+++ 0
COM15 +++$+++ SP53656529 +++$+++ ROOT +++$+++ COM14 +++$+++ 2021-05-07T20:57:30Z +++$+++ The estimate of "300 hours" is already very nebulous statistics, so I see little harm in adding much more descriptive information that only shows the number of challenges completed vs. total challenges.

I'm thumbs up for the feature because it saves the user the effort of having to click on each section to get that information.  +++$+++ 0 +++$+++ 0
COM16 +++$+++ SP63889819 +++$+++ ROOT +++$+++ COM15 +++$+++ 2021-05-07T20:58:02Z +++$+++ > Luckily, this is software, it's always changing. If we try it, and it doesn't work, atleast then we have data to re-inforce that the feature doesn't improve the app.

The one thing I really want to touch on is that freeCodeCamp operates on a budget of limited funds from our generous donors. As such, our approach does not allow for a "try it and see if it works" mindset - every feature we implement needs to be deliberate, planned, and well thought out to avoid sinking our finite development resources into something that does not pan out. +++$+++ 0 +++$+++ 0
COM17 +++$+++ SP1884376 +++$+++ ROOT +++$+++ COM16 +++$+++ 2021-05-07T21:03:09Z +++$+++ Hi everyone, 

I am going ahead and closing this thread for now. Please continue on the forum here: https://forum.freecodecamp.org/t/new-feature-indicator-of-module-level-progress/459290/12

The staff and the contributors are very much active on the forum and will be happy to answer open-ended queries there. 

We really want to limit the GitHub tracker for dev work. Please do not take this  as a rejection or endorsement of anything.

Thanks for your understanding again. +++$+++ 0 +++$+++ 0
